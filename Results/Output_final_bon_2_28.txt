2020-09-15 15:49:42.011511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.236908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.353741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.353837: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.355913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.357567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.358384: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.360365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.361768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.361973: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.361994: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.362336: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.370289: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599955000 Hz
2020-09-15 15:49:45.370491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db840df7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.370522: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.372572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.372610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18141435842634385
Epoch: 0 Idx: 5000 Loss: 0.007354600043909261
Epoch: 1 Idx: 0 Loss: 0.026626320915824377
Epoch: 1 Idx: 5000 Loss: 0.007754973080655778
Epoch: 2 Idx: 0 Loss: 0.013143593122912361
Epoch: 2 Idx: 5000 Loss: 0.018503661919554562
Epoch: 3 Idx: 0 Loss: 0.01147464296624943
Epoch: 3 Idx: 5000 Loss: 0.010025985032970194
Epoch: 4 Idx: 0 Loss: 0.019185159104009843
Epoch: 4 Idx: 5000 Loss: 0.006804558083438611
Epoch: 5 Idx: 0 Loss: 0.020581184447085357
Epoch: 5 Idx: 5000 Loss: 0.01745835209373497
Epoch: 6 Idx: 0 Loss: 0.011804366443598622
Epoch: 6 Idx: 5000 Loss: 0.008432538969263218
Epoch: 7 Idx: 0 Loss: 0.00730640889237043
Epoch: 7 Idx: 5000 Loss: 0.017142062181330762
Epoch: 8 Idx: 0 Loss: 0.021900558240204086
Epoch: 8 Idx: 5000 Loss: 0.01755363842649868
Epoch: 9 Idx: 0 Loss: 0.011893980120125942
Epoch: 9 Idx: 5000 Loss: 0.007783292355274907
Epoch: 10 Idx: 0 Loss: 0.024913975966888463
Epoch: 10 Idx: 5000 Loss: 0.05469341911150444
Epoch: 11 Idx: 0 Loss: 0.056779365801005705
Epoch: 11 Idx: 5000 Loss: 0.015547000437396284
Epoch: 12 Idx: 0 Loss: 0.0067583240330183715
Epoch: 12 Idx: 5000 Loss: 0.025207870814020046
Epoch: 13 Idx: 0 Loss: 0.00591692767783354
Epoch: 13 Idx: 5000 Loss: 0.009684823223769951
Epoch: 14 Idx: 0 Loss: 0.015275879993411881
Epoch: 14 Idx: 5000 Loss: 0.00843071903989858
Epoch: 15 Idx: 0 Loss: 0.02843675401773931
Epoch: 15 Idx: 5000 Loss: 0.019374416146266227
Epoch: 16 Idx: 0 Loss: 0.013717385480325946
Epoch: 16 Idx: 5000 Loss: 0.017139639146465428
Epoch: 17 Idx: 0 Loss: 0.012623050521354613
Epoch: 17 Idx: 5000 Loss: 0.010105050393225614
Epoch: 18 Idx: 0 Loss: 0.012577823815856388
Epoch: 18 Idx: 5000 Loss: 0.029350658115816365
Epoch: 19 Idx: 0 Loss: 0.007339198980417601
Epoch: 19 Idx: 5000 Loss: 0.015611395304668398
Epoch: 20 Idx: 0 Loss: 0.013854907550604159
Epoch: 20 Idx: 5000 Loss: 0.007022333837662464
Epoch: 21 Idx: 0 Loss: 0.020852520823283406
Epoch: 21 Idx: 5000 Loss: 0.01322604543235312
Epoch: 22 Idx: 0 Loss: 0.03221661288967647
Epoch: 22 Idx: 5000 Loss: 0.017409734292206006
Epoch: 23 Idx: 0 Loss: 0.024278392920710986
Epoch: 23 Idx: 5000 Loss: 0.028707099367784192
Epoch: 24 Idx: 0 Loss: 0.011752316904471143
Epoch: 24 Idx: 5000 Loss: 0.012419356305204078
Epoch: 25 Idx: 0 Loss: 0.011559089634749966
Epoch: 25 Idx: 5000 Loss: 0.01241866034056531
Epoch: 26 Idx: 0 Loss: 0.02519775633365712
Epoch: 26 Idx: 5000 Loss: 0.013541083574715247
Epoch: 27 Idx: 0 Loss: 0.03462870060092815
Epoch: 27 Idx: 5000 Loss: 0.009159225388389862
Epoch: 28 Idx: 0 Loss: 0.010283344742811779
Epoch: 28 Idx: 5000 Loss: 0.024422707130080365
Epoch: 29 Idx: 0 Loss: 0.015442215800572853
Epoch: 29 Idx: 5000 Loss: 0.00687501076136271
Epoch: 30 Idx: 0 Loss: 0.018543386492805097
Epoch: 30 Idx: 5000 Loss: 0.0040881036724497955
Epoch: 31 Idx: 0 Loss: 0.017875558018436533
Epoch: 31 Idx: 5000 Loss: 0.009225965372808542
Epoch: 32 Idx: 0 Loss: 0.022936864331582305
Epoch: 32 Idx: 5000 Loss: 0.011014235948951876
Epoch: 33 Idx: 0 Loss: 0.011497288324268473
Epoch: 33 Idx: 5000 Loss: 0.011458480395476174
Epoch: 34 Idx: 0 Loss: 0.03415253632198972
Epoch: 34 Idx: 5000 Loss: 0.01843358221568911
Epoch: 35 Idx: 0 Loss: 0.01798680317292664
Epoch: 35 Idx: 5000 Loss: 0.010037945492867389
Epoch: 36 Idx: 0 Loss: 0.03723613617086237
Epoch: 36 Idx: 5000 Loss: 0.014537182755741087
Epoch: 37 Idx: 0 Loss: 0.009388672498238042
Epoch: 37 Idx: 5000 Loss: 0.011930798538104602
Epoch: 38 Idx: 0 Loss: 0.020212218999486206
Epoch: 38 Idx: 5000 Loss: 0.04008388873678136
Epoch: 39 Idx: 0 Loss: 0.013562366846877158
Epoch: 39 Idx: 5000 Loss: 0.00956105227033747
Epoch: 40 Idx: 0 Loss: 0.018171243728446744
Epoch: 40 Idx: 5000 Loss: 0.01877588699145472
Epoch: 41 Idx: 0 Loss: 0.014929988554375936
Epoch: 41 Idx: 5000 Loss: 0.01744991572454345
Epoch: 42 Idx: 0 Loss: 0.010897123879258213
Epoch: 42 Idx: 5000 Loss: 0.007249184370316256
Epoch: 43 Idx: 0 Loss: 0.011546060756139929
Epoch: 43 Idx: 5000 Loss: 0.015936620935350757
Epoch: 44 Idx: 0 Loss: 0.016490696476581395
Epoch: 44 Idx: 5000 Loss: 0.023280078905230366
Epoch: 45 Idx: 0 Loss: 0.010487860094406666
Epoch: 45 Idx: 5000 Loss: 0.018837262607831914
Epoch: 46 Idx: 0 Loss: 0.010854768062071292
Epoch: 46 Idx: 5000 Loss: 0.011663094051570434
Epoch: 47 Idx: 0 Loss: 0.013344262740748881
Epoch: 47 Idx: 5000 Loss: 0.01678547322468152
Epoch: 48 Idx: 0 Loss: 0.013229873839014313
Epoch: 48 Idx: 5000 Loss: 0.025829908071654233
Epoch: 49 Idx: 0 Loss: 0.01602575555209585
Epoch: 49 Idx: 5000 Loss: 0.014140471037643694
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1480120746374164
Epoch: 0 Idx: 5000 Loss: 0.024584552451223866
Epoch: 1 Idx: 0 Loss: 0.015210239699538039
Epoch: 1 Idx: 5000 Loss: 0.030847256882066902
Epoch: 2 Idx: 0 Loss: 0.020232469264442877
Epoch: 2 Idx: 5000 Loss: 0.009305665549297447
Epoch: 3 Idx: 0 Loss: 0.01649740179354359
Epoch: 3 Idx: 5000 Loss: 0.011698599908217502
Epoch: 4 Idx: 0 Loss: 0.031619070169047
Epoch: 4 Idx: 5000 Loss: 0.021425946583809575
Epoch: 5 Idx: 0 Loss: 0.02584023894231853
Epoch: 5 Idx: 5000 Loss: 0.021696421868711895
Epoch: 6 Idx: 0 Loss: 0.024685362961727256
Epoch: 6 Idx: 5000 Loss: 0.020674657170754604
Epoch: 7 Idx: 0 Loss: 0.009428860827650378
Epoch: 7 Idx: 5000 Loss: 0.032737344717441504
Epoch: 8 Idx: 0 Loss: 0.01789819768080634
Epoch: 8 Idx: 5000 Loss: 0.012257476890597307
Epoch: 9 Idx: 0 Loss: 0.011379260965589708
Epoch: 9 Idx: 5000 Loss: 0.017490842888898087
Epoch: 10 Idx: 0 Loss: 0.00865629105330968
Epoch: 10 Idx: 5000 Loss: 0.015732425302355822
Epoch: 11 Idx: 0 Loss: 0.02889334631843771
Epoch: 11 Idx: 5000 Loss: 0.007443948510012741
Epoch: 12 Idx: 0 Loss: 0.011244376471612407
Epoch: 12 Idx: 5000 Loss: 0.015917503317196744
Epoch: 13 Idx: 0 Loss: 0.016266669223924005
Epoch: 13 Idx: 5000 Loss: 0.014784359845741434
Epoch: 14 Idx: 0 Loss: 0.023477310020322543
Epoch: 14 Idx: 5000 Loss: 0.010729271406590099
Epoch: 15 Idx: 0 Loss: 0.025012581607364717
Epoch: 15 Idx: 5000 Loss: 0.021086015546403748
Epoch: 16 Idx: 0 Loss: 0.01558406897777513
Epoch: 16 Idx: 5000 Loss: 0.020220876475790527
Epoch: 17 Idx: 0 Loss: 0.01666412979808489
Epoch: 17 Idx: 5000 Loss: 0.01398162571503704
Epoch: 18 Idx: 0 Loss: 0.00653334181531909
Epoch: 18 Idx: 5000 Loss: 0.007276066640980737
Epoch: 19 Idx: 0 Loss: 0.018501645184539086
Epoch: 19 Idx: 5000 Loss: 0.03320826361927766
Epoch: 20 Idx: 0 Loss: 0.00857751194191337
Epoch: 20 Idx: 5000 Loss: 0.014070603644739629
Epoch: 21 Idx: 0 Loss: 0.00831610080760991
Epoch: 21 Idx: 5000 Loss: 0.013729925883755162
Epoch: 22 Idx: 0 Loss: 0.010197037068878933
Epoch: 22 Idx: 5000 Loss: 0.01574810871245854
Epoch: 23 Idx: 0 Loss: 0.011856840152809836
Epoch: 23 Idx: 5000 Loss: 0.005655368272077693
Epoch: 24 Idx: 0 Loss: 0.010579023935136713
Epoch: 24 Idx: 5000 Loss: 0.010371163120384674
Epoch: 25 Idx: 0 Loss: 0.012209402779257061
Epoch: 25 Idx: 5000 Loss: 0.013057034232959893
Epoch: 26 Idx: 0 Loss: 0.012068750230102572
Epoch: 26 Idx: 5000 Loss: 0.011955980106930313
Epoch: 27 Idx: 0 Loss: 0.01801536935139484
Epoch: 27 Idx: 5000 Loss: 0.007164490286446832
Epoch: 28 Idx: 0 Loss: 0.02243966575781825
Epoch: 28 Idx: 5000 Loss: 0.007890024137567047
Epoch: 29 Idx: 0 Loss: 0.011307182612998085
Epoch: 29 Idx: 5000 Loss: 0.017060022386405742
Epoch: 30 Idx: 0 Loss: 0.010614865308845967
Epoch: 30 Idx: 5000 Loss: 0.009539350925227001
Epoch: 31 Idx: 0 Loss: 0.022102176775084664
Epoch: 31 Idx: 5000 Loss: 0.017413306873579726
Epoch: 32 Idx: 0 Loss: 0.011558069904290362
Epoch: 32 Idx: 5000 Loss: 0.027341826152521488
Epoch: 33 Idx: 0 Loss: 0.022381417799498926
Epoch: 33 Idx: 5000 Loss: 0.012649639977272944
Epoch: 34 Idx: 0 Loss: 0.010213184114486658
Epoch: 34 Idx: 5000 Loss: 0.01631661947943548
Epoch: 35 Idx: 0 Loss: 0.00732156105199608
Epoch: 35 Idx: 5000 Loss: 0.013239300998030792
Epoch: 36 Idx: 0 Loss: 0.010985443894017722
Epoch: 36 Idx: 5000 Loss: 0.010649392322328631
Epoch: 37 Idx: 0 Loss: 0.01215449050461304
Epoch: 37 Idx: 5000 Loss: 0.016586133777755217
Epoch: 38 Idx: 0 Loss: 0.029164588092137306
Epoch: 38 Idx: 5000 Loss: 0.01230531415883443
Epoch: 39 Idx: 0 Loss: 0.0155437726482025
Epoch: 39 Idx: 5000 Loss: 0.018794722284545175
Epoch: 40 Idx: 0 Loss: 0.010723429479870688
Epoch: 40 Idx: 5000 Loss: 0.013052114821039316
Epoch: 41 Idx: 0 Loss: 0.010847731353651767
Epoch: 41 Idx: 5000 Loss: 0.015793159243991446
Epoch: 42 Idx: 0 Loss: 0.010690624742998282
Epoch: 42 Idx: 5000 Loss: 0.041324664653067174
Epoch: 43 Idx: 0 Loss: 0.015406997834150286
Epoch: 43 Idx: 5000 Loss: 0.006165661901307492
Epoch: 44 Idx: 0 Loss: 0.01344360032929748
Epoch: 44 Idx: 5000 Loss: 0.024035401415363963
Epoch: 45 Idx: 0 Loss: 0.011595035314515981
Epoch: 45 Idx: 5000 Loss: 0.01224726730926426
Epoch: 46 Idx: 0 Loss: 0.03483098490079165
Epoch: 46 Idx: 5000 Loss: 0.0194019252424898
Epoch: 47 Idx: 0 Loss: 0.007533946759000451
Epoch: 47 Idx: 5000 Loss: 0.012302339752066967
Epoch: 48 Idx: 0 Loss: 0.018249315806891365
Epoch: 48 Idx: 5000 Loss: 0.012768221316964187
Epoch: 49 Idx: 0 Loss: 0.013603164765927496
Epoch: 49 Idx: 5000 Loss: 0.034672244093013026
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.11425348860719595
Epoch: 0 Idx: 5000 Loss: 0.01524490200258636
Epoch: 1 Idx: 0 Loss: 0.009973641435109332
Epoch: 1 Idx: 5000 Loss: 0.026559627130996494
Epoch: 2 Idx: 0 Loss: 0.009783013569836511
Epoch: 2 Idx: 5000 Loss: 0.014517190310707582
Epoch: 3 Idx: 0 Loss: 0.008335928010014832
Epoch: 3 Idx: 5000 Loss: 0.01715027466995432
Epoch: 4 Idx: 0 Loss: 0.02408106081334906
Epoch: 4 Idx: 5000 Loss: 0.0201870770256395
Epoch: 5 Idx: 0 Loss: 0.010559820746534328
Epoch: 5 Idx: 5000 Loss: 0.016417972694380445
Epoch: 6 Idx: 0 Loss: 0.008827195432800002
Epoch: 6 Idx: 5000 Loss: 0.015605735155458128
Epoch: 7 Idx: 0 Loss: 0.025849627048254418
Traceback (most recent call last):
  File "main.py", line 513, in <module>
    optimizer.zero_grad()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/optimizer.py", line 172, in zero_grad
    p.grad.zero_()
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc229>
Subject: Job 4066913: <python main.py 28 2 True False> in cluster <dcc> Exited

Job <python main.py 28 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc229>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 28 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   89574.14 sec.
    Max Memory :                                 2888 MB
    Average Memory :                             2693.27 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40529.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                17
    Run time :                                   46138 sec.
    Turnaround time :                            46197 sec.

The output (if any) is above this job summary.

