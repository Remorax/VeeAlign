2020-09-15 15:49:41.874919: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.020018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.140695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.140786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.142960: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.144559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.145534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.147498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.148981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.149303: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.149328: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.149666: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.158019: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600275000 Hz
2020-09-15 15:49:45.158234: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dd866f13d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.158257: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.160270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.160316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.21506018556315548
Epoch: 0 Idx: 5000 Loss: 0.012400159865430235
Epoch: 1 Idx: 0 Loss: 0.02798620788526572
Epoch: 1 Idx: 5000 Loss: 0.022213915356955258
Epoch: 2 Idx: 0 Loss: 0.00891917985038497
Epoch: 2 Idx: 5000 Loss: 0.015806542264286766
Epoch: 3 Idx: 0 Loss: 0.025914970755336962
Epoch: 3 Idx: 5000 Loss: 0.03341949510213268
Epoch: 4 Idx: 0 Loss: 0.007458497572500831
Epoch: 4 Idx: 5000 Loss: 0.012564306878164391
Epoch: 5 Idx: 0 Loss: 0.013032296018989909
Epoch: 5 Idx: 5000 Loss: 0.009856322290866047
Epoch: 6 Idx: 0 Loss: 0.007567107962416698
Epoch: 6 Idx: 5000 Loss: 0.00977811175516875
Epoch: 7 Idx: 0 Loss: 0.03095409520538249
Epoch: 7 Idx: 5000 Loss: 0.012250042405641736
Epoch: 8 Idx: 0 Loss: 0.005060028160464821
Epoch: 8 Idx: 5000 Loss: 0.009312745925634903
Epoch: 9 Idx: 0 Loss: 0.01756875266609259
Epoch: 9 Idx: 5000 Loss: 0.014270895395175351
Epoch: 10 Idx: 0 Loss: 0.0053956358272398315
Epoch: 10 Idx: 5000 Loss: 0.020448855255035196
Epoch: 11 Idx: 0 Loss: 0.01960008985737799
Epoch: 11 Idx: 5000 Loss: 0.02505051756198956
Epoch: 12 Idx: 0 Loss: 0.0063848976998119224
Epoch: 12 Idx: 5000 Loss: 0.012061003199327548
Epoch: 13 Idx: 0 Loss: 0.026333975296473675
Epoch: 13 Idx: 5000 Loss: 0.009107251759764023
Epoch: 14 Idx: 0 Loss: 0.007402765816982534
Epoch: 14 Idx: 5000 Loss: 0.00991557234894732
Epoch: 15 Idx: 0 Loss: 0.011764722557200277
Epoch: 15 Idx: 5000 Loss: 0.013947824634315755
Epoch: 16 Idx: 0 Loss: 0.00755391144401951
Epoch: 16 Idx: 5000 Loss: 0.006240711081180513
Epoch: 17 Idx: 0 Loss: 0.0188827875929962
Epoch: 17 Idx: 5000 Loss: 0.007424679515744829
Epoch: 18 Idx: 0 Loss: 0.009922239002860855
Epoch: 18 Idx: 5000 Loss: 0.011047949246292247
Epoch: 19 Idx: 0 Loss: 0.007672672604033173
Epoch: 19 Idx: 5000 Loss: 0.021215309475323574
Epoch: 20 Idx: 0 Loss: 0.005828082684956456
Epoch: 20 Idx: 5000 Loss: 0.021435697330310435
Epoch: 21 Idx: 0 Loss: 0.022125677368481964
Epoch: 21 Idx: 5000 Loss: 0.009109832174168489
Epoch: 22 Idx: 0 Loss: 0.00919013204712011
Epoch: 22 Idx: 5000 Loss: 0.019932745783198078
Epoch: 23 Idx: 0 Loss: 0.011325004172576314
Epoch: 23 Idx: 5000 Loss: 0.012368635791204202
Epoch: 24 Idx: 0 Loss: 0.013555347595360737
Epoch: 24 Idx: 5000 Loss: 0.010118553052093138
Epoch: 25 Idx: 0 Loss: 0.011048700767649404
Epoch: 25 Idx: 5000 Loss: 0.01051569649524431
Epoch: 26 Idx: 0 Loss: 0.007563433373362683
Epoch: 26 Idx: 5000 Loss: 0.02231603889202442
Epoch: 27 Idx: 0 Loss: 0.014682625884950843
Epoch: 27 Idx: 5000 Loss: 0.03504753248992986
Epoch: 28 Idx: 0 Loss: 0.009043832085386241
Epoch: 28 Idx: 5000 Loss: 0.023231824413972046
Epoch: 29 Idx: 0 Loss: 0.04222855123805365
Epoch: 29 Idx: 5000 Loss: 0.010579800699723366
Epoch: 30 Idx: 0 Loss: 0.02857447349826378
Epoch: 30 Idx: 5000 Loss: 0.004022299207160291
Epoch: 31 Idx: 0 Loss: 0.010145030967552248
Epoch: 31 Idx: 5000 Loss: 0.01888484347338888
Epoch: 32 Idx: 0 Loss: 0.016066085240591704
Epoch: 32 Idx: 5000 Loss: 0.018118096466862715
Epoch: 33 Idx: 0 Loss: 0.020680447371416128
Epoch: 33 Idx: 5000 Loss: 0.009952104001047322
Epoch: 34 Idx: 0 Loss: 0.028173807203382785
Epoch: 34 Idx: 5000 Loss: 0.03662367088317388
Epoch: 35 Idx: 0 Loss: 0.009942464525436696
Epoch: 35 Idx: 5000 Loss: 0.018471268306870892
Epoch: 36 Idx: 0 Loss: 0.024133601813104793
Epoch: 36 Idx: 5000 Loss: 0.007815695920304101
Epoch: 37 Idx: 0 Loss: 0.021617413441885266
Epoch: 37 Idx: 5000 Loss: 0.015651343397884834
Epoch: 38 Idx: 0 Loss: 0.037152486610392735
Epoch: 38 Idx: 5000 Loss: 0.023518816725732077
Epoch: 39 Idx: 0 Loss: 0.025187120118117756
Epoch: 39 Idx: 5000 Loss: 0.015057990469556899
Epoch: 40 Idx: 0 Loss: 0.006391880725160091
Epoch: 40 Idx: 5000 Loss: 0.01898485512236942
Epoch: 41 Idx: 0 Loss: 0.029304681416355133
Epoch: 41 Idx: 5000 Loss: 0.0198017507999493
Epoch: 42 Idx: 0 Loss: 0.010620422066169938
Epoch: 42 Idx: 5000 Loss: 0.02651068315292458
Epoch: 43 Idx: 0 Loss: 0.025277897650318584
Epoch: 43 Idx: 5000 Loss: 0.014529207480030466
Epoch: 44 Idx: 0 Loss: 0.015358917319980642
Epoch: 44 Idx: 5000 Loss: 0.0298393025785215
Epoch: 45 Idx: 0 Loss: 0.00785546903752661
Epoch: 45 Idx: 5000 Loss: 0.018810645542890133
Epoch: 46 Idx: 0 Loss: 0.012791548798648526
Epoch: 46 Idx: 5000 Loss: 0.017278329587589583
Epoch: 47 Idx: 0 Loss: 0.014292476851788583
Epoch: 47 Idx: 5000 Loss: 0.0063839845252840095
Epoch: 48 Idx: 0 Loss: 0.008293235657200118
Epoch: 48 Idx: 5000 Loss: 0.020264107471837843
Epoch: 49 Idx: 0 Loss: 0.017248449270377074
Epoch: 49 Idx: 5000 Loss: 0.03398380310119502
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14693528004294887
Epoch: 0 Idx: 5000 Loss: 0.03717824373391668
Epoch: 1 Idx: 0 Loss: 0.012052005529748059
Epoch: 1 Idx: 5000 Loss: 0.027218723288232955
Epoch: 2 Idx: 0 Loss: 0.021226470364803747
Epoch: 2 Idx: 5000 Loss: 0.009482208523867833
Epoch: 3 Idx: 0 Loss: 0.01405482975743125
Epoch: 3 Idx: 5000 Loss: 0.0242442232155774
Epoch: 4 Idx: 0 Loss: 0.012876115576025929
Epoch: 4 Idx: 5000 Loss: 0.013792311123222956
Epoch: 5 Idx: 0 Loss: 0.02791171679284067
Epoch: 5 Idx: 5000 Loss: 0.04528075454828277
Epoch: 6 Idx: 0 Loss: 0.01095048723872191
Epoch: 6 Idx: 5000 Loss: 0.010742853238948889
Epoch: 7 Idx: 0 Loss: 0.010769678194384937
Epoch: 7 Idx: 5000 Loss: 0.013049101165561166
Epoch: 8 Idx: 0 Loss: 0.014604903038996347
Epoch: 8 Idx: 5000 Loss: 0.021562807981230274
Epoch: 9 Idx: 0 Loss: 0.015196904017347546
Epoch: 9 Idx: 5000 Loss: 0.004100478998137813
Epoch: 10 Idx: 0 Loss: 0.011749327651970802
Epoch: 10 Idx: 5000 Loss: 0.010122419819553167
Epoch: 11 Idx: 0 Loss: 0.008922395698978753
Epoch: 11 Idx: 5000 Loss: 0.004927308948535467
Epoch: 12 Idx: 0 Loss: 0.016787279092521572
Epoch: 12 Idx: 5000 Loss: 0.024210233882539445
Epoch: 13 Idx: 0 Loss: 0.008822620550759294
Epoch: 13 Idx: 5000 Loss: 0.013128965113011922
Epoch: 14 Idx: 0 Loss: 0.013992218457411018
Epoch: 14 Idx: 5000 Loss: 0.004619561022447175
Epoch: 15 Idx: 0 Loss: 0.022554386884390966
Epoch: 15 Idx: 5000 Loss: 0.022037582415872628
Epoch: 16 Idx: 0 Loss: 0.02350329830076705
Epoch: 16 Idx: 5000 Loss: 0.019623487094902498
Epoch: 17 Idx: 0 Loss: 0.009530569151638014
Epoch: 17 Idx: 5000 Loss: 0.01911548939606996
Epoch: 18 Idx: 0 Loss: 0.014845444868311235
Epoch: 18 Idx: 5000 Loss: 0.03352712152907558
Epoch: 19 Idx: 0 Loss: 0.015945658081615167
Epoch: 19 Idx: 5000 Loss: 0.017195445820748154
Epoch: 20 Idx: 0 Loss: 0.0040380684636555355
Epoch: 20 Idx: 5000 Loss: 0.010678817653963987
Epoch: 21 Idx: 0 Loss: 0.018058652477398747
Epoch: 21 Idx: 5000 Loss: 0.017735858649372428
Epoch: 22 Idx: 0 Loss: 0.01761625228249162
Epoch: 22 Idx: 5000 Loss: 0.00689495018736574
Epoch: 23 Idx: 0 Loss: 0.023658131167526755
Epoch: 23 Idx: 5000 Loss: 0.03318720915495815
Epoch: 24 Idx: 0 Loss: 0.02259160832629402
Epoch: 24 Idx: 5000 Loss: 0.03414203929794417
Epoch: 25 Idx: 0 Loss: 0.032526325381398075
Epoch: 25 Idx: 5000 Loss: 0.02299701008525628
Epoch: 26 Idx: 0 Loss: 0.008382261230360151
Epoch: 26 Idx: 5000 Loss: 0.019889654133267456
Epoch: 27 Idx: 0 Loss: 0.03040833036519284
Epoch: 27 Idx: 5000 Loss: 0.024428741764182294
Epoch: 28 Idx: 0 Loss: 0.019672895938495506
Epoch: 28 Idx: 5000 Loss: 0.009722410378771012
Epoch: 29 Idx: 0 Loss: 0.007421306447085656
Epoch: 29 Idx: 5000 Loss: 0.0060253182055248515
Epoch: 30 Idx: 0 Loss: 0.009955824729588999
Epoch: 30 Idx: 5000 Loss: 0.010149566032835261
Epoch: 31 Idx: 0 Loss: 0.03408667549032746
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 312, in forward
    feature_emb = self.name_embedding(features[i]) #  dim: (2, batch_size, max_types, max_paths, max_pathlen, 512)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1814, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc272>
Subject: Job 4066892: <python main.py 6 21 False True> in cluster <dcc> Exited

Job <python main.py 6 21 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc272>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 21 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   45976.57 sec.
    Max Memory :                                 3009 MB
    Average Memory :                             2763.41 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40408.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46168 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

