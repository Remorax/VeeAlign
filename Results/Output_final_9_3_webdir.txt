2020-09-16 07:38:32.249172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:38:35.443283: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:38:35.563161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:38:35.563251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:38:35.565094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:38:35.566520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:38:35.566843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:38:35.568637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:38:35.569948: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:38:35.570068: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib
2020-09-16 07:38:35.570089: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:38:35.570386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:38:35.577603: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600135000 Hz
2020-09-16 07:38:35.577787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558231490840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:38:35.577809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:38:35.579688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:38:35.579715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/naveen9/arvind/VeeAlign/
Ontologies being aligned are:  [('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1799619030538936
Epoch: 0 Idx: 5000 Loss: 0.0126980757350694
Epoch: 1 Idx: 0 Loss: 0.04092902514901036
Epoch: 1 Idx: 5000 Loss: 0.007778106206554973
Epoch: 2 Idx: 0 Loss: 0.012643107575162326
Epoch: 2 Idx: 5000 Loss: 0.03995753978543623
Epoch: 3 Idx: 0 Loss: 0.01327105718242115
Epoch: 3 Idx: 5000 Loss: 0.03501328294907728
Epoch: 4 Idx: 0 Loss: 0.023905049122654298
Epoch: 4 Idx: 5000 Loss: 0.01797876476020078
Epoch: 5 Idx: 0 Loss: 0.015958116443247256
Epoch: 5 Idx: 5000 Loss: 0.05024118538514765
Epoch: 6 Idx: 0 Loss: 0.007369308973937476
Epoch: 6 Idx: 5000 Loss: 0.019257026520182505
Epoch: 7 Idx: 0 Loss: 0.028072681315818603
Epoch: 7 Idx: 5000 Loss: 0.01100549235774412
Epoch: 8 Idx: 0 Loss: 0.01220557702024794
Epoch: 8 Idx: 5000 Loss: 0.014497975200614084
Epoch: 9 Idx: 0 Loss: 0.02358397996389963
Epoch: 9 Idx: 5000 Loss: 0.008803860767169765
Epoch: 10 Idx: 0 Loss: 0.014237967721870828
Epoch: 10 Idx: 5000 Loss: 0.015420516399310288
Epoch: 11 Idx: 0 Loss: 0.009391841729409343
Epoch: 11 Idx: 5000 Loss: 0.012695019892763192
Epoch: 12 Idx: 0 Loss: 0.02783458168362942
Epoch: 12 Idx: 5000 Loss: 0.018585942249280632
Epoch: 13 Idx: 0 Loss: 0.0065438979313123535
Epoch: 13 Idx: 5000 Loss: 0.020477532743738387
Epoch: 14 Idx: 0 Loss: 0.01593211981551909
Epoch: 14 Idx: 5000 Loss: 0.013029776829283055
Epoch: 15 Idx: 0 Loss: 0.029762036197385978
Epoch: 15 Idx: 5000 Loss: 0.03191414954150139
Epoch: 16 Idx: 0 Loss: 0.010557872781398456
Epoch: 16 Idx: 5000 Loss: 0.03147071275801677
Epoch: 17 Idx: 0 Loss: 0.01064375318948465
Epoch: 17 Idx: 5000 Loss: 0.008861659653605728
Epoch: 18 Idx: 0 Loss: 0.010062996488759041
Epoch: 18 Idx: 5000 Loss: 0.017027552175871406
Epoch: 19 Idx: 0 Loss: 0.0133901820661059
Epoch: 19 Idx: 5000 Loss: 0.010850270271652267
Epoch: 20 Idx: 0 Loss: 0.011547386535455118
Epoch: 20 Idx: 5000 Loss: 0.0060277680807097915
Epoch: 21 Idx: 0 Loss: 0.010079936100646114
Epoch: 21 Idx: 5000 Loss: 0.01914914373076273
Epoch: 22 Idx: 0 Loss: 0.022974017306559135
Epoch: 22 Idx: 5000 Loss: 0.006028109587651116
Epoch: 23 Idx: 0 Loss: 0.01596550709582957
Epoch: 23 Idx: 5000 Loss: 0.02616724407299862
Epoch: 24 Idx: 0 Loss: 0.01702595546646407
Epoch: 24 Idx: 5000 Loss: 0.011597248273244435
Epoch: 25 Idx: 0 Loss: 0.010547238310302753
Epoch: 25 Idx: 5000 Loss: 0.02176677870367231
Epoch: 26 Idx: 0 Loss: 0.006259907516965174
Epoch: 26 Idx: 5000 Loss: 0.014001628796106854
Epoch: 27 Idx: 0 Loss: 0.006726335530832216
Epoch: 27 Idx: 5000 Loss: 0.007111544670144108
Epoch: 28 Idx: 0 Loss: 0.009011154658339763
Epoch: 28 Idx: 5000 Loss: 0.013724982039739231
Epoch: 29 Idx: 0 Loss: 0.01244500440956759
Epoch: 29 Idx: 5000 Loss: 0.012214401066485931
Epoch: 30 Idx: 0 Loss: 0.014923049403313788
Epoch: 30 Idx: 5000 Loss: 0.007442232705463177
Epoch: 31 Idx: 0 Loss: 0.023036374424380737
Epoch: 31 Idx: 5000 Loss: 0.03097219325997041
Epoch: 32 Idx: 0 Loss: 0.011491545966866582
Epoch: 32 Idx: 5000 Loss: 0.014768486819334873
Epoch: 33 Idx: 0 Loss: 0.030739093186788153
Epoch: 33 Idx: 5000 Loss: 0.025075192012468234
Epoch: 34 Idx: 0 Loss: 0.01747246651909946
Epoch: 34 Idx: 5000 Loss: 0.021392262460051867
Epoch: 35 Idx: 0 Loss: 0.010792969483359432
Epoch: 35 Idx: 5000 Loss: 0.008837251967702436
Epoch: 36 Idx: 0 Loss: 0.024375253673998006
Epoch: 36 Idx: 5000 Loss: 0.012512825822636664
Epoch: 37 Idx: 0 Loss: 0.053079334221639865
Epoch: 37 Idx: 5000 Loss: 0.025602715577747952
Epoch: 38 Idx: 0 Loss: 0.0386686334759527
Epoch: 38 Idx: 5000 Loss: 0.045328871113431785
Epoch: 39 Idx: 0 Loss: 0.01397061523116926
Epoch: 39 Idx: 5000 Loss: 0.03267872470615492
Epoch: 40 Idx: 0 Loss: 0.009489867496599885
Epoch: 40 Idx: 5000 Loss: 0.0129235683676949
Epoch: 41 Idx: 0 Loss: 0.015428572082116686
Epoch: 41 Idx: 5000 Loss: 0.029262715400008476
Epoch: 42 Idx: 0 Loss: 0.009857464503083765
Epoch: 42 Idx: 5000 Loss: 0.018167529707400792
Epoch: 43 Idx: 0 Loss: 0.017684181768819942
Epoch: 43 Idx: 5000 Loss: 0.019696207579649395
Epoch: 44 Idx: 0 Loss: 0.006001827237946117
Epoch: 44 Idx: 5000 Loss: 0.013381997337399006
Epoch: 45 Idx: 0 Loss: 0.008917152824797278
Epoch: 45 Idx: 5000 Loss: 0.016063913600503424
Epoch: 46 Idx: 0 Loss: 0.018761921449509958
Epoch: 46 Idx: 5000 Loss: 0.015274481533556065
Epoch: 47 Idx: 0 Loss: 0.02472129262249696
Epoch: 47 Idx: 5000 Loss: 0.01379307076727845
Epoch: 48 Idx: 0 Loss: 0.006650457488930631
Epoch: 48 Idx: 5000 Loss: 0.022786706328222633
Epoch: 49 Idx: 0 Loss: 0.012851184186141437
Epoch: 49 Idx: 5000 Loss: 0.0132320649342533
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.22536701474873566
Epoch: 0 Idx: 5000 Loss: 0.015120841972319752
Epoch: 1 Idx: 0 Loss: 0.025614745625606335
Epoch: 1 Idx: 5000 Loss: 0.010098822428652678
Epoch: 2 Idx: 0 Loss: 0.012367459910452554
Epoch: 2 Idx: 5000 Loss: 0.01686666514171574
Epoch: 3 Idx: 0 Loss: 0.021086148125468655
Epoch: 3 Idx: 5000 Loss: 0.028610945046169085
Epoch: 4 Idx: 0 Loss: 0.013748158735845254
Epoch: 4 Idx: 5000 Loss: 0.011051259445882375
Epoch: 5 Idx: 0 Loss: 0.011196120278168187
Epoch: 5 Idx: 5000 Loss: 0.0161987353638209
Epoch: 6 Idx: 0 Loss: 0.01787122798201517
Epoch: 6 Idx: 5000 Loss: 0.012495257893302138
Epoch: 7 Idx: 0 Loss: 0.016799127210264126
Epoch: 7 Idx: 5000 Loss: 0.01928779080972076
Epoch: 8 Idx: 0 Loss: 0.027780902463996424
Epoch: 8 Idx: 5000 Loss: 0.01715630679865163
Epoch: 9 Idx: 0 Loss: 0.030277362595479466
Epoch: 9 Idx: 5000 Loss: 0.006763560952220816
Epoch: 10 Idx: 0 Loss: 0.010459681997203806
Epoch: 10 Idx: 5000 Loss: 0.01875071786327154
Epoch: 11 Idx: 0 Loss: 0.012232969417313628
Epoch: 11 Idx: 5000 Loss: 0.033890334255363426
Epoch: 12 Idx: 0 Loss: 0.018720540317388297
Epoch: 12 Idx: 5000 Loss: 0.014227689302841986
Epoch: 13 Idx: 0 Loss: 0.02122658423596747
Epoch: 13 Idx: 5000 Loss: 0.006185858306224748
Epoch: 14 Idx: 0 Loss: 0.015220839721443283
Epoch: 14 Idx: 5000 Loss: 0.016608410303612084
Epoch: 15 Idx: 0 Loss: 0.011225960522431574
Epoch: 15 Idx: 5000 Loss: 0.020982620954667776
Epoch: 16 Idx: 0 Loss: 0.01354342036349806
Epoch: 16 Idx: 5000 Loss: 0.018122955391020587
Epoch: 17 Idx: 0 Loss: 0.00669551319634918
Epoch: 17 Idx: 5000 Loss: 0.04171801354433104
Epoch: 18 Idx: 0 Loss: 0.010917066605991323
Epoch: 18 Idx: 5000 Loss: 0.01193471320150389
Epoch: 19 Idx: 0 Loss: 0.012000849064721264
Epoch: 19 Idx: 5000 Loss: 0.014291230565313565
Epoch: 20 Idx: 0 Loss: 0.008126218365130352
Epoch: 20 Idx: 5000 Loss: 0.019892365029094822
Epoch: 21 Idx: 0 Loss: 0.012942048642009128
Epoch: 21 Idx: 5000 Loss: 0.013388806174370606
Epoch: 22 Idx: 0 Loss: 0.01696712715454715
Epoch: 22 Idx: 5000 Loss: 0.012480081696025595
Epoch: 23 Idx: 0 Loss: 0.01651167175912463
Epoch: 23 Idx: 5000 Loss: 0.013285690558138892
Epoch: 24 Idx: 0 Loss: 0.02187840823577907
Epoch: 24 Idx: 5000 Loss: 0.01669859125184746
Epoch: 25 Idx: 0 Loss: 0.025782964939740808
Epoch: 25 Idx: 5000 Loss: 0.012097908979910612
Epoch: 26 Idx: 0 Loss: 0.019578085243268914
Epoch: 26 Idx: 5000 Loss: 0.014995011025686351
Epoch: 27 Idx: 0 Loss: 0.010214685899712757
Epoch: 27 Idx: 5000 Loss: 0.009327900882539243
Epoch: 28 Idx: 0 Loss: 0.014052282703700757
Epoch: 28 Idx: 5000 Loss: 0.003923834800314323
Epoch: 29 Idx: 0 Loss: 0.014986214269812882
Epoch: 29 Idx: 5000 Loss: 0.012570330679270412
Epoch: 30 Idx: 0 Loss: 0.01788986035177442
Epoch: 30 Idx: 5000 Loss: 0.013960246903005423
Epoch: 31 Idx: 0 Loss: 0.028740537171267365
Epoch: 31 Idx: 5000 Loss: 0.014819477262528802
Epoch: 32 Idx: 0 Loss: 0.010274622020432734
Epoch: 32 Idx: 5000 Loss: 0.014996415715199354
Epoch: 33 Idx: 0 Loss: 0.011055903639494356
Epoch: 33 Idx: 5000 Loss: 0.015419830968463874
Epoch: 34 Idx: 0 Loss: 0.026476781160703147
Epoch: 34 Idx: 5000 Loss: 0.00843347715781563
Epoch: 35 Idx: 0 Loss: 0.014356503352368441
Epoch: 35 Idx: 5000 Loss: 0.01825572981132502
Epoch: 36 Idx: 0 Loss: 0.010466124112889498
Epoch: 36 Idx: 5000 Loss: 0.010219346877601457
Epoch: 37 Idx: 0 Loss: 0.027570450706811363
Epoch: 37 Idx: 5000 Loss: 0.011816512122059468
Epoch: 38 Idx: 0 Loss: 0.010642465003188818
Epoch: 38 Idx: 5000 Loss: 0.01908476687301133
Epoch: 39 Idx: 0 Loss: 0.008108914184150558
Epoch: 39 Idx: 5000 Loss: 0.02631493343565081
Epoch: 40 Idx: 0 Loss: 0.018565518094861535
Epoch: 40 Idx: 5000 Loss: 0.008171135275174468
Epoch: 41 Idx: 0 Loss: 0.010496848295357342
Epoch: 41 Idx: 5000 Loss: 0.011149423465220555
Epoch: 42 Idx: 0 Loss: 0.011559206512161208
Epoch: 42 Idx: 5000 Loss: 0.008485074816137184
Epoch: 43 Idx: 0 Loss: 0.009691061417124993
Epoch: 43 Idx: 5000 Loss: 0.01776320106986991
Epoch: 44 Idx: 0 Loss: 0.017198149954456284
Epoch: 44 Idx: 5000 Loss: 0.013724820866387428
Epoch: 45 Idx: 0 Loss: 0.010514004875109355
Epoch: 45 Idx: 5000 Loss: 0.013802454981138534
Epoch: 46 Idx: 0 Loss: 0.026356717122754565
Epoch: 46 Idx: 5000 Loss: 0.03278521288091521
Epoch: 47 Idx: 0 Loss: 0.014270301262275171
Epoch: 47 Idx: 5000 Loss: 0.06745271847981542
Epoch: 48 Idx: 0 Loss: 0.016360537341986208
Epoch: 48 Idx: 5000 Loss: 0.01326774715575213
Epoch: 49 Idx: 0 Loss: 0.015519407001439216
Epoch: 49 Idx: 5000 Loss: 0.01242385391138948
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.15690615780270903
Epoch: 0 Idx: 5000 Loss: 0.009130785739435023
Epoch: 1 Idx: 0 Loss: 0.014238035345770894
Epoch: 1 Idx: 5000 Loss: 0.01631099088725326
Epoch: 2 Idx: 0 Loss: 0.007818610016114296
Epoch: 2 Idx: 5000 Loss: 0.008155342946688425
Epoch: 3 Idx: 0 Loss: 0.013448056220786951
Epoch: 3 Idx: 5000 Loss: 0.010017942262230198
Epoch: 4 Idx: 0 Loss: 0.008319966293960767
Epoch: 4 Idx: 5000 Loss: 0.010634718070592237
Epoch: 5 Idx: 0 Loss: 0.010848625046224528
Epoch: 5 Idx: 5000 Loss: 0.012160617109397845
Epoch: 6 Idx: 0 Loss: 0.004754766823545463
Epoch: 6 Idx: 5000 Loss: 0.03395843289599582
Epoch: 7 Idx: 0 Loss: 0.020195018715386016
Epoch: 7 Idx: 5000 Loss: 0.014675656944688552
Epoch: 8 Idx: 0 Loss: 0.0135376175616417
Epoch: 8 Idx: 5000 Loss: 0.02468190182285667
Epoch: 9 Idx: 0 Loss: 0.013584701100577874
Epoch: 9 Idx: 5000 Loss: 0.014086008355015247
Epoch: 10 Idx: 0 Loss: 0.025623011717580767
Epoch: 10 Idx: 5000 Loss: 0.012175692100970944
Epoch: 11 Idx: 0 Loss: 0.007438527599447092
Epoch: 11 Idx: 5000 Loss: 0.014190005606375952
Epoch: 12 Idx: 0 Loss: 0.016168078325298835
Epoch: 12 Idx: 5000 Loss: 0.02638813612944028
Epoch: 13 Idx: 0 Loss: 0.020839874384954223
Epoch: 13 Idx: 5000 Loss: 0.010982960363067975
Epoch: 14 Idx: 0 Loss: 0.02746422056559739
Epoch: 14 Idx: 5000 Loss: 0.01364135164153073
Epoch: 15 Idx: 0 Loss: 0.01577542544586296
Epoch: 15 Idx: 5000 Loss: 0.01088443772481467
Epoch: 16 Idx: 0 Loss: 0.014377961954789267
Epoch: 16 Idx: 5000 Loss: 0.02404964352673989
Epoch: 17 Idx: 0 Loss: 0.030857105438271644
Epoch: 17 Idx: 5000 Loss: 0.010488034206549994
Epoch: 18 Idx: 0 Loss: 0.014807036299374025
Epoch: 18 Idx: 5000 Loss: 0.01598748783507884
Epoch: 19 Idx: 0 Loss: 0.011835035653457136
Epoch: 19 Idx: 5000 Loss: 0.016798984775103366
Epoch: 20 Idx: 0 Loss: 0.011403990488357392
Epoch: 20 Idx: 5000 Loss: 0.012217501460652293
Epoch: 21 Idx: 0 Loss: 0.009988471305867367
Epoch: 21 Idx: 5000 Loss: 0.016698216538869326
Epoch: 22 Idx: 0 Loss: 0.03627245906856031
Epoch: 22 Idx: 5000 Loss: 0.0188651467217685
Epoch: 23 Idx: 0 Loss: 0.012171918164444361
Epoch: 23 Idx: 5000 Loss: 0.011145062173608132
Epoch: 24 Idx: 0 Loss: 0.03043976165880325
Epoch: 24 Idx: 5000 Loss: 0.008237763017198323
Epoch: 25 Idx: 0 Loss: 0.011481373871453886
Epoch: 25 Idx: 5000 Loss: 0.013935726623154083
Epoch: 26 Idx: 0 Loss: 0.009685910993596884
Epoch: 26 Idx: 5000 Loss: 0.01002948812622252
Epoch: 27 Idx: 0 Loss: 0.009920481391669756
Epoch: 27 Idx: 5000 Loss: 0.03063586854718396
Epoch: 28 Idx: 0 Loss: 0.026200793787391055
Epoch: 28 Idx: 5000 Loss: 0.019269773096321392
Epoch: 29 Idx: 0 Loss: 0.01731940753348727
Epoch: 29 Idx: 5000 Loss: 0.010167338701745752
Epoch: 30 Idx: 0 Loss: 0.018072290459551273
Epoch: 30 Idx: 5000 Loss: 0.035399138378120386
Epoch: 31 Idx: 0 Loss: 0.011326579819551388
Epoch: 31 Idx: 5000 Loss: 0.01494314385772374
Epoch: 32 Idx: 0 Loss: 0.03261092571686354
Epoch: 32 Idx: 5000 Loss: 0.035087926756045364
Epoch: 33 Idx: 0 Loss: 0.02260979601247918
Epoch: 33 Idx: 5000 Loss: 0.03470369303779568
Epoch: 34 Idx: 0 Loss: 0.013725583724546818
Epoch: 34 Idx: 5000 Loss: 0.02266144619268106
Epoch: 35 Idx: 0 Loss: 0.01765545257049328
Epoch: 35 Idx: 5000 Loss: 0.007750534110287279
Epoch: 36 Idx: 0 Loss: 0.010867574991926622
Epoch: 36 Idx: 5000 Loss: 0.010481060720370361
Epoch: 37 Idx: 0 Loss: 0.014002332211282841
Epoch: 37 Idx: 5000 Loss: 0.01815940166970501
Epoch: 38 Idx: 0 Loss: 0.011167282701903975
Epoch: 38 Idx: 5000 Loss: 0.019956910639661988
Epoch: 39 Idx: 0 Loss: 0.0316759357108241
Epoch: 39 Idx: 5000 Loss: 0.00828731302911639
Epoch: 40 Idx: 0 Loss: 0.0031460161068163173
Epoch: 40 Idx: 5000 Loss: 0.017537828249030725
Epoch: 41 Idx: 0 Loss: 0.014587805761539386
Epoch: 41 Idx: 5000 Loss: 0.01869489898293205
Epoch: 42 Idx: 0 Loss: 0.018626624924351014
Epoch: 42 Idx: 5000 Loss: 0.01129192729547113
Epoch: 43 Idx: 0 Loss: 0.022107985513109964
Epoch: 43 Idx: 5000 Loss: 0.008234655249419423
Epoch: 44 Idx: 0 Loss: 0.009156358424071216
Epoch: 44 Idx: 5000 Loss: 0.022690251142749335
Epoch: 45 Idx: 0 Loss: 0.047903051149940964
Epoch: 45 Idx: 5000 Loss: 0.020012180886686298
Epoch: 46 Idx: 0 Loss: 0.023818028295523413
Epoch: 46 Idx: 5000 Loss: 0.020158529204549067
Epoch: 47 Idx: 0 Loss: 0.008331606001516341
Epoch: 47 Idx: 5000 Loss: 0.028797681354194152
Epoch: 48 Idx: 0 Loss: 0.03164357072484106
Epoch: 48 Idx: 5000 Loss: 0.022290475384190298
Epoch: 49 Idx: 0 Loss: 0.029966305425294243
Epoch: 49 Idx: 5000 Loss: 0.0069267810629961854
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.18662834801929945
Epoch: 0 Idx: 5000 Loss: 0.012443339483383793
Epoch: 1 Idx: 0 Loss: 0.01570221205799948
Epoch: 1 Idx: 5000 Loss: 0.022945414790298508
Epoch: 2 Idx: 0 Loss: 0.008813637013795728
Epoch: 2 Idx: 5000 Loss: 0.00821594520881303
Epoch: 3 Idx: 0 Loss: 0.00523782406115505
Epoch: 3 Idx: 5000 Loss: 0.009556600504555895
Epoch: 4 Idx: 0 Loss: 0.023717358909807227
Epoch: 4 Idx: 5000 Loss: 0.008824555155491355
Epoch: 5 Idx: 0 Loss: 0.008385824814105769
Epoch: 5 Idx: 5000 Loss: 0.0231285835362301
Epoch: 6 Idx: 0 Loss: 0.016154885463937865
Epoch: 6 Idx: 5000 Loss: 0.011396819617249965
Epoch: 7 Idx: 0 Loss: 0.012249893747186038
Epoch: 7 Idx: 5000 Loss: 0.009872291738744574
Epoch: 8 Idx: 0 Loss: 0.03335133784780957
Epoch: 8 Idx: 5000 Loss: 0.01175645902986747
Epoch: 9 Idx: 0 Loss: 0.01096874027855826
Epoch: 9 Idx: 5000 Loss: 0.010985857794101498
Epoch: 10 Idx: 0 Loss: 0.01678906642901735
Epoch: 10 Idx: 5000 Loss: 0.04017590208399558
Epoch: 11 Idx: 0 Loss: 0.0071874669505734515
Epoch: 11 Idx: 5000 Loss: 0.016753176554125636
Epoch: 12 Idx: 0 Loss: 0.00649768080546811
Epoch: 12 Idx: 5000 Loss: 0.04372231299886218
Epoch: 13 Idx: 0 Loss: 0.014269019653656418
Epoch: 13 Idx: 5000 Loss: 0.010242150665655318
Epoch: 14 Idx: 0 Loss: 0.005587908853916484
Epoch: 14 Idx: 5000 Loss: 0.010464374482283162
Epoch: 15 Idx: 0 Loss: 0.012489338820729333
Epoch: 15 Idx: 5000 Loss: 0.00577031352395199
Epoch: 16 Idx: 0 Loss: 0.022045224408762238
Epoch: 16 Idx: 5000 Loss: 0.014174228387600442
Epoch: 17 Idx: 0 Loss: 0.010241085271605903
Epoch: 17 Idx: 5000 Loss: 0.04223822699842942
Epoch: 18 Idx: 0 Loss: 0.013052827150660862
Epoch: 18 Idx: 5000 Loss: 0.011537212664182606
Epoch: 19 Idx: 0 Loss: 0.013429381553862078
Epoch: 19 Idx: 5000 Loss: 0.020671786658902343
Epoch: 20 Idx: 0 Loss: 0.010121654790224241
Epoch: 20 Idx: 5000 Loss: 0.008392069031415289
Epoch: 21 Idx: 0 Loss: 0.04073482825054857
Epoch: 21 Idx: 5000 Loss: 0.025331832228945902
Epoch: 22 Idx: 0 Loss: 0.01586674112360767
Epoch: 22 Idx: 5000 Loss: 0.010537385277667871
Epoch: 23 Idx: 0 Loss: 0.013816138192376206
Epoch: 23 Idx: 5000 Loss: 0.020614890233393815
Epoch: 24 Idx: 0 Loss: 0.02393629829051173
Epoch: 24 Idx: 5000 Loss: 0.00934697380425082
Epoch: 25 Idx: 0 Loss: 0.016656070656613252
Epoch: 25 Idx: 5000 Loss: 0.010272808411166777
Epoch: 26 Idx: 0 Loss: 0.007134048456008739
Epoch: 26 Idx: 5000 Loss: 0.01831314334513245
Epoch: 27 Idx: 0 Loss: 0.009610487272294854
Epoch: 27 Idx: 5000 Loss: 0.010443020714773828
Epoch: 28 Idx: 0 Loss: 0.010989406524525541
Epoch: 28 Idx: 5000 Loss: 0.010935841286134063
Epoch: 29 Idx: 0 Loss: 0.013925112976662418
Epoch: 29 Idx: 5000 Loss: 0.003723248082847565
Epoch: 30 Idx: 0 Loss: 0.027612634822579585
Epoch: 30 Idx: 5000 Loss: 0.009228358536261052
Epoch: 31 Idx: 0 Loss: 0.005912612943698142
Epoch: 31 Idx: 5000 Loss: 0.008336385386104511
Epoch: 32 Idx: 0 Loss: 0.024675204795094524
Epoch: 32 Idx: 5000 Loss: 0.024143155643170964
Epoch: 33 Idx: 0 Loss: 0.012826325199248222
Epoch: 33 Idx: 5000 Loss: 0.018361998155650323
Epoch: 34 Idx: 0 Loss: 0.014478871096705368
Epoch: 34 Idx: 5000 Loss: 0.009080851639240155
Epoch: 35 Idx: 0 Loss: 0.017080478037420677
Epoch: 35 Idx: 5000 Loss: 0.014888862234299485
Epoch: 36 Idx: 0 Loss: 0.021716926230722546
Epoch: 36 Idx: 5000 Loss: 0.04773370867487706
Epoch: 37 Idx: 0 Loss: 0.031061463280964305
Epoch: 37 Idx: 5000 Loss: 0.015768257758808166
Epoch: 38 Idx: 0 Loss: 0.009194945296778887
Epoch: 38 Idx: 5000 Loss: 0.02027700657162848
Epoch: 39 Idx: 0 Loss: 0.015487550400342442
Epoch: 39 Idx: 5000 Loss: 0.01589155005614745
Epoch: 40 Idx: 0 Loss: 0.010777323465568063
Epoch: 40 Idx: 5000 Loss: 0.014265344563328454
Epoch: 41 Idx: 0 Loss: 0.013714215620031705
Epoch: 41 Idx: 5000 Loss: 0.010630656891408637
Epoch: 42 Idx: 0 Loss: 0.008651809061095458
Epoch: 42 Idx: 5000 Loss: 0.018975475311373544
Epoch: 43 Idx: 0 Loss: 0.04062982316633882
Epoch: 43 Idx: 5000 Loss: 0.009951521526475991
Epoch: 44 Idx: 0 Loss: 0.011787277826628903
Epoch: 44 Idx: 5000 Loss: 0.038188446492551556
Epoch: 45 Idx: 0 Loss: 0.025606253743582476
Epoch: 45 Idx: 5000 Loss: 0.008917608487084523
Epoch: 46 Idx: 0 Loss: 0.010787348596478105
Epoch: 46 Idx: 5000 Loss: 0.00924662961469263
Epoch: 47 Idx: 0 Loss: 0.04090586003070031
Epoch: 47 Idx: 5000 Loss: 0.02345526957294638
Epoch: 48 Idx: 0 Loss: 0.0494551410102983
Epoch: 48 Idx: 5000 Loss: 0.012391498184051377
Epoch: 49 Idx: 0 Loss: 0.014090482917828096
Epoch: 49 Idx: 5000 Loss: 0.016920320402222327
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.208352761285714
Epoch: 1 Idx: 0 Loss: 0.024319137304805526
Epoch: 2 Idx: 0 Loss: 0.009580664354516988
Epoch: 3 Idx: 0 Loss: 0.014928166987919838
Epoch: 4 Idx: 0 Loss: 0.01004947280335123
Epoch: 5 Idx: 0 Loss: 0.02074049061104082
Epoch: 6 Idx: 0 Loss: 0.010598470446170821
Epoch: 7 Idx: 0 Loss: 0.008398028822354521
Epoch: 8 Idx: 0 Loss: 0.01807181644504846
Epoch: 9 Idx: 0 Loss: 0.02760152631514161
Epoch: 10 Idx: 0 Loss: 0.009641670031355501
Epoch: 11 Idx: 0 Loss: 0.015735198729065543
Epoch: 12 Idx: 0 Loss: 0.014348802347868228
Epoch: 13 Idx: 0 Loss: 0.013548537661917439
Epoch: 14 Idx: 0 Loss: 0.030010070360240736
Epoch: 15 Idx: 0 Loss: 0.012084773998618478
Epoch: 16 Idx: 0 Loss: 0.014474226726911982
Epoch: 17 Idx: 0 Loss: 0.007129675955769309
Epoch: 18 Idx: 0 Loss: 0.01583585268708028
Epoch: 19 Idx: 0 Loss: 0.011939598152012076
Epoch: 20 Idx: 0 Loss: 0.012628970103913862
Epoch: 21 Idx: 0 Loss: 0.014811167885137729
Epoch: 22 Idx: 0 Loss: 0.010572106780876857
Epoch: 23 Idx: 0 Loss: 0.020342429916485744
Epoch: 24 Idx: 0 Loss: 0.008258420521079139
Epoch: 25 Idx: 0 Loss: 0.010782015543469593
Epoch: 26 Idx: 0 Loss: 0.01521642686425744
Epoch: 27 Idx: 0 Loss: 0.010231327057783197
Epoch: 28 Idx: 0 Loss: 0.02452308388152814
Epoch: 29 Idx: 0 Loss: 0.013603525662190787
Epoch: 30 Idx: 0 Loss: 0.01584432674266561
Epoch: 31 Idx: 0 Loss: 0.011964085487055801
Epoch: 32 Idx: 0 Loss: 0.012891207569928372
Epoch: 33 Idx: 0 Loss: 0.029373328769713068
Epoch: 34 Idx: 0 Loss: 0.018040704243258408
Epoch: 35 Idx: 0 Loss: 0.00901349068640298
Epoch: 36 Idx: 0 Loss: 0.028924955081329654
Epoch: 37 Idx: 0 Loss: 0.014736820240966501
Epoch: 38 Idx: 0 Loss: 0.010673268302911426
Epoch: 39 Idx: 0 Loss: 0.028961366865618142
Epoch: 40 Idx: 0 Loss: 0.015015996286403273
Epoch: 41 Idx: 0 Loss: 0.014569107527031128
Epoch: 42 Idx: 0 Loss: 0.010315636880531043
Epoch: 43 Idx: 0 Loss: 0.02553486886869605
Epoch: 44 Idx: 0 Loss: 0.010568220965648132
Epoch: 45 Idx: 0 Loss: 0.01284361208527254
Epoch: 46 Idx: 0 Loss: 0.011659918605938943
Epoch: 47 Idx: 0 Loss: 0.021526064009963042
Epoch: 48 Idx: 0 Loss: 0.011746202506949462
Epoch: 49 Idx: 0 Loss: 0.02179164674623112
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.15418291103997475
Epoch: 0 Idx: 5000 Loss: 0.011892049383416495
Epoch: 1 Idx: 0 Loss: 0.010346619621673298
Epoch: 1 Idx: 5000 Loss: 0.009639134181890455
Epoch: 2 Idx: 0 Loss: 0.01651291668621528
Epoch: 2 Idx: 5000 Loss: 0.013935642996595355
Epoch: 3 Idx: 0 Loss: 0.013343281446730316
Epoch: 3 Idx: 5000 Loss: 0.010418301485236835
Epoch: 4 Idx: 0 Loss: 0.009098505146547572
Epoch: 4 Idx: 5000 Loss: 0.010781938020738385
Epoch: 5 Idx: 0 Loss: 0.04238904674792397
Epoch: 5 Idx: 5000 Loss: 0.014793581260269948
Epoch: 6 Idx: 0 Loss: 0.014726911117898072
Epoch: 6 Idx: 5000 Loss: 0.015647192906806995
Epoch: 7 Idx: 0 Loss: 0.018088381317433674
Epoch: 7 Idx: 5000 Loss: 0.01045435515443123
Epoch: 8 Idx: 0 Loss: 0.021069427545366545
Epoch: 8 Idx: 5000 Loss: 0.0354752222207646
Epoch: 9 Idx: 0 Loss: 0.009872651187459686
Epoch: 9 Idx: 5000 Loss: 0.0095169321913681
Epoch: 10 Idx: 0 Loss: 0.014575702294619042
Epoch: 10 Idx: 5000 Loss: 0.015290687404454358
Epoch: 11 Idx: 0 Loss: 0.00975118516584558
Epoch: 11 Idx: 5000 Loss: 0.023936595358958892
Epoch: 12 Idx: 0 Loss: 0.01954268506323699
Epoch: 12 Idx: 5000 Loss: 0.013643183267688855
Epoch: 13 Idx: 0 Loss: 0.00396594176082827
Epoch: 13 Idx: 5000 Loss: 0.008575721468236387
Epoch: 14 Idx: 0 Loss: 0.026977169236222672
Epoch: 14 Idx: 5000 Loss: 0.006306051251797175
Epoch: 15 Idx: 0 Loss: 0.01231405579833509
Epoch: 15 Idx: 5000 Loss: 0.012211524720001494
Epoch: 16 Idx: 0 Loss: 0.014483755163044724
Epoch: 16 Idx: 5000 Loss: 0.011636178212236774
Epoch: 17 Idx: 0 Loss: 0.006082577474489734
Epoch: 17 Idx: 5000 Loss: 0.01680074799847738
Epoch: 18 Idx: 0 Loss: 0.027132624193107514
Epoch: 18 Idx: 5000 Loss: 0.011288374144333809
Epoch: 19 Idx: 0 Loss: 0.025431832880143064
Epoch: 19 Idx: 5000 Loss: 0.016184838886211982
Epoch: 20 Idx: 0 Loss: 0.011656483808985957
Epoch: 20 Idx: 5000 Loss: 0.01367898461510119
Epoch: 21 Idx: 0 Loss: 0.021743175801316034
Epoch: 21 Idx: 5000 Loss: 0.01927863493878977
Epoch: 22 Idx: 0 Loss: 0.025671199774688284
Epoch: 22 Idx: 5000 Loss: 0.01412354253279351
Epoch: 23 Idx: 0 Loss: 0.046014561263629426
Epoch: 23 Idx: 5000 Loss: 0.009233291654469776
Epoch: 24 Idx: 0 Loss: 0.02470013480595573
Epoch: 24 Idx: 5000 Loss: 0.010778983012336419
Epoch: 25 Idx: 0 Loss: 0.012723679142047814
Epoch: 25 Idx: 5000 Loss: 0.011067292468206515
Epoch: 26 Idx: 0 Loss: 0.010898452633457241
Epoch: 26 Idx: 5000 Loss: 0.008472076453448801
Epoch: 27 Idx: 0 Loss: 0.008631670969855476
Epoch: 27 Idx: 5000 Loss: 0.010264698784857891
Epoch: 28 Idx: 0 Loss: 0.008414595279093082
Epoch: 28 Idx: 5000 Loss: 0.03699214730607192
Epoch: 29 Idx: 0 Loss: 0.03948293376878707
Epoch: 29 Idx: 5000 Loss: 0.01613521657587967
Epoch: 30 Idx: 0 Loss: 0.034772997463102265
Epoch: 30 Idx: 5000 Loss: 0.010519726047076853
Epoch: 31 Idx: 0 Loss: 0.02611341862341602
Epoch: 31 Idx: 5000 Loss: 0.023978184956504722
Epoch: 32 Idx: 0 Loss: 0.013875098182621252
Epoch: 32 Idx: 5000 Loss: 0.016658421834891583
Epoch: 33 Idx: 0 Loss: 0.006765873256404016
Epoch: 33 Idx: 5000 Loss: 0.060934667419910375
Epoch: 34 Idx: 0 Loss: 0.016731742691114247
Epoch: 34 Idx: 5000 Loss: 0.013993611285934317
Epoch: 35 Idx: 0 Loss: 0.02325481987916456
Epoch: 35 Idx: 5000 Loss: 0.04956443466277735
Epoch: 36 Idx: 0 Loss: 0.016145253703416365
Epoch: 36 Idx: 5000 Loss: 0.014343752445604492
Epoch: 37 Idx: 0 Loss: 0.018468556489683416
Epoch: 37 Idx: 5000 Loss: 0.032342883045984455
Epoch: 38 Idx: 0 Loss: 0.024009859228556564
Epoch: 38 Idx: 5000 Loss: 0.020121151086574203
Epoch: 39 Idx: 0 Loss: 0.009767210941264872
Epoch: 39 Idx: 5000 Loss: 0.008360230954436436
Epoch: 40 Idx: 0 Loss: 0.005281906042947498
Epoch: 40 Idx: 5000 Loss: 0.009153087719467067
Epoch: 41 Idx: 0 Loss: 0.00886314707142785
Epoch: 41 Idx: 5000 Loss: 0.04262149209069225
Epoch: 42 Idx: 0 Loss: 0.03132484307976226
Epoch: 42 Idx: 5000 Loss: 0.010986241576250597
Epoch: 43 Idx: 0 Loss: 0.018268898141734546
Epoch: 43 Idx: 5000 Loss: 0.012315543768737232
Epoch: 44 Idx: 0 Loss: 0.009595442561549612
Epoch: 44 Idx: 5000 Loss: 0.009107369453872772
Epoch: 45 Idx: 0 Loss: 0.009952913477249624
Epoch: 45 Idx: 5000 Loss: 0.015404203982061163
Epoch: 46 Idx: 0 Loss: 0.013323831123713908
Epoch: 46 Idx: 5000 Loss: 0.0051611692018439905
Epoch: 47 Idx: 0 Loss: 0.01679028912855585
Epoch: 47 Idx: 5000 Loss: 0.011939922252501154
Epoch: 48 Idx: 0 Loss: 0.0151391079721362
Epoch: 48 Idx: 5000 Loss: 0.008015147646965119
Epoch: 49 Idx: 0 Loss: 0.017579002807826455
Epoch: 49 Idx: 5000 Loss: 0.04066157194559571
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.19405909302430996
Epoch: 1 Idx: 0 Loss: 0.016637053364770754
Epoch: 2 Idx: 0 Loss: 0.01955967101571529
Epoch: 3 Idx: 0 Loss: 0.004271706958726126
Epoch: 4 Idx: 0 Loss: 0.012736696062060134
Epoch: 5 Idx: 0 Loss: 0.00770455100426868
Epoch: 6 Idx: 0 Loss: 0.007540161452510191
Epoch: 7 Idx: 0 Loss: 0.00494966763891517
Epoch: 8 Idx: 0 Loss: 0.016874293426934906
Epoch: 9 Idx: 0 Loss: 0.026537022281335535
Epoch: 10 Idx: 0 Loss: 0.011816266299483121
Epoch: 11 Idx: 0 Loss: 0.023123978376253858
Epoch: 12 Idx: 0 Loss: 0.027752249668214282
Epoch: 13 Idx: 0 Loss: 0.01746963302124644
Epoch: 14 Idx: 0 Loss: 0.03184916299141543
Epoch: 15 Idx: 0 Loss: 0.015958149061688486
Epoch: 16 Idx: 0 Loss: 0.014629945510023105
Epoch: 17 Idx: 0 Loss: 0.018073148658292404
Epoch: 18 Idx: 0 Loss: 0.01631620160386495
Epoch: 19 Idx: 0 Loss: 0.01226094557254142
Epoch: 20 Idx: 0 Loss: 0.013452985921105456
Epoch: 21 Idx: 0 Loss: 0.005320033253489195
Epoch: 22 Idx: 0 Loss: 0.011807528008287922
Epoch: 23 Idx: 0 Loss: 0.008395997789853046
Epoch: 24 Idx: 0 Loss: 0.011331007373475007
Epoch: 25 Idx: 0 Loss: 0.04645083265610693
Epoch: 26 Idx: 0 Loss: 0.026239692118718252
Epoch: 27 Idx: 0 Loss: 0.017569012022439903
Epoch: 28 Idx: 0 Loss: 0.013034019412830004
Epoch: 29 Idx: 0 Loss: 0.015018014869247486
Epoch: 30 Idx: 0 Loss: 0.02213497345643031
Epoch: 31 Idx: 0 Loss: 0.010457533062789832
Epoch: 32 Idx: 0 Loss: 0.02413448774959605
Epoch: 33 Idx: 0 Loss: 0.009951632932352062
Epoch: 34 Idx: 0 Loss: 0.00858289010906581
Epoch: 35 Idx: 0 Loss: 0.018035891185171758
Epoch: 36 Idx: 0 Loss: 0.008352598571415626
Epoch: 37 Idx: 0 Loss: 0.01265128990945174
Epoch: 38 Idx: 0 Loss: 0.011246776597161967
Epoch: 39 Idx: 0 Loss: 0.03410525303287443
Epoch: 40 Idx: 0 Loss: 0.020782316670757202
Epoch: 41 Idx: 0 Loss: 0.015050197210664137
Epoch: 42 Idx: 0 Loss: 0.028091622903635538
Epoch: 43 Idx: 0 Loss: 0.01842093789179922
Epoch: 44 Idx: 0 Loss: 0.007648569548296491
Epoch: 45 Idx: 0 Loss: 0.024660852932797787
Epoch: 46 Idx: 0 Loss: 0.027789711721009438
Epoch: 47 Idx: 0 Loss: 0.009905414879978749
Epoch: 48 Idx: 0 Loss: 0.02035028659053659
Epoch: 49 Idx: 0 Loss: 0.05147377716189013
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7142857142857143, 0.6666666666666666, 0.689655172413793, 0.6756756756756757, 0.704225352112676)
Performance for  [('ekaw', 'sigkdd')] is : (0.7857142857142857, 1.0, 0.88, 0.9482758620689656, 0.8208955223880596)
Performance for  [('conference', 'edas')] is : (0.8461538461538461, 0.6470588235294118, 0.7333333333333334, 0.6790123456790124, 0.7971014492753623)
Performance for  [('cmt', 'ekaw')] is : (0.5, 0.5454545454545454, 0.5217391304347826, 0.5357142857142857, 0.5084745762711864)
Performance for  [('confOf', 'edas')] is : (0.5714285714285714, 0.631578947368421, 0.6, 0.6185567010309277, 0.5825242718446602)
Performance for  [('iasted', 'sigkdd')] is : (0.5, 0.7333333333333333, 0.5945945945945945, 0.6707317073170731, 0.5339805825242718)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.70251177 0.68280684 0.67622971 0.67681753 0.68703867]
Threshold:  0.9

------------------------------------------------------------
Sender: LSF System <rer@dccxc249>
Subject: Job 4142568: <python main.py 3 9 False False> in cluster <dcc> Done

Job <python main.py 3 9 False False> was submitted from host <dccxl001> by user <naveen9> in cluster <dcc> at Wed Sep 16 06:55:11 2020
Job was executed on host(s) <dccxc249>, in queue <x86_24h>, as user <naveen9> in cluster <dcc> at Wed Sep 16 07:38:30 2020
</u/naveen9> was used as the home directory.
</u/naveen9/arvind/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:38:30 2020
Terminated at Thu Sep 17 00:27:24 2020
Results reported at Thu Sep 17 00:27:24 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 9 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   60452.23 sec.
    Max Memory :                                 2902 MB
    Average Memory :                             2738.16 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40515.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   60559 sec.
    Turnaround time :                            63133 sec.

The output (if any) is above this job summary.

