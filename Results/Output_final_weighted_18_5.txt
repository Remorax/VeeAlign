2020-09-15 15:49:37.332565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.543657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:40.657853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:40.657945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.659936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:40.661481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:40.661830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:40.663804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:40.665189: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:40.665401: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:40.665423: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:40.665732: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:40.672973: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599870000 Hz
2020-09-15 15:49:40.673160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560c7735efe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:40.673179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:40.675098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:40.675124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19255164866298527
Epoch: 0 Idx: 5000 Loss: 0.011055440374050107
Epoch: 1 Idx: 0 Loss: 0.008544003107238372
Epoch: 1 Idx: 5000 Loss: 0.013725813709437606
Epoch: 2 Idx: 0 Loss: 0.011501318177949686
Epoch: 2 Idx: 5000 Loss: 0.01880468735747387
Epoch: 3 Idx: 0 Loss: 0.025938406746709566
Epoch: 3 Idx: 5000 Loss: 0.021088750793957098
Epoch: 4 Idx: 0 Loss: 0.02274374546881673
Epoch: 4 Idx: 5000 Loss: 0.02454423056753382
Epoch: 5 Idx: 0 Loss: 0.023232454454051428
Epoch: 5 Idx: 5000 Loss: 0.006214366372461725
Epoch: 6 Idx: 0 Loss: 0.004404822614049137
Epoch: 6 Idx: 5000 Loss: 0.010015897470516108
Epoch: 7 Idx: 0 Loss: 0.033061570880706256
Epoch: 7 Idx: 5000 Loss: 0.00762144762943341
Epoch: 8 Idx: 0 Loss: 0.02563456866667046
Epoch: 8 Idx: 5000 Loss: 0.005905292183098414
Epoch: 9 Idx: 0 Loss: 0.009382082033634661
Epoch: 9 Idx: 5000 Loss: 0.008949686523894449
Epoch: 10 Idx: 0 Loss: 0.008693097271550036
Epoch: 10 Idx: 5000 Loss: 0.029971984754932086
Epoch: 11 Idx: 0 Loss: 0.00934836245000601
Epoch: 11 Idx: 5000 Loss: 0.012571358883232273
Epoch: 12 Idx: 0 Loss: 0.006115984587241256
Epoch: 12 Idx: 5000 Loss: 0.016455097334221666
Epoch: 13 Idx: 0 Loss: 0.015190947987720664
Epoch: 13 Idx: 5000 Loss: 0.005875349966839828
Epoch: 14 Idx: 0 Loss: 0.01096016062067131
Epoch: 14 Idx: 5000 Loss: 0.01361369174117248
Epoch: 15 Idx: 0 Loss: 0.02595589031094918
Epoch: 15 Idx: 5000 Loss: 0.003919558587775026
Epoch: 16 Idx: 0 Loss: 0.01338899350078978
Epoch: 16 Idx: 5000 Loss: 0.011395528599325232
Epoch: 17 Idx: 0 Loss: 0.029566443245194453
Epoch: 17 Idx: 5000 Loss: 0.02423257757579727
Epoch: 18 Idx: 0 Loss: 0.010930077084054975
Epoch: 18 Idx: 5000 Loss: 0.014492822709110183
Epoch: 19 Idx: 0 Loss: 0.018141924685465438
Epoch: 19 Idx: 5000 Loss: 0.038373517536646785
Epoch: 20 Idx: 0 Loss: 0.011023702265137065
Epoch: 20 Idx: 5000 Loss: 0.024482990121082723
Epoch: 21 Idx: 0 Loss: 0.01758934292308096
Epoch: 21 Idx: 5000 Loss: 0.015663048887972222
Epoch: 22 Idx: 0 Loss: 0.014627993674843133
Epoch: 22 Idx: 5000 Loss: 0.012864547617182958
Epoch: 23 Idx: 0 Loss: 0.011640205008272647
Epoch: 23 Idx: 5000 Loss: 0.01595157462095119
Epoch: 24 Idx: 0 Loss: 0.01412135539867581
Epoch: 24 Idx: 5000 Loss: 0.02184124218559207
Epoch: 25 Idx: 0 Loss: 0.03398589442273926
Epoch: 25 Idx: 5000 Loss: 0.02545920874999477
Epoch: 26 Idx: 0 Loss: 0.011234324593072031
Epoch: 26 Idx: 5000 Loss: 0.012634374553403365
Epoch: 27 Idx: 0 Loss: 0.021091381124419772
Epoch: 27 Idx: 5000 Loss: 0.00487428341577694
Epoch: 28 Idx: 0 Loss: 0.010060883330560304
Epoch: 28 Idx: 5000 Loss: 0.018269155256722663
Epoch: 29 Idx: 0 Loss: 0.006551599345476825
Epoch: 29 Idx: 5000 Loss: 0.006742664253355896
Epoch: 30 Idx: 0 Loss: 0.011414136785915857
Epoch: 30 Idx: 5000 Loss: 0.011820554446286043
Epoch: 31 Idx: 0 Loss: 0.038723779129485776
Epoch: 31 Idx: 5000 Loss: 0.017417449409030512
Epoch: 32 Idx: 0 Loss: 0.012429083282148586
Epoch: 32 Idx: 5000 Loss: 0.010583346131846447
Epoch: 33 Idx: 0 Loss: 0.006767467348920163
Epoch: 33 Idx: 5000 Loss: 0.011940971457277585
Epoch: 34 Idx: 0 Loss: 0.019653066780149834
Epoch: 34 Idx: 5000 Loss: 0.014330433811611129
Epoch: 35 Idx: 0 Loss: 0.007856910447717472
Epoch: 35 Idx: 5000 Loss: 0.013686544707710772
Epoch: 36 Idx: 0 Loss: 0.010882458877698191
Epoch: 36 Idx: 5000 Loss: 0.008046492136753392
Epoch: 37 Idx: 0 Loss: 0.02641241052930345
Epoch: 37 Idx: 5000 Loss: 0.0129038106417533
Epoch: 38 Idx: 0 Loss: 0.015837593627944426
Epoch: 38 Idx: 5000 Loss: 0.023441748693336983
Epoch: 39 Idx: 0 Loss: 0.010299396739874393
Epoch: 39 Idx: 5000 Loss: 0.013780265482405844
Epoch: 40 Idx: 0 Loss: 0.0068853314984859935
Epoch: 40 Idx: 5000 Loss: 0.010427383853305845
Epoch: 41 Idx: 0 Loss: 0.011437016362205428
Epoch: 41 Idx: 5000 Loss: 0.02495523088379918
Epoch: 42 Idx: 0 Loss: 0.012072596417816923
Epoch: 42 Idx: 5000 Loss: 0.02103050750327575
Epoch: 43 Idx: 0 Loss: 0.03981883880181741
Epoch: 43 Idx: 5000 Loss: 0.018119315783396817
Epoch: 44 Idx: 0 Loss: 0.016433442949044662
Epoch: 44 Idx: 5000 Loss: 0.018427923571630474
Epoch: 45 Idx: 0 Loss: 0.004486278815178081
Epoch: 45 Idx: 5000 Loss: 0.012455032586951086
Epoch: 46 Idx: 0 Loss: 0.014193733237512333
Epoch: 46 Idx: 5000 Loss: 0.014059157815694157
Epoch: 47 Idx: 0 Loss: 0.008237979196707126
Epoch: 47 Idx: 5000 Loss: 0.025068880790768744
Epoch: 48 Idx: 0 Loss: 0.012875436023862675
Epoch: 48 Idx: 5000 Loss: 0.03532372631446998
Epoch: 49 Idx: 0 Loss: 0.025098689837974794
Epoch: 49 Idx: 5000 Loss: 0.02462903402792019
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.16069414983742478
Epoch: 0 Idx: 5000 Loss: 0.029921571608229024
Epoch: 1 Idx: 0 Loss: 0.015696478844317477
Epoch: 1 Idx: 5000 Loss: 0.05081844205132858
Epoch: 2 Idx: 0 Loss: 0.0504003881980567
Epoch: 2 Idx: 5000 Loss: 0.013253851380751165
Epoch: 3 Idx: 0 Loss: 0.011793273090499812
Epoch: 3 Idx: 5000 Loss: 0.016503252945316984
Epoch: 4 Idx: 0 Loss: 0.03309998513603031
Epoch: 4 Idx: 5000 Loss: 0.010954050819257943
Epoch: 5 Idx: 0 Loss: 0.02696983643280018
Epoch: 5 Idx: 5000 Loss: 0.016097140209977996
Epoch: 6 Idx: 0 Loss: 0.007957452976403993
Epoch: 6 Idx: 5000 Loss: 0.014997820980403984
Epoch: 7 Idx: 0 Loss: 0.020899353028562915
Epoch: 7 Idx: 5000 Loss: 0.007750955659353977
Epoch: 8 Idx: 0 Loss: 0.03348605766234191
Epoch: 8 Idx: 5000 Loss: 0.030201222165703694
Epoch: 9 Idx: 0 Loss: 0.009931125538557323
Epoch: 9 Idx: 5000 Loss: 0.015630442542570153
Epoch: 10 Idx: 0 Loss: 0.028759320294879324
Epoch: 10 Idx: 5000 Loss: 0.03325045327978737
Epoch: 11 Idx: 0 Loss: 0.01058162359090124
Epoch: 11 Idx: 5000 Loss: 0.011356949405028483
Epoch: 12 Idx: 0 Loss: 0.0062945372787863805
Epoch: 12 Idx: 5000 Loss: 0.02791861936809717
Epoch: 13 Idx: 0 Loss: 0.011439565708038675
Epoch: 13 Idx: 5000 Loss: 0.005637161168863421
Epoch: 14 Idx: 0 Loss: 0.009711332543646655
Epoch: 14 Idx: 5000 Loss: 0.010709283046822279
Epoch: 15 Idx: 0 Loss: 0.017205270377438624
Epoch: 15 Idx: 5000 Loss: 0.020370099657171032
Epoch: 16 Idx: 0 Loss: 0.01473610671348088
Epoch: 16 Idx: 5000 Loss: 0.01815710730315348
Epoch: 17 Idx: 0 Loss: 0.015455250397198724
Epoch: 17 Idx: 5000 Loss: 0.04539670903335194
Epoch: 18 Idx: 0 Loss: 0.015210782426898216
Epoch: 18 Idx: 5000 Loss: 0.010184782271459351
Epoch: 19 Idx: 0 Loss: 0.022355115664586925
Epoch: 19 Idx: 5000 Loss: 0.023558574209277233
Epoch: 20 Idx: 0 Loss: 0.01578894625754029
Epoch: 20 Idx: 5000 Loss: 0.012191256546836497
Epoch: 21 Idx: 0 Loss: 0.017691564480229138
Epoch: 21 Idx: 5000 Loss: 0.023125310572351593
Epoch: 22 Idx: 0 Loss: 0.04076322934710066
Epoch: 22 Idx: 5000 Loss: 0.011643815692974352
Epoch: 23 Idx: 0 Loss: 0.018031175229089574
Epoch: 23 Idx: 5000 Loss: 0.008353783351846496
Epoch: 24 Idx: 0 Loss: 0.007668478447994568
Epoch: 24 Idx: 5000 Loss: 0.021350073972216575
Epoch: 25 Idx: 0 Loss: 0.011913176515791631
Epoch: 25 Idx: 5000 Loss: 0.015870208788625325
Epoch: 26 Idx: 0 Loss: 0.008359834853094371
Epoch: 26 Idx: 5000 Loss: 0.009677300234807909
Epoch: 27 Idx: 0 Loss: 0.016236491014239622
Epoch: 27 Idx: 5000 Loss: 0.010286636423663677
Epoch: 28 Idx: 0 Loss: 0.00975577594475269
Epoch: 28 Idx: 5000 Loss: 0.015904166019612725
Epoch: 29 Idx: 0 Loss: 0.009451891117475894
Epoch: 29 Idx: 5000 Loss: 0.01284810199609147
Epoch: 30 Idx: 0 Loss: 0.012297282541427274
Epoch: 30 Idx: 5000 Loss: 0.01608830901360367
Epoch: 31 Idx: 0 Loss: 0.01465313659878622
Epoch: 31 Idx: 5000 Loss: 0.006289992573330133
Epoch: 32 Idx: 0 Loss: 0.02663948678744931
Epoch: 32 Idx: 5000 Loss: 0.015096385762977671
Epoch: 33 Idx: 0 Loss: 0.011483021846278672
Epoch: 33 Idx: 5000 Loss: 0.01969650658708898
Epoch: 34 Idx: 0 Loss: 0.009756516612447768
Epoch: 34 Idx: 5000 Loss: 0.023812966499167778
Epoch: 35 Idx: 0 Loss: 0.006603161394730914
Epoch: 35 Idx: 5000 Loss: 0.033813500886404446
Epoch: 36 Idx: 0 Loss: 0.010424211853374934
Epoch: 36 Idx: 5000 Loss: 0.006616644014419399
Epoch: 37 Idx: 0 Loss: 0.01369729228904061
Epoch: 37 Idx: 5000 Loss: 0.010002853540709115
Epoch: 38 Idx: 0 Loss: 0.014762945092320469
Epoch: 38 Idx: 5000 Loss: 0.004042279313588325
Epoch: 39 Idx: 0 Loss: 0.017809408544811826
Epoch: 39 Idx: 5000 Loss: 0.023017124625402542
Epoch: 40 Idx: 0 Loss: 0.012060941624076437
Epoch: 40 Idx: 5000 Loss: 0.015072995530124627
Epoch: 41 Idx: 0 Loss: 0.008822896608535021
Epoch: 41 Idx: 5000 Loss: 0.014159212383133932
Epoch: 42 Idx: 0 Loss: 0.012013263193100353
Epoch: 42 Idx: 5000 Loss: 0.015516063299027666
Epoch: 43 Idx: 0 Loss: 0.017609198128609612
Epoch: 43 Idx: 5000 Loss: 0.010541582320183493
Epoch: 44 Idx: 0 Loss: 0.03194837637519744
Epoch: 44 Idx: 5000 Loss: 0.011429586939688059
Epoch: 45 Idx: 0 Loss: 0.016143998804747085
Epoch: 45 Idx: 5000 Loss: 0.010801226472367129
Epoch: 46 Idx: 0 Loss: 0.010585004697299156
Epoch: 46 Idx: 5000 Loss: 0.011052441999895978
Epoch: 47 Idx: 0 Loss: 0.008538206661530066
Epoch: 47 Idx: 5000 Loss: 0.010523456080622925
Epoch: 48 Idx: 0 Loss: 0.011626226382673528
Epoch: 48 Idx: 5000 Loss: 0.017977366543540395
Epoch: 49 Idx: 0 Loss: 0.0140269464293858
Epoch: 49 Idx: 5000 Loss: 0.014806309892520866
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.15819669408391196
Epoch: 0 Idx: 5000 Loss: 0.013755580793568353
Epoch: 1 Idx: 0 Loss: 0.017676114129393034
Epoch: 1 Idx: 5000 Loss: 0.020896035664633782
Epoch: 2 Idx: 0 Loss: 0.04035274808608916
Epoch: 2 Idx: 5000 Loss: 0.013752456988475437
Epoch: 3 Idx: 0 Loss: 0.006768328324110243
Epoch: 3 Idx: 5000 Loss: 0.011580993410949854
Epoch: 4 Idx: 0 Loss: 0.016522188720907112
Epoch: 4 Idx: 5000 Loss: 0.009180257921867706
Epoch: 5 Idx: 0 Loss: 0.011857770513666741
Epoch: 5 Idx: 5000 Loss: 0.006401867787922953
Epoch: 6 Idx: 0 Loss: 0.006322899812296272
Epoch: 6 Idx: 5000 Loss: 0.022516374248568997
Epoch: 7 Idx: 0 Loss: 0.017932807074368482
Epoch: 7 Idx: 5000 Loss: 0.013954349214671655
Epoch: 8 Idx: 0 Loss: 0.013829023271392984
Epoch: 8 Idx: 5000 Loss: 0.0067769628536520415
Epoch: 9 Idx: 0 Loss: 0.03080235370659569
Epoch: 9 Idx: 5000 Loss: 0.020766249338410387
Epoch: 10 Idx: 0 Loss: 0.019444301232856533
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc266>
Subject: Job 4066862: <python main.py 5 18 False True> in cluster <dcc> Exited

Job <python main.py 5 18 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc266>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:35 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 18 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46089.00 sec.
    Max Memory :                                 2979 MB
    Average Memory :                             2750.95 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40438.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46144 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

