2020-09-15 15:49:42.820112: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:46.377854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:46.491840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:46.491919: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:46.493876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:46.495287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:46.495657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:46.497526: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:46.498927: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:46.499199: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:46.499222: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:46.499533: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:46.506405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600130000 Hz
2020-09-15 15:49:46.506586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5646d4bfcb70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:46.506607: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:46.508472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:46.508508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.17556056433433523
Epoch: 0 Idx: 5000 Loss: 0.013093207990857404
Epoch: 1 Idx: 0 Loss: 0.011434127083112582
Epoch: 1 Idx: 5000 Loss: 0.013087725363702191
Epoch: 2 Idx: 0 Loss: 0.01893986951702698
Epoch: 2 Idx: 5000 Loss: 0.022011680663322278
Epoch: 3 Idx: 0 Loss: 0.023141037718810275
Epoch: 3 Idx: 5000 Loss: 0.02456119338771141
Epoch: 4 Idx: 0 Loss: 0.015484219492861013
Epoch: 4 Idx: 5000 Loss: 0.016063360644513868
Epoch: 5 Idx: 0 Loss: 0.026795666032391405
Epoch: 5 Idx: 5000 Loss: 0.008738510097404305
Epoch: 6 Idx: 0 Loss: 0.03518406349912668
Epoch: 6 Idx: 5000 Loss: 0.012937140021370109
Epoch: 7 Idx: 0 Loss: 0.03417281038371285
Epoch: 7 Idx: 5000 Loss: 0.008064628936654493
Epoch: 8 Idx: 0 Loss: 0.018569880840931013
Epoch: 8 Idx: 5000 Loss: 0.016638300329336053
Epoch: 9 Idx: 0 Loss: 0.010372084614787459
Epoch: 9 Idx: 5000 Loss: 0.014324013936360756
Epoch: 10 Idx: 0 Loss: 0.009864250666857269
Epoch: 10 Idx: 5000 Loss: 0.013941451403003631
Epoch: 11 Idx: 0 Loss: 0.017003512585047717
Epoch: 11 Idx: 5000 Loss: 0.027347612362928455
Epoch: 12 Idx: 0 Loss: 0.006719923620265829
Epoch: 12 Idx: 5000 Loss: 0.03217267407069631
Epoch: 13 Idx: 0 Loss: 0.009189606533499888
Epoch: 13 Idx: 5000 Loss: 0.009691082694023972
Epoch: 14 Idx: 0 Loss: 0.02495757000105854
Epoch: 14 Idx: 5000 Loss: 0.008738498650258077
Epoch: 15 Idx: 0 Loss: 0.015982395730742397
Epoch: 15 Idx: 5000 Loss: 0.013498344397870815
Epoch: 16 Idx: 0 Loss: 0.02092004964399642
Epoch: 16 Idx: 5000 Loss: 0.00883157280745642
Epoch: 17 Idx: 0 Loss: 0.010139683382108088
Epoch: 17 Idx: 5000 Loss: 0.010188475145113764
Epoch: 18 Idx: 0 Loss: 0.010748836408745828
Epoch: 18 Idx: 5000 Loss: 0.009275580957051298
Epoch: 19 Idx: 0 Loss: 0.016512595728590405
Epoch: 19 Idx: 5000 Loss: 0.007231014493999627
Epoch: 20 Idx: 0 Loss: 0.0070509860836559845
Epoch: 20 Idx: 5000 Loss: 0.005871889249680406
Epoch: 21 Idx: 0 Loss: 0.015753613166075122
Epoch: 21 Idx: 5000 Loss: 0.01206204581288256
Epoch: 22 Idx: 0 Loss: 0.015806903278705327
Epoch: 22 Idx: 5000 Loss: 0.02090681330619919
Epoch: 23 Idx: 0 Loss: 0.017617010736076515
Epoch: 23 Idx: 5000 Loss: 0.021421971979768827
Epoch: 24 Idx: 0 Loss: 0.01115430849134804
Epoch: 24 Idx: 5000 Loss: 0.011294395612287771
Epoch: 25 Idx: 0 Loss: 0.01865510895355838
Epoch: 25 Idx: 5000 Loss: 0.030565217133306795
Epoch: 26 Idx: 0 Loss: 0.011367955365300464
Epoch: 26 Idx: 5000 Loss: 0.020746667525448396
Epoch: 27 Idx: 0 Loss: 0.009116050396122673
Epoch: 27 Idx: 5000 Loss: 0.011157495426421648
Epoch: 28 Idx: 0 Loss: 0.014974507665932042
Epoch: 28 Idx: 5000 Loss: 0.023088428679678103
Epoch: 29 Idx: 0 Loss: 0.030101978664725127
Epoch: 29 Idx: 5000 Loss: 0.007099131115447629
Epoch: 30 Idx: 0 Loss: 0.010595709069383088
Epoch: 30 Idx: 5000 Loss: 0.02445429269850384
Epoch: 31 Idx: 0 Loss: 0.02079113453897269
Epoch: 31 Idx: 5000 Loss: 0.031077565271247252
Epoch: 32 Idx: 0 Loss: 0.00865960088422779
Epoch: 32 Idx: 5000 Loss: 0.01381235910311656
Epoch: 33 Idx: 0 Loss: 0.026983251790652984
Epoch: 33 Idx: 5000 Loss: 0.005863806938181894
Epoch: 34 Idx: 0 Loss: 0.0053808966121177675
Epoch: 34 Idx: 5000 Loss: 0.005804856779532811
Epoch: 35 Idx: 0 Loss: 0.019637893112414234
Epoch: 35 Idx: 5000 Loss: 0.028386677033734577
Epoch: 36 Idx: 0 Loss: 0.009849368655573234
Epoch: 36 Idx: 5000 Loss: 0.01200314763441921
Epoch: 37 Idx: 0 Loss: 0.024401342444965425
Epoch: 37 Idx: 5000 Loss: 0.0121617993041977
Epoch: 38 Idx: 0 Loss: 0.01179249958729942
Epoch: 38 Idx: 5000 Loss: 0.024989605800471895
Epoch: 39 Idx: 0 Loss: 0.015797231503422625
Epoch: 39 Idx: 5000 Loss: 0.00816710869002138
Epoch: 40 Idx: 0 Loss: 0.011048669970574519
Epoch: 40 Idx: 5000 Loss: 0.011293578165776186
Epoch: 41 Idx: 0 Loss: 0.022459011899709457
Epoch: 41 Idx: 5000 Loss: 0.007757563693329989
Epoch: 42 Idx: 0 Loss: 0.01482341416411641
Epoch: 42 Idx: 5000 Loss: 0.007458366562791381
Epoch: 43 Idx: 0 Loss: 0.03201161420287621
Epoch: 43 Idx: 5000 Loss: 0.014099327760448368
Epoch: 44 Idx: 0 Loss: 0.016697947949896125
Epoch: 44 Idx: 5000 Loss: 0.020482198886967527
Epoch: 45 Idx: 0 Loss: 0.010385098735416015
Epoch: 45 Idx: 5000 Loss: 0.02878264192184465
Epoch: 46 Idx: 0 Loss: 0.014153731750983944
Epoch: 46 Idx: 5000 Loss: 0.029937184615948447
Epoch: 47 Idx: 0 Loss: 0.007801230040806361
Epoch: 47 Idx: 5000 Loss: 0.011804623055268082
Epoch: 48 Idx: 0 Loss: 0.011290223111665266
Epoch: 48 Idx: 5000 Loss: 0.02113636958605236
Epoch: 49 Idx: 0 Loss: 0.050559019616592565
Epoch: 49 Idx: 5000 Loss: 0.014340398656315853
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1470644767317019
Epoch: 0 Idx: 5000 Loss: 0.009253242103535904
Epoch: 1 Idx: 0 Loss: 0.014037595340533348
Epoch: 1 Idx: 5000 Loss: 0.01824069796972582
Epoch: 2 Idx: 0 Loss: 0.014599257078472854
Epoch: 2 Idx: 5000 Loss: 0.005949872586422421
Epoch: 3 Idx: 0 Loss: 0.01561315082693156
Epoch: 3 Idx: 5000 Loss: 0.013123197472229634
Epoch: 4 Idx: 0 Loss: 0.006931720527309906
Epoch: 4 Idx: 5000 Loss: 0.01489736344422831
Epoch: 5 Idx: 0 Loss: 0.03782262063622627
Epoch: 5 Idx: 5000 Loss: 0.014300239275832521
Epoch: 6 Idx: 0 Loss: 0.00957548438463604
Epoch: 6 Idx: 5000 Loss: 0.011229968922859403
Epoch: 7 Idx: 0 Loss: 0.0075155370607982806
Epoch: 7 Idx: 5000 Loss: 0.007874599513187926
Epoch: 8 Idx: 0 Loss: 0.021691216503410566
Epoch: 8 Idx: 5000 Loss: 0.03181456342128884
Epoch: 9 Idx: 0 Loss: 0.01069781540804031
Epoch: 9 Idx: 5000 Loss: 0.0471351940031122
Epoch: 10 Idx: 0 Loss: 0.013005753754612862
Epoch: 10 Idx: 5000 Loss: 0.0119511280189013
Epoch: 11 Idx: 0 Loss: 0.019157750978933154
Epoch: 11 Idx: 5000 Loss: 0.007682011371806021
Epoch: 12 Idx: 0 Loss: 0.006574069819891798
Epoch: 12 Idx: 5000 Loss: 0.010282103964776303
Epoch: 13 Idx: 0 Loss: 0.02703345425551344
Epoch: 13 Idx: 5000 Loss: 0.014676940484359587
Epoch: 14 Idx: 0 Loss: 0.02299411314338716
Epoch: 14 Idx: 5000 Loss: 0.006874485889560893
Epoch: 15 Idx: 0 Loss: 0.014073455848658578
Epoch: 15 Idx: 5000 Loss: 0.011385496439140625
Epoch: 16 Idx: 0 Loss: 0.016937810834387713
Epoch: 16 Idx: 5000 Loss: 0.009018407918767155
Epoch: 17 Idx: 0 Loss: 0.008852566952647772
Epoch: 17 Idx: 5000 Loss: 0.03198212374923899
Epoch: 18 Idx: 0 Loss: 0.008488283754967345
Epoch: 18 Idx: 5000 Loss: 0.018192961300680134
Epoch: 19 Idx: 0 Loss: 0.026292445304155896
Epoch: 19 Idx: 5000 Loss: 0.0163928515935272
Epoch: 20 Idx: 0 Loss: 0.019523340871963574
Epoch: 20 Idx: 5000 Loss: 0.006471600658502501
Epoch: 21 Idx: 0 Loss: 0.008439861316563522
Epoch: 21 Idx: 5000 Loss: 0.018000943722604832
Epoch: 22 Idx: 0 Loss: 0.005959035759610607
Epoch: 22 Idx: 5000 Loss: 0.020140080782029394
Epoch: 23 Idx: 0 Loss: 0.01143233365834199
Epoch: 23 Idx: 5000 Loss: 0.008062144171991767
Epoch: 24 Idx: 0 Loss: 0.02134380684524438
Epoch: 24 Idx: 5000 Loss: 0.014999066222157168
Epoch: 25 Idx: 0 Loss: 0.0075309301453948705
Epoch: 25 Idx: 5000 Loss: 0.033434767817744813
Epoch: 26 Idx: 0 Loss: 0.012867371681665489
Epoch: 26 Idx: 5000 Loss: 0.0061868480714660995
Epoch: 27 Idx: 0 Loss: 0.013765991833560766
Epoch: 27 Idx: 5000 Loss: 0.00983032377175955
Epoch: 28 Idx: 0 Loss: 0.008851137114305026
Epoch: 28 Idx: 5000 Loss: 0.02185074892544095
Epoch: 29 Idx: 0 Loss: 0.019702894829817005
Epoch: 29 Idx: 5000 Loss: 0.017849937647210875
Epoch: 30 Idx: 0 Loss: 0.01561837886958143
Epoch: 30 Idx: 5000 Loss: 0.01804099916582674
Epoch: 31 Idx: 0 Loss: 0.008580605013548341
Epoch: 31 Idx: 5000 Loss: 0.012287005793860259
Epoch: 32 Idx: 0 Loss: 0.018105718023099373
Epoch: 32 Idx: 5000 Loss: 0.024421878955516226
Epoch: 33 Idx: 0 Loss: 0.029239947542532563
Epoch: 33 Idx: 5000 Loss: 0.028995978148110883
Epoch: 34 Idx: 0 Loss: 0.0038282869835327736
Epoch: 34 Idx: 5000 Loss: 0.009580724266978643
Epoch: 35 Idx: 0 Loss: 0.03162721578551669
Epoch: 35 Idx: 5000 Loss: 0.024894965825687898
Epoch: 36 Idx: 0 Loss: 0.02730310444481953
Epoch: 36 Idx: 5000 Loss: 0.011077618423723137
Epoch: 37 Idx: 0 Loss: 0.003824552288007833
Epoch: 37 Idx: 5000 Loss: 0.010456635838580381
Epoch: 38 Idx: 0 Loss: 0.018287045232498952
Epoch: 38 Idx: 5000 Loss: 0.012820528562223196
Epoch: 39 Idx: 0 Loss: 0.01724627819711299
Epoch: 39 Idx: 5000 Loss: 0.022337973493821984
Epoch: 40 Idx: 0 Loss: 0.018286860784187873
Epoch: 40 Idx: 5000 Loss: 0.013596192744182604
Epoch: 41 Idx: 0 Loss: 0.02563331837894037
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 336, in forward
    attended_path = node_weights.unsqueeze(-1) * best_path # dim: (batch_size, 4, max_pathlen, 512)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc201>
Subject: Job 4066917: <python main.py 38 2 True False> in cluster <dcc> Exited

Job <python main.py 38 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:42 2020
Job was executed on host(s) <dccxc201>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 38 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46134.70 sec.
    Max Memory :                                 2950 MB
    Average Memory :                             2739.18 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40467.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46139 sec.
    Turnaround time :                            46197 sec.

The output (if any) is above this job summary.

