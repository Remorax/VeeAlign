2020-09-15 15:49:41.960559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.065703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.185694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.185797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.187915: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.189385: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.189870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.191773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.193284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.193587: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.193611: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.193945: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.201489: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600065000 Hz
2020-09-15 15:49:45.201677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe63f85510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.201697: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.203640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.203679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.2241736984884452
Epoch: 0 Idx: 5000 Loss: 0.011683388512374833
Epoch: 1 Idx: 0 Loss: 0.014512113733250414
Epoch: 1 Idx: 5000 Loss: 0.010669053966607861
Epoch: 2 Idx: 0 Loss: 0.01319713105033865
Epoch: 2 Idx: 5000 Loss: 0.020727045531059196
Epoch: 3 Idx: 0 Loss: 0.012316164690779752
Epoch: 3 Idx: 5000 Loss: 0.026358900387013058
Epoch: 4 Idx: 0 Loss: 0.010829455732572432
Epoch: 4 Idx: 5000 Loss: 0.009314204605227925
Epoch: 5 Idx: 0 Loss: 0.017089032412938774
Epoch: 5 Idx: 5000 Loss: 0.018145789713409723
Epoch: 6 Idx: 0 Loss: 0.010543069043935281
Epoch: 6 Idx: 5000 Loss: 0.01212757640918442
Epoch: 7 Idx: 0 Loss: 0.025036673485156376
Epoch: 7 Idx: 5000 Loss: 0.03445294413748186
Epoch: 8 Idx: 0 Loss: 0.0331499491075538
Epoch: 8 Idx: 5000 Loss: 0.007695129393425974
Epoch: 9 Idx: 0 Loss: 0.011350725327202969
Epoch: 9 Idx: 5000 Loss: 0.01823655176423848
Epoch: 10 Idx: 0 Loss: 0.007211033397647759
Epoch: 10 Idx: 5000 Loss: 0.012851395363046598
Epoch: 11 Idx: 0 Loss: 0.019285914902830464
Epoch: 11 Idx: 5000 Loss: 0.009937316689570076
Epoch: 12 Idx: 0 Loss: 0.004194726590085592
Epoch: 12 Idx: 5000 Loss: 0.005633559609836478
Epoch: 13 Idx: 0 Loss: 0.03742849763297966
Epoch: 13 Idx: 5000 Loss: 0.0036272128174061847
Epoch: 14 Idx: 0 Loss: 0.025606759192042493
Epoch: 14 Idx: 5000 Loss: 0.01665928871002969
Epoch: 15 Idx: 0 Loss: 0.014075655779942624
Epoch: 15 Idx: 5000 Loss: 0.014536004434713253
Epoch: 16 Idx: 0 Loss: 0.01105010801566856
Epoch: 16 Idx: 5000 Loss: 0.01581634668480361
Epoch: 17 Idx: 0 Loss: 0.013454859396646425
Epoch: 17 Idx: 5000 Loss: 0.013511032297174135
Epoch: 18 Idx: 0 Loss: 0.02226079440577306
Epoch: 18 Idx: 5000 Loss: 0.007281740229820324
Epoch: 19 Idx: 0 Loss: 0.007592298808129462
Epoch: 19 Idx: 5000 Loss: 0.033247994789323235
Epoch: 20 Idx: 0 Loss: 0.009128415749748668
Epoch: 20 Idx: 5000 Loss: 0.02312096152643423
Epoch: 21 Idx: 0 Loss: 0.011383609919063805
Epoch: 21 Idx: 5000 Loss: 0.01398901917453851
Epoch: 22 Idx: 0 Loss: 0.019777181122133006
Epoch: 22 Idx: 5000 Loss: 0.009273588292444405
Epoch: 23 Idx: 0 Loss: 0.01961002576726342
Epoch: 23 Idx: 5000 Loss: 0.01877405815395388
Epoch: 24 Idx: 0 Loss: 0.010724122903791915
Epoch: 24 Idx: 5000 Loss: 0.011488771109609759
Epoch: 25 Idx: 0 Loss: 0.0117777926876033
Epoch: 25 Idx: 5000 Loss: 0.02760495683820766
Epoch: 26 Idx: 0 Loss: 0.010638105648423518
Epoch: 26 Idx: 5000 Loss: 0.027124498126432927
Epoch: 27 Idx: 0 Loss: 0.010260001586416632
Epoch: 27 Idx: 5000 Loss: 0.03760162029757288
Epoch: 28 Idx: 0 Loss: 0.024595639334772216
Epoch: 28 Idx: 5000 Loss: 0.01729370401283267
Epoch: 29 Idx: 0 Loss: 0.011617501917841926
Epoch: 29 Idx: 5000 Loss: 0.009350566582300554
Epoch: 30 Idx: 0 Loss: 0.031411765670201625
Epoch: 30 Idx: 5000 Loss: 0.020278102744664475
Epoch: 31 Idx: 0 Loss: 0.015160314534544974
Epoch: 31 Idx: 5000 Loss: 0.019929127854400003
Epoch: 32 Idx: 0 Loss: 0.036274999059840496
Epoch: 32 Idx: 5000 Loss: 0.010865066695873414
Epoch: 33 Idx: 0 Loss: 0.01530169029082478
Epoch: 33 Idx: 5000 Loss: 0.01281785775356744
Epoch: 34 Idx: 0 Loss: 0.02096144669001397
Epoch: 34 Idx: 5000 Loss: 0.02887862819103121
Epoch: 35 Idx: 0 Loss: 0.030253913783986543
Epoch: 35 Idx: 5000 Loss: 0.00977796539521219
Epoch: 36 Idx: 0 Loss: 0.019043497649623566
Epoch: 36 Idx: 5000 Loss: 0.011600674522690129
Epoch: 37 Idx: 0 Loss: 0.009341884462371103
Epoch: 37 Idx: 5000 Loss: 0.021971195885962448
Epoch: 38 Idx: 0 Loss: 0.018651796528190708
Epoch: 38 Idx: 5000 Loss: 0.034071726402973526
Epoch: 39 Idx: 0 Loss: 0.013563383894654456
Epoch: 39 Idx: 5000 Loss: 0.009779568225898677
Epoch: 40 Idx: 0 Loss: 0.005659258390619522
Epoch: 40 Idx: 5000 Loss: 0.01745986101118014
Epoch: 41 Idx: 0 Loss: 0.011128360672175673
Epoch: 41 Idx: 5000 Loss: 0.010873904430416963
Epoch: 42 Idx: 0 Loss: 0.01445849419472978
Epoch: 42 Idx: 5000 Loss: 0.02140663552343592
Epoch: 43 Idx: 0 Loss: 0.01059174551792312
Epoch: 43 Idx: 5000 Loss: 0.023386624999412898
Epoch: 44 Idx: 0 Loss: 0.010302093484308227
Epoch: 44 Idx: 5000 Loss: 0.016983180096481528
Epoch: 45 Idx: 0 Loss: 0.01540111766135201
Epoch: 45 Idx: 5000 Loss: 0.023909027678996192
Epoch: 46 Idx: 0 Loss: 0.030021550154127576
Epoch: 46 Idx: 5000 Loss: 0.0177262640712039
Epoch: 47 Idx: 0 Loss: 0.026604908129595903
Epoch: 47 Idx: 5000 Loss: 0.01546046620778465
Epoch: 48 Idx: 0 Loss: 0.013058667477404732
Epoch: 48 Idx: 5000 Loss: 0.02215114515837946
Epoch: 49 Idx: 0 Loss: 0.009649901880875424
Epoch: 49 Idx: 5000 Loss: 0.016313452421356383
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.16830751547715367
Epoch: 0 Idx: 5000 Loss: 0.026422076665338218
Epoch: 1 Idx: 0 Loss: 0.021536832836321865
Epoch: 1 Idx: 5000 Loss: 0.02280358978482166
Epoch: 2 Idx: 0 Loss: 0.011776042774453026
Epoch: 2 Idx: 5000 Loss: 0.007755272295291292
Epoch: 3 Idx: 0 Loss: 0.007756577977016265
Epoch: 3 Idx: 5000 Loss: 0.010154042348603523
Epoch: 4 Idx: 0 Loss: 0.02506104815046413
Epoch: 4 Idx: 5000 Loss: 0.011733644522750782
Epoch: 5 Idx: 0 Loss: 0.009165596958618922
Epoch: 5 Idx: 5000 Loss: 0.01149543160073686
Epoch: 6 Idx: 0 Loss: 0.010700958211129978
Epoch: 6 Idx: 5000 Loss: 0.018089223799870734
Epoch: 7 Idx: 0 Loss: 0.02098355682394468
Epoch: 7 Idx: 5000 Loss: 0.008266340064496237
Epoch: 8 Idx: 0 Loss: 0.009704047168551833
Epoch: 8 Idx: 5000 Loss: 0.033434849906810366
Epoch: 9 Idx: 0 Loss: 0.01671077457300895
Epoch: 9 Idx: 5000 Loss: 0.006172143744439955
Epoch: 10 Idx: 0 Loss: 0.008450288034043454
Epoch: 10 Idx: 5000 Loss: 0.01199799796285735
Epoch: 11 Idx: 0 Loss: 0.013175860734441656
Epoch: 11 Idx: 5000 Loss: 0.005938274643149782
Epoch: 12 Idx: 0 Loss: 0.017807836746641395
Epoch: 12 Idx: 5000 Loss: 0.011904506737077637
Epoch: 13 Idx: 0 Loss: 0.013304941879247696
Epoch: 13 Idx: 5000 Loss: 0.014826502232290754
Epoch: 14 Idx: 0 Loss: 0.014182297968614976
Epoch: 14 Idx: 5000 Loss: 0.01069798522974905
Epoch: 15 Idx: 0 Loss: 0.03949566881525079
Epoch: 15 Idx: 5000 Loss: 0.015379131058871077
Epoch: 16 Idx: 0 Loss: 0.01246668656474257
Epoch: 16 Idx: 5000 Loss: 0.011130615106152136
Epoch: 17 Idx: 0 Loss: 0.015597311297242402
Epoch: 17 Idx: 5000 Loss: 0.014593390434697975
Epoch: 18 Idx: 0 Loss: 0.032661831422432466
Epoch: 18 Idx: 5000 Loss: 0.019394211220315094
Epoch: 19 Idx: 0 Loss: 0.011005561305993016
Epoch: 19 Idx: 5000 Loss: 0.003946116544270999
Epoch: 20 Idx: 0 Loss: 0.02878333794235889
Epoch: 20 Idx: 5000 Loss: 0.007121462011423601
Epoch: 21 Idx: 0 Loss: 0.006104071944535859
Epoch: 21 Idx: 5000 Loss: 0.012315045593987254
Epoch: 22 Idx: 0 Loss: 0.011927321048052449
Epoch: 22 Idx: 5000 Loss: 0.015703753893990372
Epoch: 23 Idx: 0 Loss: 0.017145107966332205
Epoch: 23 Idx: 5000 Loss: 0.019169607042012853
Epoch: 24 Idx: 0 Loss: 0.009570608385337567
Epoch: 24 Idx: 5000 Loss: 0.016084450628309745
Epoch: 25 Idx: 0 Loss: 0.026121036452492724
Epoch: 25 Idx: 5000 Loss: 0.012231273802684583
Epoch: 26 Idx: 0 Loss: 0.031822327195238295
Epoch: 26 Idx: 5000 Loss: 0.02026982812700668
Epoch: 27 Idx: 0 Loss: 0.010505486594454503
Epoch: 27 Idx: 5000 Loss: 0.016578957033330278
Epoch: 28 Idx: 0 Loss: 0.022305402006523405
Epoch: 28 Idx: 5000 Loss: 0.014623492492075191
Epoch: 29 Idx: 0 Loss: 0.012281847524027438
Epoch: 29 Idx: 5000 Loss: 0.010430445147311828
Epoch: 30 Idx: 0 Loss: 0.038935864503597206
Epoch: 30 Idx: 5000 Loss: 0.012395336661510208
Epoch: 31 Idx: 0 Loss: 0.011957503195926027
Epoch: 31 Idx: 5000 Loss: 0.007402098116737667
Epoch: 32 Idx: 0 Loss: 0.02084380942221866
Epoch: 32 Idx: 5000 Loss: 0.014634413289523276
Epoch: 33 Idx: 0 Loss: 0.015985340708182364
Epoch: 33 Idx: 5000 Loss: 0.011586681141658228
Epoch: 34 Idx: 0 Loss: 0.012574785817574803
Epoch: 34 Idx: 5000 Loss: 0.008776479596537197
Epoch: 35 Idx: 0 Loss: 0.021832345354399985
Epoch: 35 Idx: 5000 Loss: 0.015103691436333694
Epoch: 36 Idx: 0 Loss: 0.013252496461146818
Epoch: 36 Idx: 5000 Loss: 0.0318817572945317
Epoch: 37 Idx: 0 Loss: 0.025642345668026974
Epoch: 37 Idx: 5000 Loss: 0.022034004361349252
Epoch: 38 Idx: 0 Loss: 0.015324088850632078
Epoch: 38 Idx: 5000 Loss: 0.017936139853520265
Epoch: 39 Idx: 0 Loss: 0.021283599923848404
Epoch: 39 Idx: 5000 Loss: 0.01033147184467062
Epoch: 40 Idx: 0 Loss: 0.011155651863309001
Epoch: 40 Idx: 5000 Loss: 0.0278657227148756
Epoch: 41 Idx: 0 Loss: 0.030831076730054415
Epoch: 41 Idx: 5000 Loss: 0.010646061616733028
Epoch: 42 Idx: 0 Loss: 0.014582251124222992
Epoch: 42 Idx: 5000 Loss: 0.02051537231817576
Epoch: 43 Idx: 0 Loss: 0.018548460538326712
Epoch: 43 Idx: 5000 Loss: 0.021202767750283742
Epoch: 44 Idx: 0 Loss: 0.0145401169806379
Epoch: 44 Idx: 5000 Loss: 0.016477346425747642
Epoch: 45 Idx: 0 Loss: 0.009338232023060488
Epoch: 45 Idx: 5000 Loss: 0.013643080741457913
Epoch: 46 Idx: 0 Loss: 0.0104154359343121
Epoch: 46 Idx: 5000 Loss: 0.018588998314341864
Epoch: 47 Idx: 0 Loss: 0.006345969221532781
Epoch: 47 Idx: 5000 Loss: 0.021787452147995406
Epoch: 48 Idx: 0 Loss: 0.012053380132878133
Epoch: 48 Idx: 5000 Loss: 0.008085205980803851
Epoch: 49 Idx: 0 Loss: 0.013850552523968983
Epoch: 49 Idx: 5000 Loss: 0.006735202685528362
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14076805224104855
Epoch: 0 Idx: 5000 Loss: 0.01614106566728922
Epoch: 1 Idx: 0 Loss: 0.01631941242120586
Epoch: 1 Idx: 5000 Loss: 0.016664035651413178
Epoch: 2 Idx: 0 Loss: 0.04994978824437517
Epoch: 2 Idx: 5000 Loss: 0.016198328746984306
Epoch: 3 Idx: 0 Loss: 0.01702180721861682
Epoch: 3 Idx: 5000 Loss: 0.016204563774390085
Epoch: 4 Idx: 0 Loss: 0.029891202056007055
Epoch: 4 Idx: 5000 Loss: 0.009873773019248765
Epoch: 5 Idx: 0 Loss: 0.029542893762407454
Epoch: 5 Idx: 5000 Loss: 0.015009799265582683
Epoch: 6 Idx: 0 Loss: 0.010219196193404117
Epoch: 6 Idx: 5000 Loss: 0.009919944108258184
Epoch: 7 Idx: 0 Loss: 0.010692179193961962
Epoch: 7 Idx: 5000 Loss: 0.008893331816189374
Epoch: 8 Idx: 0 Loss: 0.020555735029813872
Epoch: 8 Idx: 5000 Loss: 0.01159310955976932
Epoch: 9 Idx: 0 Loss: 0.01521146525196411
Epoch: 9 Idx: 5000 Loss: 0.00909237551897513
Epoch: 10 Idx: 0 Loss: 0.015379731321968595
Epoch: 10 Idx: 5000 Loss: 0.009883192838802908
Epoch: 11 Idx: 0 Loss: 0.012177074721180821
Epoch: 11 Idx: 5000 Loss: 0.018279626797732547
Epoch: 12 Idx: 0 Loss: 0.01077398736229803
Epoch: 12 Idx: 5000 Loss: 0.024899969318850936
Epoch: 13 Idx: 0 Loss: 0.007728943645886884
Epoch: 13 Idx: 5000 Loss: 0.010339432978482214
Epoch: 14 Idx: 0 Loss: 0.03391430704719955
Epoch: 14 Idx: 5000 Loss: 0.009005620690990436
Epoch: 15 Idx: 0 Loss: 0.020984488488934208
Epoch: 15 Idx: 5000 Loss: 0.018104232806329057
Epoch: 16 Idx: 0 Loss: 0.015565781457795948
Epoch: 16 Idx: 5000 Loss: 0.010282875811801455
Epoch: 17 Idx: 0 Loss: 0.022529604888007655
Epoch: 17 Idx: 5000 Loss: 0.01762844271521808
Epoch: 18 Idx: 0 Loss: 0.023874271712631866
Epoch: 18 Idx: 5000 Loss: 0.012296505962194842
Epoch: 19 Idx: 0 Loss: 0.012322642536670949
Epoch: 19 Idx: 5000 Loss: 0.010796258806057309
Epoch: 20 Idx: 0 Loss: 0.010881829577445018
Epoch: 20 Idx: 5000 Loss: 0.011539950953907821
Epoch: 21 Idx: 0 Loss: 0.00759981277140637
Epoch: 21 Idx: 5000 Loss: 0.0065736470935554275
Epoch: 22 Idx: 0 Loss: 0.010374442402693435
Epoch: 22 Idx: 5000 Loss: 0.015029998952956144
Epoch: 23 Idx: 0 Loss: 0.02935058082728919
Epoch: 23 Idx: 5000 Loss: 0.010590811218878527
Epoch: 24 Idx: 0 Loss: 0.004482546658296966
Epoch: 24 Idx: 5000 Loss: 0.01337572131049857
Epoch: 25 Idx: 0 Loss: 0.04789537804791499
Epoch: 25 Idx: 5000 Loss: 0.010131738032874902
Epoch: 26 Idx: 0 Loss: 0.016340732800117136
Epoch: 26 Idx: 5000 Loss: 0.03255976233570041
Epoch: 27 Idx: 0 Loss: 0.00633051113567964
Epoch: 27 Idx: 5000 Loss: 0.010738362527335945
Epoch: 28 Idx: 0 Loss: 0.024181559785687312
Epoch: 28 Idx: 5000 Loss: 0.019484799545435385
Epoch: 29 Idx: 0 Loss: 0.017772392403272576
Epoch: 29 Idx: 5000 Loss: 0.016882233385327853
Epoch: 30 Idx: 0 Loss: 0.008089429831537485
Epoch: 30 Idx: 5000 Loss: 0.01009600803189134
Epoch: 31 Idx: 0 Loss: 0.012990956188231033
Epoch: 31 Idx: 5000 Loss: 0.01905969575160636
Epoch: 32 Idx: 0 Loss: 0.005106215286503294
Epoch: 32 Idx: 5000 Loss: 0.05879483914318019
Epoch: 33 Idx: 0 Loss: 0.04438397327566717
Epoch: 33 Idx: 5000 Loss: 0.008470311614577591
Epoch: 34 Idx: 0 Loss: 0.017336762196746312
Epoch: 34 Idx: 5000 Loss: 0.01071526973079625
Epoch: 35 Idx: 0 Loss: 0.012772174085962018
Epoch: 35 Idx: 5000 Loss: 0.009700704014492387
Epoch: 36 Idx: 0 Loss: 0.029019609432056732
Epoch: 36 Idx: 5000 Loss: 0.0060723750611097055
Epoch: 37 Idx: 0 Loss: 0.02366852012917362
Epoch: 37 Idx: 5000 Loss: 0.007272433411329635
Epoch: 38 Idx: 0 Loss: 0.010698610555852993
Epoch: 38 Idx: 5000 Loss: 0.013374830296675681
Epoch: 39 Idx: 0 Loss: 0.03916480159856224
Epoch: 39 Idx: 5000 Loss: 0.015195865744295472
Epoch: 40 Idx: 0 Loss: 0.017253137368890004
Epoch: 40 Idx: 5000 Loss: 0.011361940099486607
Epoch: 41 Idx: 0 Loss: 0.02482623202336573
Epoch: 41 Idx: 5000 Loss: 0.01660837796193371
Epoch: 42 Idx: 0 Loss: 0.013980493004638724
Epoch: 42 Idx: 5000 Loss: 0.016578704194103153
Epoch: 43 Idx: 0 Loss: 0.013967751807085683
Epoch: 43 Idx: 5000 Loss: 0.038195186853114745
Epoch: 44 Idx: 0 Loss: 0.013558557004137984
Epoch: 44 Idx: 5000 Loss: 0.008433785872856061
Epoch: 45 Idx: 0 Loss: 0.01633464809825543
Epoch: 45 Idx: 5000 Loss: 0.025442599641338166
Epoch: 46 Idx: 0 Loss: 0.015938982637695547
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 330, in forward
    best_path = torch.gather(feature_emb, 2, best_path_indices).squeeze(2)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc230>
Subject: Job 4066901: <python main.py 18 2 True False> in cluster <dcc> Exited

Job <python main.py 18 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc230>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 18 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46081.19 sec.
    Max Memory :                                 2853 MB
    Average Memory :                             2675.03 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40564.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46140 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

