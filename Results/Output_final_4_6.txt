2020-09-15 15:49:39.716635: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:44.150149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:57.604726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:57.604838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:57.607049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:57.608599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:57.609034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:57.611065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:57.612627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:57.612933: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:57.612956: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:57.613267: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:57.620303: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600135000 Hz
2020-09-15 15:49:57.620507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bc6d5ed1f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:57.620527: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:57.622393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:57.622422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20078423238195348
Epoch: 0 Idx: 5000 Loss: 0.00690989472177769
Epoch: 1 Idx: 0 Loss: 0.010200593524621836
Epoch: 1 Idx: 5000 Loss: 0.0099136319196424
Epoch: 2 Idx: 0 Loss: 0.006145119128897227
Epoch: 2 Idx: 5000 Loss: 0.019521786500507253
Epoch: 3 Idx: 0 Loss: 0.016622712746417856
Epoch: 3 Idx: 5000 Loss: 0.012920919581525187
Epoch: 4 Idx: 0 Loss: 0.006348555147110911
Epoch: 4 Idx: 5000 Loss: 0.019861941144836845
Epoch: 5 Idx: 0 Loss: 0.014082097214856334
Epoch: 5 Idx: 5000 Loss: 0.026551881433620125
Epoch: 6 Idx: 0 Loss: 0.00845938006769472
Epoch: 6 Idx: 5000 Loss: 0.014946910025372365
Epoch: 7 Idx: 0 Loss: 0.012743550081488704
Epoch: 7 Idx: 5000 Loss: 0.009270021384451698
Epoch: 8 Idx: 0 Loss: 0.015270664885991924
Epoch: 8 Idx: 5000 Loss: 0.02042405172189164
Epoch: 9 Idx: 0 Loss: 0.03036021312330693
Epoch: 9 Idx: 5000 Loss: 0.008135006185640711
Epoch: 10 Idx: 0 Loss: 0.0075585265179982765
Epoch: 10 Idx: 5000 Loss: 0.016110928182777116
Epoch: 11 Idx: 0 Loss: 0.013806532410399343
Epoch: 11 Idx: 5000 Loss: 0.014028384133199102
Epoch: 12 Idx: 0 Loss: 0.012744389302350483
Epoch: 12 Idx: 5000 Loss: 0.012475986218742777
Epoch: 13 Idx: 0 Loss: 0.008656458224284997
Epoch: 13 Idx: 5000 Loss: 0.006693684895845374
Epoch: 14 Idx: 0 Loss: 0.025893922409806813
Epoch: 14 Idx: 5000 Loss: 0.009002024408685656
Epoch: 15 Idx: 0 Loss: 0.03908511961220005
Epoch: 15 Idx: 5000 Loss: 0.020336885987775964
Epoch: 16 Idx: 0 Loss: 0.024410889432315917
Epoch: 16 Idx: 5000 Loss: 0.005920184978571042
Epoch: 17 Idx: 0 Loss: 0.028862127446841898
Epoch: 17 Idx: 5000 Loss: 0.004868364537756195
Epoch: 18 Idx: 0 Loss: 0.018762159952063016
Epoch: 18 Idx: 5000 Loss: 0.00703426117539192
Epoch: 19 Idx: 0 Loss: 0.01929200472244164
Epoch: 19 Idx: 5000 Loss: 0.00926444162741432
Epoch: 20 Idx: 0 Loss: 0.01005967917399581
Epoch: 20 Idx: 5000 Loss: 0.011518916574437425
Epoch: 21 Idx: 0 Loss: 0.02923944495275707
Epoch: 21 Idx: 5000 Loss: 0.018541932037473275
Epoch: 22 Idx: 0 Loss: 0.03048819740205022
Epoch: 22 Idx: 5000 Loss: 0.025191629619216015
Epoch: 23 Idx: 0 Loss: 0.009026403522667453
Epoch: 23 Idx: 5000 Loss: 0.008837477413446707
Epoch: 24 Idx: 0 Loss: 0.009321026881297491
Epoch: 24 Idx: 5000 Loss: 0.019018268283670703
Epoch: 25 Idx: 0 Loss: 0.013540146358056343
Epoch: 25 Idx: 5000 Loss: 0.016036619804408323
Epoch: 26 Idx: 0 Loss: 0.008985536768674276
Epoch: 26 Idx: 5000 Loss: 0.009496369501109717
Epoch: 27 Idx: 0 Loss: 0.009161808493765407
Epoch: 27 Idx: 5000 Loss: 0.01356522081455279
Epoch: 28 Idx: 0 Loss: 0.008960719104270813
Epoch: 28 Idx: 5000 Loss: 0.026002305111785078
Epoch: 29 Idx: 0 Loss: 0.023652376808854212
Epoch: 29 Idx: 5000 Loss: 0.005188258015027549
Epoch: 30 Idx: 0 Loss: 0.01747924194699986
Epoch: 30 Idx: 5000 Loss: 0.004559725740889981
Epoch: 31 Idx: 0 Loss: 0.023743607684951033
Epoch: 31 Idx: 5000 Loss: 0.01574987028694355
Epoch: 32 Idx: 0 Loss: 0.025295516419926837
Epoch: 32 Idx: 5000 Loss: 0.02367665876352329
Epoch: 33 Idx: 0 Loss: 0.030338051540014878
Epoch: 33 Idx: 5000 Loss: 0.02601613571017689
Epoch: 34 Idx: 0 Loss: 0.01249267074982713
Epoch: 34 Idx: 5000 Loss: 0.01115753520178367
Epoch: 35 Idx: 0 Loss: 0.018472577356833914
Epoch: 35 Idx: 5000 Loss: 0.014125562198432159
Epoch: 36 Idx: 0 Loss: 0.011064552899928602
Epoch: 36 Idx: 5000 Loss: 0.019022791997419294
Epoch: 37 Idx: 0 Loss: 0.023352245699579922
Epoch: 37 Idx: 5000 Loss: 0.02147006356517662
Epoch: 38 Idx: 0 Loss: 0.018524726798703928
Epoch: 38 Idx: 5000 Loss: 0.008361320460787644
Epoch: 39 Idx: 0 Loss: 0.017833716990336517
Epoch: 39 Idx: 5000 Loss: 0.009535433937842175
Epoch: 40 Idx: 0 Loss: 0.0060528296088354
Epoch: 40 Idx: 5000 Loss: 0.05623502954326605
Epoch: 41 Idx: 0 Loss: 0.020693865143449685
Epoch: 41 Idx: 5000 Loss: 0.009998031839066543
Epoch: 42 Idx: 0 Loss: 0.009990375508731518
Epoch: 42 Idx: 5000 Loss: 0.023917700710917783
Epoch: 43 Idx: 0 Loss: 0.014370168302876043
Epoch: 43 Idx: 5000 Loss: 0.05209746560113125
Epoch: 44 Idx: 0 Loss: 0.027200433271442667
Epoch: 44 Idx: 5000 Loss: 0.014069521024322362
Epoch: 45 Idx: 0 Loss: 0.005228651709766069
Epoch: 45 Idx: 5000 Loss: 0.009906200004578331
Epoch: 46 Idx: 0 Loss: 0.020567772593549104
Epoch: 46 Idx: 5000 Loss: 0.011548299194584354
Epoch: 47 Idx: 0 Loss: 0.03346215523783219
Epoch: 47 Idx: 5000 Loss: 0.008967325973801453
Epoch: 48 Idx: 0 Loss: 0.017727462808087013
Epoch: 48 Idx: 5000 Loss: 0.016103314915808534
Epoch: 49 Idx: 0 Loss: 0.010532744455833305
Epoch: 49 Idx: 5000 Loss: 0.020072597807465037
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15518397356299196
Epoch: 0 Idx: 5000 Loss: 0.02520122714314592
Epoch: 1 Idx: 0 Loss: 0.010675543678172101
Epoch: 1 Idx: 5000 Loss: 0.04304894678195734
Epoch: 2 Idx: 0 Loss: 0.0487924369037405
Epoch: 2 Idx: 5000 Loss: 0.003373287496266549
Epoch: 3 Idx: 0 Loss: 0.01983165185111971
Epoch: 3 Idx: 5000 Loss: 0.011883815475064749
Epoch: 4 Idx: 0 Loss: 0.021576096915185267
Epoch: 4 Idx: 5000 Loss: 0.024703012243711835
Epoch: 5 Idx: 0 Loss: 0.009913613544057785
Epoch: 5 Idx: 5000 Loss: 0.03361648997783558
Epoch: 6 Idx: 0 Loss: 0.030920481910738155
Epoch: 6 Idx: 5000 Loss: 0.016914286812299117
Epoch: 7 Idx: 0 Loss: 0.019162080175833977
Epoch: 7 Idx: 5000 Loss: 0.021761669556473455
Epoch: 8 Idx: 0 Loss: 0.006683569778611446
Epoch: 8 Idx: 5000 Loss: 0.014284984855605596
Epoch: 9 Idx: 0 Loss: 0.011399948815066594
Epoch: 9 Idx: 5000 Loss: 0.02595604491710449
Epoch: 10 Idx: 0 Loss: 0.011404512592624618
Epoch: 10 Idx: 5000 Loss: 0.019428638837295408
Epoch: 11 Idx: 0 Loss: 0.01891339081309503
Epoch: 11 Idx: 5000 Loss: 0.005733517526576036
Epoch: 12 Idx: 0 Loss: 0.014704629438624234
Epoch: 12 Idx: 5000 Loss: 0.029401845701330667
Epoch: 13 Idx: 0 Loss: 0.013842119607993579
Epoch: 13 Idx: 5000 Loss: 0.015296728917419889
Epoch: 14 Idx: 0 Loss: 0.014921310900130278
Epoch: 14 Idx: 5000 Loss: 0.036877838723480987
Epoch: 15 Idx: 0 Loss: 0.01492798789348541
Epoch: 15 Idx: 5000 Loss: 0.020104628095422735
Epoch: 16 Idx: 0 Loss: 0.01288891485925563
Epoch: 16 Idx: 5000 Loss: 0.01144599680191014
Epoch: 17 Idx: 0 Loss: 0.01383584510385939
Epoch: 17 Idx: 5000 Loss: 0.022633517286581528
Epoch: 18 Idx: 0 Loss: 0.019270900894779164
Epoch: 18 Idx: 5000 Loss: 0.0218911180616077
Epoch: 19 Idx: 0 Loss: 0.008413370479944535
Epoch: 19 Idx: 5000 Loss: 0.010689372569665432
Epoch: 20 Idx: 0 Loss: 0.02648278471112981
Epoch: 20 Idx: 5000 Loss: 0.00900047623919027
Epoch: 21 Idx: 0 Loss: 0.006526998389527381
Epoch: 21 Idx: 5000 Loss: 0.012138947796674647
Epoch: 22 Idx: 0 Loss: 0.011326971576989132
Epoch: 22 Idx: 5000 Loss: 0.008479110915085537
Epoch: 23 Idx: 0 Loss: 0.011528207625279677
Epoch: 23 Idx: 5000 Loss: 0.010314461258803826
Epoch: 24 Idx: 0 Loss: 0.012469095034213198
Epoch: 24 Idx: 5000 Loss: 0.018944559007859428
Epoch: 25 Idx: 0 Loss: 0.008861703324238903
Epoch: 25 Idx: 5000 Loss: 0.008438247350328268
Epoch: 26 Idx: 0 Loss: 0.007091617825481136
Epoch: 26 Idx: 5000 Loss: 0.01949309247175756
Epoch: 27 Idx: 0 Loss: 0.013650118915622823
Epoch: 27 Idx: 5000 Loss: 0.019342678088205494
Epoch: 28 Idx: 0 Loss: 0.025676590033665177
Epoch: 28 Idx: 5000 Loss: 0.012051064278128956
Epoch: 29 Idx: 0 Loss: 0.01395294350931442
Epoch: 29 Idx: 5000 Loss: 0.04374470656877544
Epoch: 30 Idx: 0 Loss: 0.021334245995434757
Epoch: 30 Idx: 5000 Loss: 0.009207940366045775
Epoch: 31 Idx: 0 Loss: 0.013618406494140643
Epoch: 31 Idx: 5000 Loss: 0.013269542370020263
Epoch: 32 Idx: 0 Loss: 0.012877707149206422
Epoch: 32 Idx: 5000 Loss: 0.008553133788661911
Epoch: 33 Idx: 0 Loss: 0.012587032403491804
Epoch: 33 Idx: 5000 Loss: 0.011997455665318657
Epoch: 34 Idx: 0 Loss: 0.005442319429755182
Epoch: 34 Idx: 5000 Loss: 0.011753746816209656
Epoch: 35 Idx: 0 Loss: 0.034950090587700475
Epoch: 35 Idx: 5000 Loss: 0.02084219182980904
Epoch: 36 Idx: 0 Loss: 0.024318107008574136
Epoch: 36 Idx: 5000 Loss: 0.0123222345359339
Epoch: 37 Idx: 0 Loss: 0.013128402662017133
Epoch: 37 Idx: 5000 Loss: 0.041648629708421016
Epoch: 38 Idx: 0 Loss: 0.009817032567206617
Epoch: 38 Idx: 5000 Loss: 0.030526750910996575
Epoch: 39 Idx: 0 Loss: 0.008959685333186267
Epoch: 39 Idx: 5000 Loss: 0.0119020323239282
Epoch: 40 Idx: 0 Loss: 0.010116686135982926
Epoch: 40 Idx: 5000 Loss: 0.031373015794651266
Epoch: 41 Idx: 0 Loss: 0.031130132134843877
Epoch: 41 Idx: 5000 Loss: 0.024009114174842566
Epoch: 42 Idx: 0 Loss: 0.00819157311225545
Epoch: 42 Idx: 5000 Loss: 0.0071637801565457085
Epoch: 43 Idx: 0 Loss: 0.012453956017527367
Epoch: 43 Idx: 5000 Loss: 0.005977807223508939
Epoch: 44 Idx: 0 Loss: 0.01504349679175345
Epoch: 44 Idx: 5000 Loss: 0.020702068641126992
Epoch: 45 Idx: 0 Loss: 0.011038500821572098
Epoch: 45 Idx: 5000 Loss: 0.010805423641446515
Epoch: 46 Idx: 0 Loss: 0.012490507715823931
Epoch: 46 Idx: 5000 Loss: 0.016392989878416975
Epoch: 47 Idx: 0 Loss: 0.010805536022299722
Epoch: 47 Idx: 5000 Loss: 0.01003417293743865
Epoch: 48 Idx: 0 Loss: 0.013452672218726848
Epoch: 48 Idx: 5000 Loss: 0.027490314206873565
Epoch: 49 Idx: 0 Loss: 0.01839551221017284
Epoch: 49 Idx: 5000 Loss: 0.01388999463365348
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13947801377771057
Epoch: 0 Idx: 5000 Loss: 0.01236906338067093
Epoch: 1 Idx: 0 Loss: 0.019796330832484554
Epoch: 1 Idx: 5000 Loss: 0.006635747510225835
Epoch: 2 Idx: 0 Loss: 0.03694592693861556
Epoch: 2 Idx: 5000 Loss: 0.01267737594237391
Epoch: 3 Idx: 0 Loss: 0.020493925722858835
Epoch: 3 Idx: 5000 Loss: 0.01788962125816931
Epoch: 4 Idx: 0 Loss: 0.016653185539239578
Epoch: 4 Idx: 5000 Loss: 0.020335369536355202
Epoch: 5 Idx: 0 Loss: 0.0164206826627278
Epoch: 5 Idx: 5000 Loss: 0.02110682941501661
Epoch: 6 Idx: 0 Loss: 0.010847034102145655
Epoch: 6 Idx: 5000 Loss: 0.01698341883807937
Epoch: 7 Idx: 0 Loss: 0.01230962017448775
Epoch: 7 Idx: 5000 Loss: 0.023415232295116634
Epoch: 8 Idx: 0 Loss: 0.004194774737112078
Epoch: 8 Idx: 5000 Loss: 0.007384791537610225
Epoch: 9 Idx: 0 Loss: 0.02830811127109652
Epoch: 9 Idx: 5000 Loss: 0.013085670721918224
Epoch: 10 Idx: 0 Loss: 0.011952673334260672
Epoch: 10 Idx: 5000 Loss: 0.0078095144710180284
Epoch: 11 Idx: 0 Loss: 0.018990668491442503
Epoch: 11 Idx: 5000 Loss: 0.01609847119870597
Epoch: 12 Idx: 0 Loss: 0.009824167504074725
Epoch: 12 Idx: 5000 Loss: 0.021683369062463067
Epoch: 13 Idx: 0 Loss: 0.008734575659606196
Epoch: 13 Idx: 5000 Loss: 0.010232914619338281
Epoch: 14 Idx: 0 Loss: 0.025178767213588492
Epoch: 14 Idx: 5000 Loss: 0.021850092556656767
Epoch: 15 Idx: 0 Loss: 0.01689485361999148
Epoch: 15 Idx: 5000 Loss: 0.012538590774267111
Epoch: 16 Idx: 0 Loss: 0.02104476073376773
Epoch: 16 Idx: 5000 Loss: 0.014496891742887524
Epoch: 17 Idx: 0 Loss: 0.038618702001859
Epoch: 17 Idx: 5000 Loss: 0.016718099395725657
Epoch: 18 Idx: 0 Loss: 0.01735400162203886
Epoch: 18 Idx: 5000 Loss: 0.01216306441469416
Epoch: 19 Idx: 0 Loss: 0.006723678013584027
Epoch: 19 Idx: 5000 Loss: 0.02087744059738854
Epoch: 20 Idx: 0 Loss: 0.010816073728584463
Epoch: 20 Idx: 5000 Loss: 0.00658785925712896
Epoch: 21 Idx: 0 Loss: 0.011167754534458377
Epoch: 21 Idx: 5000 Loss: 0.010388874416459328
Epoch: 22 Idx: 0 Loss: 0.016052145750460482
Epoch: 22 Idx: 5000 Loss: 0.01023773289589331
Epoch: 23 Idx: 0 Loss: 0.013973455332172358
Epoch: 23 Idx: 5000 Loss: 0.011340491218719405
Epoch: 24 Idx: 0 Loss: 0.020674763760079172
Epoch: 24 Idx: 5000 Loss: 0.009237296420600496
Epoch: 25 Idx: 0 Loss: 0.008838891527835414
Epoch: 25 Idx: 5000 Loss: 0.011215641674291718
Epoch: 26 Idx: 0 Loss: 0.012831946350404237
Epoch: 26 Idx: 5000 Loss: 0.018877690301839153
Epoch: 27 Idx: 0 Loss: 0.01472758467291045
Epoch: 27 Idx: 5000 Loss: 0.016257383994068016
Epoch: 28 Idx: 0 Loss: 0.01595080087867659
Epoch: 28 Idx: 5000 Loss: 0.015752068155381528
Epoch: 29 Idx: 0 Loss: 0.010028246676972333
Epoch: 29 Idx: 5000 Loss: 0.014961457481807133
Epoch: 30 Idx: 0 Loss: 0.010757426261423791
Epoch: 30 Idx: 5000 Loss: 0.021073570074425462
Epoch: 31 Idx: 0 Loss: 0.009987470659538181
Epoch: 31 Idx: 5000 Loss: 0.011065422162650461
Epoch: 32 Idx: 0 Loss: 0.007724842401985755
Epoch: 32 Idx: 5000 Loss: 0.029108961774843296
Epoch: 33 Idx: 0 Loss: 0.029101337270030298
Epoch: 33 Idx: 5000 Loss: 0.02312477492817478
Epoch: 34 Idx: 0 Loss: 0.01509546482905982
Epoch: 34 Idx: 5000 Loss: 0.010419778678142732
Epoch: 35 Idx: 0 Loss: 0.03739494899098499
Epoch: 35 Idx: 5000 Loss: 0.02432188888781685
Epoch: 36 Idx: 0 Loss: 0.0313100597794894
Epoch: 36 Idx: 5000 Loss: 0.014622909819531602
Epoch: 37 Idx: 0 Loss: 0.014746800540270763
Epoch: 37 Idx: 5000 Loss: 0.010895196775128428
Epoch: 38 Idx: 0 Loss: 0.014176700480226848
Epoch: 38 Idx: 5000 Loss: 0.013073151244946471
Epoch: 39 Idx: 0 Loss: 0.025485385194096294
Epoch: 39 Idx: 5000 Loss: 0.05112253908106714
Epoch: 40 Idx: 0 Loss: 0.020730352715851948
Epoch: 40 Idx: 5000 Loss: 0.02170163140837395
Epoch: 41 Idx: 0 Loss: 0.007491057544251901
Epoch: 41 Idx: 5000 Loss: 0.014663211053476103
Epoch: 42 Idx: 0 Loss: 0.008908182100425474
Epoch: 42 Idx: 5000 Loss: 0.02718287739346771
Epoch: 43 Idx: 0 Loss: 0.009945940405559189
Epoch: 43 Idx: 5000 Loss: 0.010609798515513275
Epoch: 44 Idx: 0 Loss: 0.021294213651085747
Epoch: 44 Idx: 5000 Loss: 0.020649601544145302
Epoch: 45 Idx: 0 Loss: 0.01685008609673037
Epoch: 45 Idx: 5000 Loss: 0.019240558816343702
Epoch: 46 Idx: 0 Loss: 0.028645135759240284
Epoch: 46 Idx: 5000 Loss: 0.006975132670552555
Epoch: 47 Idx: 0 Loss: 0.009436787837700227
Epoch: 47 Idx: 5000 Loss: 0.018946956450050408
Epoch: 48 Idx: 0 Loss: 0.011855999733584562
Epoch: 48 Idx: 5000 Loss: 0.010130895021146969
Epoch: 49 Idx: 0 Loss: 0.030380363632028506
Epoch: 49 Idx: 5000 Loss: 0.012031855259980299
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.22842692069031834
Epoch: 0 Idx: 5000 Loss: 0.018114038088676634
Epoch: 1 Idx: 0 Loss: 0.014300559817294844
Epoch: 1 Idx: 5000 Loss: 0.014329925289774212
Epoch: 2 Idx: 0 Loss: 0.010466399509973343
Epoch: 2 Idx: 5000 Loss: 0.03289078754586107
Epoch: 3 Idx: 0 Loss: 0.030205857446255625
Epoch: 3 Idx: 5000 Loss: 0.012261519337279373
Epoch: 4 Idx: 0 Loss: 0.025613479040251557
Epoch: 4 Idx: 5000 Loss: 0.01948810592069093
Epoch: 5 Idx: 0 Loss: 0.006524460508710432
Epoch: 5 Idx: 5000 Loss: 0.01230722786452378
Epoch: 6 Idx: 0 Loss: 0.01600953399486121
Epoch: 6 Idx: 5000 Loss: 0.012999401223928722
Epoch: 7 Idx: 0 Loss: 0.021390202671264395
Epoch: 7 Idx: 5000 Loss: 0.011329579397186491
Epoch: 8 Idx: 0 Loss: 0.017791063194097612
Epoch: 8 Idx: 5000 Loss: 0.008828406844462493
Epoch: 9 Idx: 0 Loss: 0.008321445747001454
Epoch: 9 Idx: 5000 Loss: 0.009739944719681166
Epoch: 10 Idx: 0 Loss: 0.01828279427308783
Epoch: 10 Idx: 5000 Loss: 0.00829194945476238
Epoch: 11 Idx: 0 Loss: 0.008366091335535671
Epoch: 11 Idx: 5000 Loss: 0.01698905698532927
Epoch: 12 Idx: 0 Loss: 0.017562979463977335
Epoch: 12 Idx: 5000 Loss: 0.01780809169892379
Epoch: 13 Idx: 0 Loss: 0.011445292225815425
Epoch: 13 Idx: 5000 Loss: 0.019900513818044474
Epoch: 14 Idx: 0 Loss: 0.004381802509703289
Epoch: 14 Idx: 5000 Loss: 0.018964986867570133
Epoch: 15 Idx: 0 Loss: 0.018660790259402232
Epoch: 15 Idx: 5000 Loss: 0.007900716951351031
Epoch: 16 Idx: 0 Loss: 0.011079347003253057
Epoch: 16 Idx: 5000 Loss: 0.0090558491130053
Epoch: 17 Idx: 0 Loss: 0.016586231290479248
Epoch: 17 Idx: 5000 Loss: 0.026634734171333864
Epoch: 18 Idx: 0 Loss: 0.012316106520308403
Epoch: 18 Idx: 5000 Loss: 0.012405520969960256
Epoch: 19 Idx: 0 Loss: 0.005453718549857255
Epoch: 19 Idx: 5000 Loss: 0.008728039367141583
Epoch: 20 Idx: 0 Loss: 0.017298404349142423
Epoch: 20 Idx: 5000 Loss: 0.009858564014873526
Epoch: 21 Idx: 0 Loss: 0.009006022725755826
Epoch: 21 Idx: 5000 Loss: 0.015889649602064192
Epoch: 22 Idx: 0 Loss: 0.02251745441237411
Epoch: 22 Idx: 5000 Loss: 0.026183108450646683
Epoch: 23 Idx: 0 Loss: 0.0385332107524461
Epoch: 23 Idx: 5000 Loss: 0.011716216968426375
Epoch: 24 Idx: 0 Loss: 0.01130583478997967
Epoch: 24 Idx: 5000 Loss: 0.030374427341201635
Epoch: 25 Idx: 0 Loss: 0.011289204607475694
Epoch: 25 Idx: 5000 Loss: 0.02926642207087105
Epoch: 26 Idx: 0 Loss: 0.008952402678781434
Epoch: 26 Idx: 5000 Loss: 0.014074795696620668
Epoch: 27 Idx: 0 Loss: 0.04505677266914368
Epoch: 27 Idx: 5000 Loss: 0.03100856148065911
Epoch: 28 Idx: 0 Loss: 0.012554708924601091
Epoch: 28 Idx: 5000 Loss: 0.009438582094413409
Epoch: 29 Idx: 0 Loss: 0.016202968670913018
Epoch: 29 Idx: 5000 Loss: 0.011653496535490913
Epoch: 30 Idx: 0 Loss: 0.005239773798200689
Epoch: 30 Idx: 5000 Loss: 0.013916249588863745
Epoch: 31 Idx: 0 Loss: 0.0070066671331634476
Epoch: 31 Idx: 5000 Loss: 0.008878484263666714
Epoch: 32 Idx: 0 Loss: 0.006194691207557758
Epoch: 32 Idx: 5000 Loss: 0.021382122848794205
Epoch: 33 Idx: 0 Loss: 0.008925537795569408
Epoch: 33 Idx: 5000 Loss: 0.016842376956053944
Epoch: 34 Idx: 0 Loss: 0.006565208393017392
Epoch: 34 Idx: 5000 Loss: 0.016683127115964348
Epoch: 35 Idx: 0 Loss: 0.013340727091323584
Epoch: 35 Idx: 5000 Loss: 0.015804100833977916
Epoch: 36 Idx: 0 Loss: 0.03110790573575565
Epoch: 36 Idx: 5000 Loss: 0.006081743632288868
Epoch: 37 Idx: 0 Loss: 0.008164553266759498
Epoch: 37 Idx: 5000 Loss: 0.026785481503533173
Epoch: 38 Idx: 0 Loss: 0.012010107327899555
Epoch: 38 Idx: 5000 Loss: 0.010038875122731003
Epoch: 39 Idx: 0 Loss: 0.012512201257891254
Epoch: 39 Idx: 5000 Loss: 0.009017357665133894
Epoch: 40 Idx: 0 Loss: 0.00975755520196441
Epoch: 40 Idx: 5000 Loss: 0.017275491347618254
Epoch: 41 Idx: 0 Loss: 0.02037044062700009
Epoch: 41 Idx: 5000 Loss: 0.014845208236349427
Epoch: 42 Idx: 0 Loss: 0.011372348682841713
Epoch: 42 Idx: 5000 Loss: 0.03613302245155573
Epoch: 43 Idx: 0 Loss: 0.018936723150196393
Epoch: 43 Idx: 5000 Loss: 0.01922714111632956
Epoch: 44 Idx: 0 Loss: 0.01871521094188931
Epoch: 44 Idx: 5000 Loss: 0.01327375196421296
Epoch: 45 Idx: 0 Loss: 0.029245882989122833
Epoch: 45 Idx: 5000 Loss: 0.007007425424450894
Epoch: 46 Idx: 0 Loss: 0.02903762893305025
Epoch: 46 Idx: 5000 Loss: 0.012437278664684503
Epoch: 47 Idx: 0 Loss: 0.012169936782968488
Epoch: 47 Idx: 5000 Loss: 0.01289244567693698
Epoch: 48 Idx: 0 Loss: 0.01634449109816597
Epoch: 48 Idx: 5000 Loss: 0.016520701892854324
Epoch: 49 Idx: 0 Loss: 0.028038901739196636
Epoch: 49 Idx: 5000 Loss: 0.007534472537600121
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.20268470715663708
Epoch: 0 Idx: 5000 Loss: 0.01925513497006974
Epoch: 1 Idx: 0 Loss: 0.009915791379176322
Epoch: 1 Idx: 5000 Loss: 0.027715524432188676
Epoch: 2 Idx: 0 Loss: 0.012821263619173937
Epoch: 2 Idx: 5000 Loss: 0.03325725128066703
Epoch: 3 Idx: 0 Loss: 0.011046651512518725
Epoch: 3 Idx: 5000 Loss: 0.01211195615405736
Epoch: 4 Idx: 0 Loss: 0.010224149084748446
Epoch: 4 Idx: 5000 Loss: 0.0053679384456648445
Epoch: 5 Idx: 0 Loss: 0.02337533059634487
Epoch: 5 Idx: 5000 Loss: 0.01783742197498248
Epoch: 6 Idx: 0 Loss: 0.04372782720316998
Epoch: 6 Idx: 5000 Loss: 0.01693434160289995
Epoch: 7 Idx: 0 Loss: 0.009492304175047237
Epoch: 7 Idx: 5000 Loss: 0.00735490094867976
Epoch: 8 Idx: 0 Loss: 0.008669871397713098
Epoch: 8 Idx: 5000 Loss: 0.023275715879928275
Epoch: 9 Idx: 0 Loss: 0.012277708999708736
Epoch: 9 Idx: 5000 Loss: 0.010963138116017887
Epoch: 10 Idx: 0 Loss: 0.0074456037151858605
Epoch: 10 Idx: 5000 Loss: 0.010572955264028622
Epoch: 11 Idx: 0 Loss: 0.044978668622313006
Epoch: 11 Idx: 5000 Loss: 0.025821492454868582
Epoch: 12 Idx: 0 Loss: 0.009510397256832207
Epoch: 12 Idx: 5000 Loss: 0.02517591626423898
Epoch: 13 Idx: 0 Loss: 0.03107173201529996
Epoch: 13 Idx: 5000 Loss: 0.011173938689230608
Epoch: 14 Idx: 0 Loss: 0.009388325734043405
Epoch: 14 Idx: 5000 Loss: 0.02773461083044225
Epoch: 15 Idx: 0 Loss: 0.017882977523723444
Epoch: 15 Idx: 5000 Loss: 0.009293324140826495
Epoch: 16 Idx: 0 Loss: 0.009905568289894893
Epoch: 16 Idx: 5000 Loss: 0.01786959847193521
Epoch: 17 Idx: 0 Loss: 0.02512140805292746
Epoch: 17 Idx: 5000 Loss: 0.013881662988521233
Epoch: 18 Idx: 0 Loss: 0.01356223707469165
Epoch: 18 Idx: 5000 Loss: 0.030114549615747867
Epoch: 19 Idx: 0 Loss: 0.023523447079782673
Epoch: 19 Idx: 5000 Loss: 0.015789317125120113
Epoch: 20 Idx: 0 Loss: 0.015705208231494888
Epoch: 20 Idx: 5000 Loss: 0.02421992147655576
Epoch: 21 Idx: 0 Loss: 0.013785757309789731
Epoch: 21 Idx: 5000 Loss: 0.007797284438698757
Epoch: 22 Idx: 0 Loss: 0.013114181853539356
Epoch: 22 Idx: 5000 Loss: 0.013312671694205913
Epoch: 23 Idx: 0 Loss: 0.007699234752151156
Epoch: 23 Idx: 5000 Loss: 0.024148470660245575
Epoch: 24 Idx: 0 Loss: 0.014047185243469203
Epoch: 24 Idx: 5000 Loss: 0.007736359704107915
Epoch: 25 Idx: 0 Loss: 0.023292540116730837
Epoch: 25 Idx: 5000 Loss: 0.015747081007799993
Epoch: 26 Idx: 0 Loss: 0.012720468274688215
Epoch: 26 Idx: 5000 Loss: 0.007567007678569595
Epoch: 27 Idx: 0 Loss: 0.02223460959698333
Epoch: 27 Idx: 5000 Loss: 0.01812063639832581
Epoch: 28 Idx: 0 Loss: 0.014069035016871626
Epoch: 28 Idx: 5000 Loss: 0.013962119673169713
Epoch: 29 Idx: 0 Loss: 0.020740730272976897
Epoch: 29 Idx: 5000 Loss: 0.02333457796482342
Epoch: 30 Idx: 0 Loss: 0.02612177123272894
Epoch: 30 Idx: 5000 Loss: 0.0173560733155445
Epoch: 31 Idx: 0 Loss: 0.008909398295505421
Epoch: 31 Idx: 5000 Loss: 0.022635062615134455
Epoch: 32 Idx: 0 Loss: 0.013087219127629763
Epoch: 32 Idx: 5000 Loss: 0.011262311118918466
Epoch: 33 Idx: 0 Loss: 0.011130033903301868
Epoch: 33 Idx: 5000 Loss: 0.010107901594660552
Epoch: 34 Idx: 0 Loss: 0.007872583244519334
Epoch: 34 Idx: 5000 Loss: 0.012871594214046385
Epoch: 35 Idx: 0 Loss: 0.010763767096197856
Epoch: 35 Idx: 5000 Loss: 0.011831278912592356
Epoch: 36 Idx: 0 Loss: 0.007139648303112049
Epoch: 36 Idx: 5000 Loss: 0.02826116899181547
Epoch: 37 Idx: 0 Loss: 0.015173442486413318
Epoch: 37 Idx: 5000 Loss: 0.012479286427057902
Epoch: 38 Idx: 0 Loss: 0.027160859996877472
Epoch: 38 Idx: 5000 Loss: 0.013511083732236891
Epoch: 39 Idx: 0 Loss: 0.013983651167710876
Epoch: 39 Idx: 5000 Loss: 0.010624132927557314
Epoch: 40 Idx: 0 Loss: 0.01767339733562122
Epoch: 40 Idx: 5000 Loss: 0.015212798139234441
Epoch: 41 Idx: 0 Loss: 0.010321741882122946
Epoch: 41 Idx: 5000 Loss: 0.008464416818241963
Epoch: 42 Idx: 0 Loss: 0.008010483993666271
Epoch: 42 Idx: 5000 Loss: 0.03479190396877359
Epoch: 43 Idx: 0 Loss: 0.03058723707463242
Epoch: 43 Idx: 5000 Loss: 0.012344533156275568
Epoch: 44 Idx: 0 Loss: 0.01849025760438395
Epoch: 44 Idx: 5000 Loss: 0.01442570598707939
Epoch: 45 Idx: 0 Loss: 0.00944156596586573
Epoch: 45 Idx: 5000 Loss: 0.009353865130796384
Epoch: 46 Idx: 0 Loss: 0.011383795716177567
Epoch: 46 Idx: 5000 Loss: 0.017642048067561387
Epoch: 47 Idx: 0 Loss: 0.03149865243153175
Epoch: 47 Idx: 5000 Loss: 0.01105119495568412
Epoch: 48 Idx: 0 Loss: 0.017754650198495738
Epoch: 48 Idx: 5000 Loss: 0.006398729662948313
Epoch: 49 Idx: 0 Loss: 0.01797288322166737
Epoch: 49 Idx: 5000 Loss: 0.016781679086548346
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.19809929130259524
Epoch: 0 Idx: 5000 Loss: 0.012873573235146629
Epoch: 1 Idx: 0 Loss: 0.014666490414224414
Epoch: 1 Idx: 5000 Loss: 0.014114208835746081
Epoch: 2 Idx: 0 Loss: 0.007316265106053987
Epoch: 2 Idx: 5000 Loss: 0.02514111297468433
Epoch: 3 Idx: 0 Loss: 0.01768124466220842
Epoch: 3 Idx: 5000 Loss: 0.025802456125835597
Epoch: 4 Idx: 0 Loss: 0.018153110900447956
Epoch: 4 Idx: 5000 Loss: 0.010690974430551635
Epoch: 5 Idx: 0 Loss: 0.014552180667338835
Epoch: 5 Idx: 5000 Loss: 0.025879993751780867
Epoch: 6 Idx: 0 Loss: 0.011966927624713198
Epoch: 6 Idx: 5000 Loss: 0.013278605197130495
Epoch: 7 Idx: 0 Loss: 0.011269744700747606
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc249>
Subject: Job 4066875: <python main.py 6 4 False False> in cluster <dcc> Exited

Job <python main.py 6 4 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc249>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 4 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46123.13 sec.
    Max Memory :                                 2907 MB
    Average Memory :                             2750.67 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40510.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46142 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

