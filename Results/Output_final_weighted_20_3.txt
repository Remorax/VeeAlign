2020-09-15 15:48:41.724472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:48.975068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.094400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.094493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.096858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.131449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.172051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.249570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.278761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.279296: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.279319: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.279846: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.320221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600135000 Hz
2020-09-15 15:48:49.320489: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56539617bae0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.320509: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.323593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.323627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20406974968340152
Epoch: 0 Idx: 5000 Loss: 0.010857559714739723
Epoch: 1 Idx: 0 Loss: 0.011860216844882945
Epoch: 1 Idx: 5000 Loss: 0.009690983599482573
Epoch: 2 Idx: 0 Loss: 0.016010812400800205
Epoch: 2 Idx: 5000 Loss: 0.03066654055735346
Epoch: 3 Idx: 0 Loss: 0.008716197983452157
Epoch: 3 Idx: 5000 Loss: 0.019553399221001442
Epoch: 4 Idx: 0 Loss: 0.005542389616988563
Epoch: 4 Idx: 5000 Loss: 0.0050158768638899984
Epoch: 5 Idx: 0 Loss: 0.027896527533811808
Epoch: 5 Idx: 5000 Loss: 0.041930630272505265
Epoch: 6 Idx: 0 Loss: 0.017492484157181597
Epoch: 6 Idx: 5000 Loss: 0.012698445289708244
Epoch: 7 Idx: 0 Loss: 0.014488115744065576
Epoch: 7 Idx: 5000 Loss: 0.022631069100672273
Epoch: 8 Idx: 0 Loss: 0.026485980120652085
Epoch: 8 Idx: 5000 Loss: 0.010879826757496006
Epoch: 9 Idx: 0 Loss: 0.026122651096247687
Epoch: 9 Idx: 5000 Loss: 0.007960669361684242
Epoch: 10 Idx: 0 Loss: 0.0059624687192434776
Epoch: 10 Idx: 5000 Loss: 0.01620330662858375
Epoch: 11 Idx: 0 Loss: 0.012307594819750502
Epoch: 11 Idx: 5000 Loss: 0.01618174899477491
Epoch: 12 Idx: 0 Loss: 0.02676678717172802
Epoch: 12 Idx: 5000 Loss: 0.014883295329088967
Epoch: 13 Idx: 0 Loss: 0.02379809347032269
Epoch: 13 Idx: 5000 Loss: 0.004953948468140814
Epoch: 14 Idx: 0 Loss: 0.046849598364173586
Epoch: 14 Idx: 5000 Loss: 0.023354794686297486
Epoch: 15 Idx: 0 Loss: 0.017341446676257886
Epoch: 15 Idx: 5000 Loss: 0.01572599954173801
Epoch: 16 Idx: 0 Loss: 0.02012385744851531
Epoch: 16 Idx: 5000 Loss: 0.01270366311371619
Epoch: 17 Idx: 0 Loss: 0.023622281279594343
Epoch: 17 Idx: 5000 Loss: 0.010993036041757689
Epoch: 18 Idx: 0 Loss: 0.017483677540139644
Epoch: 18 Idx: 5000 Loss: 0.01545611528768591
Epoch: 19 Idx: 0 Loss: 0.03313065731508881
Epoch: 19 Idx: 5000 Loss: 0.029381821761802426
Epoch: 20 Idx: 0 Loss: 0.00716211593049576
Epoch: 20 Idx: 5000 Loss: 0.007262343048332573
Epoch: 21 Idx: 0 Loss: 0.054638058231799666
Epoch: 21 Idx: 5000 Loss: 0.04299035098367794
Epoch: 22 Idx: 0 Loss: 0.007870814706776174
Epoch: 22 Idx: 5000 Loss: 0.015131915967945532
Epoch: 23 Idx: 0 Loss: 0.026717303666263986
Epoch: 23 Idx: 5000 Loss: 0.010549176054608329
Epoch: 24 Idx: 0 Loss: 0.0064245510020745165
Epoch: 24 Idx: 5000 Loss: 0.01972358435927155
Epoch: 25 Idx: 0 Loss: 0.018926881578418774
Epoch: 25 Idx: 5000 Loss: 0.007764062162650239
Epoch: 26 Idx: 0 Loss: 0.008684132166545854
Epoch: 26 Idx: 5000 Loss: 0.010632160965615572
Epoch: 27 Idx: 0 Loss: 0.014032859744008608
Epoch: 27 Idx: 5000 Loss: 0.00774870388950871
Epoch: 28 Idx: 0 Loss: 0.021856370329249735
Epoch: 28 Idx: 5000 Loss: 0.009273895543736428
Epoch: 29 Idx: 0 Loss: 0.016962795420413877
Epoch: 29 Idx: 5000 Loss: 0.024125468796652703
Epoch: 30 Idx: 0 Loss: 0.017713075122920568
Epoch: 30 Idx: 5000 Loss: 0.019551297101306958
Epoch: 31 Idx: 0 Loss: 0.007873673453139881
Epoch: 31 Idx: 5000 Loss: 0.013157173213082754
Epoch: 32 Idx: 0 Loss: 0.008923929830096567
Epoch: 32 Idx: 5000 Loss: 0.010342501312183745
Epoch: 33 Idx: 0 Loss: 0.01671529501819132
Epoch: 33 Idx: 5000 Loss: 0.008553425617844126
Epoch: 34 Idx: 0 Loss: 0.007845406441502589
Epoch: 34 Idx: 5000 Loss: 0.0466623181401308
Epoch: 35 Idx: 0 Loss: 0.015219149769993338
Epoch: 35 Idx: 5000 Loss: 0.017836398783557677
Epoch: 36 Idx: 0 Loss: 0.023691250014625194
Epoch: 36 Idx: 5000 Loss: 0.033497099103302785
Epoch: 37 Idx: 0 Loss: 0.01548229887251101
Epoch: 37 Idx: 5000 Loss: 0.012208805933718944
Epoch: 38 Idx: 0 Loss: 0.006783696550959474
Epoch: 38 Idx: 5000 Loss: 0.046666312875200754
Epoch: 39 Idx: 0 Loss: 0.011196756118107576
Epoch: 39 Idx: 5000 Loss: 0.010296183520877288
Epoch: 40 Idx: 0 Loss: 0.01672238485897103
Epoch: 40 Idx: 5000 Loss: 0.03037170740184022
Epoch: 41 Idx: 0 Loss: 0.017568603722513215
Epoch: 41 Idx: 5000 Loss: 0.013598197079410235
Epoch: 42 Idx: 0 Loss: 0.014558478052283271
Epoch: 42 Idx: 5000 Loss: 0.008805289025591105
Epoch: 43 Idx: 0 Loss: 0.009737627259405007
Epoch: 43 Idx: 5000 Loss: 0.029193873544774474
Epoch: 44 Idx: 0 Loss: 0.013691631073748121
Epoch: 44 Idx: 5000 Loss: 0.006132645335801559
Epoch: 45 Idx: 0 Loss: 0.020048396374328124
Epoch: 45 Idx: 5000 Loss: 0.052033486482304346
Epoch: 46 Idx: 0 Loss: 0.011293277410504272
Epoch: 46 Idx: 5000 Loss: 0.00861020776471268
Epoch: 47 Idx: 0 Loss: 0.014377889837590356
Epoch: 47 Idx: 5000 Loss: 0.01600785579822799
Epoch: 48 Idx: 0 Loss: 0.012252716003858185
Epoch: 48 Idx: 5000 Loss: 0.029542950679664788
Epoch: 49 Idx: 0 Loss: 0.008157067483692567
Epoch: 49 Idx: 5000 Loss: 0.011011237378166753
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1390600742815906
Epoch: 0 Idx: 5000 Loss: 0.013766636297226421
Epoch: 1 Idx: 0 Loss: 0.01773280032258031
Epoch: 1 Idx: 5000 Loss: 0.05035484784630594
Epoch: 2 Idx: 0 Loss: 0.03409461584458716
Epoch: 2 Idx: 5000 Loss: 0.043464052478989365
Epoch: 3 Idx: 0 Loss: 0.015684233480550303
Epoch: 3 Idx: 5000 Loss: 0.010540821378179197
Epoch: 4 Idx: 0 Loss: 0.013411306156328134
Epoch: 4 Idx: 5000 Loss: 0.012801697740015106
Epoch: 5 Idx: 0 Loss: 0.01504888707938974
Epoch: 5 Idx: 5000 Loss: 0.011781488441154241
Epoch: 6 Idx: 0 Loss: 0.030425794407709615
Epoch: 6 Idx: 5000 Loss: 0.02135605489351704
Epoch: 7 Idx: 0 Loss: 0.027727842980572612
Epoch: 7 Idx: 5000 Loss: 0.01457842664197068
Epoch: 8 Idx: 0 Loss: 0.006677421463228705
Epoch: 8 Idx: 5000 Loss: 0.012653451033588335
Epoch: 9 Idx: 0 Loss: 0.0075765928911885475
Epoch: 9 Idx: 5000 Loss: 0.010828306664346667
Epoch: 10 Idx: 0 Loss: 0.008936759207164897
Epoch: 10 Idx: 5000 Loss: 0.005487369656906731
Epoch: 11 Idx: 0 Loss: 0.016090232312682813
Epoch: 11 Idx: 5000 Loss: 0.0051054824250133446
Epoch: 12 Idx: 0 Loss: 0.01634425732239325
Epoch: 12 Idx: 5000 Loss: 0.019143895294340643
Epoch: 13 Idx: 0 Loss: 0.010976579600044282
Epoch: 13 Idx: 5000 Loss: 0.00712996851054949
Epoch: 14 Idx: 0 Loss: 0.008619041961195915
Epoch: 14 Idx: 5000 Loss: 0.007441776070158848
Epoch: 15 Idx: 0 Loss: 0.018887803933300536
Epoch: 15 Idx: 5000 Loss: 0.013917878112989267
Epoch: 16 Idx: 0 Loss: 0.033548827566514575
Epoch: 16 Idx: 5000 Loss: 0.013196053209902288
Epoch: 17 Idx: 0 Loss: 0.014953098858427567
Epoch: 17 Idx: 5000 Loss: 0.012792307270309408
Epoch: 18 Idx: 0 Loss: 0.02404837882326441
Epoch: 18 Idx: 5000 Loss: 0.02585748605016116
Epoch: 19 Idx: 0 Loss: 0.01919496113224619
Epoch: 19 Idx: 5000 Loss: 0.03475615697514113
Epoch: 20 Idx: 0 Loss: 0.008409449544231033
Epoch: 20 Idx: 5000 Loss: 0.011832422238982475
Epoch: 21 Idx: 0 Loss: 0.018624313175171884
Epoch: 21 Idx: 5000 Loss: 0.02560222702621425
Epoch: 22 Idx: 0 Loss: 0.01832602110352414
Epoch: 22 Idx: 5000 Loss: 0.02869027057810844
Epoch: 23 Idx: 0 Loss: 0.011031098928950428
Epoch: 23 Idx: 5000 Loss: 0.016429399989962113
Epoch: 24 Idx: 0 Loss: 0.012403822165195907
Epoch: 24 Idx: 5000 Loss: 0.02466011570843447
Epoch: 25 Idx: 0 Loss: 0.007486762439413527
Epoch: 25 Idx: 5000 Loss: 0.022353726469364454
Epoch: 26 Idx: 0 Loss: 0.011938366833975665
Epoch: 26 Idx: 5000 Loss: 0.009096811009194303
Epoch: 27 Idx: 0 Loss: 0.023608879722630226
Epoch: 27 Idx: 5000 Loss: 0.012844532232153974
Epoch: 28 Idx: 0 Loss: 0.013502653149933347
Epoch: 28 Idx: 5000 Loss: 0.015744954120667586
Epoch: 29 Idx: 0 Loss: 0.013373874913828247
Epoch: 29 Idx: 5000 Loss: 0.018718006022572536
Epoch: 30 Idx: 0 Loss: 0.008039299501563112
Epoch: 30 Idx: 5000 Loss: 0.009489853715214089
Epoch: 31 Idx: 0 Loss: 0.0220975739144564
Epoch: 31 Idx: 5000 Loss: 0.0060396392536447505
Epoch: 32 Idx: 0 Loss: 0.021844063670831654
Epoch: 32 Idx: 5000 Loss: 0.00961698740278959
Epoch: 33 Idx: 0 Loss: 0.0077663326763560536
Epoch: 33 Idx: 5000 Loss: 0.006396700449362195
Epoch: 34 Idx: 0 Loss: 0.017840772925752
Epoch: 34 Idx: 5000 Loss: 0.021971590467385813
Epoch: 35 Idx: 0 Loss: 0.015781580458991994
Epoch: 35 Idx: 5000 Loss: 0.007816077043538589
Epoch: 36 Idx: 0 Loss: 0.027531805856593677
Epoch: 36 Idx: 5000 Loss: 0.006591695691689953
Epoch: 37 Idx: 0 Loss: 0.011815427149601801
Epoch: 37 Idx: 5000 Loss: 0.016328859283155778
Epoch: 38 Idx: 0 Loss: 0.01640923148281828
Epoch: 38 Idx: 5000 Loss: 0.006282902492555663
Epoch: 39 Idx: 0 Loss: 0.004685834852598041
Epoch: 39 Idx: 5000 Loss: 0.015518944730457155
Epoch: 40 Idx: 0 Loss: 0.009630667591540416
Epoch: 40 Idx: 5000 Loss: 0.012462887440324734
Epoch: 41 Idx: 0 Loss: 0.01361584866187631
Epoch: 41 Idx: 5000 Loss: 0.007136677588393894
Epoch: 42 Idx: 0 Loss: 0.012992899830579135
Epoch: 42 Idx: 5000 Loss: 0.02383997227393361
Epoch: 43 Idx: 0 Loss: 0.012795351388948429
Epoch: 43 Idx: 5000 Loss: 0.00959999684115283
Epoch: 44 Idx: 0 Loss: 0.015008468318136181
Epoch: 44 Idx: 5000 Loss: 0.011650988007842384
Epoch: 45 Idx: 0 Loss: 0.031839840863325565
Epoch: 45 Idx: 5000 Loss: 0.01036452823657095
Epoch: 46 Idx: 0 Loss: 0.0313455006501688
Epoch: 46 Idx: 5000 Loss: 0.012775328280279805
Epoch: 47 Idx: 0 Loss: 0.01823492463805101
Epoch: 47 Idx: 5000 Loss: 0.02909874726219803
Epoch: 48 Idx: 0 Loss: 0.010576381613532821
Epoch: 48 Idx: 5000 Loss: 0.024221942172454436
Epoch: 49 Idx: 0 Loss: 0.012269846139980027
Epoch: 49 Idx: 5000 Loss: 0.018836332019782236
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14012797980666966
Epoch: 0 Idx: 5000 Loss: 0.014940706052467516
Epoch: 1 Idx: 0 Loss: 0.019516644330488674
Epoch: 1 Idx: 5000 Loss: 0.03213033245247973
Epoch: 2 Idx: 0 Loss: 0.01698363802567237
Epoch: 2 Idx: 5000 Loss: 0.01971468104146088
Epoch: 3 Idx: 0 Loss: 0.01874816066515212
Epoch: 3 Idx: 5000 Loss: 0.016149456931094312
Epoch: 4 Idx: 0 Loss: 0.017303999291952896
Epoch: 4 Idx: 5000 Loss: 0.02651168818099923
Epoch: 5 Idx: 0 Loss: 0.0086311245723314
Epoch: 5 Idx: 5000 Loss: 0.00933661581990754
Epoch: 6 Idx: 0 Loss: 0.01104689955396971
Epoch: 6 Idx: 5000 Loss: 0.02988084789321474
Epoch: 7 Idx: 0 Loss: 0.019742682956239113
Epoch: 7 Idx: 5000 Loss: 0.011394010240181163
Epoch: 8 Idx: 0 Loss: 0.011244733720324446
Epoch: 8 Idx: 5000 Loss: 0.016216645561184025
Epoch: 9 Idx: 0 Loss: 0.0197326518017149
Epoch: 9 Idx: 5000 Loss: 0.025149927164958202
Epoch: 10 Idx: 0 Loss: 0.00902144490396157
Epoch: 10 Idx: 5000 Loss: 0.007161562621549847
Epoch: 11 Idx: 0 Loss: 0.008823366111424908
Epoch: 11 Idx: 5000 Loss: 0.013255326217713456
Epoch: 12 Idx: 0 Loss: 0.02228604527020471
Epoch: 12 Idx: 5000 Loss: 0.050779866200635515
Epoch: 13 Idx: 0 Loss: 0.012661403678620686
Epoch: 13 Idx: 5000 Loss: 0.011660423984889805
Epoch: 14 Idx: 0 Loss: 0.01773004906795834
Epoch: 14 Idx: 5000 Loss: 0.01758112132967546
Epoch: 15 Idx: 0 Loss: 0.007940249936597733
Epoch: 15 Idx: 5000 Loss: 0.028295815632378166
Epoch: 16 Idx: 0 Loss: 0.033962044068365296
Epoch: 16 Idx: 5000 Loss: 0.018180313592333183
Epoch: 17 Idx: 0 Loss: 0.016560886959671256
Epoch: 17 Idx: 5000 Loss: 0.014165161874910296
Epoch: 18 Idx: 0 Loss: 0.019730461499585697
Epoch: 18 Idx: 5000 Loss: 0.00742086328749069
Epoch: 19 Idx: 0 Loss: 0.0058185462851067515
Epoch: 19 Idx: 5000 Loss: 0.019418184675101934
Epoch: 20 Idx: 0 Loss: 0.008353504634748822
Epoch: 20 Idx: 5000 Loss: 0.012556527292331924
Epoch: 21 Idx: 0 Loss: 0.006053577892811775
Epoch: 21 Idx: 5000 Loss: 0.016790355282620885
Epoch: 22 Idx: 0 Loss: 0.014118762135352618
Epoch: 22 Idx: 5000 Loss: 0.005240963545163737
Epoch: 23 Idx: 0 Loss: 0.013017475307592055
Epoch: 23 Idx: 5000 Loss: 0.032003154599162933
Epoch: 24 Idx: 0 Loss: 0.018507795108702946
Epoch: 24 Idx: 5000 Loss: 0.005381093890884974
Epoch: 25 Idx: 0 Loss: 0.018887327018119585
Epoch: 25 Idx: 5000 Loss: 0.018694796250304027
Epoch: 26 Idx: 0 Loss: 0.008907341099203544
Epoch: 26 Idx: 5000 Loss: 0.012783614087956129
Epoch: 27 Idx: 0 Loss: 0.01145871814316192
Epoch: 27 Idx: 5000 Loss: 0.014069592068130727
Epoch: 28 Idx: 0 Loss: 0.016588226994665032
Epoch: 28 Idx: 5000 Loss: 0.020475039741650568
Epoch: 29 Idx: 0 Loss: 0.013791649195461143
Epoch: 29 Idx: 5000 Loss: 0.013648951331418501
Epoch: 30 Idx: 0 Loss: 0.01265548902920206
Epoch: 30 Idx: 5000 Loss: 0.008570165162621336
Epoch: 31 Idx: 0 Loss: 0.020428555283073108
Epoch: 31 Idx: 5000 Loss: 0.012979631080627354
Epoch: 32 Idx: 0 Loss: 0.009282451812516204
Epoch: 32 Idx: 5000 Loss: 0.007020258265099707
Epoch: 33 Idx: 0 Loss: 0.0070405171251818055
Epoch: 33 Idx: 5000 Loss: 0.0045225091435417
Epoch: 34 Idx: 0 Loss: 0.02180898741669698
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 312, in forward
    feature_emb = self.name_embedding(features[i]) #  dim: (2, batch_size, max_types, max_paths, max_pathlen, 512)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1814, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc249>
Subject: Job 4066803: <python main.py 3 20 False True> in cluster <dcc> Exited

Job <python main.py 3 20 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc249>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:36 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 20 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46074.73 sec.
    Max Memory :                                 2930 MB
    Average Memory :                             2723.88 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40487.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46227 sec.
    Turnaround time :                            46206 sec.

The output (if any) is above this job summary.

