2020-09-15 15:49:41.730590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:44.744381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:44.864680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1f:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:44.864754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:44.866813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:44.868202: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:44.868546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:44.870462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:44.871856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:44.872052: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:44.872071: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:44.872398: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:44.879630: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600120000 Hz
2020-09-15 15:49:44.879783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563c3e54340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:44.879803: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:44.881434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:44.881456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20360376154241422
Epoch: 0 Idx: 5000 Loss: 0.006601430824103024
Epoch: 1 Idx: 0 Loss: 0.012654868276519193
Epoch: 1 Idx: 5000 Loss: 0.015437432057451985
Epoch: 2 Idx: 0 Loss: 0.00809984952543858
Epoch: 2 Idx: 5000 Loss: 0.014462415476135812
Epoch: 3 Idx: 0 Loss: 0.012299240774559645
Epoch: 3 Idx: 5000 Loss: 0.022185882046887838
Epoch: 4 Idx: 0 Loss: 0.02207243258217888
Epoch: 4 Idx: 5000 Loss: 0.020188100312479865
Epoch: 5 Idx: 0 Loss: 0.019930878926445614
Epoch: 5 Idx: 5000 Loss: 0.00767790586043166
Epoch: 6 Idx: 0 Loss: 0.0073236740066183696
Epoch: 6 Idx: 5000 Loss: 0.006967522039378291
Epoch: 7 Idx: 0 Loss: 0.005686885390388782
Epoch: 7 Idx: 5000 Loss: 0.012909209979025688
Epoch: 8 Idx: 0 Loss: 0.0181901414805036
Epoch: 8 Idx: 5000 Loss: 0.013538493398960409
Epoch: 9 Idx: 0 Loss: 0.011223629695205243
Epoch: 9 Idx: 5000 Loss: 0.00703422747823588
Epoch: 10 Idx: 0 Loss: 0.009827920208479276
Epoch: 10 Idx: 5000 Loss: 0.01840760396755583
Epoch: 11 Idx: 0 Loss: 0.023156520000612267
Epoch: 11 Idx: 5000 Loss: 0.010351441744221153
Epoch: 12 Idx: 0 Loss: 0.013939615000245683
Epoch: 12 Idx: 5000 Loss: 0.030345945955830688
Epoch: 13 Idx: 0 Loss: 0.021847785015252984
Epoch: 13 Idx: 5000 Loss: 0.012493853486801832
Epoch: 14 Idx: 0 Loss: 0.006012928650474053
Epoch: 14 Idx: 5000 Loss: 0.02055110239555846
Epoch: 15 Idx: 0 Loss: 0.013715859904316719
Epoch: 15 Idx: 5000 Loss: 0.01493419383233191
Epoch: 16 Idx: 0 Loss: 0.015203432107377905
Epoch: 16 Idx: 5000 Loss: 0.00958235915782553
Epoch: 17 Idx: 0 Loss: 0.016125213822973588
Epoch: 17 Idx: 5000 Loss: 0.021203836179837152
Epoch: 18 Idx: 0 Loss: 0.016190490515250382
Epoch: 18 Idx: 5000 Loss: 0.0065733595469841
Epoch: 19 Idx: 0 Loss: 0.015228605997814228
Epoch: 19 Idx: 5000 Loss: 0.011928384844670932
Epoch: 20 Idx: 0 Loss: 0.007127126902358481
Epoch: 20 Idx: 5000 Loss: 0.008493689706115413
Epoch: 21 Idx: 0 Loss: 0.020772788934010373
Epoch: 21 Idx: 5000 Loss: 0.028747355002778998
Epoch: 22 Idx: 0 Loss: 0.016371066397328972
Epoch: 22 Idx: 5000 Loss: 0.018534481980084717
Epoch: 23 Idx: 0 Loss: 0.01292993466102331
Epoch: 23 Idx: 5000 Loss: 0.01385522457550158
Epoch: 24 Idx: 0 Loss: 0.006591596375440964
Epoch: 24 Idx: 5000 Loss: 0.012564591095562778
Epoch: 25 Idx: 0 Loss: 0.008620800313610571
Epoch: 25 Idx: 5000 Loss: 0.019858213012413518
Epoch: 26 Idx: 0 Loss: 0.006284880106937207
Epoch: 26 Idx: 5000 Loss: 0.02150770008498974
Epoch: 27 Idx: 0 Loss: 0.01146764741227118
Epoch: 27 Idx: 5000 Loss: 0.011116042972320064
Epoch: 28 Idx: 0 Loss: 0.014978684377604952
Epoch: 28 Idx: 5000 Loss: 0.015630596613675787
Epoch: 29 Idx: 0 Loss: 0.01946783419563523
Epoch: 29 Idx: 5000 Loss: 0.022819743705858975
Epoch: 30 Idx: 0 Loss: 0.03024639811097261
Epoch: 30 Idx: 5000 Loss: 0.009097839120467625
Epoch: 31 Idx: 0 Loss: 0.009310030502713463
Epoch: 31 Idx: 5000 Loss: 0.03349742734852148
Epoch: 32 Idx: 0 Loss: 0.020644000067824797
Epoch: 32 Idx: 5000 Loss: 0.01072342786933083
Epoch: 33 Idx: 0 Loss: 0.027872386784718973
Epoch: 33 Idx: 5000 Loss: 0.010636931804488478
Epoch: 34 Idx: 0 Loss: 0.013109582244224849
Epoch: 34 Idx: 5000 Loss: 0.012345986527381654
Epoch: 35 Idx: 0 Loss: 0.013208722589005371
Epoch: 35 Idx: 5000 Loss: 0.03193069931204217
Epoch: 36 Idx: 0 Loss: 0.015404252340825882
Epoch: 36 Idx: 5000 Loss: 0.01216123969029514
Epoch: 37 Idx: 0 Loss: 0.021431749612719344
Epoch: 37 Idx: 5000 Loss: 0.015444086203711783
Epoch: 38 Idx: 0 Loss: 0.0238887838880648
Epoch: 38 Idx: 5000 Loss: 0.020804870288322157
Epoch: 39 Idx: 0 Loss: 0.0066616119291229925
Epoch: 39 Idx: 5000 Loss: 0.020867786126245135
Epoch: 40 Idx: 0 Loss: 0.012154556402284723
Epoch: 40 Idx: 5000 Loss: 0.012593211344563853
Epoch: 41 Idx: 0 Loss: 0.006360538680263461
Epoch: 41 Idx: 5000 Loss: 0.010305519064413468
Epoch: 42 Idx: 0 Loss: 0.019202057160070216
Epoch: 42 Idx: 5000 Loss: 0.005166383788316846
Epoch: 43 Idx: 0 Loss: 0.014402329871531394
Epoch: 43 Idx: 5000 Loss: 0.034824198136371956
Epoch: 44 Idx: 0 Loss: 0.022930452282112202
Epoch: 44 Idx: 5000 Loss: 0.007978130740958513
Epoch: 45 Idx: 0 Loss: 0.012140912398200608
Epoch: 45 Idx: 5000 Loss: 0.011101481275966187
Epoch: 46 Idx: 0 Loss: 0.011412599633564346
Epoch: 46 Idx: 5000 Loss: 0.010845444756245654
Epoch: 47 Idx: 0 Loss: 0.021540330074770356
Epoch: 47 Idx: 5000 Loss: 0.009630204414425369
Epoch: 48 Idx: 0 Loss: 0.005819707986800968
Epoch: 48 Idx: 5000 Loss: 0.013529137811853206
Epoch: 49 Idx: 0 Loss: 0.009275404648219316
Epoch: 49 Idx: 5000 Loss: 0.012608641772722862
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.13557501479583564
Epoch: 0 Idx: 5000 Loss: 0.031907555374827756
Epoch: 1 Idx: 0 Loss: 0.005537552119628008
Epoch: 1 Idx: 5000 Loss: 0.012588460872892056
Epoch: 2 Idx: 0 Loss: 0.029117222008783986
Epoch: 2 Idx: 5000 Loss: 0.010362701227443896
Epoch: 3 Idx: 0 Loss: 0.009258431163596977
Epoch: 3 Idx: 5000 Loss: 0.014852751387497214
Epoch: 4 Idx: 0 Loss: 0.009872875111169462
Epoch: 4 Idx: 5000 Loss: 0.019753495839228294
Epoch: 5 Idx: 0 Loss: 0.013444770401128497
Epoch: 5 Idx: 5000 Loss: 0.013773065598067447
Epoch: 6 Idx: 0 Loss: 0.015867461212652256
Epoch: 6 Idx: 5000 Loss: 0.01070713948812408
Epoch: 7 Idx: 0 Loss: 0.007250605241061126
Epoch: 7 Idx: 5000 Loss: 0.014475023264192435
Epoch: 8 Idx: 0 Loss: 0.020256786171984422
Epoch: 8 Idx: 5000 Loss: 0.020050965147633975
Epoch: 9 Idx: 0 Loss: 0.013073004815837492
Epoch: 9 Idx: 5000 Loss: 0.017636930578906695
Epoch: 10 Idx: 0 Loss: 0.00847635228728768
Epoch: 10 Idx: 5000 Loss: 0.010329785647079821
Epoch: 11 Idx: 0 Loss: 0.01079534712742385
Epoch: 11 Idx: 5000 Loss: 0.01325270699700603
Epoch: 12 Idx: 0 Loss: 0.013818462966639276
Epoch: 12 Idx: 5000 Loss: 0.03981120056448814
Epoch: 13 Idx: 0 Loss: 0.008937624606878334
Epoch: 13 Idx: 5000 Loss: 0.008282919441580487
Epoch: 14 Idx: 0 Loss: 0.012156553611863491
Epoch: 14 Idx: 5000 Loss: 0.00960969274879971
Epoch: 15 Idx: 0 Loss: 0.0203517354210686
Epoch: 15 Idx: 5000 Loss: 0.013472078439255328
Epoch: 16 Idx: 0 Loss: 0.042318445969734865
Epoch: 16 Idx: 5000 Loss: 0.01407293734834054
Epoch: 17 Idx: 0 Loss: 0.011008008843151123
Epoch: 17 Idx: 5000 Loss: 0.021392965645724113
Epoch: 18 Idx: 0 Loss: 0.02142246444447643
Epoch: 18 Idx: 5000 Loss: 0.011072965091935465
Epoch: 19 Idx: 0 Loss: 0.014685240970288603
Epoch: 19 Idx: 5000 Loss: 0.024719666699775152
Epoch: 20 Idx: 0 Loss: 0.005896223528228927
Epoch: 20 Idx: 5000 Loss: 0.009581618117560994
Epoch: 21 Idx: 0 Loss: 0.008857583615645714
Epoch: 21 Idx: 5000 Loss: 0.006372544522313797
Epoch: 22 Idx: 0 Loss: 0.012823044670985682
Epoch: 22 Idx: 5000 Loss: 0.011269490915143848
Epoch: 23 Idx: 0 Loss: 0.0329998987193312
Epoch: 23 Idx: 5000 Loss: 0.04150355248245677
Epoch: 24 Idx: 0 Loss: 0.01570702898453583
Epoch: 24 Idx: 5000 Loss: 0.012580047434909224
Epoch: 25 Idx: 0 Loss: 0.010286972223591994
Epoch: 25 Idx: 5000 Loss: 0.01477740799497711
Epoch: 26 Idx: 0 Loss: 0.005015315276809771
Epoch: 26 Idx: 5000 Loss: 0.006192899899802891
Epoch: 27 Idx: 0 Loss: 0.009490507872954398
Epoch: 27 Idx: 5000 Loss: 0.007688206450416298
Epoch: 28 Idx: 0 Loss: 0.008257417266447128
Epoch: 28 Idx: 5000 Loss: 0.015252355497274352
Epoch: 29 Idx: 0 Loss: 0.009703777395408114
Epoch: 29 Idx: 5000 Loss: 0.024929872808101723
Epoch: 30 Idx: 0 Loss: 0.01239530945840811
Epoch: 30 Idx: 5000 Loss: 0.009799035066630662
Epoch: 31 Idx: 0 Loss: 0.01601972600492068
Epoch: 31 Idx: 5000 Loss: 0.01338252572673005
Epoch: 32 Idx: 0 Loss: 0.009473712714911223
Epoch: 32 Idx: 5000 Loss: 0.00841581249291579
Epoch: 33 Idx: 0 Loss: 0.01594844839989952
Epoch: 33 Idx: 5000 Loss: 0.011339220398278475
Epoch: 34 Idx: 0 Loss: 0.01160592563191386
Epoch: 34 Idx: 5000 Loss: 0.01110822089530032
Epoch: 35 Idx: 0 Loss: 0.008415272697897562
Epoch: 35 Idx: 5000 Loss: 0.01131561801130827
Epoch: 36 Idx: 0 Loss: 0.027449402606924512
Epoch: 36 Idx: 5000 Loss: 0.032182191807193054
Epoch: 37 Idx: 0 Loss: 0.020372769836222854
Epoch: 37 Idx: 5000 Loss: 0.01899521716594986
Epoch: 38 Idx: 0 Loss: 0.011823134434386932
Epoch: 38 Idx: 5000 Loss: 0.011314660196151297
Epoch: 39 Idx: 0 Loss: 0.004238852344751714
Epoch: 39 Idx: 5000 Loss: 0.011518814714033793
Epoch: 40 Idx: 0 Loss: 0.014208277314655121
Epoch: 40 Idx: 5000 Loss: 0.01364457197767701
Epoch: 41 Idx: 0 Loss: 0.025508928165799902
Epoch: 41 Idx: 5000 Loss: 0.009635830950800336
Epoch: 42 Idx: 0 Loss: 0.010069063329598919
Epoch: 42 Idx: 5000 Loss: 0.0227624083547439
Epoch: 43 Idx: 0 Loss: 0.013840542112820787
Epoch: 43 Idx: 5000 Loss: 0.01824626318124346
Epoch: 44 Idx: 0 Loss: 0.013802133789508182
Epoch: 44 Idx: 5000 Loss: 0.020032146715549155
Epoch: 45 Idx: 0 Loss: 0.013685329238780722
Epoch: 45 Idx: 5000 Loss: 0.011451910574015609
Epoch: 46 Idx: 0 Loss: 0.012731827038191843
Epoch: 46 Idx: 5000 Loss: 0.024091864813159548
Epoch: 47 Idx: 0 Loss: 0.009371814760941259
Epoch: 47 Idx: 5000 Loss: 0.00422192998631655
Epoch: 48 Idx: 0 Loss: 0.034894765293018756
Epoch: 48 Idx: 5000 Loss: 0.01836290447491841
Epoch: 49 Idx: 0 Loss: 0.013492709242609681
Epoch: 49 Idx: 5000 Loss: 0.011182221673203945
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1551635279295699
Epoch: 0 Idx: 5000 Loss: 0.043021301027110964
Epoch: 1 Idx: 0 Loss: 0.012351845209054848
Epoch: 1 Idx: 5000 Loss: 0.023522462339813595
Epoch: 2 Idx: 0 Loss: 0.021414549484343983
Epoch: 2 Idx: 5000 Loss: 0.013778844593919594
Epoch: 3 Idx: 0 Loss: 0.013105019419420284
Epoch: 3 Idx: 5000 Loss: 0.016477486877457856
Epoch: 4 Idx: 0 Loss: 0.012392083016722993
Epoch: 4 Idx: 5000 Loss: 0.009714752397923443
Epoch: 5 Idx: 0 Loss: 0.021798241481512097
Epoch: 5 Idx: 5000 Loss: 0.01642758052264096
Epoch: 6 Idx: 0 Loss: 0.01597239463221044
Epoch: 6 Idx: 5000 Loss: 0.01033220942656771
Epoch: 7 Idx: 0 Loss: 0.0172244682554043
Epoch: 7 Idx: 5000 Loss: 0.007576237994973329
Epoch: 8 Idx: 0 Loss: 0.012987254064319265
Epoch: 8 Idx: 5000 Loss: 0.01724261181635992
Epoch: 9 Idx: 0 Loss: 0.019881836771513527
Epoch: 9 Idx: 5000 Loss: 0.010715790565829489
Epoch: 10 Idx: 0 Loss: 0.013900194681150373
Epoch: 10 Idx: 5000 Loss: 0.008802027809791085
Epoch: 11 Idx: 0 Loss: 0.010215592625853668
Epoch: 11 Idx: 5000 Loss: 0.01823550906233914
Epoch: 12 Idx: 0 Loss: 0.011713465043329353
Epoch: 12 Idx: 5000 Loss: 0.012697130721459116
Epoch: 13 Idx: 0 Loss: 0.007220750902139051
Epoch: 13 Idx: 5000 Loss: 0.006523838420566976
Epoch: 14 Idx: 0 Loss: 0.017850222610486393
Epoch: 14 Idx: 5000 Loss: 0.019990771730491956
Epoch: 15 Idx: 0 Loss: 0.006952509655143543
Epoch: 15 Idx: 5000 Loss: 0.021625796170325545
Epoch: 16 Idx: 0 Loss: 0.010366538777154773
Epoch: 16 Idx: 5000 Loss: 0.010404338787569542
Epoch: 17 Idx: 0 Loss: 0.021321985804928598
Epoch: 17 Idx: 5000 Loss: 0.019577432386097635
Epoch: 18 Idx: 0 Loss: 0.012866241354855198
Epoch: 18 Idx: 5000 Loss: 0.010670005298535772
Epoch: 19 Idx: 0 Loss: 0.01737951786736874
Epoch: 19 Idx: 5000 Loss: 0.015592992864736536
Epoch: 20 Idx: 0 Loss: 0.008580613032952818
Epoch: 20 Idx: 5000 Loss: 0.00853971435901867
Epoch: 21 Idx: 0 Loss: 0.006047690531742978
Epoch: 21 Idx: 5000 Loss: 0.01279028145049897
Epoch: 22 Idx: 0 Loss: 0.014029330571259248
Epoch: 22 Idx: 5000 Loss: 0.013707804887109562
Epoch: 23 Idx: 0 Loss: 0.01302035478648727
Epoch: 23 Idx: 5000 Loss: 0.018811964820772086
Epoch: 24 Idx: 0 Loss: 0.025786360320222274
Epoch: 24 Idx: 5000 Loss: 0.008860079820634378
Epoch: 25 Idx: 0 Loss: 0.018535793447010965
Epoch: 25 Idx: 5000 Loss: 0.006807860065835926
Epoch: 26 Idx: 0 Loss: 0.010984919776375036
Epoch: 26 Idx: 5000 Loss: 0.015417272434876067
Epoch: 27 Idx: 0 Loss: 0.01286889897442478
Epoch: 27 Idx: 5000 Loss: 0.008010193613537038
Epoch: 28 Idx: 0 Loss: 0.015571889764550779
Epoch: 28 Idx: 5000 Loss: 0.007724757096666949
Epoch: 29 Idx: 0 Loss: 0.005864461305087247
Epoch: 29 Idx: 5000 Loss: 0.008370148154331847
Epoch: 30 Idx: 0 Loss: 0.014069781618346988
Epoch: 30 Idx: 5000 Loss: 0.014029596846103998
Epoch: 31 Idx: 0 Loss: 0.009651619978708649
Epoch: 31 Idx: 5000 Loss: 0.010531225528419048
Epoch: 32 Idx: 0 Loss: 0.015118195107180186
Epoch: 32 Idx: 5000 Loss: 0.006628549015214956
Epoch: 33 Idx: 0 Loss: 0.008926263131508093
Epoch: 33 Idx: 5000 Loss: 0.024439896524789322
Epoch: 34 Idx: 0 Loss: 0.015736780625485197
Epoch: 34 Idx: 5000 Loss: 0.007039564919726494
Epoch: 35 Idx: 0 Loss: 0.015243879342445393
Epoch: 35 Idx: 5000 Loss: 0.023846472826538054
Epoch: 36 Idx: 0 Loss: 0.018685135944490745
Epoch: 36 Idx: 5000 Loss: 0.009541617007945948
Epoch: 37 Idx: 0 Loss: 0.017995378839138553
Epoch: 37 Idx: 5000 Loss: 0.017654450746998458
Epoch: 38 Idx: 0 Loss: 0.013802254918999092
Epoch: 38 Idx: 5000 Loss: 0.013781189713037363
Epoch: 39 Idx: 0 Loss: 0.024600132113607228
Epoch: 39 Idx: 5000 Loss: 0.017501793084156045
Epoch: 40 Idx: 0 Loss: 0.02176972020712234
Epoch: 40 Idx: 5000 Loss: 0.024893708950919434
Epoch: 41 Idx: 0 Loss: 0.010861781090016119
Epoch: 41 Idx: 5000 Loss: 0.010689530023903188
Epoch: 42 Idx: 0 Loss: 0.009289903114343374
Epoch: 42 Idx: 5000 Loss: 0.007264072505649915
Epoch: 43 Idx: 0 Loss: 0.003989702372577515
Epoch: 43 Idx: 5000 Loss: 0.01554039219860864
Epoch: 44 Idx: 0 Loss: 0.02870747416807333
Epoch: 44 Idx: 5000 Loss: 0.012730864553442344
Epoch: 45 Idx: 0 Loss: 0.022604438658934942
Epoch: 45 Idx: 5000 Loss: 0.03353549759262573
Epoch: 46 Idx: 0 Loss: 0.00981501450927143
Epoch: 46 Idx: 5000 Loss: 0.028697216335427017
Epoch: 47 Idx: 0 Loss: 0.00829460443372853
Epoch: 47 Idx: 5000 Loss: 0.007508191813166821
Epoch: 48 Idx: 0 Loss: 0.018228553239016353
Epoch: 48 Idx: 5000 Loss: 0.008271534208583006
Epoch: 49 Idx: 0 Loss: 0.016389452882138684
Epoch: 49 Idx: 5000 Loss: 0.019071700943594682
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.22510670011976383
Epoch: 0 Idx: 5000 Loss: 0.015778135836663112
Epoch: 1 Idx: 0 Loss: 0.029164289268281116
Epoch: 1 Idx: 5000 Loss: 0.024951870389923962
Epoch: 2 Idx: 0 Loss: 0.004769376503665379
Epoch: 2 Idx: 5000 Loss: 0.020983931840870784
Epoch: 3 Idx: 0 Loss: 0.01233537558385789
Epoch: 3 Idx: 5000 Loss: 0.01231918637824921
Epoch: 4 Idx: 0 Loss: 0.0101231633560116
Epoch: 4 Idx: 5000 Loss: 0.010165456263592228
Epoch: 5 Idx: 0 Loss: 0.022423611906190473
Epoch: 5 Idx: 5000 Loss: 0.030590696102483342
Epoch: 6 Idx: 0 Loss: 0.021330984656076038
Epoch: 6 Idx: 5000 Loss: 0.011970531101990508
Epoch: 7 Idx: 0 Loss: 0.015019056209458845
Epoch: 7 Idx: 5000 Loss: 0.016957392701629596
Epoch: 8 Idx: 0 Loss: 0.020343448444799666
Epoch: 8 Idx: 5000 Loss: 0.011382513609555833
Epoch: 9 Idx: 0 Loss: 0.01335530852437663
Epoch: 9 Idx: 5000 Loss: 0.018010602821538574
Epoch: 10 Idx: 0 Loss: 0.009403721467677609
Epoch: 10 Idx: 5000 Loss: 0.016590081162567542
Epoch: 11 Idx: 0 Loss: 0.009118700844657738
Epoch: 11 Idx: 5000 Loss: 0.018831959019433686
Epoch: 12 Idx: 0 Loss: 0.02509248654224992
Epoch: 12 Idx: 5000 Loss: 0.015511814373844999
Epoch: 13 Idx: 0 Loss: 0.006651084612034217
Epoch: 13 Idx: 5000 Loss: 0.010013721255943204
Epoch: 14 Idx: 0 Loss: 0.012516075130435119
Epoch: 14 Idx: 5000 Loss: 0.02653188145573156
Epoch: 15 Idx: 0 Loss: 0.012587581382186611
Epoch: 15 Idx: 5000 Loss: 0.007001011269581342
Epoch: 16 Idx: 0 Loss: 0.008118579820024107
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc248>
Subject: Job 4066904: <python main.py 20 2 True True> in cluster <dcc> Exited

Job <python main.py 20 2 True True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc248>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 20 2 True True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46134.88 sec.
    Max Memory :                                 2863 MB
    Average Memory :                             2691.45 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40554.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46166 sec.
    Turnaround time :                            46197 sec.

The output (if any) is above this job summary.

