2020-09-15 15:49:58.320592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:50:01.622672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:50:01.736299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:50:01.736388: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:50:01.738663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:50:01.740216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:50:01.741195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:50:01.743201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:50:01.744724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:50:01.745024: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:50:01.745046: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:50:01.745355: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:50:01.752847: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600160000 Hz
2020-09-15 15:50:01.753088: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cd5b941080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:50:01.753109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:50:01.755106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:50:01.755160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18377204108191159
Epoch: 0 Idx: 5000 Loss: 0.015002650060447981
Epoch: 1 Idx: 0 Loss: 0.03557937136283533
Epoch: 1 Idx: 5000 Loss: 0.02986747494459643
Epoch: 2 Idx: 0 Loss: 0.006661806613028945
Epoch: 2 Idx: 5000 Loss: 0.01522849940177815
Epoch: 3 Idx: 0 Loss: 0.011989769745155825
Epoch: 3 Idx: 5000 Loss: 0.009365683055028492
Epoch: 4 Idx: 0 Loss: 0.008487435147662127
Epoch: 4 Idx: 5000 Loss: 0.030110968668462225
Epoch: 5 Idx: 0 Loss: 0.011667519715512553
Epoch: 5 Idx: 5000 Loss: 0.0075153430613979135
Epoch: 6 Idx: 0 Loss: 0.022122661520173174
Epoch: 6 Idx: 5000 Loss: 0.02102176413771935
Epoch: 7 Idx: 0 Loss: 0.008401186936878084
Epoch: 7 Idx: 5000 Loss: 0.021277699718652468
Epoch: 8 Idx: 0 Loss: 0.01601686794667558
Epoch: 8 Idx: 5000 Loss: 0.003946839650168013
Epoch: 9 Idx: 0 Loss: 0.011669570126598534
Epoch: 9 Idx: 5000 Loss: 0.013748515394162338
Epoch: 10 Idx: 0 Loss: 0.009894603846081337
Epoch: 10 Idx: 5000 Loss: 0.022027522826595015
Epoch: 11 Idx: 0 Loss: 0.010824643938111307
Epoch: 11 Idx: 5000 Loss: 0.018864561047372976
Epoch: 12 Idx: 0 Loss: 0.004910599056252515
Epoch: 12 Idx: 5000 Loss: 0.016932164121891077
Epoch: 13 Idx: 0 Loss: 0.010643458390334606
Epoch: 13 Idx: 5000 Loss: 0.004980003917826381
Epoch: 14 Idx: 0 Loss: 0.012220809529471691
Epoch: 14 Idx: 5000 Loss: 0.0239726709554054
Epoch: 15 Idx: 0 Loss: 0.0236539504131569
Epoch: 15 Idx: 5000 Loss: 0.014146092301625852
Epoch: 16 Idx: 0 Loss: 0.02258144638868477
Epoch: 16 Idx: 5000 Loss: 0.033115975447408304
Epoch: 17 Idx: 0 Loss: 0.033352743646641425
Epoch: 17 Idx: 5000 Loss: 0.009591707469491739
Epoch: 18 Idx: 0 Loss: 0.007094260456102083
Epoch: 18 Idx: 5000 Loss: 0.010658547502044334
Epoch: 19 Idx: 0 Loss: 0.037012015582249126
Epoch: 19 Idx: 5000 Loss: 0.007576783418305164
Epoch: 20 Idx: 0 Loss: 0.009202064709657322
Epoch: 20 Idx: 5000 Loss: 0.021879576789466573
Epoch: 21 Idx: 0 Loss: 0.011278117402892827
Epoch: 21 Idx: 5000 Loss: 0.03981703497257254
Epoch: 22 Idx: 0 Loss: 0.009070630244602598
Epoch: 22 Idx: 5000 Loss: 0.013268241775257397
Epoch: 23 Idx: 0 Loss: 0.03301352460342071
Epoch: 23 Idx: 5000 Loss: 0.008001220424783633
Epoch: 24 Idx: 0 Loss: 0.014659757941951871
Epoch: 24 Idx: 5000 Loss: 0.03297221638976096
Epoch: 25 Idx: 0 Loss: 0.019278011791904373
Epoch: 25 Idx: 5000 Loss: 0.010175107535412214
Epoch: 26 Idx: 0 Loss: 0.013012566550501158
Epoch: 26 Idx: 5000 Loss: 0.02456413121365871
Epoch: 27 Idx: 0 Loss: 0.01006720971730466
Epoch: 27 Idx: 5000 Loss: 0.014545938158803813
Epoch: 28 Idx: 0 Loss: 0.026897543949813918
Epoch: 28 Idx: 5000 Loss: 0.034656834131224536
Epoch: 29 Idx: 0 Loss: 0.016378549962774696
Epoch: 29 Idx: 5000 Loss: 0.010112340918559119
Epoch: 30 Idx: 0 Loss: 0.019284493873556872
Epoch: 30 Idx: 5000 Loss: 0.01485093994230902
Epoch: 31 Idx: 0 Loss: 0.019203511462351698
Epoch: 31 Idx: 5000 Loss: 0.01899246404897789
Epoch: 32 Idx: 0 Loss: 0.008558239843745392
Epoch: 32 Idx: 5000 Loss: 0.02231980845802614
Epoch: 33 Idx: 0 Loss: 0.01215560838646729
Epoch: 33 Idx: 5000 Loss: 0.013366827760584357
Epoch: 34 Idx: 0 Loss: 0.006749664364377384
Epoch: 34 Idx: 5000 Loss: 0.03582011612335286
Epoch: 35 Idx: 0 Loss: 0.004903704171161719
Epoch: 35 Idx: 5000 Loss: 0.01713699582901957
Epoch: 36 Idx: 0 Loss: 0.01434642702342611
Epoch: 36 Idx: 5000 Loss: 0.022011576878742455
Epoch: 37 Idx: 0 Loss: 0.012688435846905315
Epoch: 37 Idx: 5000 Loss: 0.012398445210500557
Epoch: 38 Idx: 0 Loss: 0.015373932172241898
Epoch: 38 Idx: 5000 Loss: 0.020264279542299538
Epoch: 39 Idx: 0 Loss: 0.007132190091107406
Epoch: 39 Idx: 5000 Loss: 0.0180333118953065
Epoch: 40 Idx: 0 Loss: 0.008979085890237127
Epoch: 40 Idx: 5000 Loss: 0.022696374927144096
Epoch: 41 Idx: 0 Loss: 0.010709435585992674
Epoch: 41 Idx: 5000 Loss: 0.006793617453988323
Epoch: 42 Idx: 0 Loss: 0.009863137549588678
Epoch: 42 Idx: 5000 Loss: 0.012905268987219195
Epoch: 43 Idx: 0 Loss: 0.018890154888636053
Epoch: 43 Idx: 5000 Loss: 0.020051965867475405
Epoch: 44 Idx: 0 Loss: 0.01562784723174102
Epoch: 44 Idx: 5000 Loss: 0.02157699730929403
Epoch: 45 Idx: 0 Loss: 0.007523467261071282
Epoch: 45 Idx: 5000 Loss: 0.01568003971277428
Epoch: 46 Idx: 0 Loss: 0.015463375615575684
Epoch: 46 Idx: 5000 Loss: 0.012572720771669484
Epoch: 47 Idx: 0 Loss: 0.009868800529966571
Epoch: 47 Idx: 5000 Loss: 0.00788396455631194
Epoch: 48 Idx: 0 Loss: 0.046526801608504434
Epoch: 48 Idx: 5000 Loss: 0.017715852146778583
Epoch: 49 Idx: 0 Loss: 0.01840563354781042
Epoch: 49 Idx: 5000 Loss: 0.023989714361777742
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.13315611545686504
Epoch: 0 Idx: 5000 Loss: 0.015355252289902002
Epoch: 1 Idx: 0 Loss: 0.01460683749448061
Epoch: 1 Idx: 5000 Loss: 0.019422663266544907
Epoch: 2 Idx: 0 Loss: 0.03743808453026744
Epoch: 2 Idx: 5000 Loss: 0.011581375798219077
Epoch: 3 Idx: 0 Loss: 0.02663117474367894
Epoch: 3 Idx: 5000 Loss: 0.01809803298265998
Epoch: 4 Idx: 0 Loss: 0.019471398107928077
Epoch: 4 Idx: 5000 Loss: 0.008509557780952469
Epoch: 5 Idx: 0 Loss: 0.013275816069825752
Epoch: 5 Idx: 5000 Loss: 0.021044654866914817
Epoch: 6 Idx: 0 Loss: 0.0125250335134461
Epoch: 6 Idx: 5000 Loss: 0.022286730065376664
Epoch: 7 Idx: 0 Loss: 0.009596990926480621
Epoch: 7 Idx: 5000 Loss: 0.03372009463592572
Epoch: 8 Idx: 0 Loss: 0.026303530600728424
Epoch: 8 Idx: 5000 Loss: 0.03587780410751247
Epoch: 9 Idx: 0 Loss: 0.015735349809196518
Epoch: 9 Idx: 5000 Loss: 0.008225714550839367
Epoch: 10 Idx: 0 Loss: 0.01005666432199536
Epoch: 10 Idx: 5000 Loss: 0.03417989772964111
Epoch: 11 Idx: 0 Loss: 0.018753155886229545
Epoch: 11 Idx: 5000 Loss: 0.00827158149968219
Epoch: 12 Idx: 0 Loss: 0.025742137323371453
Epoch: 12 Idx: 5000 Loss: 0.04830229940539676
Epoch: 13 Idx: 0 Loss: 0.005319467596925887
Epoch: 13 Idx: 5000 Loss: 0.011875274152891234
Epoch: 14 Idx: 0 Loss: 0.013167254181960124
Epoch: 14 Idx: 5000 Loss: 0.010153930131399314
Epoch: 15 Idx: 0 Loss: 0.010511011611237648
Epoch: 15 Idx: 5000 Loss: 0.015630936798179042
Epoch: 16 Idx: 0 Loss: 0.013385736124562793
Epoch: 16 Idx: 5000 Loss: 0.014789824181988497
Epoch: 17 Idx: 0 Loss: 0.03159708386589501
Epoch: 17 Idx: 5000 Loss: 0.012124147820340925
Epoch: 18 Idx: 0 Loss: 0.01230050735324062
Epoch: 18 Idx: 5000 Loss: 0.017105015424118443
Epoch: 19 Idx: 0 Loss: 0.020192590377962925
Epoch: 19 Idx: 5000 Loss: 0.030686430138590588
Epoch: 20 Idx: 0 Loss: 0.029017788137227163
Epoch: 20 Idx: 5000 Loss: 0.012639960383100574
Epoch: 21 Idx: 0 Loss: 0.007749784967577784
Epoch: 21 Idx: 5000 Loss: 0.011161835133286273
Epoch: 22 Idx: 0 Loss: 0.01072329458447742
Epoch: 22 Idx: 5000 Loss: 0.007207926032874292
Epoch: 23 Idx: 0 Loss: 0.01532051136419423
Epoch: 23 Idx: 5000 Loss: 0.023079258616150608
Epoch: 24 Idx: 0 Loss: 0.012109789712849175
Epoch: 24 Idx: 5000 Loss: 0.01728463004362086
Epoch: 25 Idx: 0 Loss: 0.04166278535580326
Epoch: 25 Idx: 5000 Loss: 0.02337401609888133
Epoch: 26 Idx: 0 Loss: 0.02039407940877034
Epoch: 26 Idx: 5000 Loss: 0.011171921511209765
Epoch: 27 Idx: 0 Loss: 0.01863015866841438
Epoch: 27 Idx: 5000 Loss: 0.007029756490179113
Epoch: 28 Idx: 0 Loss: 0.007745353952192743
Epoch: 28 Idx: 5000 Loss: 0.008540756337010073
Epoch: 29 Idx: 0 Loss: 0.008871393599170871
Epoch: 29 Idx: 5000 Loss: 0.010163978497846088
Epoch: 30 Idx: 0 Loss: 0.02312177417548931
Epoch: 30 Idx: 5000 Loss: 0.02974422710632681
Epoch: 31 Idx: 0 Loss: 0.015465664466363391
Epoch: 31 Idx: 5000 Loss: 0.010885515758548306
Epoch: 32 Idx: 0 Loss: 0.008984502696953632
Epoch: 32 Idx: 5000 Loss: 0.03749470248646649
Epoch: 33 Idx: 0 Loss: 0.027215263479839907
Epoch: 33 Idx: 5000 Loss: 0.014852319291645209
Epoch: 34 Idx: 0 Loss: 0.008769414867180731
Epoch: 34 Idx: 5000 Loss: 0.01458254410863841
Epoch: 35 Idx: 0 Loss: 0.023555904230320623
Epoch: 35 Idx: 5000 Loss: 0.016000121577942318
Epoch: 36 Idx: 0 Loss: 0.017829394695014242
Epoch: 36 Idx: 5000 Loss: 0.031265103062026955
Epoch: 37 Idx: 0 Loss: 0.008032679999214105
Epoch: 37 Idx: 5000 Loss: 0.018326907519716842
Epoch: 38 Idx: 0 Loss: 0.013010497947267264
Epoch: 38 Idx: 5000 Loss: 0.015727934041334397
Epoch: 39 Idx: 0 Loss: 0.008898906799333644
Epoch: 39 Idx: 5000 Loss: 0.02398881734958476
Epoch: 40 Idx: 0 Loss: 0.028178451317173576
Epoch: 40 Idx: 5000 Loss: 0.012155940822952578
Epoch: 41 Idx: 0 Loss: 0.028600229027033155
Epoch: 41 Idx: 5000 Loss: 0.007697938512242779
Epoch: 42 Idx: 0 Loss: 0.00879489319903145
Epoch: 42 Idx: 5000 Loss: 0.01242644814227413
Epoch: 43 Idx: 0 Loss: 0.013230812353602062
Epoch: 43 Idx: 5000 Loss: 0.007011248909114658
Epoch: 44 Idx: 0 Loss: 0.03530648069279125
Epoch: 44 Idx: 5000 Loss: 0.006874160911610577
Epoch: 45 Idx: 0 Loss: 0.010252626143491794
Epoch: 45 Idx: 5000 Loss: 0.03097702607365147
Epoch: 46 Idx: 0 Loss: 0.029908290546958392
Epoch: 46 Idx: 5000 Loss: 0.018294454695043608
Epoch: 47 Idx: 0 Loss: 0.009164249203125694
Epoch: 47 Idx: 5000 Loss: 0.01911506089904903
Epoch: 48 Idx: 0 Loss: 0.011720413259655376
Epoch: 48 Idx: 5000 Loss: 0.011586851504246256
Epoch: 49 Idx: 0 Loss: 0.007466157505520907
Epoch: 49 Idx: 5000 Loss: 0.014057321322655523
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.12426158953520615
Epoch: 0 Idx: 5000 Loss: 0.010294017994405233
Epoch: 1 Idx: 0 Loss: 0.00669320995905838
Epoch: 1 Idx: 5000 Loss: 0.004807549413435456
Epoch: 2 Idx: 0 Loss: 0.009791355207422855
Epoch: 2 Idx: 5000 Loss: 0.013558476216598569
Epoch: 3 Idx: 0 Loss: 0.04019422958293553
Epoch: 3 Idx: 5000 Loss: 0.026409851046076228
Epoch: 4 Idx: 0 Loss: 0.018197829008489468
Epoch: 4 Idx: 5000 Loss: 0.018459757324798494
Epoch: 5 Idx: 0 Loss: 0.015997406061708894
Epoch: 5 Idx: 5000 Loss: 0.009822621253857576
Epoch: 6 Idx: 0 Loss: 0.00755893336936525
Epoch: 6 Idx: 5000 Loss: 0.03595076553605005
Epoch: 7 Idx: 0 Loss: 0.02474235076505797
Epoch: 7 Idx: 5000 Loss: 0.022575644439868984
Epoch: 8 Idx: 0 Loss: 0.008126320961749554
Epoch: 8 Idx: 5000 Loss: 0.005738069378460251
Epoch: 9 Idx: 0 Loss: 0.03004237493458494
Epoch: 9 Idx: 5000 Loss: 0.01318886640231963
Epoch: 10 Idx: 0 Loss: 0.02555421146467824
Epoch: 10 Idx: 5000 Loss: 0.007050102041734252
Epoch: 11 Idx: 0 Loss: 0.007036666539041862
Epoch: 11 Idx: 5000 Loss: 0.01892974080641859
Epoch: 12 Idx: 0 Loss: 0.019964595071453775
Epoch: 12 Idx: 5000 Loss: 0.009274175916106749
Epoch: 13 Idx: 0 Loss: 0.010298974836111903
Epoch: 13 Idx: 5000 Loss: 0.005875659046158004
Epoch: 14 Idx: 0 Loss: 0.015344232024725346
Epoch: 14 Idx: 5000 Loss: 0.010033741297866154
Epoch: 15 Idx: 0 Loss: 0.03304743574360553
Epoch: 15 Idx: 5000 Loss: 0.026243368694166845
Epoch: 16 Idx: 0 Loss: 0.028097906740931444
Epoch: 16 Idx: 5000 Loss: 0.008507665441625538
Epoch: 17 Idx: 0 Loss: 0.010914266459013779
Epoch: 17 Idx: 5000 Loss: 0.011902022918211406
Epoch: 18 Idx: 0 Loss: 0.01114987665908375
Epoch: 18 Idx: 5000 Loss: 0.007655144728557972
Epoch: 19 Idx: 0 Loss: 0.010292401871636709
Epoch: 19 Idx: 5000 Loss: 0.023850183486439164
Epoch: 20 Idx: 0 Loss: 0.028936934190248474
Epoch: 20 Idx: 5000 Loss: 0.012289119322733178
Epoch: 21 Idx: 0 Loss: 0.010271282568157035
Epoch: 21 Idx: 5000 Loss: 0.023265734683958473
Epoch: 22 Idx: 0 Loss: 0.028997467399503395
Epoch: 22 Idx: 5000 Loss: 0.012930023144518885
Epoch: 23 Idx: 0 Loss: 0.017052143685488328
Epoch: 23 Idx: 5000 Loss: 0.008654026444059071
Epoch: 24 Idx: 0 Loss: 0.01503258222966922
Epoch: 24 Idx: 5000 Loss: 0.0371953563980153
Epoch: 25 Idx: 0 Loss: 0.007358772713183853
Epoch: 25 Idx: 5000 Loss: 0.03092961526976648
Epoch: 26 Idx: 0 Loss: 0.0033901221702695218
Epoch: 26 Idx: 5000 Loss: 0.021039598520664875
Epoch: 27 Idx: 0 Loss: 0.027001054167299844
Epoch: 27 Idx: 5000 Loss: 0.01537794876823199
Epoch: 28 Idx: 0 Loss: 0.013231103275850715
Epoch: 28 Idx: 5000 Loss: 0.009075010330869514
Epoch: 29 Idx: 0 Loss: 0.018695274529021564
Epoch: 29 Idx: 5000 Loss: 0.007241961196542514
Epoch: 30 Idx: 0 Loss: 0.03961845487063118
Epoch: 30 Idx: 5000 Loss: 0.01479099895082331
Epoch: 31 Idx: 0 Loss: 0.028992596343537846
Epoch: 31 Idx: 5000 Loss: 0.013027412425343712
Epoch: 32 Idx: 0 Loss: 0.026074034466061543
Epoch: 32 Idx: 5000 Loss: 0.017756171645554486
Epoch: 33 Idx: 0 Loss: 0.00515505860465228
Epoch: 33 Idx: 5000 Loss: 0.007372239209624908
Epoch: 34 Idx: 0 Loss: 0.01471688340536331
Epoch: 34 Idx: 5000 Loss: 0.012200647396182145
Epoch: 35 Idx: 0 Loss: 0.013600873780819743
Epoch: 35 Idx: 5000 Loss: 0.009671189941518894
Epoch: 36 Idx: 0 Loss: 0.010563797360417591
Epoch: 36 Idx: 5000 Loss: 0.037921636963344475
Epoch: 37 Idx: 0 Loss: 0.020569262513069297
Epoch: 37 Idx: 5000 Loss: 0.02467691940553527
Epoch: 38 Idx: 0 Loss: 0.008672110664564182
Epoch: 38 Idx: 5000 Loss: 0.008943016321248907
Epoch: 39 Idx: 0 Loss: 0.012010994943056696
Epoch: 39 Idx: 5000 Loss: 0.02100460245946036
Epoch: 40 Idx: 0 Loss: 0.04582976003998391
Epoch: 40 Idx: 5000 Loss: 0.011447954959398782
Epoch: 41 Idx: 0 Loss: 0.006913087098947214
Epoch: 41 Idx: 5000 Loss: 0.010785438551365583
Epoch: 42 Idx: 0 Loss: 0.023187786766309282
Epoch: 42 Idx: 5000 Loss: 0.018661349502788912
Epoch: 43 Idx: 0 Loss: 0.009212046130084008
Epoch: 43 Idx: 5000 Loss: 0.011407354005673595
Epoch: 44 Idx: 0 Loss: 0.03472912893219285
Epoch: 44 Idx: 5000 Loss: 0.007891722606823748
Epoch: 45 Idx: 0 Loss: 0.01632860060946077
Epoch: 45 Idx: 5000 Loss: 0.014525144961029994
Epoch: 46 Idx: 0 Loss: 0.017505502086379385
Epoch: 46 Idx: 5000 Loss: 0.0068017300139711105
Epoch: 47 Idx: 0 Loss: 0.018673811161824358
Epoch: 47 Idx: 5000 Loss: 0.037269088099044896
Epoch: 48 Idx: 0 Loss: 0.01487642450254675
Epoch: 48 Idx: 5000 Loss: 0.016981523856039755
Epoch: 49 Idx: 0 Loss: 0.009260787996176065
Epoch: 49 Idx: 5000 Loss: 0.02228266375546586
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.23121119102598264
Epoch: 0 Idx: 5000 Loss: 0.03463102747208311
Epoch: 1 Idx: 0 Loss: 0.025593693893808337
Epoch: 1 Idx: 5000 Loss: 0.021443035833699206
Epoch: 2 Idx: 0 Loss: 0.006615214076557737
Epoch: 2 Idx: 5000 Loss: 0.01688587319125894
Epoch: 3 Idx: 0 Loss: 0.013862776706090898
Epoch: 3 Idx: 5000 Loss: 0.03172694615533293
Epoch: 4 Idx: 0 Loss: 0.012594348311384307
Epoch: 4 Idx: 5000 Loss: 0.015172035101289243
Epoch: 5 Idx: 0 Loss: 0.01443217452670369
Epoch: 5 Idx: 5000 Loss: 0.010452891648531885
Epoch: 6 Idx: 0 Loss: 0.022728692408716
Epoch: 6 Idx: 5000 Loss: 0.009229789922085629
Epoch: 7 Idx: 0 Loss: 0.012838379679071123
Epoch: 7 Idx: 5000 Loss: 0.00940657977189754
Epoch: 8 Idx: 0 Loss: 0.013361332676139589
Epoch: 8 Idx: 5000 Loss: 0.015478769602456425
Epoch: 9 Idx: 0 Loss: 0.008885143232040163
Epoch: 9 Idx: 5000 Loss: 0.007699720399378638
Epoch: 10 Idx: 0 Loss: 0.01327998247646917
Epoch: 10 Idx: 5000 Loss: 0.022182051602112236
Epoch: 11 Idx: 0 Loss: 0.03294499948098916
Epoch: 11 Idx: 5000 Loss: 0.016461708273901775
Epoch: 12 Idx: 0 Loss: 0.01000238007085166
Epoch: 12 Idx: 5000 Loss: 0.008520805234146616
Epoch: 13 Idx: 0 Loss: 0.012298109516662778
Epoch: 13 Idx: 5000 Loss: 0.03981091825342856
Epoch: 14 Idx: 0 Loss: 0.015729209079029298
Epoch: 14 Idx: 5000 Loss: 0.008167933032757231
Epoch: 15 Idx: 0 Loss: 0.01812328873810846
Epoch: 15 Idx: 5000 Loss: 0.006702857955674389
Epoch: 16 Idx: 0 Loss: 0.015553264378751964
Epoch: 16 Idx: 5000 Loss: 0.030088609942361545
Epoch: 17 Idx: 0 Loss: 0.022697269598969283
Epoch: 17 Idx: 5000 Loss: 0.011170069014375304
Epoch: 18 Idx: 0 Loss: 0.017742388859963962
Epoch: 18 Idx: 5000 Loss: 0.008856596454964918
Epoch: 19 Idx: 0 Loss: 0.03480728122284261
Epoch: 19 Idx: 5000 Loss: 0.014068898431509038
Epoch: 20 Idx: 0 Loss: 0.009417501961544979
Epoch: 20 Idx: 5000 Loss: 0.022654708598729707
Epoch: 21 Idx: 0 Loss: 0.013859567681563406
Epoch: 21 Idx: 5000 Loss: 0.014108357359845185
Epoch: 22 Idx: 0 Loss: 0.037725039734263166
Epoch: 22 Idx: 5000 Loss: 0.014100689123277338
Epoch: 23 Idx: 0 Loss: 0.0152194096930306
Epoch: 23 Idx: 5000 Loss: 0.016288741228735908
Epoch: 24 Idx: 0 Loss: 0.02842649685155509
Epoch: 24 Idx: 5000 Loss: 0.008917335100516283
Epoch: 25 Idx: 0 Loss: 0.009034136899921207
Epoch: 25 Idx: 5000 Loss: 0.014079755172059658
Epoch: 26 Idx: 0 Loss: 0.02279748508416548
Epoch: 26 Idx: 5000 Loss: 0.008042152697726764
Epoch: 27 Idx: 0 Loss: 0.008009940909871706
Epoch: 27 Idx: 5000 Loss: 0.02026764179115514
Epoch: 28 Idx: 0 Loss: 0.02119650191322471
Epoch: 28 Idx: 5000 Loss: 0.012141383245532012
Epoch: 29 Idx: 0 Loss: 0.011595723225366002
Epoch: 29 Idx: 5000 Loss: 0.013175828022324209
Epoch: 30 Idx: 0 Loss: 0.008171975979298259
Epoch: 30 Idx: 5000 Loss: 0.018875616449608994
Epoch: 31 Idx: 0 Loss: 0.0154107624577371
Epoch: 31 Idx: 5000 Loss: 0.01914264189656041
Epoch: 32 Idx: 0 Loss: 0.01317188674235375
Epoch: 32 Idx: 5000 Loss: 0.026118751894881193
Epoch: 33 Idx: 0 Loss: 0.0064442563233321325
Epoch: 33 Idx: 5000 Loss: 0.013338572813385005
Epoch: 34 Idx: 0 Loss: 0.017545533419208365
Epoch: 34 Idx: 5000 Loss: 0.016989413234284732
Epoch: 35 Idx: 0 Loss: 0.027700742369398436
Epoch: 35 Idx: 5000 Loss: 0.045080211332079706
Epoch: 36 Idx: 0 Loss: 0.02574505051253958
Epoch: 36 Idx: 5000 Loss: 0.008124715767009025
Epoch: 37 Idx: 0 Loss: 0.018942492768234766
Epoch: 37 Idx: 5000 Loss: 0.02401180613525837
Epoch: 38 Idx: 0 Loss: 0.02707751466219974
Epoch: 38 Idx: 5000 Loss: 0.007381032523811022
Epoch: 39 Idx: 0 Loss: 0.010951732853723977
Epoch: 39 Idx: 5000 Loss: 0.019030643040455677
Epoch: 40 Idx: 0 Loss: 0.014299521742690648
Epoch: 40 Idx: 5000 Loss: 0.02204982658933191
Epoch: 41 Idx: 0 Loss: 0.035954439883881806
Epoch: 41 Idx: 5000 Loss: 0.00805704857671085
Epoch: 42 Idx: 0 Loss: 0.00942852771180789
Epoch: 42 Idx: 5000 Loss: 0.0066006479675673625
Epoch: 43 Idx: 0 Loss: 0.01314697920488774
Epoch: 43 Idx: 5000 Loss: 0.0215025880851435
Epoch: 44 Idx: 0 Loss: 0.013750600044880502
Epoch: 44 Idx: 5000 Loss: 0.024729307837791776
Epoch: 45 Idx: 0 Loss: 0.008608078682099493
Epoch: 45 Idx: 5000 Loss: 0.016955349488358057
Epoch: 46 Idx: 0 Loss: 0.01563461585031721
Epoch: 46 Idx: 5000 Loss: 0.01876497734906366
Epoch: 47 Idx: 0 Loss: 0.008655057633842972
Epoch: 47 Idx: 5000 Loss: 0.008237428892069252
Epoch: 48 Idx: 0 Loss: 0.015186483471800703
Epoch: 48 Idx: 5000 Loss: 0.02186009421579621
Epoch: 49 Idx: 0 Loss: 0.012863083088932904
Epoch: 49 Idx: 5000 Loss: 0.008864043269119621
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.19976236235319758
Epoch: 0 Idx: 5000 Loss: 0.0050165917339746275
Epoch: 1 Idx: 0 Loss: 0.015112002905563481
Epoch: 1 Idx: 5000 Loss: 0.007317307947693653
Epoch: 2 Idx: 0 Loss: 0.014217009803265415
Epoch: 2 Idx: 5000 Loss: 0.011748259032357329
Epoch: 3 Idx: 0 Loss: 0.012842349694121458
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 357, in forward
    output_node_emb = self.output(contextual_node_emb)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 91, in forward
    return F.linear(input, self.weight, self.bias)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in linear
    ret = torch.addmm(bias, input, weight.t())
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc232>
Subject: Job 4066900: <python main.py 12 2 True True> in cluster <dcc> Exited

Job <python main.py 12 2 True True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc232>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 12 2 True True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46060.25 sec.
    Max Memory :                                 2828 MB
    Average Memory :                             2661.98 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40589.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46138 sec.
    Turnaround time :                            46197 sec.

The output (if any) is above this job summary.

