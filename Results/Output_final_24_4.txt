2020-09-15 15:48:43.640939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.784877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:50.898396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:50.898471: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.900771: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.902859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.903386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.905610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.907197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.907508: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.907544: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.908036: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.945231: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600160000 Hz
2020-09-15 15:48:50.945567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56088f97b9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.945588: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.948532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.948560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19373289292291554
Epoch: 0 Idx: 5000 Loss: 0.008543803267942669
Epoch: 1 Idx: 0 Loss: 0.00607783864436975
Epoch: 1 Idx: 5000 Loss: 0.006133286683174416
Epoch: 2 Idx: 0 Loss: 0.012980129515136447
Epoch: 2 Idx: 5000 Loss: 0.026122584128428307
Epoch: 3 Idx: 0 Loss: 0.010938288949998161
Epoch: 3 Idx: 5000 Loss: 0.014055834594348064
Epoch: 4 Idx: 0 Loss: 0.012236070197105346
Epoch: 4 Idx: 5000 Loss: 0.008006785394537792
Epoch: 5 Idx: 0 Loss: 0.013718992455899408
Epoch: 5 Idx: 5000 Loss: 0.013240538831652278
Epoch: 6 Idx: 0 Loss: 0.010992848915129312
Epoch: 6 Idx: 5000 Loss: 0.018654826967385497
Epoch: 7 Idx: 0 Loss: 0.025176265559611874
Epoch: 7 Idx: 5000 Loss: 0.008600539012185212
Epoch: 8 Idx: 0 Loss: 0.017043900767126297
Epoch: 8 Idx: 5000 Loss: 0.020654128354724938
Epoch: 9 Idx: 0 Loss: 0.010910446241111583
Epoch: 9 Idx: 5000 Loss: 0.006022271241663112
Epoch: 10 Idx: 0 Loss: 0.013535619875125249
Epoch: 10 Idx: 5000 Loss: 0.01091485157337787
Epoch: 11 Idx: 0 Loss: 0.021941507827651776
Epoch: 11 Idx: 5000 Loss: 0.021048044365041624
Epoch: 12 Idx: 0 Loss: 0.004504185508093555
Epoch: 12 Idx: 5000 Loss: 0.02567940984624832
Epoch: 13 Idx: 0 Loss: 0.00459006218217424
Epoch: 13 Idx: 5000 Loss: 0.013760872794951645
Epoch: 14 Idx: 0 Loss: 0.01482135587747059
Epoch: 14 Idx: 5000 Loss: 0.020088807662689175
Epoch: 15 Idx: 0 Loss: 0.012951429704436837
Epoch: 15 Idx: 5000 Loss: 0.01918229821902167
Epoch: 16 Idx: 0 Loss: 0.010371420400477747
Epoch: 16 Idx: 5000 Loss: 0.009818261361435593
Epoch: 17 Idx: 0 Loss: 0.026769426306288993
Epoch: 17 Idx: 5000 Loss: 0.011500820389893576
Epoch: 18 Idx: 0 Loss: 0.027833807019224353
Epoch: 18 Idx: 5000 Loss: 0.047957477268282686
Epoch: 19 Idx: 0 Loss: 0.01166572151341119
Epoch: 19 Idx: 5000 Loss: 0.02872605317937993
Epoch: 20 Idx: 0 Loss: 0.007539086001788901
Epoch: 20 Idx: 5000 Loss: 0.03323935861673469
Epoch: 21 Idx: 0 Loss: 0.015444439983186451
Epoch: 21 Idx: 5000 Loss: 0.013887479489991618
Epoch: 22 Idx: 0 Loss: 0.006201471299020843
Epoch: 22 Idx: 5000 Loss: 0.018643634062809444
Epoch: 23 Idx: 0 Loss: 0.021571040519330995
Epoch: 23 Idx: 5000 Loss: 0.03142980517646027
Epoch: 24 Idx: 0 Loss: 0.012893869245276194
Epoch: 24 Idx: 5000 Loss: 0.022827569598453536
Epoch: 25 Idx: 0 Loss: 0.019057692486066934
Epoch: 25 Idx: 5000 Loss: 0.026268359196777284
Epoch: 26 Idx: 0 Loss: 0.009584641222180779
Epoch: 26 Idx: 5000 Loss: 0.016639845184320403
Epoch: 27 Idx: 0 Loss: 0.02602275020677087
Epoch: 27 Idx: 5000 Loss: 0.017522303563480064
Epoch: 28 Idx: 0 Loss: 0.01791503506168926
Epoch: 28 Idx: 5000 Loss: 0.040858440860673695
Epoch: 29 Idx: 0 Loss: 0.009948152034917807
Epoch: 29 Idx: 5000 Loss: 0.011699178137056182
Epoch: 30 Idx: 0 Loss: 0.040454755556120346
Epoch: 30 Idx: 5000 Loss: 0.008432480640094385
Epoch: 31 Idx: 0 Loss: 0.009415214204427307
Epoch: 31 Idx: 5000 Loss: 0.019055330066644702
Epoch: 32 Idx: 0 Loss: 0.03903194504940283
Epoch: 32 Idx: 5000 Loss: 0.012266545541643498
Epoch: 33 Idx: 0 Loss: 0.00774869036537221
Epoch: 33 Idx: 5000 Loss: 0.009825561738517197
Epoch: 34 Idx: 0 Loss: 0.011029144249331971
Epoch: 34 Idx: 5000 Loss: 0.0267443534418792
Epoch: 35 Idx: 0 Loss: 0.018040513603388778
Epoch: 35 Idx: 5000 Loss: 0.012332616542252988
Epoch: 36 Idx: 0 Loss: 0.009950302062121313
Epoch: 36 Idx: 5000 Loss: 0.011101679784033423
Epoch: 37 Idx: 0 Loss: 0.02437566856774862
Epoch: 37 Idx: 5000 Loss: 0.009700021049437903
Epoch: 38 Idx: 0 Loss: 0.017842702377116132
Epoch: 38 Idx: 5000 Loss: 0.01613213892141002
Epoch: 39 Idx: 0 Loss: 0.03765608709679198
Epoch: 39 Idx: 5000 Loss: 0.013682411876049608
Epoch: 40 Idx: 0 Loss: 0.030810780040882783
Epoch: 40 Idx: 5000 Loss: 0.011703235061085174
Epoch: 41 Idx: 0 Loss: 0.014643305603709335
Epoch: 41 Idx: 5000 Loss: 0.009376322808161145
Epoch: 42 Idx: 0 Loss: 0.013273070326660152
Epoch: 42 Idx: 5000 Loss: 0.007978280783035405
Epoch: 43 Idx: 0 Loss: 0.030612406966210703
Epoch: 43 Idx: 5000 Loss: 0.011325414808522238
Epoch: 44 Idx: 0 Loss: 0.012513759001993512
Epoch: 44 Idx: 5000 Loss: 0.014685852276559224
Epoch: 45 Idx: 0 Loss: 0.012102397266475402
Epoch: 45 Idx: 5000 Loss: 0.00589996350430085
Epoch: 46 Idx: 0 Loss: 0.02141226458694507
Epoch: 46 Idx: 5000 Loss: 0.016660819559220094
Epoch: 47 Idx: 0 Loss: 0.016657363169871153
Epoch: 47 Idx: 5000 Loss: 0.029028469218695025
Epoch: 48 Idx: 0 Loss: 0.006161209466051179
Epoch: 48 Idx: 5000 Loss: 0.006764253743132528
Epoch: 49 Idx: 0 Loss: 0.006688239744936632
Epoch: 49 Idx: 5000 Loss: 0.020030892367442574
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.16537827997057242
Epoch: 0 Idx: 5000 Loss: 0.007168760950746696
Epoch: 1 Idx: 0 Loss: 0.009936897256311441
Epoch: 1 Idx: 5000 Loss: 0.011164564025118659
Epoch: 2 Idx: 0 Loss: 0.03839397078412514
Epoch: 2 Idx: 5000 Loss: 0.031045610380750478
Epoch: 3 Idx: 0 Loss: 0.010591950101345254
Epoch: 3 Idx: 5000 Loss: 0.04268200803344939
Epoch: 4 Idx: 0 Loss: 0.01605350961417868
Epoch: 4 Idx: 5000 Loss: 0.015872922989636343
Epoch: 5 Idx: 0 Loss: 0.009382090872682398
Epoch: 5 Idx: 5000 Loss: 0.03413555175698992
Epoch: 6 Idx: 0 Loss: 0.03137708885582514
Epoch: 6 Idx: 5000 Loss: 0.020962875623192302
Epoch: 7 Idx: 0 Loss: 0.012260191379409913
Epoch: 7 Idx: 5000 Loss: 0.013633697252172384
Epoch: 8 Idx: 0 Loss: 0.004545391870006614
Epoch: 8 Idx: 5000 Loss: 0.01184529681491157
Epoch: 9 Idx: 0 Loss: 0.01970310513645669
Epoch: 9 Idx: 5000 Loss: 0.00794960124172306
Epoch: 10 Idx: 0 Loss: 0.009963441574034363
Epoch: 10 Idx: 5000 Loss: 0.005144937627585535
Epoch: 11 Idx: 0 Loss: 0.010397209466369095
Epoch: 11 Idx: 5000 Loss: 0.012105660244492542
Epoch: 12 Idx: 0 Loss: 0.015425239863687157
Epoch: 12 Idx: 5000 Loss: 0.020593052213796148
Epoch: 13 Idx: 0 Loss: 0.01981136839380164
Epoch: 13 Idx: 5000 Loss: 0.00551562965310032
Epoch: 14 Idx: 0 Loss: 0.008055818002137881
Epoch: 14 Idx: 5000 Loss: 0.015076501056127106
Epoch: 15 Idx: 0 Loss: 0.04481711776690426
Epoch: 15 Idx: 5000 Loss: 0.01712811795957008
Epoch: 16 Idx: 0 Loss: 0.019087708068521947
Epoch: 16 Idx: 5000 Loss: 0.019212293824280722
Epoch: 17 Idx: 0 Loss: 0.02175426504343162
Epoch: 17 Idx: 5000 Loss: 0.012369184246113125
Epoch: 18 Idx: 0 Loss: 0.01646115970483788
Epoch: 18 Idx: 5000 Loss: 0.012537005137759571
Epoch: 19 Idx: 0 Loss: 0.02046615799631049
Epoch: 19 Idx: 5000 Loss: 0.010077165695962606
Epoch: 20 Idx: 0 Loss: 0.02956045199723637
Epoch: 20 Idx: 5000 Loss: 0.007196693121221214
Epoch: 21 Idx: 0 Loss: 0.014366177689535829
Epoch: 21 Idx: 5000 Loss: 0.01844449378688454
Epoch: 22 Idx: 0 Loss: 0.024894562490885327
Epoch: 22 Idx: 5000 Loss: 0.027400718225648026
Epoch: 23 Idx: 0 Loss: 0.014112532019212136
Epoch: 23 Idx: 5000 Loss: 0.03687431656332233
Epoch: 24 Idx: 0 Loss: 0.007362732589333893
Epoch: 24 Idx: 5000 Loss: 0.013921317618653499
Epoch: 25 Idx: 0 Loss: 0.012302498072358059
Epoch: 25 Idx: 5000 Loss: 0.012121325250792164
Epoch: 26 Idx: 0 Loss: 0.011094137510836915
Epoch: 26 Idx: 5000 Loss: 0.009676847379901545
Epoch: 27 Idx: 0 Loss: 0.01912378793923078
Epoch: 27 Idx: 5000 Loss: 0.013661328087057186
Epoch: 28 Idx: 0 Loss: 0.013391070088418357
Epoch: 28 Idx: 5000 Loss: 0.006940671840442746
Epoch: 29 Idx: 0 Loss: 0.010152269462164892
Epoch: 29 Idx: 5000 Loss: 0.010237389747548696
Epoch: 30 Idx: 0 Loss: 0.004946148740164075
Epoch: 30 Idx: 5000 Loss: 0.04482212682039236
Epoch: 31 Idx: 0 Loss: 0.010412139115933696
Epoch: 31 Idx: 5000 Loss: 0.015957858356588563
Epoch: 32 Idx: 0 Loss: 0.012905268969011088
Epoch: 32 Idx: 5000 Loss: 0.009611584618808629
Epoch: 33 Idx: 0 Loss: 0.016078744775330108
Epoch: 33 Idx: 5000 Loss: 0.013527760829880763
Epoch: 34 Idx: 0 Loss: 0.009208790537624417
Epoch: 34 Idx: 5000 Loss: 0.01174722001465306
Epoch: 35 Idx: 0 Loss: 0.017910061512096002
Epoch: 35 Idx: 5000 Loss: 0.0046000661107311516
Epoch: 36 Idx: 0 Loss: 0.017739473011643685
Epoch: 36 Idx: 5000 Loss: 0.00550655553655003
Epoch: 37 Idx: 0 Loss: 0.006529190087547121
Epoch: 37 Idx: 5000 Loss: 0.016912439538910633
Epoch: 38 Idx: 0 Loss: 0.02942120387430735
Epoch: 38 Idx: 5000 Loss: 0.024735298977264543
Epoch: 39 Idx: 0 Loss: 0.011406755247249536
Epoch: 39 Idx: 5000 Loss: 0.015213250611804648
Epoch: 40 Idx: 0 Loss: 0.006631275499485546
Epoch: 40 Idx: 5000 Loss: 0.033710605477594024
Epoch: 41 Idx: 0 Loss: 0.020504914164721267
Epoch: 41 Idx: 5000 Loss: 0.016256262288938637
Epoch: 42 Idx: 0 Loss: 0.010635954868131363
Epoch: 42 Idx: 5000 Loss: 0.021552561496083956
Epoch: 43 Idx: 0 Loss: 0.011067412405211217
Epoch: 43 Idx: 5000 Loss: 0.007756888087371905
Epoch: 44 Idx: 0 Loss: 0.012423621099948321
Epoch: 44 Idx: 5000 Loss: 0.013380664266323613
Epoch: 45 Idx: 0 Loss: 0.01937022093281011
Epoch: 45 Idx: 5000 Loss: 0.010487692446248302
Epoch: 46 Idx: 0 Loss: 0.012095676726857062
Epoch: 46 Idx: 5000 Loss: 0.028971781907840822
Epoch: 47 Idx: 0 Loss: 0.024572123616399263
Epoch: 47 Idx: 5000 Loss: 0.013108658811469477
Epoch: 48 Idx: 0 Loss: 0.028449332728086574
Epoch: 48 Idx: 5000 Loss: 0.017023996815291754
Epoch: 49 Idx: 0 Loss: 0.011540019130456977
Epoch: 49 Idx: 5000 Loss: 0.016319162123860198
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13905331411875027
Epoch: 0 Idx: 5000 Loss: 0.02920596314794563
Epoch: 1 Idx: 0 Loss: 0.010155059153338388
Epoch: 1 Idx: 5000 Loss: 0.007215947782968052
Epoch: 2 Idx: 0 Loss: 0.01429572223923622
Epoch: 2 Idx: 5000 Loss: 0.00735732484614131
Epoch: 3 Idx: 0 Loss: 0.028602723139376608
Epoch: 3 Idx: 5000 Loss: 0.026417622234339258
Epoch: 4 Idx: 0 Loss: 0.011011533110786445
Epoch: 4 Idx: 5000 Loss: 0.01072937039540829
Epoch: 5 Idx: 0 Loss: 0.011136331104954838
Epoch: 5 Idx: 5000 Loss: 0.012415510106609174
Epoch: 6 Idx: 0 Loss: 0.033299479066910755
Epoch: 6 Idx: 5000 Loss: 0.016714829003403105
Epoch: 7 Idx: 0 Loss: 0.03164784132913388
Epoch: 7 Idx: 5000 Loss: 0.015412190539363088
Epoch: 8 Idx: 0 Loss: 0.011477843079414164
Epoch: 8 Idx: 5000 Loss: 0.022070190850471464
Epoch: 9 Idx: 0 Loss: 0.018087600720352745
Epoch: 9 Idx: 5000 Loss: 0.009407066213754287
Epoch: 10 Idx: 0 Loss: 0.03880178348460393
Epoch: 10 Idx: 5000 Loss: 0.008393470884684113
Epoch: 11 Idx: 0 Loss: 0.021294557148862296
Epoch: 11 Idx: 5000 Loss: 0.020407044648621094
Epoch: 12 Idx: 0 Loss: 0.010170691175354534
Epoch: 12 Idx: 5000 Loss: 0.008917594727116887
Epoch: 13 Idx: 0 Loss: 0.011230718674073624
Epoch: 13 Idx: 5000 Loss: 0.007982464254146528
Epoch: 14 Idx: 0 Loss: 0.02950977778213255
Epoch: 14 Idx: 5000 Loss: 0.014163890404475729
Epoch: 15 Idx: 0 Loss: 0.009875282786537855
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 312, in forward
    feature_emb = self.name_embedding(features[i]) #  dim: (2, batch_size, max_types, max_paths, max_pathlen, 512)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1814, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc232>
Subject: Job 4066841: <python main.py 4 24 False False> in cluster <dcc> Exited

Job <python main.py 4 24 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc232>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:38 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 24 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46180.00 sec.
    Max Memory :                                 2987 MB
    Average Memory :                             2740.30 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40430.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46221 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

