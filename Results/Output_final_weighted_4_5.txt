2020-09-15 15:48:45.548594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.913620: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:53.035662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:53.035743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:53.037991: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:53.057500: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:53.091638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:53.153442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:53.176480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:53.177016: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:53.177040: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:53.177519: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:53.217105: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600005000 Hz
2020-09-15 15:48:53.217362: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d647995a30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:53.217385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:53.220436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:53.220465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19189226706745216
Epoch: 0 Idx: 5000 Loss: 0.014541304670934094
Epoch: 1 Idx: 0 Loss: 0.012745255513408308
Epoch: 1 Idx: 5000 Loss: 0.006653769295543137
Epoch: 2 Idx: 0 Loss: 0.010337639684879555
Epoch: 2 Idx: 5000 Loss: 0.02800826411027148
Epoch: 3 Idx: 0 Loss: 0.01399867832503818
Epoch: 3 Idx: 5000 Loss: 0.014472570726106044
Epoch: 4 Idx: 0 Loss: 0.011941794419301429
Epoch: 4 Idx: 5000 Loss: 0.008068419108433592
Epoch: 5 Idx: 0 Loss: 0.015279320523161312
Epoch: 5 Idx: 5000 Loss: 0.01643367882787875
Epoch: 6 Idx: 0 Loss: 0.007313017748424287
Epoch: 6 Idx: 5000 Loss: 0.017877095137151376
Epoch: 7 Idx: 0 Loss: 0.018187334770673327
Epoch: 7 Idx: 5000 Loss: 0.02097401093761957
Epoch: 8 Idx: 0 Loss: 0.026373473161124684
Epoch: 8 Idx: 5000 Loss: 0.011889236084200635
Epoch: 9 Idx: 0 Loss: 0.014044554724465582
Epoch: 9 Idx: 5000 Loss: 0.007374653780418223
Epoch: 10 Idx: 0 Loss: 0.014939322861474884
Epoch: 10 Idx: 5000 Loss: 0.014970907051141041
Epoch: 11 Idx: 0 Loss: 0.012773204538009116
Epoch: 11 Idx: 5000 Loss: 0.02022179650905776
Epoch: 12 Idx: 0 Loss: 0.013971514994629734
Epoch: 12 Idx: 5000 Loss: 0.01994857192207605
Epoch: 13 Idx: 0 Loss: 0.011126648828927086
Epoch: 13 Idx: 5000 Loss: 0.008557194370228406
Epoch: 14 Idx: 0 Loss: 0.025466223374350852
Epoch: 14 Idx: 5000 Loss: 0.005001233074010546
Epoch: 15 Idx: 0 Loss: 0.016633671801752146
Epoch: 15 Idx: 5000 Loss: 0.02263910224295613
Epoch: 16 Idx: 0 Loss: 0.006914746144423615
Epoch: 16 Idx: 5000 Loss: 0.008456558366415706
Epoch: 17 Idx: 0 Loss: 0.0183921175235233
Epoch: 17 Idx: 5000 Loss: 0.008947280749696935
Epoch: 18 Idx: 0 Loss: 0.02007641145589191
Epoch: 18 Idx: 5000 Loss: 0.01599430285781245
Epoch: 19 Idx: 0 Loss: 0.033915365186044495
Epoch: 19 Idx: 5000 Loss: 0.015457915913412008
Epoch: 20 Idx: 0 Loss: 0.009707293739049497
Epoch: 20 Idx: 5000 Loss: 0.025344190146122214
Epoch: 21 Idx: 0 Loss: 0.011338818085592327
Epoch: 21 Idx: 5000 Loss: 0.033258638091804814
Epoch: 22 Idx: 0 Loss: 0.010254543474415791
Epoch: 22 Idx: 5000 Loss: 0.016291333161500176
Epoch: 23 Idx: 0 Loss: 0.01782527692325362
Epoch: 23 Idx: 5000 Loss: 0.014289609938468114
Epoch: 24 Idx: 0 Loss: 0.0089723333081916
Epoch: 24 Idx: 5000 Loss: 0.020425428532372943
Epoch: 25 Idx: 0 Loss: 0.01353431710439876
Epoch: 25 Idx: 5000 Loss: 0.012934378917015167
Epoch: 26 Idx: 0 Loss: 0.007491657981199566
Epoch: 26 Idx: 5000 Loss: 0.007372764585295105
Epoch: 27 Idx: 0 Loss: 0.019387705654321165
Epoch: 27 Idx: 5000 Loss: 0.01127837146179771
Epoch: 28 Idx: 0 Loss: 0.014290054074966727
Epoch: 28 Idx: 5000 Loss: 0.025156130077409036
Epoch: 29 Idx: 0 Loss: 0.026542380049875053
Epoch: 29 Idx: 5000 Loss: 0.011121431845054541
Epoch: 30 Idx: 0 Loss: 0.013675471256173206
Epoch: 30 Idx: 5000 Loss: 0.010244860114366915
Epoch: 31 Idx: 0 Loss: 0.008086645809567052
Epoch: 31 Idx: 5000 Loss: 0.022586676001043235
Epoch: 32 Idx: 0 Loss: 0.01816953817150109
Epoch: 32 Idx: 5000 Loss: 0.008348683559258217
Epoch: 33 Idx: 0 Loss: 0.016654721666535827
Epoch: 33 Idx: 5000 Loss: 0.013895387352011655
Epoch: 34 Idx: 0 Loss: 0.008701117033510402
Epoch: 34 Idx: 5000 Loss: 0.00927582230983025
Epoch: 35 Idx: 0 Loss: 0.013893564981514901
Epoch: 35 Idx: 5000 Loss: 0.011476382233326761
Epoch: 36 Idx: 0 Loss: 0.024558296272476715
Epoch: 36 Idx: 5000 Loss: 0.01991183928459576
Epoch: 37 Idx: 0 Loss: 0.04304087688141168
Epoch: 37 Idx: 5000 Loss: 0.016812685348493263
Epoch: 38 Idx: 0 Loss: 0.018015765785688732
Epoch: 38 Idx: 5000 Loss: 0.014169719298741924
Epoch: 39 Idx: 0 Loss: 0.029792568605312493
Epoch: 39 Idx: 5000 Loss: 0.017200921562375345
Epoch: 40 Idx: 0 Loss: 0.024947780637459713
Epoch: 40 Idx: 5000 Loss: 0.01976662443065423
Epoch: 41 Idx: 0 Loss: 0.02213087213881226
Epoch: 41 Idx: 5000 Loss: 0.023498265762592146
Epoch: 42 Idx: 0 Loss: 0.012184018030647802
Epoch: 42 Idx: 5000 Loss: 0.015379213511496565
Epoch: 43 Idx: 0 Loss: 0.012981215748167685
Epoch: 43 Idx: 5000 Loss: 0.010786502642192445
Epoch: 44 Idx: 0 Loss: 0.02653198151111642
Epoch: 44 Idx: 5000 Loss: 0.007101250693908578
Epoch: 45 Idx: 0 Loss: 0.008841416610161851
Epoch: 45 Idx: 5000 Loss: 0.015442199017341448
Epoch: 46 Idx: 0 Loss: 0.009861875717195056
Epoch: 46 Idx: 5000 Loss: 0.007803895085721654
Epoch: 47 Idx: 0 Loss: 0.014376444497167427
Epoch: 47 Idx: 5000 Loss: 0.020193254654198963
Epoch: 48 Idx: 0 Loss: 0.015534386867788085
Epoch: 48 Idx: 5000 Loss: 0.0259682852070608
Epoch: 49 Idx: 0 Loss: 0.01949318507569833
Epoch: 49 Idx: 5000 Loss: 0.017552652978873803
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1535463988441285
Epoch: 0 Idx: 5000 Loss: 0.016656586093930472
Epoch: 1 Idx: 0 Loss: 0.017759076621546153
Epoch: 1 Idx: 5000 Loss: 0.029822772509646572
Epoch: 2 Idx: 0 Loss: 0.022936742021561745
Epoch: 2 Idx: 5000 Loss: 0.005277283662155869
Epoch: 3 Idx: 0 Loss: 0.02078714043806691
Epoch: 3 Idx: 5000 Loss: 0.018411063211845515
Epoch: 4 Idx: 0 Loss: 0.016123689768618544
Epoch: 4 Idx: 5000 Loss: 0.015663379285628182
Epoch: 5 Idx: 0 Loss: 0.016190655636261108
Epoch: 5 Idx: 5000 Loss: 0.012005540961950115
Epoch: 6 Idx: 0 Loss: 0.019631672827408006
Epoch: 6 Idx: 5000 Loss: 0.022254872890246545
Epoch: 7 Idx: 0 Loss: 0.01310121785348216
Epoch: 7 Idx: 5000 Loss: 0.01989672953614296
Epoch: 8 Idx: 0 Loss: 0.007034049857429817
Epoch: 8 Idx: 5000 Loss: 0.024163625918357377
Epoch: 9 Idx: 0 Loss: 0.009299632326876096
Epoch: 9 Idx: 5000 Loss: 0.006877026705686907
Epoch: 10 Idx: 0 Loss: 0.01061069823386841
Epoch: 10 Idx: 5000 Loss: 0.021455822051775764
Epoch: 11 Idx: 0 Loss: 0.01973105349658506
Epoch: 11 Idx: 5000 Loss: 0.0017965296427928858
Epoch: 12 Idx: 0 Loss: 0.014801845237891544
Epoch: 12 Idx: 5000 Loss: 0.030213745469458833
Epoch: 13 Idx: 0 Loss: 0.023140286558796873
Epoch: 13 Idx: 5000 Loss: 0.017453774393542763
Epoch: 14 Idx: 0 Loss: 0.010584518004285668
Epoch: 14 Idx: 5000 Loss: 0.01737450486901386
Epoch: 15 Idx: 0 Loss: 0.016836136047654757
Epoch: 15 Idx: 5000 Loss: 0.0074580731562456344
Epoch: 16 Idx: 0 Loss: 0.013014806970471226
Epoch: 16 Idx: 5000 Loss: 0.01979381466748452
Epoch: 17 Idx: 0 Loss: 0.010161816091676261
Epoch: 17 Idx: 5000 Loss: 0.015100009900109393
Epoch: 18 Idx: 0 Loss: 0.007658414894093008
Epoch: 18 Idx: 5000 Loss: 0.02931798851812203
Epoch: 19 Idx: 0 Loss: 0.011633605481263347
Epoch: 19 Idx: 5000 Loss: 0.009809279781662864
Epoch: 20 Idx: 0 Loss: 0.02749043736223317
Epoch: 20 Idx: 5000 Loss: 0.009202982329907457
Epoch: 21 Idx: 0 Loss: 0.015584555208802087
Epoch: 21 Idx: 5000 Loss: 0.011050151080295117
Epoch: 22 Idx: 0 Loss: 0.008423528996165514
Epoch: 22 Idx: 5000 Loss: 0.02090596775370385
Epoch: 23 Idx: 0 Loss: 0.006924465966027353
Epoch: 23 Idx: 5000 Loss: 0.00891518587258331
Epoch: 24 Idx: 0 Loss: 0.007970591655766326
Epoch: 24 Idx: 5000 Loss: 0.010600349066360015
Epoch: 25 Idx: 0 Loss: 0.02102747696421588
Epoch: 25 Idx: 5000 Loss: 0.025100184803575634
Epoch: 26 Idx: 0 Loss: 0.01013123311583099
Epoch: 26 Idx: 5000 Loss: 0.024198656409422543
Epoch: 27 Idx: 0 Loss: 0.018307198862662317
Epoch: 27 Idx: 5000 Loss: 0.011955928472568704
Epoch: 28 Idx: 0 Loss: 0.008712732912137417
Epoch: 28 Idx: 5000 Loss: 0.00409905169192392
Epoch: 29 Idx: 0 Loss: 0.025085889566498216
Epoch: 29 Idx: 5000 Loss: 0.027001500983298933
Epoch: 30 Idx: 0 Loss: 0.011880697421482293
Epoch: 30 Idx: 5000 Loss: 0.013537708962885184
Epoch: 31 Idx: 0 Loss: 0.02819799911964124
Epoch: 31 Idx: 5000 Loss: 0.008032644405266898
Epoch: 32 Idx: 0 Loss: 0.008789421645984341
Epoch: 32 Idx: 5000 Loss: 0.018108355863679745
Epoch: 33 Idx: 0 Loss: 0.02069270625675861
Epoch: 33 Idx: 5000 Loss: 0.0160889888478235
Epoch: 34 Idx: 0 Loss: 0.011891051612106197
Epoch: 34 Idx: 5000 Loss: 0.012426339467615649
Epoch: 35 Idx: 0 Loss: 0.00715318632937084
Epoch: 35 Idx: 5000 Loss: 0.012625136923160571
Epoch: 36 Idx: 0 Loss: 0.025155017583429147
Epoch: 36 Idx: 5000 Loss: 0.012794144904000637
Epoch: 37 Idx: 0 Loss: 0.013489744631281528
Epoch: 37 Idx: 5000 Loss: 0.016376060852340515
Epoch: 38 Idx: 0 Loss: 0.007577288228496292
Epoch: 38 Idx: 5000 Loss: 0.015289533239031664
Epoch: 39 Idx: 0 Loss: 0.011510576837876912
Epoch: 39 Idx: 5000 Loss: 0.017655453375635385
Epoch: 40 Idx: 0 Loss: 0.010870875895336932
Epoch: 40 Idx: 5000 Loss: 0.017580768522737912
Epoch: 41 Idx: 0 Loss: 0.024337232616402027
Epoch: 41 Idx: 5000 Loss: 0.015520741046705432
Epoch: 42 Idx: 0 Loss: 0.014390449285945394
Epoch: 42 Idx: 5000 Loss: 0.007049585936889754
Epoch: 43 Idx: 0 Loss: 0.037430699770284404
Epoch: 43 Idx: 5000 Loss: 0.00765632779562043
Epoch: 44 Idx: 0 Loss: 0.027227426193884834
Epoch: 44 Idx: 5000 Loss: 0.012363179247796383
Epoch: 45 Idx: 0 Loss: 0.009560020852855223
Epoch: 45 Idx: 5000 Loss: 0.009299514369737765
Epoch: 46 Idx: 0 Loss: 0.013366122028928326
Epoch: 46 Idx: 5000 Loss: 0.029123130961079585
Epoch: 47 Idx: 0 Loss: 0.011317305651591749
Epoch: 47 Idx: 5000 Loss: 0.00843365159618878
Epoch: 48 Idx: 0 Loss: 0.013099424927495145
Epoch: 48 Idx: 5000 Loss: 0.007170132270336296
Epoch: 49 Idx: 0 Loss: 0.0116352364181804
Epoch: 49 Idx: 5000 Loss: 0.009352872456833545
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13015112307091262
Epoch: 0 Idx: 5000 Loss: 0.02511792750811217
Epoch: 1 Idx: 0 Loss: 0.012768307802381421
Epoch: 1 Idx: 5000 Loss: 0.012798643658949262
Epoch: 2 Idx: 0 Loss: 0.013331240486534172
Epoch: 2 Idx: 5000 Loss: 0.01140194057851457
Epoch: 3 Idx: 0 Loss: 0.016188009336243345
Epoch: 3 Idx: 5000 Loss: 0.015123210547295936
Epoch: 4 Idx: 0 Loss: 0.013288579259536627
Epoch: 4 Idx: 5000 Loss: 0.021284962742861555
Epoch: 5 Idx: 0 Loss: 0.03450879031166753
Epoch: 5 Idx: 5000 Loss: 0.01901451493939548
Epoch: 6 Idx: 0 Loss: 0.010246386890117413
Epoch: 6 Idx: 5000 Loss: 0.02729064375922847
Epoch: 7 Idx: 0 Loss: 0.014456015263581692
Epoch: 7 Idx: 5000 Loss: 0.014358123037821975
Epoch: 8 Idx: 0 Loss: 0.00981234006156528
Epoch: 8 Idx: 5000 Loss: 0.008704114105261097
Epoch: 9 Idx: 0 Loss: 0.014168602218375256
Epoch: 9 Idx: 5000 Loss: 0.007728994768082874
Epoch: 10 Idx: 0 Loss: 0.009745379833025473
Epoch: 10 Idx: 5000 Loss: 0.007760689767376264
Epoch: 11 Idx: 0 Loss: 0.015415337851523941
Epoch: 11 Idx: 5000 Loss: 0.02491761420401284
Epoch: 12 Idx: 0 Loss: 0.01817636102998781
Epoch: 12 Idx: 5000 Loss: 0.01629996267180687
Epoch: 13 Idx: 0 Loss: 0.011860250919722367
Epoch: 13 Idx: 5000 Loss: 0.007961378262399123
Epoch: 14 Idx: 0 Loss: 0.015615481767915513
Epoch: 14 Idx: 5000 Loss: 0.008423096025044954
Epoch: 15 Idx: 0 Loss: 0.017859903420372008
Epoch: 15 Idx: 5000 Loss: 0.01271386891173451
Epoch: 16 Idx: 0 Loss: 0.011889102075252931
Epoch: 16 Idx: 5000 Loss: 0.014555047469056642
Epoch: 17 Idx: 0 Loss: 0.012180499095810461
Epoch: 17 Idx: 5000 Loss: 0.03931948185790679
Epoch: 18 Idx: 0 Loss: 0.014594632678102789
Epoch: 18 Idx: 5000 Loss: 0.007044463616234077
Epoch: 19 Idx: 0 Loss: 0.016113086350418773
Epoch: 19 Idx: 5000 Loss: 0.03155035145857564
Epoch: 20 Idx: 0 Loss: 0.01206704132630727
Epoch: 20 Idx: 5000 Loss: 0.015562807962450085
Epoch: 21 Idx: 0 Loss: 0.005927732046094216
Epoch: 21 Idx: 5000 Loss: 0.03359846837754844
Epoch: 22 Idx: 0 Loss: 0.03288972094006967
Epoch: 22 Idx: 5000 Loss: 0.028709657354935234
Epoch: 23 Idx: 0 Loss: 0.020623720327737047
Epoch: 23 Idx: 5000 Loss: 0.014136845217973135
Epoch: 24 Idx: 0 Loss: 0.005825725901792851
Epoch: 24 Idx: 5000 Loss: 0.027617838290899487
Epoch: 25 Idx: 0 Loss: 0.015015485893086003
Epoch: 25 Idx: 5000 Loss: 0.0178431447987834
Epoch: 26 Idx: 0 Loss: 0.03805191163998413
Epoch: 26 Idx: 5000 Loss: 0.013237818935238012
Epoch: 27 Idx: 0 Loss: 0.02078982246849279
Epoch: 27 Idx: 5000 Loss: 0.0114049727610319
Epoch: 28 Idx: 0 Loss: 0.03460902982859944
Epoch: 28 Idx: 5000 Loss: 0.018788169448624145
Epoch: 29 Idx: 0 Loss: 0.015473706463799782
Epoch: 29 Idx: 5000 Loss: 0.012583020993649026
Epoch: 30 Idx: 0 Loss: 0.004536037317786052
Epoch: 30 Idx: 5000 Loss: 0.011694283262116776
Epoch: 31 Idx: 0 Loss: 0.009100689826388397
Epoch: 31 Idx: 5000 Loss: 0.01653548442038034
Epoch: 32 Idx: 0 Loss: 0.007675465384110142
Epoch: 32 Idx: 5000 Loss: 0.012821123161164467
Epoch: 33 Idx: 0 Loss: 0.006986733117406297
Epoch: 33 Idx: 5000 Loss: 0.01063523710269313
Epoch: 34 Idx: 0 Loss: 0.02482166934089443
Epoch: 34 Idx: 5000 Loss: 0.012042934552588827
Epoch: 35 Idx: 0 Loss: 0.032118756690263234
Epoch: 35 Idx: 5000 Loss: 0.013468611705150383
Epoch: 36 Idx: 0 Loss: 0.017458075028765126
Epoch: 36 Idx: 5000 Loss: 0.01089092831176036
Epoch: 37 Idx: 0 Loss: 0.01459224439106602
Epoch: 37 Idx: 5000 Loss: 0.009889998560562057
Epoch: 38 Idx: 0 Loss: 0.020046405985247713
Epoch: 38 Idx: 5000 Loss: 0.014410579471528847
Epoch: 39 Idx: 0 Loss: 0.018406485001345528
Epoch: 39 Idx: 5000 Loss: 0.01198906430182737
Epoch: 40 Idx: 0 Loss: 0.02913253684100326
Epoch: 40 Idx: 5000 Loss: 0.006153950115314634
Epoch: 41 Idx: 0 Loss: 0.014347749843357419
Epoch: 41 Idx: 5000 Loss: 0.014997618604422235
Epoch: 42 Idx: 0 Loss: 0.011093544027181962
Epoch: 42 Idx: 5000 Loss: 0.006821312507865296
Epoch: 43 Idx: 0 Loss: 0.019960714935597368
Epoch: 43 Idx: 5000 Loss: 0.008720453789842736
Epoch: 44 Idx: 0 Loss: 0.016409909407352687
Epoch: 44 Idx: 5000 Loss: 0.008690849439169972
Epoch: 45 Idx: 0 Loss: 0.013543578064616552
Epoch: 45 Idx: 5000 Loss: 0.020150858193490516
Epoch: 46 Idx: 0 Loss: 0.02831595541274861
Epoch: 46 Idx: 5000 Loss: 0.01666162372776409
Epoch: 47 Idx: 0 Loss: 0.015912548456729094
Epoch: 47 Idx: 5000 Loss: 0.0228327194402119
Epoch: 48 Idx: 0 Loss: 0.021047874282540697
Epoch: 48 Idx: 5000 Loss: 0.00799315937176433
Epoch: 49 Idx: 0 Loss: 0.03823713709665978
Epoch: 49 Idx: 5000 Loss: 0.013022052669684297
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.23453591555744185
Epoch: 0 Idx: 5000 Loss: 0.015397191932134251
Epoch: 1 Idx: 0 Loss: 0.03233567864961024
Epoch: 1 Idx: 5000 Loss: 0.012959878454424829
Epoch: 2 Idx: 0 Loss: 0.014106596261333343
Epoch: 2 Idx: 5000 Loss: 0.0492327258411792
Epoch: 3 Idx: 0 Loss: 0.010404277769677457
Epoch: 3 Idx: 5000 Loss: 0.008682970253306149
Epoch: 4 Idx: 0 Loss: 0.02619546381265209
Epoch: 4 Idx: 5000 Loss: 0.006541778766150343
Epoch: 5 Idx: 0 Loss: 0.007261777616694875
Epoch: 5 Idx: 5000 Loss: 0.021519571972653008
Epoch: 6 Idx: 0 Loss: 0.006495366649120518
Epoch: 6 Idx: 5000 Loss: 0.02434389700569177
Epoch: 7 Idx: 0 Loss: 0.012677868692502089
Epoch: 7 Idx: 5000 Loss: 0.015084632334409603
Epoch: 8 Idx: 0 Loss: 0.013328445606246136
Epoch: 8 Idx: 5000 Loss: 0.014255756574735039
Epoch: 9 Idx: 0 Loss: 0.00854397832454247
Epoch: 9 Idx: 5000 Loss: 0.030899253355363834
Epoch: 10 Idx: 0 Loss: 0.01177883194998829
Epoch: 10 Idx: 5000 Loss: 0.006389727153853948
Epoch: 11 Idx: 0 Loss: 0.014408464760814253
Epoch: 11 Idx: 5000 Loss: 0.05231559282344303
Epoch: 12 Idx: 0 Loss: 0.015836491358847925
Epoch: 12 Idx: 5000 Loss: 0.011578250563375723
Epoch: 13 Idx: 0 Loss: 0.03452645046028318
Epoch: 13 Idx: 5000 Loss: 0.02761723188812813
Epoch: 14 Idx: 0 Loss: 0.013109692365227882
Epoch: 14 Idx: 5000 Loss: 0.025037960366963853
Epoch: 15 Idx: 0 Loss: 0.01595920603546381
Epoch: 15 Idx: 5000 Loss: 0.02076720118749831
Epoch: 16 Idx: 0 Loss: 0.019356128283350264
Epoch: 16 Idx: 5000 Loss: 0.009323886796900934
Epoch: 17 Idx: 0 Loss: 0.013952337371721822
Epoch: 17 Idx: 5000 Loss: 0.01652637546240391
Epoch: 18 Idx: 0 Loss: 0.021587797250754787
Epoch: 18 Idx: 5000 Loss: 0.025508668436758627
Epoch: 19 Idx: 0 Loss: 0.006090411867341163
Epoch: 19 Idx: 5000 Loss: 0.022501905849747084
Epoch: 20 Idx: 0 Loss: 0.008015237869562899
Epoch: 20 Idx: 5000 Loss: 0.02371808775215722
Epoch: 21 Idx: 0 Loss: 0.025797278019579727
Epoch: 21 Idx: 5000 Loss: 0.009981846652016822
Epoch: 22 Idx: 0 Loss: 0.01643327693912218
Epoch: 22 Idx: 5000 Loss: 0.01332480363639623
Epoch: 23 Idx: 0 Loss: 0.020280523592516895
Epoch: 23 Idx: 5000 Loss: 0.011773388290607173
Epoch: 24 Idx: 0 Loss: 0.022262182220496154
Epoch: 24 Idx: 5000 Loss: 0.009690621980937801
Epoch: 25 Idx: 0 Loss: 0.0136031362434259
Epoch: 25 Idx: 5000 Loss: 0.04207307428758836
Epoch: 26 Idx: 0 Loss: 0.013947559896569636
Epoch: 26 Idx: 5000 Loss: 0.018740443525228027
Epoch: 27 Idx: 0 Loss: 0.013502339398226575
Epoch: 27 Idx: 5000 Loss: 0.014897205884521845
Epoch: 28 Idx: 0 Loss: 0.015690586904783425
Epoch: 28 Idx: 5000 Loss: 0.011286635911993376
Epoch: 29 Idx: 0 Loss: 0.009301891599042924
Epoch: 29 Idx: 5000 Loss: 0.035191086271357155
Epoch: 30 Idx: 0 Loss: 0.009463751909823709
Epoch: 30 Idx: 5000 Loss: 0.01919046193743007
Epoch: 31 Idx: 0 Loss: 0.01110202667724361
Epoch: 31 Idx: 5000 Loss: 0.02789480221670991
Epoch: 32 Idx: 0 Loss: 0.02001893886513567
Epoch: 32 Idx: 5000 Loss: 0.03692764866297713
Epoch: 33 Idx: 0 Loss: 0.004029929829544521
Epoch: 33 Idx: 5000 Loss: 0.02350882127941563
Epoch: 34 Idx: 0 Loss: 0.007949450270603522
Epoch: 34 Idx: 5000 Loss: 0.032752349341454046
Epoch: 35 Idx: 0 Loss: 0.006428464261702492
Epoch: 35 Idx: 5000 Loss: 0.03353093085938274
Epoch: 36 Idx: 0 Loss: 0.052813915843329624
Epoch: 36 Idx: 5000 Loss: 0.005851066671995407
Epoch: 37 Idx: 0 Loss: 0.01265916396929008
Epoch: 37 Idx: 5000 Loss: 0.008276916555139749
Epoch: 38 Idx: 0 Loss: 0.03322089390934114
Epoch: 38 Idx: 5000 Loss: 0.04716925088948014
Epoch: 39 Idx: 0 Loss: 0.013964015467150056
Epoch: 39 Idx: 5000 Loss: 0.016177654010537272
Epoch: 40 Idx: 0 Loss: 0.06338891098645931
Epoch: 40 Idx: 5000 Loss: 0.01239129324028186
Epoch: 41 Idx: 0 Loss: 0.009469543132220244
Epoch: 41 Idx: 5000 Loss: 0.009437435434376307
Epoch: 42 Idx: 0 Loss: 0.005150530836665122
Epoch: 42 Idx: 5000 Loss: 0.010917286770474346
Epoch: 43 Idx: 0 Loss: 0.006289414657837483
Epoch: 43 Idx: 5000 Loss: 0.02156481452969644
Epoch: 44 Idx: 0 Loss: 0.012252936221399184
Epoch: 44 Idx: 5000 Loss: 0.011467824512111134
Epoch: 45 Idx: 0 Loss: 0.02448808744755816
Epoch: 45 Idx: 5000 Loss: 0.011140207405016228
Epoch: 46 Idx: 0 Loss: 0.022570509716545714
Epoch: 46 Idx: 5000 Loss: 0.011225681208383244
Epoch: 47 Idx: 0 Loss: 0.007378902732712518
Epoch: 47 Idx: 5000 Loss: 0.012140049696308506
Epoch: 48 Idx: 0 Loss: 0.028168871363947835
Epoch: 48 Idx: 5000 Loss: 0.012350791646876151
Epoch: 49 Idx: 0 Loss: 0.011965801494358823
Epoch: 49 Idx: 5000 Loss: 0.005757916194576399
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.18586464168509442
Epoch: 0 Idx: 5000 Loss: 0.032659237401375774
Epoch: 1 Idx: 0 Loss: 0.020026520364835345
Epoch: 1 Idx: 5000 Loss: 0.011797709939298816
Epoch: 2 Idx: 0 Loss: 0.006014234212014815
Epoch: 2 Idx: 5000 Loss: 0.015628238938261207
Epoch: 3 Idx: 0 Loss: 0.015164008260915206
Epoch: 3 Idx: 5000 Loss: 0.026135088746639792
Epoch: 4 Idx: 0 Loss: 0.013371579738053379
Epoch: 4 Idx: 5000 Loss: 0.016688830892193893
Epoch: 5 Idx: 0 Loss: 0.011515575767676029
Epoch: 5 Idx: 5000 Loss: 0.013127674789281604
Epoch: 6 Idx: 0 Loss: 0.016542033942558532
Epoch: 6 Idx: 5000 Loss: 0.017000658233348398
Epoch: 7 Idx: 0 Loss: 0.027418751333439295
Epoch: 7 Idx: 5000 Loss: 0.01725695445205426
Epoch: 8 Idx: 0 Loss: 0.006625723488876505
Epoch: 8 Idx: 5000 Loss: 0.034062509026732135
Epoch: 9 Idx: 0 Loss: 0.027071915681930535
Epoch: 9 Idx: 5000 Loss: 0.01607773912294986
Epoch: 10 Idx: 0 Loss: 0.03620248506608531
Epoch: 10 Idx: 5000 Loss: 0.02088936542221257
Epoch: 11 Idx: 0 Loss: 0.026056987767487928
Epoch: 11 Idx: 5000 Loss: 0.01948762502613438
Epoch: 12 Idx: 0 Loss: 0.012108277395240757
Epoch: 12 Idx: 5000 Loss: 0.010114547550653857
Epoch: 13 Idx: 0 Loss: 0.012817763463368232
Epoch: 13 Idx: 5000 Loss: 0.020098545754242487
Epoch: 14 Idx: 0 Loss: 0.007439128463043744
Epoch: 14 Idx: 5000 Loss: 0.014933938279744392
Epoch: 15 Idx: 0 Loss: 0.014047403253211578
Epoch: 15 Idx: 5000 Loss: 0.026254670077335764
Epoch: 16 Idx: 0 Loss: 0.028918130637054763
Epoch: 16 Idx: 5000 Loss: 0.005049342667753867
Epoch: 17 Idx: 0 Loss: 0.00750396760042653
Epoch: 17 Idx: 5000 Loss: 0.01064346274174825
Epoch: 18 Idx: 0 Loss: 0.023959742084605492
Epoch: 18 Idx: 5000 Loss: 0.018731084672544963
Epoch: 19 Idx: 0 Loss: 0.016991520710585142
Epoch: 19 Idx: 5000 Loss: 0.022365090597185965
Epoch: 20 Idx: 0 Loss: 0.03281930328365251
Epoch: 20 Idx: 5000 Loss: 0.041314612430029686
Epoch: 21 Idx: 0 Loss: 0.006477048881034205
Epoch: 21 Idx: 5000 Loss: 0.03320650416587506
Epoch: 22 Idx: 0 Loss: 0.008125045575002432
Epoch: 22 Idx: 5000 Loss: 0.01998407747330582
Epoch: 23 Idx: 0 Loss: 0.01407978354528395
Epoch: 23 Idx: 5000 Loss: 0.012453097798997278
Epoch: 24 Idx: 0 Loss: 0.013408174825783825
Epoch: 24 Idx: 5000 Loss: 0.014944431560770325
Epoch: 25 Idx: 0 Loss: 0.012080367844868496
Epoch: 25 Idx: 5000 Loss: 0.024125744064612275
Epoch: 26 Idx: 0 Loss: 0.022890595223852298
Epoch: 26 Idx: 5000 Loss: 0.006761636177608052
Epoch: 27 Idx: 0 Loss: 0.008616508844747324
Epoch: 27 Idx: 5000 Loss: 0.00941109565915316
Epoch: 28 Idx: 0 Loss: 0.018965825922632826
Epoch: 28 Idx: 5000 Loss: 0.021982207811801855
Epoch: 29 Idx: 0 Loss: 0.02566083363648757
Epoch: 29 Idx: 5000 Loss: 0.013561803115907616
Epoch: 30 Idx: 0 Loss: 0.012216954390768158
Epoch: 30 Idx: 5000 Loss: 0.013958379611010957
Epoch: 31 Idx: 0 Loss: 0.00878771345734108
Epoch: 31 Idx: 5000 Loss: 0.019978668023275355
Epoch: 32 Idx: 0 Loss: 0.01922651200722686
Epoch: 32 Idx: 5000 Loss: 0.00980007358568244
Epoch: 33 Idx: 0 Loss: 0.01170894267734572
Epoch: 33 Idx: 5000 Loss: 0.007396337676169028
Epoch: 34 Idx: 0 Loss: 0.031739545841334045
Epoch: 34 Idx: 5000 Loss: 0.012209773891951476
Epoch: 35 Idx: 0 Loss: 0.03926743766604095
Epoch: 35 Idx: 5000 Loss: 0.01619846968289707
Epoch: 36 Idx: 0 Loss: 0.028067844363981177
Epoch: 36 Idx: 5000 Loss: 0.007268684311644827
Epoch: 37 Idx: 0 Loss: 0.013312525437754992
Epoch: 37 Idx: 5000 Loss: 0.00733633534418189
Epoch: 38 Idx: 0 Loss: 0.019120238430023938
Epoch: 38 Idx: 5000 Loss: 0.008195794783920216
Epoch: 39 Idx: 0 Loss: 0.012105654562743054
Epoch: 39 Idx: 5000 Loss: 0.00927112068354656
Epoch: 40 Idx: 0 Loss: 0.009310147986225616
Epoch: 40 Idx: 5000 Loss: 0.02614685511931549
Epoch: 41 Idx: 0 Loss: 0.016747498710573478
Epoch: 41 Idx: 5000 Loss: 0.010776003598881017
Epoch: 42 Idx: 0 Loss: 0.006532961412923838
Epoch: 42 Idx: 5000 Loss: 0.013427998336026543
Epoch: 43 Idx: 0 Loss: 0.03399443299864573
Epoch: 43 Idx: 5000 Loss: 0.011302991198209612
Epoch: 44 Idx: 0 Loss: 0.00676529372514908
Epoch: 44 Idx: 5000 Loss: 0.011346205891713899
Epoch: 45 Idx: 0 Loss: 0.009638534187053804
Epoch: 45 Idx: 5000 Loss: 0.023178897087117102
Epoch: 46 Idx: 0 Loss: 0.01916018468426712
Epoch: 46 Idx: 5000 Loss: 0.012280984491627515
Epoch: 47 Idx: 0 Loss: 0.01263630815831643
Epoch: 47 Idx: 5000 Loss: 0.009112106709779924
Epoch: 48 Idx: 0 Loss: 0.02759254821266699
Epoch: 48 Idx: 5000 Loss: 0.02683731705584592
Epoch: 49 Idx: 0 Loss: 0.016239184919403404
Epoch: 49 Idx: 5000 Loss: 0.01243131145425929
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.2106870711549166
Epoch: 0 Idx: 5000 Loss: 0.020142704194423267
Epoch: 1 Idx: 0 Loss: 0.013190711379583542
Epoch: 1 Idx: 5000 Loss: 0.04221331465098202
Epoch: 2 Idx: 0 Loss: 0.013156674921800473
Epoch: 2 Idx: 5000 Loss: 0.018152749114176803
Epoch: 3 Idx: 0 Loss: 0.024315568322731518
Epoch: 3 Idx: 5000 Loss: 0.023520790299650447
Epoch: 4 Idx: 0 Loss: 0.01945240655077716
Epoch: 4 Idx: 5000 Loss: 0.0060120557270019505
Epoch: 5 Idx: 0 Loss: 0.0144434570774837
Epoch: 5 Idx: 5000 Loss: 0.006670674200242183
Epoch: 6 Idx: 0 Loss: 0.008969331980425922
Epoch: 6 Idx: 5000 Loss: 0.005539484404435751
Epoch: 7 Idx: 0 Loss: 0.013552647628422397
Epoch: 7 Idx: 5000 Loss: 0.01151410501201331
Epoch: 8 Idx: 0 Loss: 0.006881620818342533
Epoch: 8 Idx: 5000 Loss: 0.012013784951225213
Epoch: 9 Idx: 0 Loss: 0.015980560234285804
Epoch: 9 Idx: 5000 Loss: 0.01171310420350342
Epoch: 10 Idx: 0 Loss: 0.012954221533023922
Epoch: 10 Idx: 5000 Loss: 0.013058596234634784
Epoch: 11 Idx: 0 Loss: 0.02665853012857195
Epoch: 11 Idx: 5000 Loss: 0.029677719724576928
Epoch: 12 Idx: 0 Loss: 0.02224287036964687
Epoch: 12 Idx: 5000 Loss: 0.01170024963877342
Epoch: 13 Idx: 0 Loss: 0.01062835140090283
Epoch: 13 Idx: 5000 Loss: 0.010362369256625856
Epoch: 14 Idx: 0 Loss: 0.018184547242912436
Epoch: 14 Idx: 5000 Loss: 0.03684086199533377
Epoch: 15 Idx: 0 Loss: 0.009462035084210866
Epoch: 15 Idx: 5000 Loss: 0.01859507097555053
Epoch: 16 Idx: 0 Loss: 0.01808148985370966
Epoch: 16 Idx: 5000 Loss: 0.01358530713218737
Epoch: 17 Idx: 0 Loss: 0.014858039472030782
Epoch: 17 Idx: 5000 Loss: 0.060718818295935464
Epoch: 18 Idx: 0 Loss: 0.007317894095331167
Epoch: 18 Idx: 5000 Loss: 0.013558613891373725
Epoch: 19 Idx: 0 Loss: 0.01496805392782063
Epoch: 19 Idx: 5000 Loss: 0.030266383094524698
Epoch: 20 Idx: 0 Loss: 0.020625892053343992
Epoch: 20 Idx: 5000 Loss: 0.02243524830318441
Epoch: 21 Idx: 0 Loss: 0.04921056231670274
Epoch: 21 Idx: 5000 Loss: 0.015028519139163551
Epoch: 22 Idx: 0 Loss: 0.009688691384274726
Epoch: 22 Idx: 5000 Loss: 0.019613414021487724
Epoch: 23 Idx: 0 Loss: 0.017805377777960804
Epoch: 23 Idx: 5000 Loss: 0.019063708732430566
Epoch: 24 Idx: 0 Loss: 0.019045837757640686
Epoch: 24 Idx: 5000 Loss: 0.02870241724055628
Epoch: 25 Idx: 0 Loss: 0.011204648712904285
Epoch: 25 Idx: 5000 Loss: 0.010209931958294423
Epoch: 26 Idx: 0 Loss: 0.016869351141844673
Epoch: 26 Idx: 5000 Loss: 0.0190273407367149
Epoch: 27 Idx: 0 Loss: 0.011724821001196258
Epoch: 27 Idx: 5000 Loss: 0.006640431721070877
Epoch: 28 Idx: 0 Loss: 0.021315362117536134
Epoch: 28 Idx: 5000 Loss: 0.012445869008152786
Epoch: 29 Idx: 0 Loss: 0.02766035047922291
Epoch: 29 Idx: 5000 Loss: 0.01052599527094395
Epoch: 30 Idx: 0 Loss: 0.006440736674151502
Epoch: 30 Idx: 5000 Loss: 0.024073806111675585
Epoch: 31 Idx: 0 Loss: 0.03121721603667807
Epoch: 31 Idx: 5000 Loss: 0.006348685423916969
Epoch: 32 Idx: 0 Loss: 0.022537845102354473
Epoch: 32 Idx: 5000 Loss: 0.014457559654557178
Epoch: 33 Idx: 0 Loss: 0.010972755591161941
Epoch: 33 Idx: 5000 Loss: 0.011285313117481915
Epoch: 34 Idx: 0 Loss: 0.03567621000363001
Epoch: 34 Idx: 5000 Loss: 0.029297916923600537
Epoch: 35 Idx: 0 Loss: 0.013003464318426599
Epoch: 35 Idx: 5000 Loss: 0.006745329893554423
Epoch: 36 Idx: 0 Loss: 0.018122766387386118
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 323, in forward
    best_path = torch.bmm(path_weights.reshape(-1, 1, self.max_paths), feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc206>
Subject: Job 4066850: <python main.py 5 4 False True> in cluster <dcc> Exited

Job <python main.py 5 4 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc206>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 4 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46047.02 sec.
    Max Memory :                                 2901 MB
    Average Memory :                             2738.73 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40516.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46200 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

