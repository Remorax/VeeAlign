2020-09-15 15:48:44.775013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.117921: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:52.228892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:52.228968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.231276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:52.250646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:52.285499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:52.328247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:52.350356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:52.350856: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:52.350879: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:52.351384: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:52.391925: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600075000 Hz
2020-09-15 15:48:52.392205: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561b7ff8d520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:52.392227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:52.395325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:52.395347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.2006317701546554
Epoch: 0 Idx: 5000 Loss: 0.0028462010634320535
Epoch: 1 Idx: 0 Loss: 0.015696916157843868
Epoch: 1 Idx: 5000 Loss: 0.019665778341862977
Epoch: 2 Idx: 0 Loss: 0.022186896256219845
Epoch: 2 Idx: 5000 Loss: 0.018601628932377663
Epoch: 3 Idx: 0 Loss: 0.02467574237349866
Epoch: 3 Idx: 5000 Loss: 0.010552235157881769
Epoch: 4 Idx: 0 Loss: 0.018011882474268673
Epoch: 4 Idx: 5000 Loss: 0.04465748989146384
Epoch: 5 Idx: 0 Loss: 0.011438188463468408
Epoch: 5 Idx: 5000 Loss: 0.013303797471959386
Epoch: 6 Idx: 0 Loss: 0.016265085073058596
Epoch: 6 Idx: 5000 Loss: 0.006946825482515108
Epoch: 7 Idx: 0 Loss: 0.011506107047050608
Epoch: 7 Idx: 5000 Loss: 0.008645250551023002
Epoch: 8 Idx: 0 Loss: 0.04223854747588969
Epoch: 8 Idx: 5000 Loss: 0.00708204493904387
Epoch: 9 Idx: 0 Loss: 0.008240727995858978
Epoch: 9 Idx: 5000 Loss: 0.01408802616376022
Epoch: 10 Idx: 0 Loss: 0.013166071039117166
Epoch: 10 Idx: 5000 Loss: 0.015872759962682264
Epoch: 11 Idx: 0 Loss: 0.01819056355356995
Epoch: 11 Idx: 5000 Loss: 0.0388543689810529
Epoch: 12 Idx: 0 Loss: 0.010544442347228808
Epoch: 12 Idx: 5000 Loss: 0.021486059212265776
Epoch: 13 Idx: 0 Loss: 0.0059987191718915926
Epoch: 13 Idx: 5000 Loss: 0.009420359592806751
Epoch: 14 Idx: 0 Loss: 0.018379484057773714
Epoch: 14 Idx: 5000 Loss: 0.02319328743435005
Epoch: 15 Idx: 0 Loss: 0.025270077610857877
Epoch: 15 Idx: 5000 Loss: 0.014665824362934801
Epoch: 16 Idx: 0 Loss: 0.007140110327397063
Epoch: 16 Idx: 5000 Loss: 0.006313503378709897
Epoch: 17 Idx: 0 Loss: 0.011731823570464517
Epoch: 17 Idx: 5000 Loss: 0.013028778320185359
Epoch: 18 Idx: 0 Loss: 0.01414243210293291
Epoch: 18 Idx: 5000 Loss: 0.029783933943385438
Epoch: 19 Idx: 0 Loss: 0.026752328611143385
Epoch: 19 Idx: 5000 Loss: 0.01995182292174401
Epoch: 20 Idx: 0 Loss: 0.004564916418489811
Epoch: 20 Idx: 5000 Loss: 0.036767987792762025
Epoch: 21 Idx: 0 Loss: 0.03495461813639173
Epoch: 21 Idx: 5000 Loss: 0.015127246110096151
Epoch: 22 Idx: 0 Loss: 0.020302670556975374
Epoch: 22 Idx: 5000 Loss: 0.012685427789729717
Epoch: 23 Idx: 0 Loss: 0.025394366071667913
Epoch: 23 Idx: 5000 Loss: 0.02982848180527195
Epoch: 24 Idx: 0 Loss: 0.012273811124574933
Epoch: 24 Idx: 5000 Loss: 0.024370202799730883
Epoch: 25 Idx: 0 Loss: 0.020453016389911736
Epoch: 25 Idx: 5000 Loss: 0.06115697832803433
Epoch: 26 Idx: 0 Loss: 0.010308525243888518
Epoch: 26 Idx: 5000 Loss: 0.010665854896367672
Epoch: 27 Idx: 0 Loss: 0.03552778260170898
Epoch: 27 Idx: 5000 Loss: 0.034089672567316126
Epoch: 28 Idx: 0 Loss: 0.005400592287147691
Epoch: 28 Idx: 5000 Loss: 0.01603099711091125
Epoch: 29 Idx: 0 Loss: 0.020602733979787416
Epoch: 29 Idx: 5000 Loss: 0.02535390285775076
Epoch: 30 Idx: 0 Loss: 0.025368210825404563
Epoch: 30 Idx: 5000 Loss: 0.007975927828815729
Epoch: 31 Idx: 0 Loss: 0.014900018762211736
Epoch: 31 Idx: 5000 Loss: 0.021155888437318356
Epoch: 32 Idx: 0 Loss: 0.03297145882186566
Epoch: 32 Idx: 5000 Loss: 0.008211699666392234
Epoch: 33 Idx: 0 Loss: 0.025419086326940593
Epoch: 33 Idx: 5000 Loss: 0.009095700832950002
Epoch: 34 Idx: 0 Loss: 0.007573460941931888
Epoch: 34 Idx: 5000 Loss: 0.015892429307812202
Epoch: 35 Idx: 0 Loss: 0.010435496311801584
Epoch: 35 Idx: 5000 Loss: 0.01453889355111931
Epoch: 36 Idx: 0 Loss: 0.006318504572040907
Epoch: 36 Idx: 5000 Loss: 0.0277567605765121
Epoch: 37 Idx: 0 Loss: 0.017694012932051063
Epoch: 37 Idx: 5000 Loss: 0.01376436958877724
Epoch: 38 Idx: 0 Loss: 0.006947650904377325
Epoch: 38 Idx: 5000 Loss: 0.02895723852229676
Epoch: 39 Idx: 0 Loss: 0.009165306803434203
Epoch: 39 Idx: 5000 Loss: 0.013758355558756022
Epoch: 40 Idx: 0 Loss: 0.007134239248244149
Epoch: 40 Idx: 5000 Loss: 0.017072667977147484
Epoch: 41 Idx: 0 Loss: 0.010297945959008842
Epoch: 41 Idx: 5000 Loss: 0.011691447673833007
Epoch: 42 Idx: 0 Loss: 0.014687707433379
Epoch: 42 Idx: 5000 Loss: 0.009095738051432429
Epoch: 43 Idx: 0 Loss: 0.01615058412210616
Epoch: 43 Idx: 5000 Loss: 0.021768218834962404
Epoch: 44 Idx: 0 Loss: 0.0101711742153999
Epoch: 44 Idx: 5000 Loss: 0.0362645708753422
Epoch: 45 Idx: 0 Loss: 0.012492101006538914
Epoch: 45 Idx: 5000 Loss: 0.022637260863309767
Epoch: 46 Idx: 0 Loss: 0.017457670527851216
Epoch: 46 Idx: 5000 Loss: 0.026002309518163357
Epoch: 47 Idx: 0 Loss: 0.011757433820726533
Epoch: 47 Idx: 5000 Loss: 0.01935164859453449
Epoch: 48 Idx: 0 Loss: 0.020440351273853276
Epoch: 48 Idx: 5000 Loss: 0.029892449746792858
Epoch: 49 Idx: 0 Loss: 0.01316538308298101
Epoch: 49 Idx: 5000 Loss: 0.019615872170798746
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15108073090017976
Epoch: 0 Idx: 5000 Loss: 0.02147968290675567
Epoch: 1 Idx: 0 Loss: 0.02782317406894307
Epoch: 1 Idx: 5000 Loss: 0.009120397580773439
Epoch: 2 Idx: 0 Loss: 0.02251982330712511
Epoch: 2 Idx: 5000 Loss: 0.009646114012667614
Epoch: 3 Idx: 0 Loss: 0.005473961969657055
Epoch: 3 Idx: 5000 Loss: 0.029076103672767518
Epoch: 4 Idx: 0 Loss: 0.006749186624329306
Epoch: 4 Idx: 5000 Loss: 0.031283929648275394
Epoch: 5 Idx: 0 Loss: 0.014389631614005867
Epoch: 5 Idx: 5000 Loss: 0.013568048262666796
Epoch: 6 Idx: 0 Loss: 0.008714534938379646
Epoch: 6 Idx: 5000 Loss: 0.01167116652641253
Epoch: 7 Idx: 0 Loss: 0.017106767706360684
Epoch: 7 Idx: 5000 Loss: 0.024578497161034076
Epoch: 8 Idx: 0 Loss: 0.014392503502877515
Epoch: 8 Idx: 5000 Loss: 0.0067618007307044
Epoch: 9 Idx: 0 Loss: 0.018271589424716933
Epoch: 9 Idx: 5000 Loss: 0.01154473982224735
Epoch: 10 Idx: 0 Loss: 0.007740835111997573
Epoch: 10 Idx: 5000 Loss: 0.00911415158261368
Epoch: 11 Idx: 0 Loss: 0.010565994215373546
Epoch: 11 Idx: 5000 Loss: 0.006842561419068875
Epoch: 12 Idx: 0 Loss: 0.02504303696740371
Epoch: 12 Idx: 5000 Loss: 0.015001598901124524
Epoch: 13 Idx: 0 Loss: 0.026530238900574928
Epoch: 13 Idx: 5000 Loss: 0.007952388750965732
Epoch: 14 Idx: 0 Loss: 0.01818747692155575
Epoch: 14 Idx: 5000 Loss: 0.01057817845816972
Epoch: 15 Idx: 0 Loss: 0.006860342316366155
Epoch: 15 Idx: 5000 Loss: 0.009311657898682076
Epoch: 16 Idx: 0 Loss: 0.02676978407506327
Epoch: 16 Idx: 5000 Loss: 0.007670800825798603
Epoch: 17 Idx: 0 Loss: 0.008836976211728059
Epoch: 17 Idx: 5000 Loss: 0.038822325760094104
Epoch: 18 Idx: 0 Loss: 0.014406735567706955
Epoch: 18 Idx: 5000 Loss: 0.01693405457872168
Epoch: 19 Idx: 0 Loss: 0.028431193441188045
Epoch: 19 Idx: 5000 Loss: 0.013329915469917861
Epoch: 20 Idx: 0 Loss: 0.017162985986250545
Epoch: 20 Idx: 5000 Loss: 0.006514688941309801
Epoch: 21 Idx: 0 Loss: 0.010650853466252226
Epoch: 21 Idx: 5000 Loss: 0.027651843950145524
Epoch: 22 Idx: 0 Loss: 0.025752541576624204
Epoch: 22 Idx: 5000 Loss: 0.015442648859948673
Epoch: 23 Idx: 0 Loss: 0.008028589830467999
Epoch: 23 Idx: 5000 Loss: 0.018148935747347276
Epoch: 24 Idx: 0 Loss: 0.012447003975678545
Epoch: 24 Idx: 5000 Loss: 0.017006620730855772
Epoch: 25 Idx: 0 Loss: 0.026534536372028877
Epoch: 25 Idx: 5000 Loss: 0.009745511016829576
Epoch: 26 Idx: 0 Loss: 0.018052530082121165
Epoch: 26 Idx: 5000 Loss: 0.013282003229905054
Epoch: 27 Idx: 0 Loss: 0.01551561869310217
Epoch: 27 Idx: 5000 Loss: 0.03307419827191155
Epoch: 28 Idx: 0 Loss: 0.011581462613351717
Epoch: 28 Idx: 5000 Loss: 0.008261332437671014
Epoch: 29 Idx: 0 Loss: 0.006608202335819428
Epoch: 29 Idx: 5000 Loss: 0.020937507986648514
Epoch: 30 Idx: 0 Loss: 0.010308243159654382
Epoch: 30 Idx: 5000 Loss: 0.014103744108118238
Epoch: 31 Idx: 0 Loss: 0.033140234985251676
Epoch: 31 Idx: 5000 Loss: 0.009068276852044536
Epoch: 32 Idx: 0 Loss: 0.021881515413225246
Epoch: 32 Idx: 5000 Loss: 0.017551508847837443
Epoch: 33 Idx: 0 Loss: 0.038037998053396756
Epoch: 33 Idx: 5000 Loss: 0.007971210760233957
Epoch: 34 Idx: 0 Loss: 0.01247851490638603
Epoch: 34 Idx: 5000 Loss: 0.011576350867636491
Epoch: 35 Idx: 0 Loss: 0.021210050356360432
Epoch: 35 Idx: 5000 Loss: 0.032102267455406404
Epoch: 36 Idx: 0 Loss: 0.012536664405003072
Epoch: 36 Idx: 5000 Loss: 0.0162988155391146
Epoch: 37 Idx: 0 Loss: 0.022656016927024097
Epoch: 37 Idx: 5000 Loss: 0.02134230628470077
Epoch: 38 Idx: 0 Loss: 0.01942531797025738
Epoch: 38 Idx: 5000 Loss: 0.013277358198764556
Epoch: 39 Idx: 0 Loss: 0.004860687127899169
Epoch: 39 Idx: 5000 Loss: 0.0065037531467765745
Epoch: 40 Idx: 0 Loss: 0.03959601852402546
Epoch: 40 Idx: 5000 Loss: 0.016482440057736025
Epoch: 41 Idx: 0 Loss: 0.01830675397124413
Epoch: 41 Idx: 5000 Loss: 0.017351518953693145
Epoch: 42 Idx: 0 Loss: 0.012445666251098369
Epoch: 42 Idx: 5000 Loss: 0.006367541048504433
Epoch: 43 Idx: 0 Loss: 0.013450035449577923
Epoch: 43 Idx: 5000 Loss: 0.014334838152733186
Epoch: 44 Idx: 0 Loss: 0.012551508547763799
Epoch: 44 Idx: 5000 Loss: 0.01564241216420236
Epoch: 45 Idx: 0 Loss: 0.011906175779370788
Epoch: 45 Idx: 5000 Loss: 0.007373081707467036
Epoch: 46 Idx: 0 Loss: 0.016021524938601248
Epoch: 46 Idx: 5000 Loss: 0.006081413863598533
Epoch: 47 Idx: 0 Loss: 0.00800645464552761
Epoch: 47 Idx: 5000 Loss: 0.009524261113946463
Epoch: 48 Idx: 0 Loss: 0.020768616600536298
Epoch: 48 Idx: 5000 Loss: 0.0179915520288562
Epoch: 49 Idx: 0 Loss: 0.007407932831388541
Epoch: 49 Idx: 5000 Loss: 0.008407851022402341
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14736936471993717
Epoch: 0 Idx: 5000 Loss: 0.009881937132824174
Epoch: 1 Idx: 0 Loss: 0.01963837770257408
Epoch: 1 Idx: 5000 Loss: 0.005529394027562281
Epoch: 2 Idx: 0 Loss: 0.01872969726736479
Epoch: 2 Idx: 5000 Loss: 0.011583110440867326
Epoch: 3 Idx: 0 Loss: 0.009114208745431875
Epoch: 3 Idx: 5000 Loss: 0.013018524472390776
Epoch: 4 Idx: 0 Loss: 0.018195071901714637
Epoch: 4 Idx: 5000 Loss: 0.012304651730553645
Epoch: 5 Idx: 0 Loss: 0.010440740090310622
Epoch: 5 Idx: 5000 Loss: 0.017998599383496825
Epoch: 6 Idx: 0 Loss: 0.019228130342277907
Epoch: 6 Idx: 5000 Loss: 0.008891366545562707
Epoch: 7 Idx: 0 Loss: 0.01097530039952457
Epoch: 7 Idx: 5000 Loss: 0.035426559687747765
Epoch: 8 Idx: 0 Loss: 0.013493406832627262
Epoch: 8 Idx: 5000 Loss: 0.012440047516425985
Epoch: 9 Idx: 0 Loss: 0.032409590065288055
Epoch: 9 Idx: 5000 Loss: 0.006859019882583955
Epoch: 10 Idx: 0 Loss: 0.011788792519987278
Epoch: 10 Idx: 5000 Loss: 0.010263901172248825
Epoch: 11 Idx: 0 Loss: 0.029778135539697236
Epoch: 11 Idx: 5000 Loss: 0.009509309321592711
Epoch: 12 Idx: 0 Loss: 0.011309280537395853
Epoch: 12 Idx: 5000 Loss: 0.013759282108697712
Epoch: 13 Idx: 0 Loss: 0.011488973399602809
Epoch: 13 Idx: 5000 Loss: 0.005762282809510108
Epoch: 14 Idx: 0 Loss: 0.01884632682161512
Epoch: 14 Idx: 5000 Loss: 0.019745377168145603
Epoch: 15 Idx: 0 Loss: 0.011427175311153372
Epoch: 15 Idx: 5000 Loss: 0.012474923458624537
Epoch: 16 Idx: 0 Loss: 0.03168986266778618
Epoch: 16 Idx: 5000 Loss: 0.016690252382900797
Epoch: 17 Idx: 0 Loss: 0.03729573641567625
Epoch: 17 Idx: 5000 Loss: 0.008171751989800522
Epoch: 18 Idx: 0 Loss: 0.016042964994987717
Epoch: 18 Idx: 5000 Loss: 0.007735177047449578
Epoch: 19 Idx: 0 Loss: 0.014236327869570645
Epoch: 19 Idx: 5000 Loss: 0.031024784810286185
Epoch: 20 Idx: 0 Loss: 0.009488376259868096
Epoch: 20 Idx: 5000 Loss: 0.004887409078898247
Epoch: 21 Idx: 0 Loss: 0.009048481204019932
Epoch: 21 Idx: 5000 Loss: 0.02227260874810004
Epoch: 22 Idx: 0 Loss: 0.011101762528769177
Epoch: 22 Idx: 5000 Loss: 0.01654311138074406
Epoch: 23 Idx: 0 Loss: 0.023045628564764133
Epoch: 23 Idx: 5000 Loss: 0.014644306530774562
Epoch: 24 Idx: 0 Loss: 0.025190479895812547
Epoch: 24 Idx: 5000 Loss: 0.009278288930134139
Epoch: 25 Idx: 0 Loss: 0.03529725152317672
Epoch: 25 Idx: 5000 Loss: 0.016507767670888414
Epoch: 26 Idx: 0 Loss: 0.02096839150366204
Epoch: 26 Idx: 5000 Loss: 0.021484655510006986
Epoch: 27 Idx: 0 Loss: 0.015790838864441336
Epoch: 27 Idx: 5000 Loss: 0.028009976125517897
Epoch: 28 Idx: 0 Loss: 0.025490206490278194
Epoch: 28 Idx: 5000 Loss: 0.006483932029121118
Epoch: 29 Idx: 0 Loss: 0.0062134893220551005
Epoch: 29 Idx: 5000 Loss: 0.01599291045186426
Epoch: 30 Idx: 0 Loss: 0.01511514692906819
Epoch: 30 Idx: 5000 Loss: 0.020692326914908597
Epoch: 31 Idx: 0 Loss: 0.020453998304961283
Epoch: 31 Idx: 5000 Loss: 0.011175315398755884
Epoch: 32 Idx: 0 Loss: 0.012447572183158524
Epoch: 32 Idx: 5000 Loss: 0.006111290901272006
Epoch: 33 Idx: 0 Loss: 0.022434868111171957
Epoch: 33 Idx: 5000 Loss: 0.019555425058070126
Epoch: 34 Idx: 0 Loss: 0.02020489398069013
Epoch: 34 Idx: 5000 Loss: 0.022985691894204782
Epoch: 35 Idx: 0 Loss: 0.011575071782654087
Epoch: 35 Idx: 5000 Loss: 0.02726502731323598
Epoch: 36 Idx: 0 Loss: 0.013014792726033328
Epoch: 36 Idx: 5000 Loss: 0.013950686128518837
Epoch: 37 Idx: 0 Loss: 0.013296308722601367
Epoch: 37 Idx: 5000 Loss: 0.012541959593589919
Epoch: 38 Idx: 0 Loss: 0.014704839467787632
Epoch: 38 Idx: 5000 Loss: 0.01578633588020411
Epoch: 39 Idx: 0 Loss: 0.013492489619717822
Epoch: 39 Idx: 5000 Loss: 0.011042233973474959
Epoch: 40 Idx: 0 Loss: 0.03185881771164917
Epoch: 40 Idx: 5000 Loss: 0.015487864454811644
Epoch: 41 Idx: 0 Loss: 0.01413874682457825
Epoch: 41 Idx: 5000 Loss: 0.012319008954516451
Epoch: 42 Idx: 0 Loss: 0.023591007357245473
Epoch: 42 Idx: 5000 Loss: 0.009426604859086377
Epoch: 43 Idx: 0 Loss: 0.010815858501157702
Epoch: 43 Idx: 5000 Loss: 0.007785877673878977
Epoch: 44 Idx: 0 Loss: 0.014402244764860584
Epoch: 44 Idx: 5000 Loss: 0.013534477919805759
Epoch: 45 Idx: 0 Loss: 0.019480908190801734
Epoch: 45 Idx: 5000 Loss: 0.011339812077243081
Epoch: 46 Idx: 0 Loss: 0.012046680216469924
Epoch: 46 Idx: 5000 Loss: 0.006280417889146672
Epoch: 47 Idx: 0 Loss: 0.03275217575858718
Epoch: 47 Idx: 5000 Loss: 0.018582726817617516
Epoch: 48 Idx: 0 Loss: 0.03957839198783114
Epoch: 48 Idx: 5000 Loss: 0.021455428846437235
Epoch: 49 Idx: 0 Loss: 0.03586603383618389
Epoch: 49 Idx: 5000 Loss: 0.0072086438942844805
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.23563822320104358
Epoch: 0 Idx: 5000 Loss: 0.034412267122384745
Epoch: 1 Idx: 0 Loss: 0.01767431274044637
Epoch: 1 Idx: 5000 Loss: 0.00856970867360219
Epoch: 2 Idx: 0 Loss: 0.009328559196256114
Epoch: 2 Idx: 5000 Loss: 0.016838822101198643
Epoch: 3 Idx: 0 Loss: 0.008543914944319837
Epoch: 3 Idx: 5000 Loss: 0.0296179128650826
Epoch: 4 Idx: 0 Loss: 0.00938119768969351
Epoch: 4 Idx: 5000 Loss: 0.012100139635007631
Epoch: 5 Idx: 0 Loss: 0.012911119268838667
Epoch: 5 Idx: 5000 Loss: 0.029258986685303492
Epoch: 6 Idx: 0 Loss: 0.01470070763770337
Epoch: 6 Idx: 5000 Loss: 0.00877815703497704
Epoch: 7 Idx: 0 Loss: 0.013879360679836701
Epoch: 7 Idx: 5000 Loss: 0.00836823303584922
Epoch: 8 Idx: 0 Loss: 0.0174804575400927
Epoch: 8 Idx: 5000 Loss: 0.007814058325076628
Epoch: 9 Idx: 0 Loss: 0.011524480724583251
Epoch: 9 Idx: 5000 Loss: 0.027607667120443456
Epoch: 10 Idx: 0 Loss: 0.012002701051481464
Epoch: 10 Idx: 5000 Loss: 0.01352707231366688
Epoch: 11 Idx: 0 Loss: 0.017377188530802015
Epoch: 11 Idx: 5000 Loss: 0.022333379784121407
Epoch: 12 Idx: 0 Loss: 0.014189077628089446
Epoch: 12 Idx: 5000 Loss: 0.0237168686329369
Epoch: 13 Idx: 0 Loss: 0.011551032909149795
Epoch: 13 Idx: 5000 Loss: 0.013936118581693777
Epoch: 14 Idx: 0 Loss: 0.038757823749920206
Epoch: 14 Idx: 5000 Loss: 0.01930507167325111
Epoch: 15 Idx: 0 Loss: 0.01324328202207119
Epoch: 15 Idx: 5000 Loss: 0.008766000491766188
Epoch: 16 Idx: 0 Loss: 0.02397637779491657
Epoch: 16 Idx: 5000 Loss: 0.02399164296614636
Epoch: 17 Idx: 0 Loss: 0.01855978539544369
Epoch: 17 Idx: 5000 Loss: 0.019436718193838548
Epoch: 18 Idx: 0 Loss: 0.020487815911232037
Epoch: 18 Idx: 5000 Loss: 0.0184228259568189
Epoch: 19 Idx: 0 Loss: 0.01716226472880726
Epoch: 19 Idx: 5000 Loss: 0.010118986603908801
Epoch: 20 Idx: 0 Loss: 0.01867001502860455
Epoch: 20 Idx: 5000 Loss: 0.012494573537461518
Epoch: 21 Idx: 0 Loss: 0.008158796923211496
Epoch: 21 Idx: 5000 Loss: 0.03567976081199138
Epoch: 22 Idx: 0 Loss: 0.007277652073853024
Epoch: 22 Idx: 5000 Loss: 0.011280476198610511
Epoch: 23 Idx: 0 Loss: 0.035227690534165884
Epoch: 23 Idx: 5000 Loss: 0.02188027365340075
Epoch: 24 Idx: 0 Loss: 0.021879117167325553
Epoch: 24 Idx: 5000 Loss: 0.018686333461936475
Epoch: 25 Idx: 0 Loss: 0.02213788063965509
Epoch: 25 Idx: 5000 Loss: 0.01903802318640778
Epoch: 26 Idx: 0 Loss: 0.009425320125749887
Epoch: 26 Idx: 5000 Loss: 0.007992261184131485
Epoch: 27 Idx: 0 Loss: 0.008822709149947589
Epoch: 27 Idx: 5000 Loss: 0.018246778402197975
Epoch: 28 Idx: 0 Loss: 0.016793665836072977
Epoch: 28 Idx: 5000 Loss: 0.011355413059924487
Epoch: 29 Idx: 0 Loss: 0.010587313965509002
Epoch: 29 Idx: 5000 Loss: 0.0181588480171235
Epoch: 30 Idx: 0 Loss: 0.013336520114997372
Epoch: 30 Idx: 5000 Loss: 0.05951799230246389
Epoch: 31 Idx: 0 Loss: 0.005072806143309573
Epoch: 31 Idx: 5000 Loss: 0.012892408648274681
Epoch: 32 Idx: 0 Loss: 0.0462305542955829
Epoch: 32 Idx: 5000 Loss: 0.015920756564493526
Epoch: 33 Idx: 0 Loss: 0.009249561424526771
Epoch: 33 Idx: 5000 Loss: 0.01629916015742338
Epoch: 34 Idx: 0 Loss: 0.01105848385725057
Epoch: 34 Idx: 5000 Loss: 0.01294244001528106
Epoch: 35 Idx: 0 Loss: 0.025812150016644803
Epoch: 35 Idx: 5000 Loss: 0.025782277813491617
Epoch: 36 Idx: 0 Loss: 0.007011670314059395
Epoch: 36 Idx: 5000 Loss: 0.012937973905261678
Epoch: 37 Idx: 0 Loss: 0.007744747026514294
Epoch: 37 Idx: 5000 Loss: 0.012266631011327094
Epoch: 38 Idx: 0 Loss: 0.03927670880070799
Epoch: 38 Idx: 5000 Loss: 0.005287855192557297
Epoch: 39 Idx: 0 Loss: 0.012159256892677208
Epoch: 39 Idx: 5000 Loss: 0.01335607502395797
Epoch: 40 Idx: 0 Loss: 0.010260325260239136
Epoch: 40 Idx: 5000 Loss: 0.0392382093912256
Epoch: 41 Idx: 0 Loss: 0.010073475879608204
Epoch: 41 Idx: 5000 Loss: 0.023687836574068692
Epoch: 42 Idx: 0 Loss: 0.012676405716758057
Epoch: 42 Idx: 5000 Loss: 0.017057188107597557
Epoch: 43 Idx: 0 Loss: 0.016689732921354457
Epoch: 43 Idx: 5000 Loss: 0.02170077193254389
Epoch: 44 Idx: 0 Loss: 0.011870848964380903
Epoch: 44 Idx: 5000 Loss: 0.052489808172030264
Epoch: 45 Idx: 0 Loss: 0.02739723660975313
Epoch: 45 Idx: 5000 Loss: 0.013428640856346607
Epoch: 46 Idx: 0 Loss: 0.012469347546805183
Epoch: 46 Idx: 5000 Loss: 0.029087015821129866
Epoch: 47 Idx: 0 Loss: 0.01851130508678535
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 336, in forward
    attended_path = node_weights.unsqueeze(-1) * best_path # dim: (batch_size, 4, max_pathlen, 512)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc270>
Subject: Job 4066856: <python main.py 5 9 False True> in cluster <dcc> Exited

Job <python main.py 5 9 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc270>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 9 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46186.13 sec.
    Max Memory :                                 2937 MB
    Average Memory :                             2740.51 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40480.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46202 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

