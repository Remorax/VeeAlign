2020-09-15 15:48:42.597360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.932604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:50.051414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:50.051494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.053890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.075980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.102887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.118524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.120388: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.120684: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.120705: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.121191: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.165094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600185000 Hz
2020-09-15 15:48:50.165343: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5626c2c6e3b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.165363: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.168328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.168393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20041207842454176
Epoch: 0 Idx: 5000 Loss: 0.010730202015997989
Epoch: 1 Idx: 0 Loss: 0.0295185552102347
Epoch: 1 Idx: 5000 Loss: 0.03321206772398872
Epoch: 2 Idx: 0 Loss: 0.012973166813382416
Epoch: 2 Idx: 5000 Loss: 0.010843419910903894
Epoch: 3 Idx: 0 Loss: 0.016782941343187006
Epoch: 3 Idx: 5000 Loss: 0.023953147041437247
Epoch: 4 Idx: 0 Loss: 0.006882649221732571
Epoch: 4 Idx: 5000 Loss: 0.013171020879224721
Epoch: 5 Idx: 0 Loss: 0.02986826759510794
Epoch: 5 Idx: 5000 Loss: 0.024169062447625636
Epoch: 6 Idx: 0 Loss: 0.008020151089461056
Epoch: 6 Idx: 5000 Loss: 0.00978309126119447
Epoch: 7 Idx: 0 Loss: 0.006788843616994876
Epoch: 7 Idx: 5000 Loss: 0.011917927751265696
Epoch: 8 Idx: 0 Loss: 0.03497921947758472
Epoch: 8 Idx: 5000 Loss: 0.015937574434304533
Epoch: 9 Idx: 0 Loss: 0.02000700689766465
Epoch: 9 Idx: 5000 Loss: 0.004633691297626601
Epoch: 10 Idx: 0 Loss: 0.009363868041402278
Epoch: 10 Idx: 5000 Loss: 0.023866281199748113
Epoch: 11 Idx: 0 Loss: 0.02065197907846563
Epoch: 11 Idx: 5000 Loss: 0.026816471799921943
Epoch: 12 Idx: 0 Loss: 0.008881796715259066
Epoch: 12 Idx: 5000 Loss: 0.010296611499899948
Epoch: 13 Idx: 0 Loss: 0.015029607917661614
Epoch: 13 Idx: 5000 Loss: 0.007853975641199471
Epoch: 14 Idx: 0 Loss: 0.016792641053483583
Epoch: 14 Idx: 5000 Loss: 0.011006238306126383
Epoch: 15 Idx: 0 Loss: 0.018294592153956082
Epoch: 15 Idx: 5000 Loss: 0.01710716227901853
Epoch: 16 Idx: 0 Loss: 0.01239380236391473
Epoch: 16 Idx: 5000 Loss: 0.022966400283219467
Epoch: 17 Idx: 0 Loss: 0.022618735432116586
Epoch: 17 Idx: 5000 Loss: 0.011520368456792753
Epoch: 18 Idx: 0 Loss: 0.013459735901835367
Epoch: 18 Idx: 5000 Loss: 0.01207595057247024
Epoch: 19 Idx: 0 Loss: 0.03886175564833002
Epoch: 19 Idx: 5000 Loss: 0.008108360676961733
Epoch: 20 Idx: 0 Loss: 0.005602845315103154
Epoch: 20 Idx: 5000 Loss: 0.019449258565541205
Epoch: 21 Idx: 0 Loss: 0.016424846746425276
Epoch: 21 Idx: 5000 Loss: 0.02038104971904081
Epoch: 22 Idx: 0 Loss: 0.02727514869309365
Epoch: 22 Idx: 5000 Loss: 0.026819211663718874
Epoch: 23 Idx: 0 Loss: 0.017934113810553966
Epoch: 23 Idx: 5000 Loss: 0.03245496247004459
Epoch: 24 Idx: 0 Loss: 0.017124779090569718
Epoch: 24 Idx: 5000 Loss: 0.01718567133104803
Epoch: 25 Idx: 0 Loss: 0.01765122203133748
Epoch: 25 Idx: 5000 Loss: 0.018961215462562263
Epoch: 26 Idx: 0 Loss: 0.010518460814706579
Epoch: 26 Idx: 5000 Loss: 0.02945803045940511
Epoch: 27 Idx: 0 Loss: 0.011836655526389692
Epoch: 27 Idx: 5000 Loss: 0.009789668544358072
Epoch: 28 Idx: 0 Loss: 0.00949058723538633
Epoch: 28 Idx: 5000 Loss: 0.023564363832579188
Epoch: 29 Idx: 0 Loss: 0.02813902031220515
Epoch: 29 Idx: 5000 Loss: 0.007408823590457457
Epoch: 30 Idx: 0 Loss: 0.021174150829546615
Epoch: 30 Idx: 5000 Loss: 0.007615786092396104
Epoch: 31 Idx: 0 Loss: 0.015335704711180738
Epoch: 31 Idx: 5000 Loss: 0.013837961939132377
Epoch: 32 Idx: 0 Loss: 0.007100150918271217
Epoch: 32 Idx: 5000 Loss: 0.011105985028389328
Epoch: 33 Idx: 0 Loss: 0.018557530726454382
Epoch: 33 Idx: 5000 Loss: 0.013198996175426747
Epoch: 34 Idx: 0 Loss: 0.012375577800368001
Epoch: 34 Idx: 5000 Loss: 0.023294513768841105
Epoch: 35 Idx: 0 Loss: 0.007613538967298722
Epoch: 35 Idx: 5000 Loss: 0.01846123571296254
Epoch: 36 Idx: 0 Loss: 0.014958274298537293
Epoch: 36 Idx: 5000 Loss: 0.014738069237156209
Epoch: 37 Idx: 0 Loss: 0.016612625489340765
Epoch: 37 Idx: 5000 Loss: 0.014510943273646035
Epoch: 38 Idx: 0 Loss: 0.020063914141649784
Epoch: 38 Idx: 5000 Loss: 0.015215074145895116
Epoch: 39 Idx: 0 Loss: 0.018124570870500827
Epoch: 39 Idx: 5000 Loss: 0.015483269098682542
Epoch: 40 Idx: 0 Loss: 0.024992192475876054
Epoch: 40 Idx: 5000 Loss: 0.010214717188148589
Epoch: 41 Idx: 0 Loss: 0.017415927660925885
Epoch: 41 Idx: 5000 Loss: 0.007606510304670152
Epoch: 42 Idx: 0 Loss: 0.011086559651684553
Epoch: 42 Idx: 5000 Loss: 0.010286035354158896
Epoch: 43 Idx: 0 Loss: 0.03299140225106959
Epoch: 43 Idx: 5000 Loss: 0.018393358810377257
Epoch: 44 Idx: 0 Loss: 0.011808181322975484
Epoch: 44 Idx: 5000 Loss: 0.016473007858476683
Epoch: 45 Idx: 0 Loss: 0.016811226907317553
Epoch: 45 Idx: 5000 Loss: 0.02428659356590275
Epoch: 46 Idx: 0 Loss: 0.01852424037755249
Epoch: 46 Idx: 5000 Loss: 0.010368931199993485
Epoch: 47 Idx: 0 Loss: 0.015647003045335478
Epoch: 47 Idx: 5000 Loss: 0.006146417624868064
Epoch: 48 Idx: 0 Loss: 0.025758921588902507
Epoch: 48 Idx: 5000 Loss: 0.015134365034678991
Epoch: 49 Idx: 0 Loss: 0.010487955368534573
Epoch: 49 Idx: 5000 Loss: 0.016317440067980988
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14220189839792266
Epoch: 0 Idx: 5000 Loss: 0.012567057893794756
Epoch: 1 Idx: 0 Loss: 0.03572174302549876
Epoch: 1 Idx: 5000 Loss: 0.012929345744619448
Epoch: 2 Idx: 0 Loss: 0.012087901688884644
Epoch: 2 Idx: 5000 Loss: 0.014285476355778108
Epoch: 3 Idx: 0 Loss: 0.011203738755940882
Epoch: 3 Idx: 5000 Loss: 0.013735449225817624
Epoch: 4 Idx: 0 Loss: 0.014463865208017047
Epoch: 4 Idx: 5000 Loss: 0.012488066975039402
Epoch: 5 Idx: 0 Loss: 0.010091282322182807
Epoch: 5 Idx: 5000 Loss: 0.022768692423960353
Epoch: 6 Idx: 0 Loss: 0.014373839464391053
Epoch: 6 Idx: 5000 Loss: 0.01897366479529507
Epoch: 7 Idx: 0 Loss: 0.026813182395709255
Epoch: 7 Idx: 5000 Loss: 0.01958372832702785
Epoch: 8 Idx: 0 Loss: 0.004216709800050405
Epoch: 8 Idx: 5000 Loss: 0.04910475829051673
Epoch: 9 Idx: 0 Loss: 0.010522187845539148
Epoch: 9 Idx: 5000 Loss: 0.010107566824860642
Epoch: 10 Idx: 0 Loss: 0.019606987835407
Epoch: 10 Idx: 5000 Loss: 0.013531712678655527
Epoch: 11 Idx: 0 Loss: 0.010998463470455896
Epoch: 11 Idx: 5000 Loss: 0.01480928888496727
Epoch: 12 Idx: 0 Loss: 0.008914677028957717
Epoch: 12 Idx: 5000 Loss: 0.012753419426106248
Epoch: 13 Idx: 0 Loss: 0.01116352855640256
Epoch: 13 Idx: 5000 Loss: 0.044590115439829284
Epoch: 14 Idx: 0 Loss: 0.013412199610541301
Epoch: 14 Idx: 5000 Loss: 0.013752437049952083
Epoch: 15 Idx: 0 Loss: 0.011209232739857519
Epoch: 15 Idx: 5000 Loss: 0.03016604251101409
Epoch: 16 Idx: 0 Loss: 0.03184752612531568
Epoch: 16 Idx: 5000 Loss: 0.036029382404864044
Epoch: 17 Idx: 0 Loss: 0.02618605498036468
Epoch: 17 Idx: 5000 Loss: 0.01659231412415131
Epoch: 18 Idx: 0 Loss: 0.0271674906578461
Epoch: 18 Idx: 5000 Loss: 0.0073698575115892645
Epoch: 19 Idx: 0 Loss: 0.019697813789277145
Epoch: 19 Idx: 5000 Loss: 0.007154109668735058
Epoch: 20 Idx: 0 Loss: 0.022669964695308648
Epoch: 20 Idx: 5000 Loss: 0.011058876306864945
Epoch: 21 Idx: 0 Loss: 0.005237635947638699
Epoch: 21 Idx: 5000 Loss: 0.02669500060599775
Epoch: 22 Idx: 0 Loss: 0.021479030628329895
Epoch: 22 Idx: 5000 Loss: 0.006529541996109006
Epoch: 23 Idx: 0 Loss: 0.019269704934484932
Epoch: 23 Idx: 5000 Loss: 0.01354075411534885
Epoch: 24 Idx: 0 Loss: 0.010326919214712725
Epoch: 24 Idx: 5000 Loss: 0.02366015666014036
Epoch: 25 Idx: 0 Loss: 0.020157007828755614
Epoch: 25 Idx: 5000 Loss: 0.014192440559786194
Epoch: 26 Idx: 0 Loss: 0.02047713056657574
Epoch: 26 Idx: 5000 Loss: 0.011806435571075713
Epoch: 27 Idx: 0 Loss: 0.029953583486407358
Epoch: 27 Idx: 5000 Loss: 0.01191379273079816
Epoch: 28 Idx: 0 Loss: 0.027374715376651017
Epoch: 28 Idx: 5000 Loss: 0.011528018630548253
Epoch: 29 Idx: 0 Loss: 0.029147748110982467
Epoch: 29 Idx: 5000 Loss: 0.010286946093583391
Epoch: 30 Idx: 0 Loss: 0.013706166867426551
Epoch: 30 Idx: 5000 Loss: 0.02723246038450915
Epoch: 31 Idx: 0 Loss: 0.021357112648580524
Epoch: 31 Idx: 5000 Loss: 0.009421562602708364
Epoch: 32 Idx: 0 Loss: 0.009329239253323005
Epoch: 32 Idx: 5000 Loss: 0.029767131261852084
Epoch: 33 Idx: 0 Loss: 0.006706173521734516
Epoch: 33 Idx: 5000 Loss: 0.027963973607636923
Epoch: 34 Idx: 0 Loss: 0.011212064568618485
Epoch: 34 Idx: 5000 Loss: 0.007843198222357453
Epoch: 35 Idx: 0 Loss: 0.006052923319077353
Epoch: 35 Idx: 5000 Loss: 0.018290173550379214
Epoch: 36 Idx: 0 Loss: 0.017799196258686267
Epoch: 36 Idx: 5000 Loss: 0.008458603768529572
Epoch: 37 Idx: 0 Loss: 0.008572648452579993
Epoch: 37 Idx: 5000 Loss: 0.024427456539444878
Epoch: 38 Idx: 0 Loss: 0.02524014568592812
Epoch: 38 Idx: 5000 Loss: 0.012356635757273866
Epoch: 39 Idx: 0 Loss: 0.008196767282752173
Epoch: 39 Idx: 5000 Loss: 0.01374876618135774
Epoch: 40 Idx: 0 Loss: 0.007870395507077669
Epoch: 40 Idx: 5000 Loss: 0.01737810397353967
Epoch: 41 Idx: 0 Loss: 0.0123605544044012
Epoch: 41 Idx: 5000 Loss: 0.014398060749027858
Epoch: 42 Idx: 0 Loss: 0.010740406227900422
Epoch: 42 Idx: 5000 Loss: 0.008295224255668292
Epoch: 43 Idx: 0 Loss: 0.011338477598989458
Epoch: 43 Idx: 5000 Loss: 0.027584143455556057
Epoch: 44 Idx: 0 Loss: 0.03667071241588464
Epoch: 44 Idx: 5000 Loss: 0.01818554275362734
Epoch: 45 Idx: 0 Loss: 0.026408125510699525
Epoch: 45 Idx: 5000 Loss: 0.004854616115518375
Epoch: 46 Idx: 0 Loss: 0.018405410133948794
Epoch: 46 Idx: 5000 Loss: 0.014705602539532004
Epoch: 47 Idx: 0 Loss: 0.016383643027321183
Epoch: 47 Idx: 5000 Loss: 0.01738817161064983
Epoch: 48 Idx: 0 Loss: 0.009169035824119393
Epoch: 48 Idx: 5000 Loss: 0.01301567887349237
Epoch: 49 Idx: 0 Loss: 0.00881526152046815
Epoch: 49 Idx: 5000 Loss: 0.013723597823932652
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1455358007965012
Epoch: 0 Idx: 5000 Loss: 0.021819084601487168
Epoch: 1 Idx: 0 Loss: 0.026058959862038836
Epoch: 1 Idx: 5000 Loss: 0.005536280120785818
Epoch: 2 Idx: 0 Loss: 0.006596775926744885
Epoch: 2 Idx: 5000 Loss: 0.02025960201783738
Epoch: 3 Idx: 0 Loss: 0.017159732539070695
Epoch: 3 Idx: 5000 Loss: 0.018419559478041747
Epoch: 4 Idx: 0 Loss: 0.00854578723306045
Epoch: 4 Idx: 5000 Loss: 0.012976690171411696
Epoch: 5 Idx: 0 Loss: 0.01586938290486757
Epoch: 5 Idx: 5000 Loss: 0.013119284522088034
Epoch: 6 Idx: 0 Loss: 0.014109412238785458
Epoch: 6 Idx: 5000 Loss: 0.04415904093439461
Epoch: 7 Idx: 0 Loss: 0.0091446835552715
Epoch: 7 Idx: 5000 Loss: 0.007182779869090273
Epoch: 8 Idx: 0 Loss: 0.009781892475711386
Epoch: 8 Idx: 5000 Loss: 0.022198597355658302
Epoch: 9 Idx: 0 Loss: 0.01641462079965821
Epoch: 9 Idx: 5000 Loss: 0.008379375182415333
Epoch: 10 Idx: 0 Loss: 0.02191988472923225
Epoch: 10 Idx: 5000 Loss: 0.00974382252786578
Epoch: 11 Idx: 0 Loss: 0.02682694717392222
Epoch: 11 Idx: 5000 Loss: 0.013042192236159305
Epoch: 12 Idx: 0 Loss: 0.009425703008057113
Epoch: 12 Idx: 5000 Loss: 0.02001592968962715
Epoch: 13 Idx: 0 Loss: 0.010450979355559685
Epoch: 13 Idx: 5000 Loss: 0.02852029894512747
Epoch: 14 Idx: 0 Loss: 0.02083603694380272
Epoch: 14 Idx: 5000 Loss: 0.02871490900249652
Epoch: 15 Idx: 0 Loss: 0.008610138242041028
Epoch: 15 Idx: 5000 Loss: 0.01646336449400649
Epoch: 16 Idx: 0 Loss: 0.021027280781175085
Epoch: 16 Idx: 5000 Loss: 0.015484665107446192
Epoch: 17 Idx: 0 Loss: 0.014399359804357033
Epoch: 17 Idx: 5000 Loss: 0.01128511613139541
Epoch: 18 Idx: 0 Loss: 0.007251126269444189
Epoch: 18 Idx: 5000 Loss: 0.016240797879397015
Epoch: 19 Idx: 0 Loss: 0.010403169880198716
Epoch: 19 Idx: 5000 Loss: 0.036686075065163484
Epoch: 20 Idx: 0 Loss: 0.02764341480921726
Epoch: 20 Idx: 5000 Loss: 0.00988460990234281
Epoch: 21 Idx: 0 Loss: 0.026713597146121013
Epoch: 21 Idx: 5000 Loss: 0.01399370237911742
Epoch: 22 Idx: 0 Loss: 0.019337772521610366
Epoch: 22 Idx: 5000 Loss: 0.019991396026484462
Epoch: 23 Idx: 0 Loss: 0.03553231475384232
Epoch: 23 Idx: 5000 Loss: 0.02748282480654511
Epoch: 24 Idx: 0 Loss: 0.01753999646454076
Epoch: 24 Idx: 5000 Loss: 0.01140903441460376
Epoch: 25 Idx: 0 Loss: 0.010371375415615017
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 315, in forward
    path_weights = torch.bmm(node_emb[:, None, :], feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc267>
Subject: Job 4066808: <python main.py 3 26 False False> in cluster <dcc> Exited

Job <python main.py 3 26 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
Job was executed on host(s) <dccxc267>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 26 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46187.12 sec.
    Max Memory :                                 2955 MB
    Average Memory :                             2734.61 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40462.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46203 sec.
    Turnaround time :                            46204 sec.

The output (if any) is above this job summary.

