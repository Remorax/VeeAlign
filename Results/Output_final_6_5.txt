2020-09-15 15:48:45.461807: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.558746: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:52.681951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:52.682017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.684222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:52.702784: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:52.752213: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:52.794243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:52.825600: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:52.826025: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:52.826049: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:52.826459: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:52.861233: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599885000 Hz
2020-09-15 15:48:52.861468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562950ba5d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:52.861489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:52.864246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:52.864270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1847839876817123
Epoch: 0 Idx: 5000 Loss: 0.008293992584777695
Epoch: 1 Idx: 0 Loss: 0.013928424365305721
Epoch: 1 Idx: 5000 Loss: 0.00960605841704676
Epoch: 2 Idx: 0 Loss: 0.012866784758168631
Epoch: 2 Idx: 5000 Loss: 0.013145470133001607
Epoch: 3 Idx: 0 Loss: 0.012185926251716939
Epoch: 3 Idx: 5000 Loss: 0.03491223181804817
Epoch: 4 Idx: 0 Loss: 0.015141557589865027
Epoch: 4 Idx: 5000 Loss: 0.009345987001493604
Epoch: 5 Idx: 0 Loss: 0.006996338382643221
Epoch: 5 Idx: 5000 Loss: 0.020697937698979346
Epoch: 6 Idx: 0 Loss: 0.009758380906318793
Epoch: 6 Idx: 5000 Loss: 0.013088901910059556
Epoch: 7 Idx: 0 Loss: 0.01955484816767787
Epoch: 7 Idx: 5000 Loss: 0.014028911504635897
Epoch: 8 Idx: 0 Loss: 0.021697134467016772
Epoch: 8 Idx: 5000 Loss: 0.016115949988595897
Epoch: 9 Idx: 0 Loss: 0.019134020595287064
Epoch: 9 Idx: 5000 Loss: 0.013396880078543505
Epoch: 10 Idx: 0 Loss: 0.008841857555830042
Epoch: 10 Idx: 5000 Loss: 0.0069056030152316004
Epoch: 11 Idx: 0 Loss: 0.010826120877260897
Epoch: 11 Idx: 5000 Loss: 0.015800602967771957
Epoch: 12 Idx: 0 Loss: 0.005849056357832905
Epoch: 12 Idx: 5000 Loss: 0.020197612164725126
Epoch: 13 Idx: 0 Loss: 0.01053082640963283
Epoch: 13 Idx: 5000 Loss: 0.0076394576343942165
Epoch: 14 Idx: 0 Loss: 0.02503338883004881
Epoch: 14 Idx: 5000 Loss: 0.019147291479664926
Epoch: 15 Idx: 0 Loss: 0.012415665217811896
Epoch: 15 Idx: 5000 Loss: 0.011724589099748528
Epoch: 16 Idx: 0 Loss: 0.0068903370497067525
Epoch: 16 Idx: 5000 Loss: 0.009516963123762228
Epoch: 17 Idx: 0 Loss: 0.01312884669718057
Epoch: 17 Idx: 5000 Loss: 0.00918908627147125
Epoch: 18 Idx: 0 Loss: 0.012282161008295515
Epoch: 18 Idx: 5000 Loss: 0.02770655991925591
Epoch: 19 Idx: 0 Loss: 0.01406041221868336
Epoch: 19 Idx: 5000 Loss: 0.027730582886530904
Epoch: 20 Idx: 0 Loss: 0.004699843393446599
Epoch: 20 Idx: 5000 Loss: 0.019982333793554352
Epoch: 21 Idx: 0 Loss: 0.028287358898879445
Epoch: 21 Idx: 5000 Loss: 0.010606939015346947
Epoch: 22 Idx: 0 Loss: 0.02315154285356964
Epoch: 22 Idx: 5000 Loss: 0.012507824089708047
Epoch: 23 Idx: 0 Loss: 0.026122336335353352
Epoch: 23 Idx: 5000 Loss: 0.03956639741279443
Epoch: 24 Idx: 0 Loss: 0.02424013208488731
Epoch: 24 Idx: 5000 Loss: 0.00782890821796066
Epoch: 25 Idx: 0 Loss: 0.010327659526370277
Epoch: 25 Idx: 5000 Loss: 0.012413790766721942
Epoch: 26 Idx: 0 Loss: 0.00767049853841015
Epoch: 26 Idx: 5000 Loss: 0.03445104425542044
Epoch: 27 Idx: 0 Loss: 0.006171937619460178
Epoch: 27 Idx: 5000 Loss: 0.008877654548397573
Epoch: 28 Idx: 0 Loss: 0.025279734487993488
Epoch: 28 Idx: 5000 Loss: 0.0132816207191504
Epoch: 29 Idx: 0 Loss: 0.026502091253451508
Epoch: 29 Idx: 5000 Loss: 0.006604410037464947
Epoch: 30 Idx: 0 Loss: 0.026439107673037806
Epoch: 30 Idx: 5000 Loss: 0.016751779476397274
Epoch: 31 Idx: 0 Loss: 0.018910409102053664
Epoch: 31 Idx: 5000 Loss: 0.01772990220296164
Epoch: 32 Idx: 0 Loss: 0.020429370324989957
Epoch: 32 Idx: 5000 Loss: 0.012172522951188477
Epoch: 33 Idx: 0 Loss: 0.00950714080927398
Epoch: 33 Idx: 5000 Loss: 0.021700027615404946
Epoch: 34 Idx: 0 Loss: 0.024830282372266005
Epoch: 34 Idx: 5000 Loss: 0.014722430616256976
Epoch: 35 Idx: 0 Loss: 0.029569791655963726
Epoch: 35 Idx: 5000 Loss: 0.013999733723177414
Epoch: 36 Idx: 0 Loss: 0.02228103484893973
Epoch: 36 Idx: 5000 Loss: 0.019280350017340714
Epoch: 37 Idx: 0 Loss: 0.01716768108589506
Epoch: 37 Idx: 5000 Loss: 0.014137874455604847
Epoch: 38 Idx: 0 Loss: 0.015399559962870409
Epoch: 38 Idx: 5000 Loss: 0.016108368789009127
Epoch: 39 Idx: 0 Loss: 0.022023951924444694
Epoch: 39 Idx: 5000 Loss: 0.02622437286761794
Epoch: 40 Idx: 0 Loss: 0.007656672618620769
Epoch: 40 Idx: 5000 Loss: 0.023567700837286355
Epoch: 41 Idx: 0 Loss: 0.023784623769965037
Epoch: 41 Idx: 5000 Loss: 0.014488698636197478
Epoch: 42 Idx: 0 Loss: 0.008890756065642602
Epoch: 42 Idx: 5000 Loss: 0.014386065780585178
Epoch: 43 Idx: 0 Loss: 0.013397083830470311
Epoch: 43 Idx: 5000 Loss: 0.009715556842992959
Epoch: 44 Idx: 0 Loss: 0.01957333431903477
Epoch: 44 Idx: 5000 Loss: 0.017519338277938275
Epoch: 45 Idx: 0 Loss: 0.023757162068856804
Epoch: 45 Idx: 5000 Loss: 0.016502662586176692
Epoch: 46 Idx: 0 Loss: 0.02057207308167974
Epoch: 46 Idx: 5000 Loss: 0.01706453324500761
Epoch: 47 Idx: 0 Loss: 0.014043566335622891
Epoch: 47 Idx: 5000 Loss: 0.012840321786841873
Epoch: 48 Idx: 0 Loss: 0.012880523227006113
Epoch: 48 Idx: 5000 Loss: 0.027577810477055015
Epoch: 49 Idx: 0 Loss: 0.04280800277997423
Epoch: 49 Idx: 5000 Loss: 0.01632919464814007
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.12730709633895926
Epoch: 0 Idx: 5000 Loss: 0.023146636747307853
Epoch: 1 Idx: 0 Loss: 0.010670257142451671
Epoch: 1 Idx: 5000 Loss: 0.01795133663684899
Epoch: 2 Idx: 0 Loss: 0.0579914064660793
Epoch: 2 Idx: 5000 Loss: 0.010403804783293676
Epoch: 3 Idx: 0 Loss: 0.009067716379276392
Epoch: 3 Idx: 5000 Loss: 0.009909679674466433
Epoch: 4 Idx: 0 Loss: 0.008968179016803055
Epoch: 4 Idx: 5000 Loss: 0.015719619604231155
Epoch: 5 Idx: 0 Loss: 0.024913499537030634
Epoch: 5 Idx: 5000 Loss: 0.023153648365730542
Epoch: 6 Idx: 0 Loss: 0.034931018608814556
Epoch: 6 Idx: 5000 Loss: 0.03420046224539575
Epoch: 7 Idx: 0 Loss: 0.030434256308092524
Epoch: 7 Idx: 5000 Loss: 0.007986029552988778
Epoch: 8 Idx: 0 Loss: 0.007552344707095175
Epoch: 8 Idx: 5000 Loss: 0.013470095091085389
Epoch: 9 Idx: 0 Loss: 0.026167369178543107
Epoch: 9 Idx: 5000 Loss: 0.01236086522998697
Epoch: 10 Idx: 0 Loss: 0.023610969631296518
Epoch: 10 Idx: 5000 Loss: 0.032595056179312215
Epoch: 11 Idx: 0 Loss: 0.01225022405245184
Epoch: 11 Idx: 5000 Loss: 0.009077483388889597
Epoch: 12 Idx: 0 Loss: 0.045337374656709
Epoch: 12 Idx: 5000 Loss: 0.02946916282017792
Epoch: 13 Idx: 0 Loss: 0.00977072540568251
Epoch: 13 Idx: 5000 Loss: 0.008325034362014172
Epoch: 14 Idx: 0 Loss: 0.023864627416896055
Epoch: 14 Idx: 5000 Loss: 0.0061607724451162695
Epoch: 15 Idx: 0 Loss: 0.00833720698027354
Epoch: 15 Idx: 5000 Loss: 0.033934982664764836
Epoch: 16 Idx: 0 Loss: 0.021978262187914408
Epoch: 16 Idx: 5000 Loss: 0.01490834996147345
Epoch: 17 Idx: 0 Loss: 0.04674354890041463
Epoch: 17 Idx: 5000 Loss: 0.010221084109214839
Epoch: 18 Idx: 0 Loss: 0.015046130181404108
Epoch: 18 Idx: 5000 Loss: 0.021853865075538565
Epoch: 19 Idx: 0 Loss: 0.02431550704230677
Epoch: 19 Idx: 5000 Loss: 0.009409727009240035
Epoch: 20 Idx: 0 Loss: 0.017767919347266098
Epoch: 20 Idx: 5000 Loss: 0.02192476035560112
Epoch: 21 Idx: 0 Loss: 0.02228418805159602
Epoch: 21 Idx: 5000 Loss: 0.03176076415569806
Epoch: 22 Idx: 0 Loss: 0.01223848112965582
Epoch: 22 Idx: 5000 Loss: 0.011934449131679903
Epoch: 23 Idx: 0 Loss: 0.03439609748816671
Epoch: 23 Idx: 5000 Loss: 0.03151865430317677
Epoch: 24 Idx: 0 Loss: 0.010923261769020694
Epoch: 24 Idx: 5000 Loss: 0.028509486123109974
Epoch: 25 Idx: 0 Loss: 0.014043694040289214
Epoch: 25 Idx: 5000 Loss: 0.01617038854172851
Epoch: 26 Idx: 0 Loss: 0.017488542252670138
Epoch: 26 Idx: 5000 Loss: 0.019427906313724645
Epoch: 27 Idx: 0 Loss: 0.009959408375276415
Epoch: 27 Idx: 5000 Loss: 0.01809405106207525
Epoch: 28 Idx: 0 Loss: 0.015534042649410117
Epoch: 28 Idx: 5000 Loss: 0.00501661244661133
Epoch: 29 Idx: 0 Loss: 0.020915944912853188
Epoch: 29 Idx: 5000 Loss: 0.011953126466696534
Epoch: 30 Idx: 0 Loss: 0.011329246858313435
Epoch: 30 Idx: 5000 Loss: 0.005441058573805059
Epoch: 31 Idx: 0 Loss: 0.020396765055464103
Epoch: 31 Idx: 5000 Loss: 0.014272513323836158
Epoch: 32 Idx: 0 Loss: 0.010445664528483422
Epoch: 32 Idx: 5000 Loss: 0.03444694892167684
Epoch: 33 Idx: 0 Loss: 0.012667734509447848
Epoch: 33 Idx: 5000 Loss: 0.009443762788096173
Epoch: 34 Idx: 0 Loss: 0.01679687562873621
Epoch: 34 Idx: 5000 Loss: 0.01304643694401298
Epoch: 35 Idx: 0 Loss: 0.01445206809856514
Epoch: 35 Idx: 5000 Loss: 0.013307453561264206
Epoch: 36 Idx: 0 Loss: 0.025493385415290327
Epoch: 36 Idx: 5000 Loss: 0.014046638480631674
Epoch: 37 Idx: 0 Loss: 0.009966714345865012
Epoch: 37 Idx: 5000 Loss: 0.014273144255393198
Epoch: 38 Idx: 0 Loss: 0.018094756751976596
Epoch: 38 Idx: 5000 Loss: 0.008561755701902794
Epoch: 39 Idx: 0 Loss: 0.01117520434885154
Epoch: 39 Idx: 5000 Loss: 0.007741441352476692
Epoch: 40 Idx: 0 Loss: 0.011606918599906276
Epoch: 40 Idx: 5000 Loss: 0.018631428064278775
Epoch: 41 Idx: 0 Loss: 0.013376196813606736
Epoch: 41 Idx: 5000 Loss: 0.011750745306997028
Epoch: 42 Idx: 0 Loss: 0.0195821549643661
Epoch: 42 Idx: 5000 Loss: 0.006438298722383261
Epoch: 43 Idx: 0 Loss: 0.011745259982418413
Epoch: 43 Idx: 5000 Loss: 0.006459216183814872
Epoch: 44 Idx: 0 Loss: 0.008252858199517083
Epoch: 44 Idx: 5000 Loss: 0.03340456671679467
Epoch: 45 Idx: 0 Loss: 0.009675516394425824
Epoch: 45 Idx: 5000 Loss: 0.011011137778545692
Epoch: 46 Idx: 0 Loss: 0.016172369616444
Epoch: 46 Idx: 5000 Loss: 0.010192784553814515
Epoch: 47 Idx: 0 Loss: 0.009708636840591735
Epoch: 47 Idx: 5000 Loss: 0.010823970916441283
Epoch: 48 Idx: 0 Loss: 0.014330662923710573
Epoch: 48 Idx: 5000 Loss: 0.00986674569863017
Epoch: 49 Idx: 0 Loss: 0.023838244626216334
Epoch: 49 Idx: 5000 Loss: 0.008463544637813349
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1565968308588014
Epoch: 0 Idx: 5000 Loss: 0.013680066941561708
Epoch: 1 Idx: 0 Loss: 0.02115447906772377
Epoch: 1 Idx: 5000 Loss: 0.013257924432115955
Epoch: 2 Idx: 0 Loss: 0.017571256923209946
Epoch: 2 Idx: 5000 Loss: 0.030568535199821285
Epoch: 3 Idx: 0 Loss: 0.03773390718013442
Epoch: 3 Idx: 5000 Loss: 0.010820718520264285
Epoch: 4 Idx: 0 Loss: 0.01983286921759726
Epoch: 4 Idx: 5000 Loss: 0.030764479488782793
Epoch: 5 Idx: 0 Loss: 0.033136344977162446
Epoch: 5 Idx: 5000 Loss: 0.011156451569327677
Epoch: 6 Idx: 0 Loss: 0.026503785656387394
Epoch: 6 Idx: 5000 Loss: 0.014985707399140626
Epoch: 7 Idx: 0 Loss: 0.016794695161732626
Epoch: 7 Idx: 5000 Loss: 0.012206362665716472
Epoch: 8 Idx: 0 Loss: 0.004106226789930032
Epoch: 8 Idx: 5000 Loss: 0.007547252004607643
Epoch: 9 Idx: 0 Loss: 0.032249030099401374
Epoch: 9 Idx: 5000 Loss: 0.009191161623418797
Epoch: 10 Idx: 0 Loss: 0.005245592159384132
Epoch: 10 Idx: 5000 Loss: 0.012390423456860788
Epoch: 11 Idx: 0 Loss: 0.03412047511874893
Epoch: 11 Idx: 5000 Loss: 0.028177217371036657
Epoch: 12 Idx: 0 Loss: 0.00793192062794644
Epoch: 12 Idx: 5000 Loss: 0.017421988300893393
Epoch: 13 Idx: 0 Loss: 0.019932045601698666
Epoch: 13 Idx: 5000 Loss: 0.00988710190388302
Epoch: 14 Idx: 0 Loss: 0.03769805622999367
Epoch: 14 Idx: 5000 Loss: 0.022520920659704208
Epoch: 15 Idx: 0 Loss: 0.01649388391902121
Epoch: 15 Idx: 5000 Loss: 0.010444976158608649
Epoch: 16 Idx: 0 Loss: 0.019561828838951772
Epoch: 16 Idx: 5000 Loss: 0.008687204482881038
Epoch: 17 Idx: 0 Loss: 0.013293780250832433
Epoch: 17 Idx: 5000 Loss: 0.034458138964098495
Epoch: 18 Idx: 0 Loss: 0.014649909162801199
Epoch: 18 Idx: 5000 Loss: 0.02579450703575679
Epoch: 19 Idx: 0 Loss: 0.01698821946089618
Epoch: 19 Idx: 5000 Loss: 0.024961640150314133
Epoch: 20 Idx: 0 Loss: 0.014062728520152794
Epoch: 20 Idx: 5000 Loss: 0.009707771170113335
Epoch: 21 Idx: 0 Loss: 0.008886925400142251
Epoch: 21 Idx: 5000 Loss: 0.008118954672002764
Epoch: 22 Idx: 0 Loss: 0.01844942941224288
Epoch: 22 Idx: 5000 Loss: 0.02732845486270996
Epoch: 23 Idx: 0 Loss: 0.014596241401408508
Epoch: 23 Idx: 5000 Loss: 0.016198090348014317
Epoch: 24 Idx: 0 Loss: 0.010898747998976584
Epoch: 24 Idx: 5000 Loss: 0.04183975855467956
Epoch: 25 Idx: 0 Loss: 0.022114332669521806
Epoch: 25 Idx: 5000 Loss: 0.00958967303660006
Epoch: 26 Idx: 0 Loss: 0.01300467446100727
Epoch: 26 Idx: 5000 Loss: 0.018540902898984437
Epoch: 27 Idx: 0 Loss: 0.01982729340598039
Epoch: 27 Idx: 5000 Loss: 0.016758791366532737
Epoch: 28 Idx: 0 Loss: 0.01646714607329566
Epoch: 28 Idx: 5000 Loss: 0.016810281084324516
Epoch: 29 Idx: 0 Loss: 0.019760588533159925
Epoch: 29 Idx: 5000 Loss: 0.010077213262426488
Epoch: 30 Idx: 0 Loss: 0.007641853145661073
Epoch: 30 Idx: 5000 Loss: 0.010774853562573211
Epoch: 31 Idx: 0 Loss: 0.027149277110254503
Epoch: 31 Idx: 5000 Loss: 0.026294513963059738
Epoch: 32 Idx: 0 Loss: 0.011724791583946383
Epoch: 32 Idx: 5000 Loss: 0.010253599040794703
Epoch: 33 Idx: 0 Loss: 0.009306304953977714
Epoch: 33 Idx: 5000 Loss: 0.023631757462056757
Epoch: 34 Idx: 0 Loss: 0.01780121756650092
Epoch: 34 Idx: 5000 Loss: 0.015635676099749748
Epoch: 35 Idx: 0 Loss: 0.01437421531405656
Epoch: 35 Idx: 5000 Loss: 0.015622911445867284
Epoch: 36 Idx: 0 Loss: 0.026665493289565117
Epoch: 36 Idx: 5000 Loss: 0.010939578201828351
Epoch: 37 Idx: 0 Loss: 0.022140725265633016
Epoch: 37 Idx: 5000 Loss: 0.01814731299385986
Epoch: 38 Idx: 0 Loss: 0.02104797591167145
Epoch: 38 Idx: 5000 Loss: 0.013514822759594133
Epoch: 39 Idx: 0 Loss: 0.022154531084092734
Epoch: 39 Idx: 5000 Loss: 0.014238716788234903
Epoch: 40 Idx: 0 Loss: 0.031122979474903077
Epoch: 40 Idx: 5000 Loss: 0.03436062875565752
Epoch: 41 Idx: 0 Loss: 0.011334902568624867
Epoch: 41 Idx: 5000 Loss: 0.010136126748251286
Epoch: 42 Idx: 0 Loss: 0.0273208464950732
Epoch: 42 Idx: 5000 Loss: 0.0293651717113473
Epoch: 43 Idx: 0 Loss: 0.009451725212954174
Epoch: 43 Idx: 5000 Loss: 0.005759213182179549
Epoch: 44 Idx: 0 Loss: 0.017410514080457403
Epoch: 44 Idx: 5000 Loss: 0.03659886058253314
Epoch: 45 Idx: 0 Loss: 0.025554764774307043
Epoch: 45 Idx: 5000 Loss: 0.016597807113990195
Epoch: 46 Idx: 0 Loss: 0.009749795812143296
Epoch: 46 Idx: 5000 Loss: 0.037861566433799454
Epoch: 47 Idx: 0 Loss: 0.0509863704345018
Epoch: 47 Idx: 5000 Loss: 0.018196005775537386
Epoch: 48 Idx: 0 Loss: 0.016285563607906978
Epoch: 48 Idx: 5000 Loss: 0.01753944413074366
Epoch: 49 Idx: 0 Loss: 0.014687646004814136
Epoch: 49 Idx: 5000 Loss: 0.007081392402592711
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.2509051375593171
Epoch: 0 Idx: 5000 Loss: 0.032477844495448716
Epoch: 1 Idx: 0 Loss: 0.012076314584757056
Epoch: 1 Idx: 5000 Loss: 0.020384728949645492
Epoch: 2 Idx: 0 Loss: 0.011658574711582862
Epoch: 2 Idx: 5000 Loss: 0.022049873200889837
Epoch: 3 Idx: 0 Loss: 0.022750615421806362
Epoch: 3 Idx: 5000 Loss: 0.05479926208757051
Epoch: 4 Idx: 0 Loss: 0.014038871680150139
Epoch: 4 Idx: 5000 Loss: 0.015948986457682706
Epoch: 5 Idx: 0 Loss: 0.02781770513963073
Epoch: 5 Idx: 5000 Loss: 0.020514646248774044
Epoch: 6 Idx: 0 Loss: 0.006261418267230714
Epoch: 6 Idx: 5000 Loss: 0.033762057667104335
Epoch: 7 Idx: 0 Loss: 0.007201251454109606
Epoch: 7 Idx: 5000 Loss: 0.019284256660688805
Epoch: 8 Idx: 0 Loss: 0.01525703161261326
Epoch: 8 Idx: 5000 Loss: 0.014544247427297124
Epoch: 9 Idx: 0 Loss: 0.013784478887779368
Epoch: 9 Idx: 5000 Loss: 0.011623389664123516
Epoch: 10 Idx: 0 Loss: 0.018410852629749747
Epoch: 10 Idx: 5000 Loss: 0.010240918398320243
Epoch: 11 Idx: 0 Loss: 0.01722159466918108
Epoch: 11 Idx: 5000 Loss: 0.021838614410668877
Epoch: 12 Idx: 0 Loss: 0.013682987890216436
Epoch: 12 Idx: 5000 Loss: 0.01392112734578769
Epoch: 13 Idx: 0 Loss: 0.010928479041266263
Epoch: 13 Idx: 5000 Loss: 0.014885807241239748
Epoch: 14 Idx: 0 Loss: 0.03143681295833673
Epoch: 14 Idx: 5000 Loss: 0.0156894458283667
Epoch: 15 Idx: 0 Loss: 0.02737441232573885
Epoch: 15 Idx: 5000 Loss: 0.01124454002464727
Epoch: 16 Idx: 0 Loss: 0.007805832209416921
Epoch: 16 Idx: 5000 Loss: 0.017066652282321695
Epoch: 17 Idx: 0 Loss: 0.018346278450811784
Epoch: 17 Idx: 5000 Loss: 0.01260971235166215
Epoch: 18 Idx: 0 Loss: 0.02723076792654712
Epoch: 18 Idx: 5000 Loss: 0.008899800957930984
Epoch: 19 Idx: 0 Loss: 0.007607478382313269
Epoch: 19 Idx: 5000 Loss: 0.007838395998233062
Epoch: 20 Idx: 0 Loss: 0.030893395960857172
Epoch: 20 Idx: 5000 Loss: 0.017183944129441985
Epoch: 21 Idx: 0 Loss: 0.010339396786065205
Epoch: 21 Idx: 5000 Loss: 0.019322620102178868
Epoch: 22 Idx: 0 Loss: 0.014024504646337485
Epoch: 22 Idx: 5000 Loss: 0.013806829798120791
Epoch: 23 Idx: 0 Loss: 0.008999941923158875
Epoch: 23 Idx: 5000 Loss: 0.007933309006691518
Epoch: 24 Idx: 0 Loss: 0.008791118610081899
Epoch: 24 Idx: 5000 Loss: 0.00717004781825485
Epoch: 25 Idx: 0 Loss: 0.010557281407344719
Epoch: 25 Idx: 5000 Loss: 0.009021022029080908
Epoch: 26 Idx: 0 Loss: 0.01789655418502365
Epoch: 26 Idx: 5000 Loss: 0.011607320110065744
Epoch: 27 Idx: 0 Loss: 0.010622835586902201
Epoch: 27 Idx: 5000 Loss: 0.016328627550807256
Epoch: 28 Idx: 0 Loss: 0.025157904965042725
Epoch: 28 Idx: 5000 Loss: 0.01399297140950453
Epoch: 29 Idx: 0 Loss: 0.010464931403200624
Epoch: 29 Idx: 5000 Loss: 0.008041467297235929
Epoch: 30 Idx: 0 Loss: 0.024600418958058683
Epoch: 30 Idx: 5000 Loss: 0.01851924395507933
Epoch: 31 Idx: 0 Loss: 0.02246489041053838
Epoch: 31 Idx: 5000 Loss: 0.005163862239166326
Epoch: 32 Idx: 0 Loss: 0.02887842450763764
Epoch: 32 Idx: 5000 Loss: 0.008149482676385102
Epoch: 33 Idx: 0 Loss: 0.010512640111600257
Epoch: 33 Idx: 5000 Loss: 0.032336636085627715
Epoch: 34 Idx: 0 Loss: 0.03730807323034056
Epoch: 34 Idx: 5000 Loss: 0.03041636722516875
Epoch: 35 Idx: 0 Loss: 0.023052715308366258
Epoch: 35 Idx: 5000 Loss: 0.011135258924929432
Epoch: 36 Idx: 0 Loss: 0.011113557188895114
Epoch: 36 Idx: 5000 Loss: 0.008471925517597598
Epoch: 37 Idx: 0 Loss: 0.008881500728808594
Epoch: 37 Idx: 5000 Loss: 0.011897329259662163
Epoch: 38 Idx: 0 Loss: 0.022167681517904155
Epoch: 38 Idx: 5000 Loss: 0.013992831227900895
Epoch: 39 Idx: 0 Loss: 0.005921777877543643
Epoch: 39 Idx: 5000 Loss: 0.021972347269035224
Epoch: 40 Idx: 0 Loss: 0.022714405889722872
Epoch: 40 Idx: 5000 Loss: 0.013103264935503612
Epoch: 41 Idx: 0 Loss: 0.011192010608882492
Epoch: 41 Idx: 5000 Loss: 0.007721807179706229
Epoch: 42 Idx: 0 Loss: 0.014138975400009022
Epoch: 42 Idx: 5000 Loss: 0.006797825324703279
Epoch: 43 Idx: 0 Loss: 0.010836962395992817
Epoch: 43 Idx: 5000 Loss: 0.009482038378985308
Epoch: 44 Idx: 0 Loss: 0.01065145336043101
Epoch: 44 Idx: 5000 Loss: 0.014373324327565846
Epoch: 45 Idx: 0 Loss: 0.01813617229156997
Epoch: 45 Idx: 5000 Loss: 0.035102797766876505
Epoch: 46 Idx: 0 Loss: 0.020262679045990217
Epoch: 46 Idx: 5000 Loss: 0.006332753362275867
Epoch: 47 Idx: 0 Loss: 0.009980729811551247
Epoch: 47 Idx: 5000 Loss: 0.011179506374792689
Epoch: 48 Idx: 0 Loss: 0.014441965151391551
Epoch: 48 Idx: 5000 Loss: 0.010672958835884198
Epoch: 49 Idx: 0 Loss: 0.006503408020062681
Epoch: 49 Idx: 5000 Loss: 0.01622260348823859
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.20605039399729524
Epoch: 0 Idx: 5000 Loss: 0.020176701513108453
Epoch: 1 Idx: 0 Loss: 0.013940792089367453
Epoch: 1 Idx: 5000 Loss: 0.004698365467172749
Epoch: 2 Idx: 0 Loss: 0.01448235131694526
Epoch: 2 Idx: 5000 Loss: 0.02040783137619469
Epoch: 3 Idx: 0 Loss: 0.015911533623513503
Epoch: 3 Idx: 5000 Loss: 0.007634862329527443
Epoch: 4 Idx: 0 Loss: 0.03215023178373943
Epoch: 4 Idx: 5000 Loss: 0.008978901028005028
Epoch: 5 Idx: 0 Loss: 0.02029755438108248
Epoch: 5 Idx: 5000 Loss: 0.02941182430390681
Epoch: 6 Idx: 0 Loss: 0.023785580384688573
Epoch: 6 Idx: 5000 Loss: 0.022016260128278092
Epoch: 7 Idx: 0 Loss: 0.012027014971479122
Epoch: 7 Idx: 5000 Loss: 0.013184526384196395
Epoch: 8 Idx: 0 Loss: 0.022214715270219725
Epoch: 8 Idx: 5000 Loss: 0.03662967256177596
Epoch: 9 Idx: 0 Loss: 0.013626567721887549
Epoch: 9 Idx: 5000 Loss: 0.013403561138404017
Epoch: 10 Idx: 0 Loss: 0.026029037159452872
Epoch: 10 Idx: 5000 Loss: 0.004753595974278471
Epoch: 11 Idx: 0 Loss: 0.012197672489895046
Epoch: 11 Idx: 5000 Loss: 0.009285028037499286
Epoch: 12 Idx: 0 Loss: 0.012380435504486566
Epoch: 12 Idx: 5000 Loss: 0.016600591601499622
Epoch: 13 Idx: 0 Loss: 0.03609273281870006
Epoch: 13 Idx: 5000 Loss: 0.00887073028162454
Epoch: 14 Idx: 0 Loss: 0.015577351446262683
Epoch: 14 Idx: 5000 Loss: 0.011473079464212289
Epoch: 15 Idx: 0 Loss: 0.020844866529538285
Epoch: 15 Idx: 5000 Loss: 0.027865066474972222
Epoch: 16 Idx: 0 Loss: 0.012149297310976944
Epoch: 16 Idx: 5000 Loss: 0.019541858235412504
Epoch: 17 Idx: 0 Loss: 0.011813711014211681
Epoch: 17 Idx: 5000 Loss: 0.011880866437373537
Epoch: 18 Idx: 0 Loss: 0.036180820367528344
Epoch: 18 Idx: 5000 Loss: 0.027212630192202856
Epoch: 19 Idx: 0 Loss: 0.005799193627893347
Epoch: 19 Idx: 5000 Loss: 0.015982305837303326
Epoch: 20 Idx: 0 Loss: 0.011590825450931916
Epoch: 20 Idx: 5000 Loss: 0.020580911959791
Epoch: 21 Idx: 0 Loss: 0.021122335390117264
Epoch: 21 Idx: 5000 Loss: 0.005622043327355015
Epoch: 22 Idx: 0 Loss: 0.009136420141563344
Epoch: 22 Idx: 5000 Loss: 0.009172133861753527
Epoch: 23 Idx: 0 Loss: 0.020757191914845395
Epoch: 23 Idx: 5000 Loss: 0.02093585401406471
Epoch: 24 Idx: 0 Loss: 0.026695363347577543
Epoch: 24 Idx: 5000 Loss: 0.015525995925110222
Epoch: 25 Idx: 0 Loss: 0.0402606316875352
Epoch: 25 Idx: 5000 Loss: 0.026457290288163522
Epoch: 26 Idx: 0 Loss: 0.02415120281308671
Epoch: 26 Idx: 5000 Loss: 0.016177279106288345
Epoch: 27 Idx: 0 Loss: 0.005580998032153042
Epoch: 27 Idx: 5000 Loss: 0.028989790456046785
Epoch: 28 Idx: 0 Loss: 0.011417355568159754
Epoch: 28 Idx: 5000 Loss: 0.008589919304464035
Epoch: 29 Idx: 0 Loss: 0.0054499345413469855
Epoch: 29 Idx: 5000 Loss: 0.012381860967815836
Epoch: 30 Idx: 0 Loss: 0.025244260846811903
Epoch: 30 Idx: 5000 Loss: 0.009929319702102575
Epoch: 31 Idx: 0 Loss: 0.00841059433053391
Epoch: 31 Idx: 5000 Loss: 0.018483493066678777
Epoch: 32 Idx: 0 Loss: 0.03216189152176413
Epoch: 32 Idx: 5000 Loss: 0.020120055890915194
Epoch: 33 Idx: 0 Loss: 0.007320101723856626
Epoch: 33 Idx: 5000 Loss: 0.012796304966224631
Epoch: 34 Idx: 0 Loss: 0.014028556057316295
Epoch: 34 Idx: 5000 Loss: 0.027471463313157224
Epoch: 35 Idx: 0 Loss: 0.01968333761378864
Epoch: 35 Idx: 5000 Loss: 0.015001898887931008
Epoch: 36 Idx: 0 Loss: 0.01330660590560387
Epoch: 36 Idx: 5000 Loss: 0.009629259268237001
Epoch: 37 Idx: 0 Loss: 0.011314028287019079
Epoch: 37 Idx: 5000 Loss: 0.016184534206374054
Epoch: 38 Idx: 0 Loss: 0.027439007268699005
Epoch: 38 Idx: 5000 Loss: 0.02392418729160647
Epoch: 39 Idx: 0 Loss: 0.012441639293775418
Epoch: 39 Idx: 5000 Loss: 0.028711976042342553
Epoch: 40 Idx: 0 Loss: 0.011197853380117582
Epoch: 40 Idx: 5000 Loss: 0.010728907029634466
Epoch: 41 Idx: 0 Loss: 0.029278105360759643
Epoch: 41 Idx: 5000 Loss: 0.026460438286808646
Epoch: 42 Idx: 0 Loss: 0.012267218599176666
Epoch: 42 Idx: 5000 Loss: 0.007376521368867286
Epoch: 43 Idx: 0 Loss: 0.028738622536718925
Epoch: 43 Idx: 5000 Loss: 0.023739337032999294
Epoch: 44 Idx: 0 Loss: 0.016901051208766407
Epoch: 44 Idx: 5000 Loss: 0.014608901891253991
Epoch: 45 Idx: 0 Loss: 0.030228714099793927
Epoch: 45 Idx: 5000 Loss: 0.009518666946922896
Epoch: 46 Idx: 0 Loss: 0.021275437273180604
Epoch: 46 Idx: 5000 Loss: 0.009647749770402276
Epoch: 47 Idx: 0 Loss: 0.03975627888521538
Epoch: 47 Idx: 5000 Loss: 0.021804115044157822
Epoch: 48 Idx: 0 Loss: 0.01923083025498959
Epoch: 48 Idx: 5000 Loss: 0.009473937503560344
Epoch: 49 Idx: 0 Loss: 0.02152117385301121
Epoch: 49 Idx: 5000 Loss: 0.02358416730517327
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.21497743070014408
Epoch: 0 Idx: 5000 Loss: 0.02001107599570463
Epoch: 1 Idx: 0 Loss: 0.007243517249101376
Epoch: 1 Idx: 5000 Loss: 0.01283640001245085
Epoch: 2 Idx: 0 Loss: 0.027689147121494416
Epoch: 2 Idx: 5000 Loss: 0.01587547597308087
Epoch: 3 Idx: 0 Loss: 0.006268306009579515
Epoch: 3 Idx: 5000 Loss: 0.00584608906190291
Epoch: 4 Idx: 0 Loss: 0.01620252930630934
Epoch: 4 Idx: 5000 Loss: 0.012411069425892943
Epoch: 5 Idx: 0 Loss: 0.011453066634075934
Epoch: 5 Idx: 5000 Loss: 0.021303772339560496
Epoch: 6 Idx: 0 Loss: 0.012919454209338866
Epoch: 6 Idx: 5000 Loss: 0.03782647270835052
Epoch: 7 Idx: 0 Loss: 0.014336953951160622
Epoch: 7 Idx: 5000 Loss: 0.013011692304958505
Epoch: 8 Idx: 0 Loss: 0.018517590046708842
Epoch: 8 Idx: 5000 Loss: 0.012631972084848415
Epoch: 9 Idx: 0 Loss: 0.008147146386138093
Epoch: 9 Idx: 5000 Loss: 0.008346962656789613
Epoch: 10 Idx: 0 Loss: 0.017034406411455507
Epoch: 10 Idx: 5000 Loss: 0.01126828493385438
Epoch: 11 Idx: 0 Loss: 0.010467176578765496
Epoch: 11 Idx: 5000 Loss: 0.03029633225483386
Epoch: 12 Idx: 0 Loss: 0.01854669042889718
Epoch: 12 Idx: 5000 Loss: 0.017313738108390847
Epoch: 13 Idx: 0 Loss: 0.010297589910486783
Epoch: 13 Idx: 5000 Loss: 0.004212435837657197
Epoch: 14 Idx: 0 Loss: 0.025727573742629958
Epoch: 14 Idx: 5000 Loss: 0.03509812769744658
Epoch: 15 Idx: 0 Loss: 0.011626416137859221
Epoch: 15 Idx: 5000 Loss: 0.012870347503273283
Epoch: 16 Idx: 0 Loss: 0.008732673784706737
Epoch: 16 Idx: 5000 Loss: 0.016054410754638485
Epoch: 17 Idx: 0 Loss: 0.02566186673225535
Epoch: 17 Idx: 5000 Loss: 0.028341089871983964
Epoch: 18 Idx: 0 Loss: 0.028308591005171354
Epoch: 18 Idx: 5000 Loss: 0.023565666630802264
Epoch: 19 Idx: 0 Loss: 0.019985152625342565
Epoch: 19 Idx: 5000 Loss: 0.008139859443764655
Epoch: 20 Idx: 0 Loss: 0.021450954227683602
Epoch: 20 Idx: 5000 Loss: 0.01766455609780885
Epoch: 21 Idx: 0 Loss: 0.016697146275908424
Epoch: 21 Idx: 5000 Loss: 0.02611276395659292
Epoch: 22 Idx: 0 Loss: 0.018505935287461524
Epoch: 22 Idx: 5000 Loss: 0.011211887568052456
Epoch: 23 Idx: 0 Loss: 0.0121354969712694
Epoch: 23 Idx: 5000 Loss: 0.0205876998662718
Epoch: 24 Idx: 0 Loss: 0.01424779893422986
Epoch: 24 Idx: 5000 Loss: 0.00978569397110068
Epoch: 25 Idx: 0 Loss: 0.011300368958044364
Epoch: 25 Idx: 5000 Loss: 0.03562659886962117
Epoch: 26 Idx: 0 Loss: 0.01428870829405125
Epoch: 26 Idx: 5000 Loss: 0.012269432329904243
Epoch: 27 Idx: 0 Loss: 0.022568328977159106
Epoch: 27 Idx: 5000 Loss: 0.0035356684761899053
Epoch: 28 Idx: 0 Loss: 0.01087230940652789
Epoch: 28 Idx: 5000 Loss: 0.020823248105703067
Epoch: 29 Idx: 0 Loss: 0.006160984551996898
Epoch: 29 Idx: 5000 Loss: 0.019927975283394204
Epoch: 30 Idx: 0 Loss: 0.016724291162220985
Epoch: 30 Idx: 5000 Loss: 0.0339432905227375
Epoch: 31 Idx: 0 Loss: 0.005767899395122774
Epoch: 31 Idx: 5000 Loss: 0.008374127029695137
Epoch: 32 Idx: 0 Loss: 0.007741827286707925
Epoch: 32 Idx: 5000 Loss: 0.016333046752076474
Epoch: 33 Idx: 0 Loss: 0.013731804273725202
Epoch: 33 Idx: 5000 Loss: 0.02183425649733218
Epoch: 34 Idx: 0 Loss: 0.032268453950488656
Epoch: 34 Idx: 5000 Loss: 0.012051016366686075
Epoch: 35 Idx: 0 Loss: 0.007021878004377896
Epoch: 35 Idx: 5000 Loss: 0.018398601224400766
Epoch: 36 Idx: 0 Loss: 0.011384189423086197
Epoch: 36 Idx: 5000 Loss: 0.013504046190420404
Epoch: 37 Idx: 0 Loss: 0.006846354733285414
Epoch: 37 Idx: 5000 Loss: 0.009318634119051442
Epoch: 38 Idx: 0 Loss: 0.004852811160219893
Epoch: 38 Idx: 5000 Loss: 0.024178581590209056
Epoch: 39 Idx: 0 Loss: 0.0050318420561118226
Epoch: 39 Idx: 5000 Loss: 0.022599980743925854
Epoch: 40 Idx: 0 Loss: 0.01984771838994907
Epoch: 40 Idx: 5000 Loss: 0.0058059559050251675
Epoch: 41 Idx: 0 Loss: 0.01682515855291742
Epoch: 41 Idx: 5000 Loss: 0.015186036533095174
Epoch: 42 Idx: 0 Loss: 0.007577396604010584
Epoch: 42 Idx: 5000 Loss: 0.03597853088336393
Epoch: 43 Idx: 0 Loss: 0.009159155083654131
Epoch: 43 Idx: 5000 Loss: 0.018916953466748723
Epoch: 44 Idx: 0 Loss: 0.01130665272699723
Epoch: 44 Idx: 5000 Loss: 0.018851173854280916
Epoch: 45 Idx: 0 Loss: 0.01760149593577876
Epoch: 45 Idx: 5000 Loss: 0.01379779614371764
Epoch: 46 Idx: 0 Loss: 0.0125958086555326
Epoch: 46 Idx: 5000 Loss: 0.01049565131654047
Epoch: 47 Idx: 0 Loss: 0.01723725565225148
Epoch: 47 Idx: 5000 Loss: 0.015038048673645363
Epoch: 48 Idx: 0 Loss: 0.016143777001589033
Epoch: 48 Idx: 5000 Loss: 0.0215296234331701
Epoch: 49 Idx: 0 Loss: 0.023914775395547566
Epoch: 49 Idx: 5000 Loss: 0.04105397828576806
Len (direct inputs):  1690
Inputs len 10074 10 11464
Len (direct inputs):  1400
Starting sliding window evaluation...
Step 12/7
Val onto:  [('conference', 'iasted')] test_onto:  [('confof', 'edas')]
Training size: 104813 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.18604712656406752
Traceback (most recent call last):
  File "main.py", line 518, in <module>
    optimizer.step()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/adam.py", line 107, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc222>
Subject: Job 4066853: <python main.py 5 6 False False> in cluster <dcc> Exited

Job <python main.py 5 6 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc222>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 6 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46189.25 sec.
    Max Memory :                                 2915 MB
    Average Memory :                             2761.00 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40502.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46198 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

