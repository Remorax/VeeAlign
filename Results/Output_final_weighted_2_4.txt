2020-09-15 15:48:42.563008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.818345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.935812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.935910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.938248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.963670: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.997447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.044063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.066516: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.067067: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.067092: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.067559: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.110741: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600015000 Hz
2020-09-15 15:48:50.111065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617ffedcc10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.111087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.114331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.114393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20067440859121227
Epoch: 0 Idx: 5000 Loss: 0.0226421944448301
Epoch: 1 Idx: 0 Loss: 0.03329688463987784
Epoch: 1 Idx: 5000 Loss: 0.04067872938188706
Epoch: 2 Idx: 0 Loss: 0.012864369071305611
Epoch: 2 Idx: 5000 Loss: 0.008815379992702821
Epoch: 3 Idx: 0 Loss: 0.012490925051328847
Epoch: 3 Idx: 5000 Loss: 0.02071042200180451
Epoch: 4 Idx: 0 Loss: 0.010659373998013182
Epoch: 4 Idx: 5000 Loss: 0.009843029931961494
Epoch: 5 Idx: 0 Loss: 0.016959185222434406
Epoch: 5 Idx: 5000 Loss: 0.010045092654503634
Epoch: 6 Idx: 0 Loss: 0.01010365007017959
Epoch: 6 Idx: 5000 Loss: 0.03193515283855128
Epoch: 7 Idx: 0 Loss: 0.010212256475098427
Epoch: 7 Idx: 5000 Loss: 0.012024779904760998
Epoch: 8 Idx: 0 Loss: 0.01712860733445541
Epoch: 8 Idx: 5000 Loss: 0.0160156082440175
Epoch: 9 Idx: 0 Loss: 0.02046788553807531
Epoch: 9 Idx: 5000 Loss: 0.008871019235597497
Epoch: 10 Idx: 0 Loss: 0.014288236338976537
Epoch: 10 Idx: 5000 Loss: 0.022959622905670735
Epoch: 11 Idx: 0 Loss: 0.011075439569521655
Epoch: 11 Idx: 5000 Loss: 0.014467787175831474
Epoch: 12 Idx: 0 Loss: 0.015314603482332368
Epoch: 12 Idx: 5000 Loss: 0.010299524992327051
Epoch: 13 Idx: 0 Loss: 0.007420910996833362
Epoch: 13 Idx: 5000 Loss: 0.01648032190546537
Epoch: 14 Idx: 0 Loss: 0.019583223375153017
Epoch: 14 Idx: 5000 Loss: 0.01608593779531153
Epoch: 15 Idx: 0 Loss: 0.011270913301287893
Epoch: 15 Idx: 5000 Loss: 0.02476579854500715
Epoch: 16 Idx: 0 Loss: 0.007705970547991333
Epoch: 16 Idx: 5000 Loss: 0.019073749921163605
Epoch: 17 Idx: 0 Loss: 0.02296271628453854
Epoch: 17 Idx: 5000 Loss: 0.023620799532122417
Epoch: 18 Idx: 0 Loss: 0.01186036640801023
Epoch: 18 Idx: 5000 Loss: 0.007751050961731492
Epoch: 19 Idx: 0 Loss: 0.015636198750518998
Epoch: 19 Idx: 5000 Loss: 0.015275339601472676
Epoch: 20 Idx: 0 Loss: 0.006434986173209909
Epoch: 20 Idx: 5000 Loss: 0.009653508786584055
Epoch: 21 Idx: 0 Loss: 0.013608688227509404
Epoch: 21 Idx: 5000 Loss: 0.009726930897857254
Epoch: 22 Idx: 0 Loss: 0.019746263090663255
Epoch: 22 Idx: 5000 Loss: 0.02524573178670782
Epoch: 23 Idx: 0 Loss: 0.011776858559842802
Epoch: 23 Idx: 5000 Loss: 0.01035483780538877
Epoch: 24 Idx: 0 Loss: 0.015941881195240457
Epoch: 24 Idx: 5000 Loss: 0.018327734435318647
Epoch: 25 Idx: 0 Loss: 0.02410070531908276
Epoch: 25 Idx: 5000 Loss: 0.030237106755671553
Epoch: 26 Idx: 0 Loss: 0.014223737298962955
Epoch: 26 Idx: 5000 Loss: 0.007808553971418235
Epoch: 27 Idx: 0 Loss: 0.011019013477279165
Epoch: 27 Idx: 5000 Loss: 0.03347554494695562
Epoch: 28 Idx: 0 Loss: 0.022353219732268247
Epoch: 28 Idx: 5000 Loss: 0.03285582756578709
Epoch: 29 Idx: 0 Loss: 0.017007438272671316
Epoch: 29 Idx: 5000 Loss: 0.008702258308242878
Epoch: 30 Idx: 0 Loss: 0.060367605446485784
Epoch: 30 Idx: 5000 Loss: 0.005749978733549229
Epoch: 31 Idx: 0 Loss: 0.015227971913095075
Epoch: 31 Idx: 5000 Loss: 0.017362353955692498
Epoch: 32 Idx: 0 Loss: 0.030820385908740897
Epoch: 32 Idx: 5000 Loss: 0.018053156292792562
Epoch: 33 Idx: 0 Loss: 0.02125132437822212
Epoch: 33 Idx: 5000 Loss: 0.015577959784891938
Epoch: 34 Idx: 0 Loss: 0.015980559796265018
Epoch: 34 Idx: 5000 Loss: 0.01011983602820576
Epoch: 35 Idx: 0 Loss: 0.01131243856778316
Epoch: 35 Idx: 5000 Loss: 0.017935794921293234
Epoch: 36 Idx: 0 Loss: 0.018510712845295728
Epoch: 36 Idx: 5000 Loss: 0.006120931378272048
Epoch: 37 Idx: 0 Loss: 0.011976808626750546
Epoch: 37 Idx: 5000 Loss: 0.016554054962717373
Epoch: 38 Idx: 0 Loss: 0.008829925995703035
Epoch: 38 Idx: 5000 Loss: 0.02763027754477465
Epoch: 39 Idx: 0 Loss: 0.027151047571936777
Epoch: 39 Idx: 5000 Loss: 0.006969291229866939
Epoch: 40 Idx: 0 Loss: 0.009945983401736889
Epoch: 40 Idx: 5000 Loss: 0.008972175567002005
Epoch: 41 Idx: 0 Loss: 0.01014724634438766
Epoch: 41 Idx: 5000 Loss: 0.011328148107281662
Epoch: 42 Idx: 0 Loss: 0.006264772564098218
Epoch: 42 Idx: 5000 Loss: 0.011226128319190039
Epoch: 43 Idx: 0 Loss: 0.017705736452602264
Epoch: 43 Idx: 5000 Loss: 0.014215164811442306
Epoch: 44 Idx: 0 Loss: 0.012191343818278551
Epoch: 44 Idx: 5000 Loss: 0.019259226080278205
Epoch: 45 Idx: 0 Loss: 0.014677885453758394
Epoch: 45 Idx: 5000 Loss: 0.010029062024892392
Epoch: 46 Idx: 0 Loss: 0.009531588253518707
Epoch: 46 Idx: 5000 Loss: 0.006994371614862842
Epoch: 47 Idx: 0 Loss: 0.01585085872275217
Epoch: 47 Idx: 5000 Loss: 0.010676035927602308
Epoch: 48 Idx: 0 Loss: 0.02001509455426705
Epoch: 48 Idx: 5000 Loss: 0.011223916635121695
Epoch: 49 Idx: 0 Loss: 0.024257294559726285
Epoch: 49 Idx: 5000 Loss: 0.014188883368125974
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.13907943749348192
Epoch: 0 Idx: 5000 Loss: 0.010776836533823912
Epoch: 1 Idx: 0 Loss: 0.009496393103121153
Epoch: 1 Idx: 5000 Loss: 0.028372019840893464
Epoch: 2 Idx: 0 Loss: 0.021255105291685478
Epoch: 2 Idx: 5000 Loss: 0.009867105015407402
Epoch: 3 Idx: 0 Loss: 0.009774466492499268
Epoch: 3 Idx: 5000 Loss: 0.00824586514789261
Epoch: 4 Idx: 0 Loss: 0.00609835018702851
Epoch: 4 Idx: 5000 Loss: 0.012297421677826523
Epoch: 5 Idx: 0 Loss: 0.014379181911925984
Epoch: 5 Idx: 5000 Loss: 0.031441989197089376
Epoch: 6 Idx: 0 Loss: 0.008224964713239578
Epoch: 6 Idx: 5000 Loss: 0.008353663832866913
Epoch: 7 Idx: 0 Loss: 0.009657671330252578
Epoch: 7 Idx: 5000 Loss: 0.02060146728746625
Epoch: 8 Idx: 0 Loss: 0.0129977663722342
Epoch: 8 Idx: 5000 Loss: 0.010703530514488642
Epoch: 9 Idx: 0 Loss: 0.006455161524343005
Epoch: 9 Idx: 5000 Loss: 0.013669061616153637
Epoch: 10 Idx: 0 Loss: 0.018456112980603782
Epoch: 10 Idx: 5000 Loss: 0.008606387747662224
Epoch: 11 Idx: 0 Loss: 0.027313512530212164
Epoch: 11 Idx: 5000 Loss: 0.013113931000469616
Epoch: 12 Idx: 0 Loss: 0.022824854775806713
Epoch: 12 Idx: 5000 Loss: 0.01799587798350963
Epoch: 13 Idx: 0 Loss: 0.016297952207915956
Epoch: 13 Idx: 5000 Loss: 0.016109380189738363
Epoch: 14 Idx: 0 Loss: 0.011360617585516762
Epoch: 14 Idx: 5000 Loss: 0.01886677951281597
Epoch: 15 Idx: 0 Loss: 0.006576816937576462
Epoch: 15 Idx: 5000 Loss: 0.011931024045391645
Epoch: 16 Idx: 0 Loss: 0.023631991329424937
Epoch: 16 Idx: 5000 Loss: 0.02568729613462474
Epoch: 17 Idx: 0 Loss: 0.006242315759101852
Epoch: 17 Idx: 5000 Loss: 0.010738719832658929
Epoch: 18 Idx: 0 Loss: 0.017275268888543978
Epoch: 18 Idx: 5000 Loss: 0.015023100190682223
Epoch: 19 Idx: 0 Loss: 0.04450146096422249
Epoch: 19 Idx: 5000 Loss: 0.004185190554384548
Epoch: 20 Idx: 0 Loss: 0.016684909219122725
Epoch: 20 Idx: 5000 Loss: 0.018756303708829386
Epoch: 21 Idx: 0 Loss: 0.009039137592010886
Epoch: 21 Idx: 5000 Loss: 0.028332018274681715
Epoch: 22 Idx: 0 Loss: 0.0076269726407511805
Epoch: 22 Idx: 5000 Loss: 0.009401564859645734
Epoch: 23 Idx: 0 Loss: 0.013300643778954332
Epoch: 23 Idx: 5000 Loss: 0.015973547086366762
Epoch: 24 Idx: 0 Loss: 0.011347416280465827
Epoch: 24 Idx: 5000 Loss: 0.027057959980994424
Epoch: 25 Idx: 0 Loss: 0.013832541399959168
Epoch: 25 Idx: 5000 Loss: 0.006449523074238031
Epoch: 26 Idx: 0 Loss: 0.015136614633741743
Epoch: 26 Idx: 5000 Loss: 0.022161757143023268
Epoch: 27 Idx: 0 Loss: 0.017146290324863353
Epoch: 27 Idx: 5000 Loss: 0.01723832413230999
Epoch: 28 Idx: 0 Loss: 0.023010747219659546
Epoch: 28 Idx: 5000 Loss: 0.005427834663070986
Epoch: 29 Idx: 0 Loss: 0.02990100810557415
Epoch: 29 Idx: 5000 Loss: 0.024760120910742218
Epoch: 30 Idx: 0 Loss: 0.02305695078609375
Epoch: 30 Idx: 5000 Loss: 0.009102910039156354
Epoch: 31 Idx: 0 Loss: 0.018115169104214183
Epoch: 31 Idx: 5000 Loss: 0.015057772448359253
Epoch: 32 Idx: 0 Loss: 0.020546933608359692
Epoch: 32 Idx: 5000 Loss: 0.008947485115308466
Epoch: 33 Idx: 0 Loss: 0.009431724353381745
Epoch: 33 Idx: 5000 Loss: 0.008185874656904298
Epoch: 34 Idx: 0 Loss: 0.012479798415862626
Epoch: 34 Idx: 5000 Loss: 0.019325981132068532
Epoch: 35 Idx: 0 Loss: 0.007859662196371738
Epoch: 35 Idx: 5000 Loss: 0.01887767771421585
Epoch: 36 Idx: 0 Loss: 0.01298591900874878
Epoch: 36 Idx: 5000 Loss: 0.011287270179009743
Epoch: 37 Idx: 0 Loss: 0.02060460721501452
Epoch: 37 Idx: 5000 Loss: 0.016587646978448455
Epoch: 38 Idx: 0 Loss: 0.007461408962910158
Epoch: 38 Idx: 5000 Loss: 0.009102564988206057
Epoch: 39 Idx: 0 Loss: 0.009813049448182943
Epoch: 39 Idx: 5000 Loss: 0.02114062063884834
Epoch: 40 Idx: 0 Loss: 0.008362181260187345
Epoch: 40 Idx: 5000 Loss: 0.023753271521580386
Epoch: 41 Idx: 0 Loss: 0.026187175811795204
Epoch: 41 Idx: 5000 Loss: 0.008959984664930013
Epoch: 42 Idx: 0 Loss: 0.014158057190012802
Epoch: 42 Idx: 5000 Loss: 0.059334999926789214
Epoch: 43 Idx: 0 Loss: 0.01140852363535851
Epoch: 43 Idx: 5000 Loss: 0.029515745609090774
Epoch: 44 Idx: 0 Loss: 0.010241107168530543
Epoch: 44 Idx: 5000 Loss: 0.015961680178558226
Epoch: 45 Idx: 0 Loss: 0.006359656129241536
Epoch: 45 Idx: 5000 Loss: 0.013051424242751393
Epoch: 46 Idx: 0 Loss: 0.00817491352201661
Epoch: 46 Idx: 5000 Loss: 0.023780821598655136
Epoch: 47 Idx: 0 Loss: 0.01297921110770603
Epoch: 47 Idx: 5000 Loss: 0.011801279292624374
Epoch: 48 Idx: 0 Loss: 0.03930818431444082
Epoch: 48 Idx: 5000 Loss: 0.027416574069590582
Epoch: 49 Idx: 0 Loss: 0.014197569453460927
Epoch: 49 Idx: 5000 Loss: 0.013696419065294075
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14036730216411147
Epoch: 0 Idx: 5000 Loss: 0.009445282448241176
Epoch: 1 Idx: 0 Loss: 0.01654805255609798
Epoch: 1 Idx: 5000 Loss: 0.006781517418849417
Epoch: 2 Idx: 0 Loss: 0.020340139383478548
Epoch: 2 Idx: 5000 Loss: 0.01312889847342459
Epoch: 3 Idx: 0 Loss: 0.012187173754262013
Epoch: 3 Idx: 5000 Loss: 0.013656097529502594
Epoch: 4 Idx: 0 Loss: 0.035161831485115085
Epoch: 4 Idx: 5000 Loss: 0.01182333177671857
Epoch: 5 Idx: 0 Loss: 0.01999064991010347
Epoch: 5 Idx: 5000 Loss: 0.009013139562592474
Epoch: 6 Idx: 0 Loss: 0.0068824682341816325
Epoch: 6 Idx: 5000 Loss: 0.018830093889643868
Epoch: 7 Idx: 0 Loss: 0.01276019218075342
Epoch: 7 Idx: 5000 Loss: 0.015056628365769
Epoch: 8 Idx: 0 Loss: 0.003580335880857258
Epoch: 8 Idx: 5000 Loss: 0.010664373975213973
Epoch: 9 Idx: 0 Loss: 0.014235174685800937
Epoch: 9 Idx: 5000 Loss: 0.012696560158464602
Epoch: 10 Idx: 0 Loss: 0.014713766851447556
Epoch: 10 Idx: 5000 Loss: 0.014557207800969533
Epoch: 11 Idx: 0 Loss: 0.013007117752619262
Epoch: 11 Idx: 5000 Loss: 0.019466878371922573
Epoch: 12 Idx: 0 Loss: 0.016937534564247354
Epoch: 12 Idx: 5000 Loss: 0.01908560508092562
Epoch: 13 Idx: 0 Loss: 0.010625569550106358
Epoch: 13 Idx: 5000 Loss: 0.03307707324642051
Epoch: 14 Idx: 0 Loss: 0.014803456840988532
Epoch: 14 Idx: 5000 Loss: 0.007800157559902064
Epoch: 15 Idx: 0 Loss: 0.008437719342163346
Epoch: 15 Idx: 5000 Loss: 0.00980809431444614
Epoch: 16 Idx: 0 Loss: 0.014642584481308809
Epoch: 16 Idx: 5000 Loss: 0.012173052074627027
Epoch: 17 Idx: 0 Loss: 0.040409938262403564
Epoch: 17 Idx: 5000 Loss: 0.011410705945402468
Epoch: 18 Idx: 0 Loss: 0.017297737521442806
Epoch: 18 Idx: 5000 Loss: 0.009003064294108696
Epoch: 19 Idx: 0 Loss: 0.02199637213488417
Epoch: 19 Idx: 5000 Loss: 0.0159234543890062
Epoch: 20 Idx: 0 Loss: 0.004615030935326207
Epoch: 20 Idx: 5000 Loss: 0.011983211565078821
Epoch: 21 Idx: 0 Loss: 0.004910691755706001
Epoch: 21 Idx: 5000 Loss: 0.01054284750350928
Epoch: 22 Idx: 0 Loss: 0.022143766168334796
Epoch: 22 Idx: 5000 Loss: 0.01834401550707632
Epoch: 23 Idx: 0 Loss: 0.01946640394632028
Epoch: 23 Idx: 5000 Loss: 0.013590901942597478
Epoch: 24 Idx: 0 Loss: 0.01763297998588798
Epoch: 24 Idx: 5000 Loss: 0.013763912746376865
Epoch: 25 Idx: 0 Loss: 0.013315089110391358
Epoch: 25 Idx: 5000 Loss: 0.03832112943099292
Epoch: 26 Idx: 0 Loss: 0.020979065410748364
Epoch: 26 Idx: 5000 Loss: 0.019866149136758847
Epoch: 27 Idx: 0 Loss: 0.017876393147258782
Epoch: 27 Idx: 5000 Loss: 0.0071589857231090315
Epoch: 28 Idx: 0 Loss: 0.011528979226338887
Epoch: 28 Idx: 5000 Loss: 0.020452017301224715
Epoch: 29 Idx: 0 Loss: 0.01717850801259909
Epoch: 29 Idx: 5000 Loss: 0.007422723635333962
Epoch: 30 Idx: 0 Loss: 0.02952239182976623
Epoch: 30 Idx: 5000 Loss: 0.010384889891222888
Epoch: 31 Idx: 0 Loss: 0.012066203643669848
Epoch: 31 Idx: 5000 Loss: 0.012554054217585361
Epoch: 32 Idx: 0 Loss: 0.0045050082751102154
Epoch: 32 Idx: 5000 Loss: 0.023058595306710894
Epoch: 33 Idx: 0 Loss: 0.004548461067080012
Epoch: 33 Idx: 5000 Loss: 0.014528233419640931
Epoch: 34 Idx: 0 Loss: 0.014915561951927886
Epoch: 34 Idx: 5000 Loss: 0.016351460762592373
Epoch: 35 Idx: 0 Loss: 0.015886047941878853
Epoch: 35 Idx: 5000 Loss: 0.008194612220011006
Epoch: 36 Idx: 0 Loss: 0.008423308693356679
Epoch: 36 Idx: 5000 Loss: 0.01726596491919343
Epoch: 37 Idx: 0 Loss: 0.036857305589587074
Epoch: 37 Idx: 5000 Loss: 0.007839219730339759
Epoch: 38 Idx: 0 Loss: 0.010730283099642884
Epoch: 38 Idx: 5000 Loss: 0.013820873784870472
Epoch: 39 Idx: 0 Loss: 0.01132979861705586
Epoch: 39 Idx: 5000 Loss: 0.010821528526652635
Epoch: 40 Idx: 0 Loss: 0.014047113121970328
Epoch: 40 Idx: 5000 Loss: 0.011447284900903383
Epoch: 41 Idx: 0 Loss: 0.013858921931232027
Epoch: 41 Idx: 5000 Loss: 0.014572439925890234
Epoch: 42 Idx: 0 Loss: 0.02623736618581001
Epoch: 42 Idx: 5000 Loss: 0.013465939318617436
Epoch: 43 Idx: 0 Loss: 0.004506401724320559
Epoch: 43 Idx: 5000 Loss: 0.007251454353149141
Epoch: 44 Idx: 0 Loss: 0.02391198658096097
Epoch: 44 Idx: 5000 Loss: 0.013199673191899037
Epoch: 45 Idx: 0 Loss: 0.01817474281964721
Epoch: 45 Idx: 5000 Loss: 0.018105700075680027
Epoch: 46 Idx: 0 Loss: 0.011216044401639641
Epoch: 46 Idx: 5000 Loss: 0.01693038530051617
Epoch: 47 Idx: 0 Loss: 0.026876478336723474
Epoch: 47 Idx: 5000 Loss: 0.026458978036309887
Epoch: 48 Idx: 0 Loss: 0.009188765649473525
Epoch: 48 Idx: 5000 Loss: 0.01473337900085037
Epoch: 49 Idx: 0 Loss: 0.015735968521920125
Epoch: 49 Idx: 5000 Loss: 0.005681779313172132
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.22049473711740764
Epoch: 0 Idx: 5000 Loss: 0.02879641085999628
Epoch: 1 Idx: 0 Loss: 0.014145038094397447
Epoch: 1 Idx: 5000 Loss: 0.021491012595913926
Epoch: 2 Idx: 0 Loss: 0.012096125449615837
Epoch: 2 Idx: 5000 Loss: 0.027938436586725658
Epoch: 3 Idx: 0 Loss: 0.012617640027149256
Epoch: 3 Idx: 5000 Loss: 0.018296453119315593
Epoch: 4 Idx: 0 Loss: 0.019875318965652117
Epoch: 4 Idx: 5000 Loss: 0.009332963504119426
Epoch: 5 Idx: 0 Loss: 0.022836083691443923
Epoch: 5 Idx: 5000 Loss: 0.010873821631416283
Epoch: 6 Idx: 0 Loss: 0.02630783953243042
Epoch: 6 Idx: 5000 Loss: 0.01349539551709218
Epoch: 7 Idx: 0 Loss: 0.015881156449353746
Epoch: 7 Idx: 5000 Loss: 0.012892805084322757
Epoch: 8 Idx: 0 Loss: 0.040883056065314505
Epoch: 8 Idx: 5000 Loss: 0.0126824913127586
Epoch: 9 Idx: 0 Loss: 0.009657775240158137
Epoch: 9 Idx: 5000 Loss: 0.008325297255509014
Epoch: 10 Idx: 0 Loss: 0.01060021799863637
Epoch: 10 Idx: 5000 Loss: 0.008413235812792796
Epoch: 11 Idx: 0 Loss: 0.01457323548141037
Epoch: 11 Idx: 5000 Loss: 0.008203852960857308
Epoch: 12 Idx: 0 Loss: 0.012478955520220231
Epoch: 12 Idx: 5000 Loss: 0.02233370909164014
Epoch: 13 Idx: 0 Loss: 0.025744171813863397
Epoch: 13 Idx: 5000 Loss: 0.01742399371500683
Epoch: 14 Idx: 0 Loss: 0.011150313020897158
Epoch: 14 Idx: 5000 Loss: 0.008171334615329932
Epoch: 15 Idx: 0 Loss: 0.00977390031158468
Epoch: 15 Idx: 5000 Loss: 0.02488978904138646
Epoch: 16 Idx: 0 Loss: 0.010238725069075796
Epoch: 16 Idx: 5000 Loss: 0.013160379917409835
Epoch: 17 Idx: 0 Loss: 0.014325423647238655
Epoch: 17 Idx: 5000 Loss: 0.04793799946276244
Epoch: 18 Idx: 0 Loss: 0.0265994233458811
Epoch: 18 Idx: 5000 Loss: 0.008324202406233666
Epoch: 19 Idx: 0 Loss: 0.0052481920924099855
Epoch: 19 Idx: 5000 Loss: 0.008313190854490646
Epoch: 20 Idx: 0 Loss: 0.008871213373054956
Epoch: 20 Idx: 5000 Loss: 0.01736994179817762
Epoch: 21 Idx: 0 Loss: 0.02256677586342156
Epoch: 21 Idx: 5000 Loss: 0.017860520599777913
Epoch: 22 Idx: 0 Loss: 0.007207916924890474
Epoch: 22 Idx: 5000 Loss: 0.007209123743672031
Epoch: 23 Idx: 0 Loss: 0.013828380153777709
Epoch: 23 Idx: 5000 Loss: 0.014408322107049048
Epoch: 24 Idx: 0 Loss: 0.022774210967639586
Epoch: 24 Idx: 5000 Loss: 0.006410939415931586
Epoch: 25 Idx: 0 Loss: 0.029165882039036986
Epoch: 25 Idx: 5000 Loss: 0.029103384615869764
Epoch: 26 Idx: 0 Loss: 0.00876412320156001
Epoch: 26 Idx: 5000 Loss: 0.027163710708779293
Epoch: 27 Idx: 0 Loss: 0.0069040434632795565
Epoch: 27 Idx: 5000 Loss: 0.019661414932861377
Epoch: 28 Idx: 0 Loss: 0.02599310240573931
Epoch: 28 Idx: 5000 Loss: 0.00944271368861786
Epoch: 29 Idx: 0 Loss: 0.007217852882187079
Epoch: 29 Idx: 5000 Loss: 0.01802205957411396
Epoch: 30 Idx: 0 Loss: 0.01700231446771441
Epoch: 30 Idx: 5000 Loss: 0.031638935083950055
Epoch: 31 Idx: 0 Loss: 0.02047092213278378
Epoch: 31 Idx: 5000 Loss: 0.011832985367041672
Epoch: 32 Idx: 0 Loss: 0.0352008663065521
Epoch: 32 Idx: 5000 Loss: 0.019830986744899654
Epoch: 33 Idx: 0 Loss: 0.018227185850627072
Epoch: 33 Idx: 5000 Loss: 0.02525687014133779
Epoch: 34 Idx: 0 Loss: 0.019473177656864515
Epoch: 34 Idx: 5000 Loss: 0.02047075556671958
Epoch: 35 Idx: 0 Loss: 0.023790542485609776
Epoch: 35 Idx: 5000 Loss: 0.013024118019044174
Epoch: 36 Idx: 0 Loss: 0.0650346555306214
Epoch: 36 Idx: 5000 Loss: 0.030113880558113364
Epoch: 37 Idx: 0 Loss: 0.023043927194482127
Epoch: 37 Idx: 5000 Loss: 0.025505575520851288
Epoch: 38 Idx: 0 Loss: 0.014319510531520932
Epoch: 38 Idx: 5000 Loss: 0.006794029389312509
Epoch: 39 Idx: 0 Loss: 0.013842825612831287
Epoch: 39 Idx: 5000 Loss: 0.0274241986270547
Epoch: 40 Idx: 0 Loss: 0.016520733410181305
Epoch: 40 Idx: 5000 Loss: 0.020016806155875148
Epoch: 41 Idx: 0 Loss: 0.018742757667569866
Epoch: 41 Idx: 5000 Loss: 0.009260743849348212
Epoch: 42 Idx: 0 Loss: 0.00735363055649404
Epoch: 42 Idx: 5000 Loss: 0.008118853632918244
Epoch: 43 Idx: 0 Loss: 0.017767745897331138
Epoch: 43 Idx: 5000 Loss: 0.02528497664464523
Epoch: 44 Idx: 0 Loss: 0.012560023043546111
Epoch: 44 Idx: 5000 Loss: 0.03167581196478419
Epoch: 45 Idx: 0 Loss: 0.008818401724908604
Epoch: 45 Idx: 5000 Loss: 0.012803187106062094
Epoch: 46 Idx: 0 Loss: 0.02209075032793939
Epoch: 46 Idx: 5000 Loss: 0.01386704485730528
Epoch: 47 Idx: 0 Loss: 0.018540260831872546
Epoch: 47 Idx: 5000 Loss: 0.014940834416974328
Epoch: 48 Idx: 0 Loss: 0.01683366941504531
Epoch: 48 Idx: 5000 Loss: 0.012673345018129828
Epoch: 49 Idx: 0 Loss: 0.017852020333511888
Epoch: 49 Idx: 5000 Loss: 0.00995704208991685
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.19417621739265012
Epoch: 0 Idx: 5000 Loss: 0.017890795058224322
Epoch: 1 Idx: 0 Loss: 0.009581560929811828
Epoch: 1 Idx: 5000 Loss: 0.012652931355750989
Epoch: 2 Idx: 0 Loss: 0.013292367914641222
Epoch: 2 Idx: 5000 Loss: 0.016604583139853517
Epoch: 3 Idx: 0 Loss: 0.00652344393611829
Epoch: 3 Idx: 5000 Loss: 0.012560149542591083
Epoch: 4 Idx: 0 Loss: 0.025990300249837527
Epoch: 4 Idx: 5000 Loss: 0.013982124389121664
Epoch: 5 Idx: 0 Loss: 0.011152363673686619
Epoch: 5 Idx: 5000 Loss: 0.03721214519218998
Epoch: 6 Idx: 0 Loss: 0.014168209044973517
Epoch: 6 Idx: 5000 Loss: 0.006120314165800822
Epoch: 7 Idx: 0 Loss: 0.014729106480608434
Epoch: 7 Idx: 5000 Loss: 0.037859000395380295
Epoch: 8 Idx: 0 Loss: 0.01188730513726924
Epoch: 8 Idx: 5000 Loss: 0.01527804344418289
Epoch: 9 Idx: 0 Loss: 0.012181965060589058
Epoch: 9 Idx: 5000 Loss: 0.007813749549251464
Epoch: 10 Idx: 0 Loss: 0.011167281703465185
Epoch: 10 Idx: 5000 Loss: 0.0052297739314730845
Epoch: 11 Idx: 0 Loss: 0.030501431186575972
Epoch: 11 Idx: 5000 Loss: 0.015400871563760011
Epoch: 12 Idx: 0 Loss: 0.007001537615721239
Epoch: 12 Idx: 5000 Loss: 0.010058782775984876
Epoch: 13 Idx: 0 Loss: 0.00906732353788607
Epoch: 13 Idx: 5000 Loss: 0.010700595435096431
Epoch: 14 Idx: 0 Loss: 0.013804901598727855
Epoch: 14 Idx: 5000 Loss: 0.022258009385097935
Epoch: 15 Idx: 0 Loss: 0.006342237951322692
Epoch: 15 Idx: 5000 Loss: 0.011901771845711725
Epoch: 16 Idx: 0 Loss: 0.019200331861327427
Epoch: 16 Idx: 5000 Loss: 0.013236733763612568
Epoch: 17 Idx: 0 Loss: 0.02070517228740774
Epoch: 17 Idx: 5000 Loss: 0.0267967008148412
Epoch: 18 Idx: 0 Loss: 0.015083339605109599
Epoch: 18 Idx: 5000 Loss: 0.02284332359729949
Epoch: 19 Idx: 0 Loss: 0.014588270642935445
Epoch: 19 Idx: 5000 Loss: 0.015579488713912194
Epoch: 20 Idx: 0 Loss: 0.02345434820997444
Epoch: 20 Idx: 5000 Loss: 0.013652542595623714
Epoch: 21 Idx: 0 Loss: 0.02518625738884403
Epoch: 21 Idx: 5000 Loss: 0.01205712118512035
Epoch: 22 Idx: 0 Loss: 0.009061722067215325
Epoch: 22 Idx: 5000 Loss: 0.007185549353208837
Epoch: 23 Idx: 0 Loss: 0.013291388089643572
Epoch: 23 Idx: 5000 Loss: 0.043875420824384795
Epoch: 24 Idx: 0 Loss: 0.009702434981268142
Epoch: 24 Idx: 5000 Loss: 0.015599719192349083
Epoch: 25 Idx: 0 Loss: 0.01713433369215147
Epoch: 25 Idx: 5000 Loss: 0.031433053960693735
Epoch: 26 Idx: 0 Loss: 0.009720992879880985
Epoch: 26 Idx: 5000 Loss: 0.03218418008182752
Epoch: 27 Idx: 0 Loss: 0.006361050377534729
Epoch: 27 Idx: 5000 Loss: 0.010674982114658116
Epoch: 28 Idx: 0 Loss: 0.011429080114671522
Epoch: 28 Idx: 5000 Loss: 0.007871310696787766
Epoch: 29 Idx: 0 Loss: 0.015811414357374137
Epoch: 29 Idx: 5000 Loss: 0.008524718385162696
Epoch: 30 Idx: 0 Loss: 0.009093152813239221
Epoch: 30 Idx: 5000 Loss: 0.014314411080619292
Epoch: 31 Idx: 0 Loss: 0.02366373213740063
Epoch: 31 Idx: 5000 Loss: 0.01539117524517064
Epoch: 32 Idx: 0 Loss: 0.017988853167267775
Epoch: 32 Idx: 5000 Loss: 0.017163497226401418
Epoch: 33 Idx: 0 Loss: 0.011190690318127854
Epoch: 33 Idx: 5000 Loss: 0.02315849795934799
Epoch: 34 Idx: 0 Loss: 0.01332450434272845
Epoch: 34 Idx: 5000 Loss: 0.018367282377925124
Epoch: 35 Idx: 0 Loss: 0.014780216916313878
Epoch: 35 Idx: 5000 Loss: 0.031892967549820836
Epoch: 36 Idx: 0 Loss: 0.012364227469057342
Epoch: 36 Idx: 5000 Loss: 0.005724344781613008
Epoch: 37 Idx: 0 Loss: 0.020647914074668042
Epoch: 37 Idx: 5000 Loss: 0.018437784393425118
Epoch: 38 Idx: 0 Loss: 0.013256994450115274
Epoch: 38 Idx: 5000 Loss: 0.03541252656651621
Epoch: 39 Idx: 0 Loss: 0.009512303808340845
Epoch: 39 Idx: 5000 Loss: 0.013920106407125953
Epoch: 40 Idx: 0 Loss: 0.012461436019086839
Epoch: 40 Idx: 5000 Loss: 0.02504400070171668
Epoch: 41 Idx: 0 Loss: 0.008619597016578606
Epoch: 41 Idx: 5000 Loss: 0.010868098429067743
Epoch: 42 Idx: 0 Loss: 0.007545987130122249
Epoch: 42 Idx: 5000 Loss: 0.017452839776800746
Epoch: 43 Idx: 0 Loss: 0.018072465136664405
Epoch: 43 Idx: 5000 Loss: 0.03436287614891299
Epoch: 44 Idx: 0 Loss: 0.01342282810986522
Epoch: 44 Idx: 5000 Loss: 0.0202953565039923
Epoch: 45 Idx: 0 Loss: 0.027572373264222842
Epoch: 45 Idx: 5000 Loss: 0.016539348516667697
Epoch: 46 Idx: 0 Loss: 0.011838214701945644
Epoch: 46 Idx: 5000 Loss: 0.012692711097911894
Epoch: 47 Idx: 0 Loss: 0.017014064211281314
Epoch: 47 Idx: 5000 Loss: 0.007217667653325795
Epoch: 48 Idx: 0 Loss: 0.014282558862768899
Epoch: 48 Idx: 5000 Loss: 0.010471263244108875
Epoch: 49 Idx: 0 Loss: 0.03272742125995851
Epoch: 49 Idx: 5000 Loss: 0.014647745025071789
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.2139258693006804
Epoch: 0 Idx: 5000 Loss: 0.03230043941530093
Epoch: 1 Idx: 0 Loss: 0.0204357594343184
Epoch: 1 Idx: 5000 Loss: 0.03155608433574086
Epoch: 2 Idx: 0 Loss: 0.018312140944480203
Epoch: 2 Idx: 5000 Loss: 0.017694006766700906
Epoch: 3 Idx: 0 Loss: 0.010608129419042094
Epoch: 3 Idx: 5000 Loss: 0.018834848354682583
Epoch: 4 Idx: 0 Loss: 0.01697770461498271
Epoch: 4 Idx: 5000 Loss: 0.012297192276038437
Epoch: 5 Idx: 0 Loss: 0.020421873919496066
Epoch: 5 Idx: 5000 Loss: 0.013943686644507906
Epoch: 6 Idx: 0 Loss: 0.013401094706338034
Epoch: 6 Idx: 5000 Loss: 0.012830368789201997
Epoch: 7 Idx: 0 Loss: 0.010043035606406996
Epoch: 7 Idx: 5000 Loss: 0.010975366652666617
Epoch: 8 Idx: 0 Loss: 0.0068476919457693625
Epoch: 8 Idx: 5000 Loss: 0.02228588048191798
Epoch: 9 Idx: 0 Loss: 0.008976525163198072
Epoch: 9 Idx: 5000 Loss: 0.008940264463503215
Epoch: 10 Idx: 0 Loss: 0.009796786114023423
Epoch: 10 Idx: 5000 Loss: 0.011954791959952263
Epoch: 11 Idx: 0 Loss: 0.009479359942651682
Epoch: 11 Idx: 5000 Loss: 0.021762084811923307
Epoch: 12 Idx: 0 Loss: 0.015527878818930894
Epoch: 12 Idx: 5000 Loss: 0.006994630952387111
Epoch: 13 Idx: 0 Loss: 0.02517650260883085
Epoch: 13 Idx: 5000 Loss: 0.010672758732906313
Epoch: 14 Idx: 0 Loss: 0.008511831788229087
Epoch: 14 Idx: 5000 Loss: 0.009044608190457524
Epoch: 15 Idx: 0 Loss: 0.014282766947813587
Epoch: 15 Idx: 5000 Loss: 0.04212219867172598
Epoch: 16 Idx: 0 Loss: 0.010541192648160983
Epoch: 16 Idx: 5000 Loss: 0.01575427273363947
Epoch: 17 Idx: 0 Loss: 0.009580085549591492
Epoch: 17 Idx: 5000 Loss: 0.022612089564515627
Epoch: 18 Idx: 0 Loss: 0.023172767780422827
Epoch: 18 Idx: 5000 Loss: 0.012499872979034054
Epoch: 19 Idx: 0 Loss: 0.01756943996335638
Epoch: 19 Idx: 5000 Loss: 0.02163708529460777
Epoch: 20 Idx: 0 Loss: 0.023171121960362268
Epoch: 20 Idx: 5000 Loss: 0.016930226761822955
Epoch: 21 Idx: 0 Loss: 0.011118027710015788
Epoch: 21 Idx: 5000 Loss: 0.009515235824022996
Epoch: 22 Idx: 0 Loss: 0.011185242952382601
Epoch: 22 Idx: 5000 Loss: 0.01889707266792248
Epoch: 23 Idx: 0 Loss: 0.008964886922026028
Epoch: 23 Idx: 5000 Loss: 0.009525350829193379
Epoch: 24 Idx: 0 Loss: 0.010447909439175049
Epoch: 24 Idx: 5000 Loss: 0.027974454281106724
Epoch: 25 Idx: 0 Loss: 0.019639706554429738
Epoch: 25 Idx: 5000 Loss: 0.015177215653113068
Epoch: 26 Idx: 0 Loss: 0.018321737191356886
Epoch: 26 Idx: 5000 Loss: 0.016714330428599093
Epoch: 27 Idx: 0 Loss: 0.022363696648632372
Epoch: 27 Idx: 5000 Loss: 0.012490203650657531
Epoch: 28 Idx: 0 Loss: 0.01045021188035481
Epoch: 28 Idx: 5000 Loss: 0.012917527794309406
Epoch: 29 Idx: 0 Loss: 0.008522561409039325
Epoch: 29 Idx: 5000 Loss: 0.022911935748755125
Epoch: 30 Idx: 0 Loss: 0.039443280039559415
Epoch: 30 Idx: 5000 Loss: 0.00658674769820315
Epoch: 31 Idx: 0 Loss: 0.01526125977489478
Epoch: 31 Idx: 5000 Loss: 0.02121851439827848
Epoch: 32 Idx: 0 Loss: 0.029365782669057268
Epoch: 32 Idx: 5000 Loss: 0.021032318920312848
Epoch: 33 Idx: 0 Loss: 0.008422371851587543
Epoch: 33 Idx: 5000 Loss: 0.035582917688331564
Epoch: 34 Idx: 0 Loss: 0.01575652433792872
Epoch: 34 Idx: 5000 Loss: 0.02139565359607491
Epoch: 35 Idx: 0 Loss: 0.007299663171406
Epoch: 35 Idx: 5000 Loss: 0.010585372298191096
Epoch: 36 Idx: 0 Loss: 0.04472212342822381
Epoch: 36 Idx: 5000 Loss: 0.010672838226507147
Epoch: 37 Idx: 0 Loss: 0.010207470162504426
Epoch: 37 Idx: 5000 Loss: 0.010408521761883087
Epoch: 38 Idx: 0 Loss: 0.007423184040421969
Epoch: 38 Idx: 5000 Loss: 0.01206441631042543
Epoch: 39 Idx: 0 Loss: 0.005581774772627171
Epoch: 39 Idx: 5000 Loss: 0.01999663308227118
Epoch: 40 Idx: 0 Loss: 0.009439531847329742
Epoch: 40 Idx: 5000 Loss: 0.011519208795953468
Epoch: 41 Idx: 0 Loss: 0.0059429888112323
Epoch: 41 Idx: 5000 Loss: 0.009936780642101144
Epoch: 42 Idx: 0 Loss: 0.009789485847155424
Epoch: 42 Idx: 5000 Loss: 0.007869631185243517
Epoch: 43 Idx: 0 Loss: 0.009587335419370919
Epoch: 43 Idx: 5000 Loss: 0.02362539071959257
Epoch: 44 Idx: 0 Loss: 0.010997347621672064
Epoch: 44 Idx: 5000 Loss: 0.013989699945625853
Epoch: 45 Idx: 0 Loss: 0.019357451694759935
Epoch: 45 Idx: 5000 Loss: 0.007363968552190456
Epoch: 46 Idx: 0 Loss: 0.019683000435541567
Epoch: 46 Idx: 5000 Loss: 0.017311856313798328
Epoch: 47 Idx: 0 Loss: 0.02120107846236756
Epoch: 47 Idx: 5000 Loss: 0.010392695400580921
Epoch: 48 Idx: 0 Loss: 0.009310230490652735
Epoch: 48 Idx: 5000 Loss: 0.011852781790715512
Epoch: 49 Idx: 0 Loss: 0.03365056563361121
Epoch: 49 Idx: 5000 Loss: 0.017752212476435495
Len (direct inputs):  1690
Inputs len 10074 10 11464
Len (direct inputs):  1400
Starting sliding window evaluation...
Step 12/7
Val onto:  [('conference', 'iasted')] test_onto:  [('confof', 'edas')]
Training size: 104813 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.20929431490185887
Epoch: 0 Idx: 5000 Loss: 0.014637364045322931
Epoch: 1 Idx: 0 Loss: 0.0076391904088441275
Epoch: 1 Idx: 5000 Loss: 0.03142718527695324
Epoch: 2 Idx: 0 Loss: 0.012276754696626495
Epoch: 2 Idx: 5000 Loss: 0.02674968286140548
Epoch: 3 Idx: 0 Loss: 0.02009567822732702
Epoch: 3 Idx: 5000 Loss: 0.013376055092620881
Epoch: 4 Idx: 0 Loss: 0.01113777980073489
Epoch: 4 Idx: 5000 Loss: 0.010569379672943406
Epoch: 5 Idx: 0 Loss: 0.022267186064590286
Epoch: 5 Idx: 5000 Loss: 0.02643685143426632
Epoch: 6 Idx: 0 Loss: 0.011073816868260943
Epoch: 6 Idx: 5000 Loss: 0.03356956448847936
Epoch: 7 Idx: 0 Loss: 0.031711928800570485
Epoch: 7 Idx: 5000 Loss: 0.022261539735460346
Epoch: 8 Idx: 0 Loss: 0.011428615380343324
Epoch: 8 Idx: 5000 Loss: 0.007612679652149746
Epoch: 9 Idx: 0 Loss: 0.04312472689095955
Epoch: 9 Idx: 5000 Loss: 0.025007317863798298
Epoch: 10 Idx: 0 Loss: 0.00742560097273858
Epoch: 10 Idx: 5000 Loss: 0.016016260961773963
Epoch: 11 Idx: 0 Loss: 0.029461447711736744
Epoch: 11 Idx: 5000 Loss: 0.01562720711524315
Epoch: 12 Idx: 0 Loss: 0.015457393418731279
Epoch: 12 Idx: 5000 Loss: 0.008428940642533977
Epoch: 13 Idx: 0 Loss: 0.021938703161936492
Epoch: 13 Idx: 5000 Loss: 0.011494921459430651
Epoch: 14 Idx: 0 Loss: 0.013935193007056286
Epoch: 14 Idx: 5000 Loss: 0.012177374531434915
Epoch: 15 Idx: 0 Loss: 0.019246945490535773
Epoch: 15 Idx: 5000 Loss: 0.01075974407467589
Epoch: 16 Idx: 0 Loss: 0.010277222593931643
Epoch: 16 Idx: 5000 Loss: 0.014956642125173851
Epoch: 17 Idx: 0 Loss: 0.009816027630804242
Epoch: 17 Idx: 5000 Loss: 0.020912011256940678
Epoch: 18 Idx: 0 Loss: 0.011849338529327683
Epoch: 18 Idx: 5000 Loss: 0.011113251960761138
Epoch: 19 Idx: 0 Loss: 0.029275037925023336
Epoch: 19 Idx: 5000 Loss: 0.01770862744553031
Epoch: 20 Idx: 0 Loss: 0.013980760550831434
Epoch: 20 Idx: 5000 Loss: 0.015097931747216293
Epoch: 21 Idx: 0 Loss: 0.009794404471455189
Epoch: 21 Idx: 5000 Loss: 0.016488016361561116
Epoch: 22 Idx: 0 Loss: 0.014652138478378157
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 323, in forward
    best_path = torch.bmm(path_weights.reshape(-1, 1, self.max_paths), feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc269>
Subject: Job 4066811: <python main.py 4 2 False True> in cluster <dcc> Exited

Job <python main.py 4 2 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
Job was executed on host(s) <dccxc269>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 2 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46131.19 sec.
    Max Memory :                                 2886 MB
    Average Memory :                             2730.02 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40531.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46218 sec.
    Turnaround time :                            46204 sec.

The output (if any) is above this job summary.

