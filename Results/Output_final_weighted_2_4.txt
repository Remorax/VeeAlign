2020-09-16 07:37:37.228374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:47.477962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:37:47.588608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:37:47.588683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:47.590641: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:37:47.592092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:37:47.592494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:37:47.594351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:37:47.595715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:37:47.595922: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 07:37:47.595944: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:37:47.596387: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:37:47.623307: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599940000 Hz
2020-09-16 07:37:47.623525: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55815952aea0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:37:47.623544: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:37:47.625575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:37:47.625596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20221939375557893
Epoch: 0 Idx: 5000 Loss: 0.009461401623969837
Epoch: 1 Idx: 0 Loss: 0.01366522066421385
Epoch: 1 Idx: 5000 Loss: 0.022320718417540783
Epoch: 2 Idx: 0 Loss: 0.010384294450967547
Epoch: 2 Idx: 5000 Loss: 0.013811673507055673
Epoch: 3 Idx: 0 Loss: 0.018043631020184834
Epoch: 3 Idx: 5000 Loss: 0.03446965214459103
Epoch: 4 Idx: 0 Loss: 0.009686792150105462
Epoch: 4 Idx: 5000 Loss: 0.013393294770249657
Epoch: 5 Idx: 0 Loss: 0.015442974160887456
Epoch: 5 Idx: 5000 Loss: 0.011115023884851992
Epoch: 6 Idx: 0 Loss: 0.010397261213814095
Epoch: 6 Idx: 5000 Loss: 0.030209606289883163
Epoch: 7 Idx: 0 Loss: 0.009019083241498452
Epoch: 7 Idx: 5000 Loss: 0.010842802476505741
Epoch: 8 Idx: 0 Loss: 0.04183885858186922
Epoch: 8 Idx: 5000 Loss: 0.011946321222679714
Epoch: 9 Idx: 0 Loss: 0.010966538831965127
Epoch: 9 Idx: 5000 Loss: 0.010927056854189158
Epoch: 10 Idx: 0 Loss: 0.007912053897988582
Epoch: 10 Idx: 5000 Loss: 0.014291965091044193
Epoch: 11 Idx: 0 Loss: 0.02487636390477288
Epoch: 11 Idx: 5000 Loss: 0.01530387675224949
Epoch: 12 Idx: 0 Loss: 0.005234108284470257
Epoch: 12 Idx: 5000 Loss: 0.02104750189231509
Epoch: 13 Idx: 0 Loss: 0.03190514646343697
Epoch: 13 Idx: 5000 Loss: 0.012321343876256089
Epoch: 14 Idx: 0 Loss: 0.008708403717522304
Epoch: 14 Idx: 5000 Loss: 0.008967075524637207
Epoch: 15 Idx: 0 Loss: 0.02543430121789623
Epoch: 15 Idx: 5000 Loss: 0.013810740003314108
Epoch: 16 Idx: 0 Loss: 0.00461070053600487
Epoch: 16 Idx: 5000 Loss: 0.01767686307094256
Epoch: 17 Idx: 0 Loss: 0.03350128657291366
Epoch: 17 Idx: 5000 Loss: 0.009225784410301956
Epoch: 18 Idx: 0 Loss: 0.011138522112067084
Epoch: 18 Idx: 5000 Loss: 0.023161445329633233
Epoch: 19 Idx: 0 Loss: 0.0129441599574903
Epoch: 19 Idx: 5000 Loss: 0.01303521063203001
Epoch: 20 Idx: 0 Loss: 0.014973707253182523
Epoch: 20 Idx: 5000 Loss: 0.01591539007893908
Epoch: 21 Idx: 0 Loss: 0.02074543780783035
Epoch: 21 Idx: 5000 Loss: 0.01952390288824441
Epoch: 22 Idx: 0 Loss: 0.031620000298656234
Epoch: 22 Idx: 5000 Loss: 0.01807137939738787
Epoch: 23 Idx: 0 Loss: 0.014195566993693048
Epoch: 23 Idx: 5000 Loss: 0.019943074417605754
Epoch: 24 Idx: 0 Loss: 0.01549062397095705
Epoch: 24 Idx: 5000 Loss: 0.022790905906346186
Epoch: 25 Idx: 0 Loss: 0.034065607673879776
Epoch: 25 Idx: 5000 Loss: 0.01230247679565697
Epoch: 26 Idx: 0 Loss: 0.01660144876944161
Epoch: 26 Idx: 5000 Loss: 0.008116900113036679
Epoch: 27 Idx: 0 Loss: 0.0217787770449176
Epoch: 27 Idx: 5000 Loss: 0.009341474309340621
Epoch: 28 Idx: 0 Loss: 0.009549211049382986
Epoch: 28 Idx: 5000 Loss: 0.03591474501858145
Epoch: 29 Idx: 0 Loss: 0.022934750081000287
Epoch: 29 Idx: 5000 Loss: 0.010852245099862393
Epoch: 30 Idx: 0 Loss: 0.013039268209123506
Epoch: 30 Idx: 5000 Loss: 0.008566200685711638
Epoch: 31 Idx: 0 Loss: 0.009285123566611198
Epoch: 31 Idx: 5000 Loss: 0.009023411589024902
Epoch: 32 Idx: 0 Loss: 0.015424230276188501
Epoch: 32 Idx: 5000 Loss: 0.013868322174431845
Epoch: 33 Idx: 0 Loss: 0.014753847885687885
Epoch: 33 Idx: 5000 Loss: 0.02365556728362283
Epoch: 34 Idx: 0 Loss: 0.00632127400272652
Epoch: 34 Idx: 5000 Loss: 0.008799234834221254
Epoch: 35 Idx: 0 Loss: 0.016812252479857497
Epoch: 35 Idx: 5000 Loss: 0.031100057227011153
Epoch: 36 Idx: 0 Loss: 0.016288899480718367
Epoch: 36 Idx: 5000 Loss: 0.010268768749388434
Epoch: 37 Idx: 0 Loss: 0.02225633640709456
Epoch: 37 Idx: 5000 Loss: 0.028703353946822392
Epoch: 38 Idx: 0 Loss: 0.016356308722878524
Epoch: 38 Idx: 5000 Loss: 0.03486395092173711
Epoch: 39 Idx: 0 Loss: 0.017135970737431075
Epoch: 39 Idx: 5000 Loss: 0.017844689871386887
Epoch: 40 Idx: 0 Loss: 0.0074730712660306415
Epoch: 40 Idx: 5000 Loss: 0.025935565197227336
Epoch: 41 Idx: 0 Loss: 0.022095484917623205
Epoch: 41 Idx: 5000 Loss: 0.021654217662113447
Epoch: 42 Idx: 0 Loss: 0.01215626550217909
Epoch: 42 Idx: 5000 Loss: 0.006257513352733486
Epoch: 43 Idx: 0 Loss: 0.012912362577316445
Epoch: 43 Idx: 5000 Loss: 0.010203194254372428
Epoch: 44 Idx: 0 Loss: 0.017304150208848332
Epoch: 44 Idx: 5000 Loss: 0.012590601840546212
Epoch: 45 Idx: 0 Loss: 0.00616932406914243
Epoch: 45 Idx: 5000 Loss: 0.01475143236415433
Epoch: 46 Idx: 0 Loss: 0.015276128903602602
Epoch: 46 Idx: 5000 Loss: 0.0153114920332297
Epoch: 47 Idx: 0 Loss: 0.034570238425771296
Epoch: 47 Idx: 5000 Loss: 0.018747418749837288
Epoch: 48 Idx: 0 Loss: 0.02336625531333863
Epoch: 48 Idx: 5000 Loss: 0.02236649925097104
Epoch: 49 Idx: 0 Loss: 0.02100856638821649
Epoch: 49 Idx: 5000 Loss: 0.013776334014579887
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.25161693010044245
Epoch: 0 Idx: 5000 Loss: 0.017040016223049143
Epoch: 1 Idx: 0 Loss: 0.01231099387371989
Epoch: 1 Idx: 5000 Loss: 0.013482933234254925
Epoch: 2 Idx: 0 Loss: 0.017320827595446994
Epoch: 2 Idx: 5000 Loss: 0.013539776678982072
Epoch: 3 Idx: 0 Loss: 0.008819781518053058
Epoch: 3 Idx: 5000 Loss: 0.02292451460244775
Epoch: 4 Idx: 0 Loss: 0.010410460865629918
Epoch: 4 Idx: 5000 Loss: 0.006581745043990973
Epoch: 5 Idx: 0 Loss: 0.03221209246733744
Epoch: 5 Idx: 5000 Loss: 0.010832936559753991
Epoch: 6 Idx: 0 Loss: 0.010739955118156841
Epoch: 6 Idx: 5000 Loss: 0.016927094096021108
Epoch: 7 Idx: 0 Loss: 0.012348858112720306
Epoch: 7 Idx: 5000 Loss: 0.020702557500051122
Epoch: 8 Idx: 0 Loss: 0.01538877454823121
Epoch: 8 Idx: 5000 Loss: 0.010535497269920282
Epoch: 9 Idx: 0 Loss: 0.010958365055191363
Epoch: 9 Idx: 5000 Loss: 0.0066735436621636265
Epoch: 10 Idx: 0 Loss: 0.02604456664308922
Epoch: 10 Idx: 5000 Loss: 0.012676179373515648
Epoch: 11 Idx: 0 Loss: 0.008759981443952833
Epoch: 11 Idx: 5000 Loss: 0.01064343382049637
Epoch: 12 Idx: 0 Loss: 0.011155251447844561
Epoch: 12 Idx: 5000 Loss: 0.01020222172500308
Epoch: 13 Idx: 0 Loss: 0.01459453951226881
Epoch: 13 Idx: 5000 Loss: 0.011979815712595241
Epoch: 14 Idx: 0 Loss: 0.028342530778085264
Epoch: 14 Idx: 5000 Loss: 0.016420155128576412
Epoch: 15 Idx: 0 Loss: 0.0070429354137647076
Epoch: 15 Idx: 5000 Loss: 0.02274038693752043
Epoch: 16 Idx: 0 Loss: 0.010938909771175294
Epoch: 16 Idx: 5000 Loss: 0.05414583757643164
Epoch: 17 Idx: 0 Loss: 0.014876218885154061
Epoch: 17 Idx: 5000 Loss: 0.04293099862838434
Epoch: 18 Idx: 0 Loss: 0.01607766254800935
Epoch: 18 Idx: 5000 Loss: 0.01190606443180268
Epoch: 19 Idx: 0 Loss: 0.00976310829614997
Epoch: 19 Idx: 5000 Loss: 0.018044299483770274
Epoch: 20 Idx: 0 Loss: 0.015014488934619243
Epoch: 20 Idx: 5000 Loss: 0.019311439474571552
Epoch: 21 Idx: 0 Loss: 0.009120174326239038
Epoch: 21 Idx: 5000 Loss: 0.026048651585908154
Epoch: 22 Idx: 0 Loss: 0.018532782357991648
Epoch: 22 Idx: 5000 Loss: 0.02351221156055756
Epoch: 23 Idx: 0 Loss: 0.020591757836440162
Epoch: 23 Idx: 5000 Loss: 0.01115968721424601
Epoch: 24 Idx: 0 Loss: 0.037726902008272306
Epoch: 24 Idx: 5000 Loss: 0.008126077371174503
Epoch: 25 Idx: 0 Loss: 0.013302411591037887
Epoch: 25 Idx: 5000 Loss: 0.016359072363773604
Epoch: 26 Idx: 0 Loss: 0.018854360805511915
Epoch: 26 Idx: 5000 Loss: 0.016999313958636054
Epoch: 27 Idx: 0 Loss: 0.011726566904332988
Epoch: 27 Idx: 5000 Loss: 0.005067578414698834
Epoch: 28 Idx: 0 Loss: 0.019301005301526578
Epoch: 28 Idx: 5000 Loss: 0.017979873908015687
Epoch: 29 Idx: 0 Loss: 0.024448170531993968
Epoch: 29 Idx: 5000 Loss: 0.01438904792848334
Epoch: 30 Idx: 0 Loss: 0.018147006597887247
Epoch: 30 Idx: 5000 Loss: 0.01074721909739966
Epoch: 31 Idx: 0 Loss: 0.009671381036203052
Epoch: 31 Idx: 5000 Loss: 0.042446893919605426
Epoch: 32 Idx: 0 Loss: 0.028884312901174568
Epoch: 32 Idx: 5000 Loss: 0.00974293933736366
Epoch: 33 Idx: 0 Loss: 0.01255739667182109
Epoch: 33 Idx: 5000 Loss: 0.016935806181827225
Epoch: 34 Idx: 0 Loss: 0.013397927112300166
Epoch: 34 Idx: 5000 Loss: 0.03366135081925535
Epoch: 35 Idx: 0 Loss: 0.015885792614213384
Epoch: 35 Idx: 5000 Loss: 0.01431774967775572
Epoch: 36 Idx: 0 Loss: 0.01231225245404675
Epoch: 36 Idx: 5000 Loss: 0.016266322845443142
Epoch: 37 Idx: 0 Loss: 0.020132857029271912
Epoch: 37 Idx: 5000 Loss: 0.014314061384593919
Epoch: 38 Idx: 0 Loss: 0.01238043342693685
Epoch: 38 Idx: 5000 Loss: 0.0307480330106374
Epoch: 39 Idx: 0 Loss: 0.00819177311119596
Epoch: 39 Idx: 5000 Loss: 0.008738267534655828
Epoch: 40 Idx: 0 Loss: 0.022822615341387645
Epoch: 40 Idx: 5000 Loss: 0.026615994999937477
Epoch: 41 Idx: 0 Loss: 0.008344103812907087
Epoch: 41 Idx: 5000 Loss: 0.03217648286678121
Epoch: 42 Idx: 0 Loss: 0.022786890072759403
Epoch: 42 Idx: 5000 Loss: 0.02622816026456211
Epoch: 43 Idx: 0 Loss: 0.006994192329090169
Epoch: 43 Idx: 5000 Loss: 0.009418437495309264
Epoch: 44 Idx: 0 Loss: 0.010415732007128056
Epoch: 44 Idx: 5000 Loss: 0.009342241683412206
Epoch: 45 Idx: 0 Loss: 0.013758908146880498
Epoch: 45 Idx: 5000 Loss: 0.0054708481752932595
Epoch: 46 Idx: 0 Loss: 0.02460576624675475
Epoch: 46 Idx: 5000 Loss: 0.023083753461259602
Epoch: 47 Idx: 0 Loss: 0.007383066696788636
Epoch: 47 Idx: 5000 Loss: 0.009219919754664132
Epoch: 48 Idx: 0 Loss: 0.01337575594495546
Epoch: 48 Idx: 5000 Loss: 0.00712863102173272
Epoch: 49 Idx: 0 Loss: 0.011505028591262918
Epoch: 49 Idx: 5000 Loss: 0.02091510627726368
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.15707031182805556
Epoch: 0 Idx: 5000 Loss: 0.03906969591073542
Epoch: 1 Idx: 0 Loss: 0.011188067475200562
Epoch: 1 Idx: 5000 Loss: 0.018833640187972542
Epoch: 2 Idx: 0 Loss: 0.013518457599235485
Epoch: 2 Idx: 5000 Loss: 0.008584276452736725
Epoch: 3 Idx: 0 Loss: 0.017327455569869775
Epoch: 3 Idx: 5000 Loss: 0.014430730611715984
Epoch: 4 Idx: 0 Loss: 0.014426920975566958
Epoch: 4 Idx: 5000 Loss: 0.016503842073016084
Epoch: 5 Idx: 0 Loss: 0.02000106986285023
Epoch: 5 Idx: 5000 Loss: 0.013660645603532015
Epoch: 6 Idx: 0 Loss: 0.01403399218484478
Epoch: 6 Idx: 5000 Loss: 0.01513372405621789
Epoch: 7 Idx: 0 Loss: 0.015933922824857585
Epoch: 7 Idx: 5000 Loss: 0.007114707129004997
Epoch: 8 Idx: 0 Loss: 0.01999114364856839
Epoch: 8 Idx: 5000 Loss: 0.022138210954766722
Epoch: 9 Idx: 0 Loss: 0.024782458712258905
Epoch: 9 Idx: 5000 Loss: 0.014734168103970663
Epoch: 10 Idx: 0 Loss: 0.01445945497765595
Epoch: 10 Idx: 5000 Loss: 0.012630581759886038
Epoch: 11 Idx: 0 Loss: 0.016339302951755383
Epoch: 11 Idx: 5000 Loss: 0.015430049690901114
Epoch: 12 Idx: 0 Loss: 0.030941050327370153
Epoch: 12 Idx: 5000 Loss: 0.03257829877741092
Epoch: 13 Idx: 0 Loss: 0.0132162514315446
Epoch: 13 Idx: 5000 Loss: 0.006256152408408265
Epoch: 14 Idx: 0 Loss: 0.014143453018935645
Epoch: 14 Idx: 5000 Loss: 0.011105855324355807
Epoch: 15 Idx: 0 Loss: 0.014659452942217174
Epoch: 15 Idx: 5000 Loss: 0.0063047984879779
Epoch: 16 Idx: 0 Loss: 0.035956422726623374
Epoch: 16 Idx: 5000 Loss: 0.006859213384012543
Epoch: 17 Idx: 0 Loss: 0.008724183895219504
Epoch: 17 Idx: 5000 Loss: 0.015357445740163579
Epoch: 18 Idx: 0 Loss: 0.006383431897566696
Epoch: 18 Idx: 5000 Loss: 0.006762247830621718
Epoch: 19 Idx: 0 Loss: 0.011425436043149946
Epoch: 19 Idx: 5000 Loss: 0.01019922815225246
Epoch: 20 Idx: 0 Loss: 0.022513900209928692
Epoch: 20 Idx: 5000 Loss: 0.02091060659477899
Epoch: 21 Idx: 0 Loss: 0.026516445861058224
Epoch: 21 Idx: 5000 Loss: 0.034761611776098725
Epoch: 22 Idx: 0 Loss: 0.011022466184420748
Epoch: 22 Idx: 5000 Loss: 0.01695307055677829
Epoch: 23 Idx: 0 Loss: 0.018262309736948704
Epoch: 23 Idx: 5000 Loss: 0.007002038291206858
Epoch: 24 Idx: 0 Loss: 0.012828939914076163
Epoch: 24 Idx: 5000 Loss: 0.016837012053201234
Epoch: 25 Idx: 0 Loss: 0.01270433785694021
Epoch: 25 Idx: 5000 Loss: 0.014053037173843454
Epoch: 26 Idx: 0 Loss: 0.007009405437294948
Epoch: 26 Idx: 5000 Loss: 0.01718357273664238
Epoch: 27 Idx: 0 Loss: 0.008605417509524194
Epoch: 27 Idx: 5000 Loss: 0.02166261736404443
Epoch: 28 Idx: 0 Loss: 0.012213284297546135
Epoch: 28 Idx: 5000 Loss: 0.011120973566427383
Epoch: 29 Idx: 0 Loss: 0.019842462308960605
Epoch: 29 Idx: 5000 Loss: 0.009636268696080797
Epoch: 30 Idx: 0 Loss: 0.015555633818722384
Epoch: 30 Idx: 5000 Loss: 0.007323441253312912
Epoch: 31 Idx: 0 Loss: 0.009663147542785726
Epoch: 31 Idx: 5000 Loss: 0.0638635589351233
Epoch: 32 Idx: 0 Loss: 0.013785440940721377
Epoch: 32 Idx: 5000 Loss: 0.025145959740214933
Epoch: 33 Idx: 0 Loss: 0.014350591026105681
Epoch: 33 Idx: 5000 Loss: 0.017100981543218687
Epoch: 34 Idx: 0 Loss: 0.037550655109461734
Epoch: 34 Idx: 5000 Loss: 0.012608119931931533
Epoch: 35 Idx: 0 Loss: 0.00758704264311221
Epoch: 35 Idx: 5000 Loss: 0.00791086253655976
Epoch: 36 Idx: 0 Loss: 0.014636918737340125
Epoch: 36 Idx: 5000 Loss: 0.03822362906320074
Epoch: 37 Idx: 0 Loss: 0.006007363249012639
Epoch: 37 Idx: 5000 Loss: 0.013385071123813368
Epoch: 38 Idx: 0 Loss: 0.009144391021947688
Epoch: 38 Idx: 5000 Loss: 0.011790231717657858
Epoch: 39 Idx: 0 Loss: 0.009922430212598747
Epoch: 39 Idx: 5000 Loss: 0.021873652748175966
Epoch: 40 Idx: 0 Loss: 0.016776945874969338
Epoch: 40 Idx: 5000 Loss: 0.0236731315939273
Epoch: 41 Idx: 0 Loss: 0.010395765334881148
Epoch: 41 Idx: 5000 Loss: 0.03184599146067717
Epoch: 42 Idx: 0 Loss: 0.012128717405415376
Epoch: 42 Idx: 5000 Loss: 0.009904845623715434
Epoch: 43 Idx: 0 Loss: 0.030238801752083763
Epoch: 43 Idx: 5000 Loss: 0.019832809159224328
Epoch: 44 Idx: 0 Loss: 0.025370237983127496
Epoch: 44 Idx: 5000 Loss: 0.01931784503936842
Epoch: 45 Idx: 0 Loss: 0.021017119627033586
Epoch: 45 Idx: 5000 Loss: 0.01108626697938067
Epoch: 46 Idx: 0 Loss: 0.028636052219734514
Epoch: 46 Idx: 5000 Loss: 0.005579162234824565
Epoch: 47 Idx: 0 Loss: 0.017494500531324522
Epoch: 47 Idx: 5000 Loss: 0.049610140019316004
Epoch: 48 Idx: 0 Loss: 0.018005113670251413
Epoch: 48 Idx: 5000 Loss: 0.022630273462092232
Epoch: 49 Idx: 0 Loss: 0.02022691779302249
Epoch: 49 Idx: 5000 Loss: 0.014165288123092881
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.19319845550292966
Epoch: 0 Idx: 5000 Loss: 0.01638129131644797
Epoch: 1 Idx: 0 Loss: 0.017191561845669348
Epoch: 1 Idx: 5000 Loss: 0.019373136886162566
Epoch: 2 Idx: 0 Loss: 0.00815518571001326
Epoch: 2 Idx: 5000 Loss: 0.02182638545480372
Epoch: 3 Idx: 0 Loss: 0.010242890004485361
Epoch: 3 Idx: 5000 Loss: 0.01688253002307263
Epoch: 4 Idx: 0 Loss: 0.013385276315163761
Epoch: 4 Idx: 5000 Loss: 0.01566968098256128
Epoch: 5 Idx: 0 Loss: 0.0075067728524650925
Epoch: 5 Idx: 5000 Loss: 0.016419793593290856
Epoch: 6 Idx: 0 Loss: 0.014335205764393524
Epoch: 6 Idx: 5000 Loss: 0.03153053454018198
Epoch: 7 Idx: 0 Loss: 0.018602312767650547
Epoch: 7 Idx: 5000 Loss: 0.010935352705212736
Epoch: 8 Idx: 0 Loss: 0.010141483865023188
Epoch: 8 Idx: 5000 Loss: 0.013177122608026472
Epoch: 9 Idx: 0 Loss: 0.01223218280039693
Epoch: 9 Idx: 5000 Loss: 0.007636966596547385
Epoch: 10 Idx: 0 Loss: 0.021586338367289598
Epoch: 10 Idx: 5000 Loss: 0.006850190066861341
Epoch: 11 Idx: 0 Loss: 0.00801577962727075
Epoch: 11 Idx: 5000 Loss: 0.007780509895535767
Epoch: 12 Idx: 0 Loss: 0.009089069703929021
Epoch: 12 Idx: 5000 Loss: 0.017251224611423525
Epoch: 13 Idx: 0 Loss: 0.007899008885917685
Epoch: 13 Idx: 5000 Loss: 0.022630503700752078
Epoch: 14 Idx: 0 Loss: 0.024351526533755902
Epoch: 14 Idx: 5000 Loss: 0.019174312816206632
Epoch: 15 Idx: 0 Loss: 0.015525396111835664
Epoch: 15 Idx: 5000 Loss: 0.01785030300090029
Epoch: 16 Idx: 0 Loss: 0.027226997681686967
Epoch: 16 Idx: 5000 Loss: 0.02162204239793081
Epoch: 17 Idx: 0 Loss: 0.008273734554713544
Epoch: 17 Idx: 5000 Loss: 0.04094492329238083
Epoch: 18 Idx: 0 Loss: 0.008912122110246265
Epoch: 18 Idx: 5000 Loss: 0.02333418285614768
Epoch: 19 Idx: 0 Loss: 0.021329432507878797
Epoch: 19 Idx: 5000 Loss: 0.011949524410432451
Epoch: 20 Idx: 0 Loss: 0.009496056150929584
Epoch: 20 Idx: 5000 Loss: 0.015196301229443893
Epoch: 21 Idx: 0 Loss: 0.018706810862093123
Epoch: 21 Idx: 5000 Loss: 0.025152403058696992
Epoch: 22 Idx: 0 Loss: 0.010625273110934553
Epoch: 22 Idx: 5000 Loss: 0.03599617716655792
Epoch: 23 Idx: 0 Loss: 0.017841783200877405
Epoch: 23 Idx: 5000 Loss: 0.007075033536375192
Epoch: 24 Idx: 0 Loss: 0.013714691203947478
Epoch: 24 Idx: 5000 Loss: 0.03081240365911462
Epoch: 25 Idx: 0 Loss: 0.010936427342359546
Epoch: 25 Idx: 5000 Loss: 0.01010983907439452
Epoch: 26 Idx: 0 Loss: 0.010329824498696065
Epoch: 26 Idx: 5000 Loss: 0.010349893572963953
Epoch: 27 Idx: 0 Loss: 0.021291861940794552
Epoch: 27 Idx: 5000 Loss: 0.010577921678816793
Epoch: 28 Idx: 0 Loss: 0.01047623124750971
Epoch: 28 Idx: 5000 Loss: 0.016152552522295555
Epoch: 29 Idx: 0 Loss: 0.012179533815768685
Epoch: 29 Idx: 5000 Loss: 0.016168337509866283
Epoch: 30 Idx: 0 Loss: 0.015808845233604003
Epoch: 30 Idx: 5000 Loss: 0.015876532212639915
Epoch: 31 Idx: 0 Loss: 0.048731039728112324
Epoch: 31 Idx: 5000 Loss: 0.020700498775367764
Epoch: 32 Idx: 0 Loss: 0.016068784159408423
Epoch: 32 Idx: 5000 Loss: 0.01035593424414809
Epoch: 33 Idx: 0 Loss: 0.02245737486941567
Epoch: 33 Idx: 5000 Loss: 0.012539089935665448
Epoch: 34 Idx: 0 Loss: 0.02759278637273819
Epoch: 34 Idx: 5000 Loss: 0.010906955626214458
Epoch: 35 Idx: 0 Loss: 0.01620542432140154
Epoch: 35 Idx: 5000 Loss: 0.0229518094317495
Epoch: 36 Idx: 0 Loss: 0.013120655908051688
Epoch: 36 Idx: 5000 Loss: 0.00899307760945729
Epoch: 37 Idx: 0 Loss: 0.016252427689633878
Epoch: 37 Idx: 5000 Loss: 0.030545293449320887
Epoch: 38 Idx: 0 Loss: 0.019804858448918168
Epoch: 38 Idx: 5000 Loss: 0.010793630173668616
Epoch: 39 Idx: 0 Loss: 0.016624145108112717
Epoch: 39 Idx: 5000 Loss: 0.009495015437788721
Epoch: 40 Idx: 0 Loss: 0.01284045031143024
Epoch: 40 Idx: 5000 Loss: 0.017303045497472254
Epoch: 41 Idx: 0 Loss: 0.008812616938780778
Epoch: 41 Idx: 5000 Loss: 0.008974412303637354
Epoch: 42 Idx: 0 Loss: 0.01277111862083071
Epoch: 42 Idx: 5000 Loss: 0.006791205144427003
Epoch: 43 Idx: 0 Loss: 0.015624149930561233
Epoch: 43 Idx: 5000 Loss: 0.010833352971144116
Epoch: 44 Idx: 0 Loss: 0.006513456932372871
Epoch: 44 Idx: 5000 Loss: 0.018467150708335045
Epoch: 45 Idx: 0 Loss: 0.012890468057089863
Epoch: 45 Idx: 5000 Loss: 0.0201683113003926
Epoch: 46 Idx: 0 Loss: 0.014082819054918183
Epoch: 46 Idx: 5000 Loss: 0.013822593897668939
Epoch: 47 Idx: 0 Loss: 0.015691618794851727
Epoch: 47 Idx: 5000 Loss: 0.02970206165405616
Epoch: 48 Idx: 0 Loss: 0.007317041027806442
Epoch: 48 Idx: 5000 Loss: 0.013234154915403223
Epoch: 49 Idx: 0 Loss: 0.011964273840486803
Epoch: 49 Idx: 5000 Loss: 0.014475306758892846
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.21723960182001922
Epoch: 1 Idx: 0 Loss: 0.01444688086744422
Epoch: 2 Idx: 0 Loss: 0.011326863076766763
Epoch: 3 Idx: 0 Loss: 0.040073823594098314
Epoch: 4 Idx: 0 Loss: 0.010738681751528829
Epoch: 5 Idx: 0 Loss: 0.029194770913928927
Epoch: 6 Idx: 0 Loss: 0.011335171765296583
Epoch: 7 Idx: 0 Loss: 0.022128833855602364
Epoch: 8 Idx: 0 Loss: 0.019510471648938325
Epoch: 9 Idx: 0 Loss: 0.018055805221996412
Epoch: 10 Idx: 0 Loss: 0.007628761915411961
Epoch: 11 Idx: 0 Loss: 0.00716305934358227
Epoch: 12 Idx: 0 Loss: 0.014937412349338274
Epoch: 13 Idx: 0 Loss: 0.034405265577788495
Epoch: 14 Idx: 0 Loss: 0.03140955471900992
Epoch: 15 Idx: 0 Loss: 0.010074152393861726
Epoch: 16 Idx: 0 Loss: 0.00968556893324861
Epoch: 17 Idx: 0 Loss: 0.013425665309506297
Epoch: 18 Idx: 0 Loss: 0.009341874143058851
Epoch: 19 Idx: 0 Loss: 0.015318092436065432
Epoch: 20 Idx: 0 Loss: 0.011748641106908753
Epoch: 21 Idx: 0 Loss: 0.005877062049192937
Epoch: 22 Idx: 0 Loss: 0.01194945656548308
Epoch: 23 Idx: 0 Loss: 0.008753578173193974
Epoch: 24 Idx: 0 Loss: 0.023802366878346495
Epoch: 25 Idx: 0 Loss: 0.010984845695453348
Epoch: 26 Idx: 0 Loss: 0.01959819382119305
Epoch: 27 Idx: 0 Loss: 0.0166756002144616
Epoch: 28 Idx: 0 Loss: 0.0146682335551624
Epoch: 29 Idx: 0 Loss: 0.014956527362385038
Epoch: 30 Idx: 0 Loss: 0.02500663209938078
Epoch: 31 Idx: 0 Loss: 0.036496816623883814
Epoch: 32 Idx: 0 Loss: 0.015917403854687224
Epoch: 33 Idx: 0 Loss: 0.012864807971239137
Epoch: 34 Idx: 0 Loss: 0.019765645889102745
Epoch: 35 Idx: 0 Loss: 0.014306379783138923
Epoch: 36 Idx: 0 Loss: 0.02530027380640463
Epoch: 37 Idx: 0 Loss: 0.014666283846973504
Epoch: 38 Idx: 0 Loss: 0.016038681187327423
Epoch: 39 Idx: 0 Loss: 0.011472163517797592
Epoch: 40 Idx: 0 Loss: 0.014583894398451213
Epoch: 41 Idx: 0 Loss: 0.009441190556647439
Epoch: 42 Idx: 0 Loss: 0.009176444834582083
Epoch: 43 Idx: 0 Loss: 0.02072413683513131
Epoch: 44 Idx: 0 Loss: 0.011928116083870916
Epoch: 45 Idx: 0 Loss: 0.00963433202740899
Epoch: 46 Idx: 0 Loss: 0.03642233501148319
Epoch: 47 Idx: 0 Loss: 0.013403758407278988
Epoch: 48 Idx: 0 Loss: 0.014457329711174745
Epoch: 49 Idx: 0 Loss: 0.009644755552428226
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.1543697392781115
Epoch: 0 Idx: 5000 Loss: 0.017650969106624097
Epoch: 1 Idx: 0 Loss: 0.010761997816049074
Epoch: 1 Idx: 5000 Loss: 0.028997959435771836
Epoch: 2 Idx: 0 Loss: 0.017803644926349536
Epoch: 2 Idx: 5000 Loss: 0.013566654157241977
Epoch: 3 Idx: 0 Loss: 0.015756958174455563
Epoch: 3 Idx: 5000 Loss: 0.005744891495914683
Epoch: 4 Idx: 0 Loss: 0.02509296526034266
Epoch: 4 Idx: 5000 Loss: 0.012021170905038065
Epoch: 5 Idx: 0 Loss: 0.007095237404530327
Epoch: 5 Idx: 5000 Loss: 0.01534308955456807
Epoch: 6 Idx: 0 Loss: 0.031267164764330134
Epoch: 6 Idx: 5000 Loss: 0.01445106108376655
Epoch: 7 Idx: 0 Loss: 0.024847700692216527
Epoch: 7 Idx: 5000 Loss: 0.02040840742248943
Epoch: 8 Idx: 0 Loss: 0.018438591893572498
Epoch: 8 Idx: 5000 Loss: 0.015753039369455307
Epoch: 9 Idx: 0 Loss: 0.012236337030033144
Epoch: 9 Idx: 5000 Loss: 0.019938575767593128
Epoch: 10 Idx: 0 Loss: 0.0250386628830088
Epoch: 10 Idx: 5000 Loss: 0.016046120055134394
Epoch: 11 Idx: 0 Loss: 0.01612058086133692
Epoch: 11 Idx: 5000 Loss: 0.010015757317068632
Epoch: 12 Idx: 0 Loss: 0.01563269011917216
Epoch: 12 Idx: 5000 Loss: 0.02371214824514865
Epoch: 13 Idx: 0 Loss: 0.031887140824805066
Epoch: 13 Idx: 5000 Loss: 0.02342389594013645
Epoch: 14 Idx: 0 Loss: 0.01357645027628165
Epoch: 14 Idx: 5000 Loss: 0.013881123465761865
Epoch: 15 Idx: 0 Loss: 0.007527637765781768
Epoch: 15 Idx: 5000 Loss: 0.015796909693445993
Epoch: 16 Idx: 0 Loss: 0.009493378232769276
Epoch: 16 Idx: 5000 Loss: 0.007510696641092889
Epoch: 17 Idx: 0 Loss: 0.012014117146906055
Epoch: 17 Idx: 5000 Loss: 0.019396587070945923
Epoch: 18 Idx: 0 Loss: 0.008708155947930424
Epoch: 18 Idx: 5000 Loss: 0.017143099081250963
Epoch: 19 Idx: 0 Loss: 0.008437605445398044
Epoch: 19 Idx: 5000 Loss: 0.01354677300023625
Epoch: 20 Idx: 0 Loss: 0.017620183609065115
Epoch: 20 Idx: 5000 Loss: 0.011073909119500161
Epoch: 21 Idx: 0 Loss: 0.005038479699696199
Epoch: 21 Idx: 5000 Loss: 0.01048721314981763
Epoch: 22 Idx: 0 Loss: 0.007966076345735474
Epoch: 22 Idx: 5000 Loss: 0.018739454664298598
Epoch: 23 Idx: 0 Loss: 0.007757531696619159
Epoch: 23 Idx: 5000 Loss: 0.03659280521121977
Epoch: 24 Idx: 0 Loss: 0.02476335774420718
Epoch: 24 Idx: 5000 Loss: 0.02095228069725702
Epoch: 25 Idx: 0 Loss: 0.012906242436176291
Epoch: 25 Idx: 5000 Loss: 0.011616069101340293
Epoch: 26 Idx: 0 Loss: 0.014822812947162721
Epoch: 26 Idx: 5000 Loss: 0.018790614168706463
Epoch: 27 Idx: 0 Loss: 0.006942263149483542
Epoch: 27 Idx: 5000 Loss: 0.010179408278299835
Epoch: 28 Idx: 0 Loss: 0.02244564516755325
Epoch: 28 Idx: 5000 Loss: 0.02051479284901126
Epoch: 29 Idx: 0 Loss: 0.025626546450681718
Epoch: 29 Idx: 5000 Loss: 0.009761000547467535
Epoch: 30 Idx: 0 Loss: 0.009838134809824498
Epoch: 30 Idx: 5000 Loss: 0.020540807486456467
Epoch: 31 Idx: 0 Loss: 0.014736761886808149
Epoch: 31 Idx: 5000 Loss: 0.013136501206212393
Epoch: 32 Idx: 0 Loss: 0.016777205647024562
Epoch: 32 Idx: 5000 Loss: 0.00453878500406341
Epoch: 33 Idx: 0 Loss: 0.006938947780878628
Epoch: 33 Idx: 5000 Loss: 0.015543188190689075
Epoch: 34 Idx: 0 Loss: 0.015831297102823595
Epoch: 34 Idx: 5000 Loss: 0.023251958745958937
Epoch: 35 Idx: 0 Loss: 0.00617609886527243
Epoch: 35 Idx: 5000 Loss: 0.020393868119342115
Epoch: 36 Idx: 0 Loss: 0.03067001120796911
Epoch: 36 Idx: 5000 Loss: 0.017405395837590102
Epoch: 37 Idx: 0 Loss: 0.021270612803909142
Epoch: 37 Idx: 5000 Loss: 0.028738265449742693
Epoch: 38 Idx: 0 Loss: 0.0069500556548196795
Epoch: 38 Idx: 5000 Loss: 0.012240675823053965
Epoch: 39 Idx: 0 Loss: 0.013799454420327394
Epoch: 39 Idx: 5000 Loss: 0.015300323638395636
Epoch: 40 Idx: 0 Loss: 0.00459397542646507
Epoch: 40 Idx: 5000 Loss: 0.008990120876394161
Epoch: 41 Idx: 0 Loss: 0.006979415555206164
Epoch: 41 Idx: 5000 Loss: 0.024336442167001086
Epoch: 42 Idx: 0 Loss: 0.015123229460690593
Epoch: 42 Idx: 5000 Loss: 0.008112000472246167
Epoch: 43 Idx: 0 Loss: 0.015667212850694116
Epoch: 43 Idx: 5000 Loss: 0.02598639834337817
Epoch: 44 Idx: 0 Loss: 0.009249815101815521
Epoch: 44 Idx: 5000 Loss: 0.01207394507751666
Epoch: 45 Idx: 0 Loss: 0.013841996731067282
Epoch: 45 Idx: 5000 Loss: 0.024576065007118012
Epoch: 46 Idx: 0 Loss: 0.009221201812000476
Epoch: 46 Idx: 5000 Loss: 0.01631197056091414
Epoch: 47 Idx: 0 Loss: 0.011261897371480542
Epoch: 47 Idx: 5000 Loss: 0.006416988681018995
Epoch: 48 Idx: 0 Loss: 0.013045531904838328
Epoch: 48 Idx: 5000 Loss: 0.01376749662654812
Epoch: 49 Idx: 0 Loss: 0.013525679231433621
Epoch: 49 Idx: 5000 Loss: 0.014176637727218864
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.20327521587347655
Epoch: 1 Idx: 0 Loss: 0.010328218393957221
Epoch: 2 Idx: 0 Loss: 0.009383874466584587
Epoch: 3 Idx: 0 Loss: 0.021599461724024997
Epoch: 4 Idx: 0 Loss: 0.025070431123654122
Epoch: 5 Idx: 0 Loss: 0.009073650978968768
Epoch: 6 Idx: 0 Loss: 0.00617022231295806
Epoch: 7 Idx: 0 Loss: 0.008076203917410723
Epoch: 8 Idx: 0 Loss: 0.011899466873726987
Epoch: 9 Idx: 0 Loss: 0.011522731801046553
Epoch: 10 Idx: 0 Loss: 0.007936771472287895
Epoch: 11 Idx: 0 Loss: 0.012980885874523727
Epoch: 12 Idx: 0 Loss: 0.010771692843853415
Epoch: 13 Idx: 0 Loss: 0.030528186411441217
Epoch: 14 Idx: 0 Loss: 0.009349562108254078
Epoch: 15 Idx: 0 Loss: 0.033075761331970634
Epoch: 16 Idx: 0 Loss: 0.015581502241191543
Epoch: 17 Idx: 0 Loss: 0.028128706587527065
Epoch: 18 Idx: 0 Loss: 0.020021503016730058
Epoch: 19 Idx: 0 Loss: 0.03644176225909903
Epoch: 20 Idx: 0 Loss: 0.032344800645562395
Epoch: 21 Idx: 0 Loss: 0.0066038791774394355
Epoch: 22 Idx: 0 Loss: 0.017114336362471526
Epoch: 23 Idx: 0 Loss: 0.006250322201243276
Epoch: 24 Idx: 0 Loss: 0.011594768875573853
Epoch: 25 Idx: 0 Loss: 0.011281895524567554
Epoch: 26 Idx: 0 Loss: 0.04320086970826019
Epoch: 27 Idx: 0 Loss: 0.01851724397925554
Epoch: 28 Idx: 0 Loss: 0.011049910817036098
Epoch: 29 Idx: 0 Loss: 0.04221136969747898
Epoch: 30 Idx: 0 Loss: 0.0409262774438301
Epoch: 31 Idx: 0 Loss: 0.010331845246797623
Epoch: 32 Idx: 0 Loss: 0.007708701742931753
Epoch: 33 Idx: 0 Loss: 0.02148788781380844
Epoch: 34 Idx: 0 Loss: 0.020119272225891938
Epoch: 35 Idx: 0 Loss: 0.012294128693488216
Epoch: 36 Idx: 0 Loss: 0.017806904599016737
Epoch: 37 Idx: 0 Loss: 0.007236262388479967
Epoch: 38 Idx: 0 Loss: 0.005788491203722916
Epoch: 39 Idx: 0 Loss: 0.010283355070080286
Epoch: 40 Idx: 0 Loss: 0.025828417639301614
Epoch: 41 Idx: 0 Loss: 0.01519618371215978
Epoch: 42 Idx: 0 Loss: 0.018442572596898812
Epoch: 43 Idx: 0 Loss: 0.023010081063562473
Epoch: 44 Idx: 0 Loss: 0.004095724464128056
Epoch: 45 Idx: 0 Loss: 0.027636694946213212
Epoch: 46 Idx: 0 Loss: 0.007729769717788748
Epoch: 47 Idx: 0 Loss: 0.011684566695757926
Epoch: 48 Idx: 0 Loss: 0.01851745883320747
Epoch: 49 Idx: 0 Loss: 0.005879096855020917
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.6875, 0.7333333333333333, 0.7096774193548386, 0.7236842105263157, 0.6962025316455696)
Performance for  [('ekaw', 'sigkdd')] is : (0.8461538461538461, 1.0, 0.9166666666666666, 0.9649122807017543, 0.8730158730158731)
Performance for  [('conference', 'edas')] is : (0.75, 0.8823529411764706, 0.8108108108108107, 0.8522727272727272, 0.7731958762886597)
Performance for  [('cmt', 'ekaw')] is : (0.46153846153846156, 0.5454545454545454, 0.4999999999999999, 0.5263157894736842, 0.4761904761904762)
Performance for  [('confOf', 'edas')] is : (0.5416666666666666, 0.6842105263157895, 0.6046511627906976, 0.65, 0.5652173913043478)
Performance for  [('iasted', 'sigkdd')] is : (0.375, 0.8, 0.5106382978723405, 0.6521739130434783, 0.4195804195804196)
Performance for  [('confOf', 'iasted')] is : (0.875, 0.7777777777777778, 0.823529411764706, 0.7954545454545454, 0.8536585365853658)
Final Results: [0.64812271 0.77473273 0.69656768 0.7378305  0.66529444]
Threshold:  0.872
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2af89c63eaf0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc274>
Subject: Job 4142704: <python main.py 4 2 False True> in cluster <dcc> Done

Job <python main.py 4 2 False True> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:24 2020
Job was executed on host(s) <dccxc274>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 07:37:31 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:37:31 2020
Terminated at Wed Sep 16 12:22:35 2020
Results reported at Wed Sep 16 12:22:35 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 2 False True
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17065.52 sec.
    Max Memory :                                 4218 MB
    Average Memory :                             4049.46 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39199.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   17109 sec.
    Turnaround time :                            19451 sec.

The output (if any) is above this job summary.

