2020-09-16 07:37:37.187372: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:47.549607: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:37:47.667220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:37:47.667289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:47.669352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:37:47.697003: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:37:47.774566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:37:47.841272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:37:47.894792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:37:47.895149: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 07:37:47.895171: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:37:47.895645: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:37:47.924855: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600010000 Hz
2020-09-16 07:37:47.925080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559d772a3430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:37:47.925100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:37:47.927206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:37:47.927231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.16506857891586274
Epoch: 0 Idx: 5000 Loss: 0.02157915920842888
Epoch: 1 Idx: 0 Loss: 0.010602245290896824
Epoch: 1 Idx: 5000 Loss: 0.007585736690868922
Epoch: 2 Idx: 0 Loss: 0.011269726302502931
Epoch: 2 Idx: 5000 Loss: 0.028247614690996896
Epoch: 3 Idx: 0 Loss: 0.00976565113170556
Epoch: 3 Idx: 5000 Loss: 0.014613156803166041
Epoch: 4 Idx: 0 Loss: 0.006971985123074793
Epoch: 4 Idx: 5000 Loss: 0.010048484915201522
Epoch: 5 Idx: 0 Loss: 0.013728406687278778
Epoch: 5 Idx: 5000 Loss: 0.013854996146726771
Epoch: 6 Idx: 0 Loss: 0.011364175339118442
Epoch: 6 Idx: 5000 Loss: 0.008061658034491943
Epoch: 7 Idx: 0 Loss: 0.010584684844014307
Epoch: 7 Idx: 5000 Loss: 0.011749071441883596
Epoch: 8 Idx: 0 Loss: 0.025597008650245952
Epoch: 8 Idx: 5000 Loss: 0.018464799963672857
Epoch: 9 Idx: 0 Loss: 0.02535838280146671
Epoch: 9 Idx: 5000 Loss: 0.014663727300451266
Epoch: 10 Idx: 0 Loss: 0.009772422756911637
Epoch: 10 Idx: 5000 Loss: 0.015418900476322675
Epoch: 11 Idx: 0 Loss: 0.023302185224110573
Epoch: 11 Idx: 5000 Loss: 0.01292006276850535
Epoch: 12 Idx: 0 Loss: 0.008478618532058536
Epoch: 12 Idx: 5000 Loss: 0.015844376560040088
Epoch: 13 Idx: 0 Loss: 0.00575703671667825
Epoch: 13 Idx: 5000 Loss: 0.008903474277401412
Epoch: 14 Idx: 0 Loss: 0.0234748358908137
Epoch: 14 Idx: 5000 Loss: 0.029852135746997747
Epoch: 15 Idx: 0 Loss: 0.010520291028686258
Epoch: 15 Idx: 5000 Loss: 0.014122216069530935
Epoch: 16 Idx: 0 Loss: 0.010476115525469547
Epoch: 16 Idx: 5000 Loss: 0.0026514378354257737
Epoch: 17 Idx: 0 Loss: 0.019026098609997134
Epoch: 17 Idx: 5000 Loss: 0.018007211496062745
Epoch: 18 Idx: 0 Loss: 0.018463156207200463
Epoch: 18 Idx: 5000 Loss: 0.01566445221300814
Epoch: 19 Idx: 0 Loss: 0.027981317167569165
Epoch: 19 Idx: 5000 Loss: 0.014984911167740221
Epoch: 20 Idx: 0 Loss: 0.007543838883240179
Epoch: 20 Idx: 5000 Loss: 0.008478630700748016
Epoch: 21 Idx: 0 Loss: 0.009304742179957618
Epoch: 21 Idx: 5000 Loss: 0.016181930175164144
Epoch: 22 Idx: 0 Loss: 0.02260958105121497
Epoch: 22 Idx: 5000 Loss: 0.010226783491565021
Epoch: 23 Idx: 0 Loss: 0.03793750567045412
Epoch: 23 Idx: 5000 Loss: 0.018246575555179008
Epoch: 24 Idx: 0 Loss: 0.011812920131285636
Epoch: 24 Idx: 5000 Loss: 0.010559568529087213
Epoch: 25 Idx: 0 Loss: 0.01949762340735743
Epoch: 25 Idx: 5000 Loss: 0.016061085366298265
Epoch: 26 Idx: 0 Loss: 0.008585250567381962
Epoch: 26 Idx: 5000 Loss: 0.012893303033357836
Epoch: 27 Idx: 0 Loss: 0.009966102058699872
Epoch: 27 Idx: 5000 Loss: 0.013696163327363155
Epoch: 28 Idx: 0 Loss: 0.02208675626079801
Epoch: 28 Idx: 5000 Loss: 0.03395127851098279
Epoch: 29 Idx: 0 Loss: 0.013278354831880387
Epoch: 29 Idx: 5000 Loss: 0.013281581883428423
Epoch: 30 Idx: 0 Loss: 0.010108597038133686
Epoch: 30 Idx: 5000 Loss: 0.006981734908847181
Epoch: 31 Idx: 0 Loss: 0.015382236685128378
Epoch: 31 Idx: 5000 Loss: 0.026504330469210077
Epoch: 32 Idx: 0 Loss: 0.02735979000745276
Epoch: 32 Idx: 5000 Loss: 0.00862618024750951
Epoch: 33 Idx: 0 Loss: 0.017428071618461705
Epoch: 33 Idx: 5000 Loss: 0.021075099717523926
Epoch: 34 Idx: 0 Loss: 0.012586822268723636
Epoch: 34 Idx: 5000 Loss: 0.026738014608424725
Epoch: 35 Idx: 0 Loss: 0.01749484686382148
Epoch: 35 Idx: 5000 Loss: 0.008790216725381803
Epoch: 36 Idx: 0 Loss: 0.016264057491883324
Epoch: 36 Idx: 5000 Loss: 0.018913469976842352
Epoch: 37 Idx: 0 Loss: 0.04126031765613471
Epoch: 37 Idx: 5000 Loss: 0.027346378797747973
Epoch: 38 Idx: 0 Loss: 0.010817165377213155
Epoch: 38 Idx: 5000 Loss: 0.026062356366860228
Epoch: 39 Idx: 0 Loss: 0.00885419478660483
Epoch: 39 Idx: 5000 Loss: 0.0185758913426149
Epoch: 40 Idx: 0 Loss: 0.011101451050567751
Epoch: 40 Idx: 5000 Loss: 0.00919390106890166
Epoch: 41 Idx: 0 Loss: 0.008514968924664072
Epoch: 41 Idx: 5000 Loss: 0.01268596395145415
Epoch: 42 Idx: 0 Loss: 0.0175764114585527
Epoch: 42 Idx: 5000 Loss: 0.006530050899734276
Epoch: 43 Idx: 0 Loss: 0.013590052805151954
Epoch: 43 Idx: 5000 Loss: 0.02737864080988197
Epoch: 44 Idx: 0 Loss: 0.01102535080160029
Epoch: 44 Idx: 5000 Loss: 0.01578172053455694
Epoch: 45 Idx: 0 Loss: 0.010573184404647407
Epoch: 45 Idx: 5000 Loss: 0.02138212935492467
Epoch: 46 Idx: 0 Loss: 0.009745572716433617
Epoch: 46 Idx: 5000 Loss: 0.02399422063329125
Epoch: 47 Idx: 0 Loss: 0.011868960769803405
Epoch: 47 Idx: 5000 Loss: 0.019652710307654406
Epoch: 48 Idx: 0 Loss: 0.017454082303406074
Epoch: 48 Idx: 5000 Loss: 0.010738351626323552
Epoch: 49 Idx: 0 Loss: 0.006663815397254646
Epoch: 49 Idx: 5000 Loss: 0.02155285476093384
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.22930598855047513
Epoch: 0 Idx: 5000 Loss: 0.015059777883894364
Epoch: 1 Idx: 0 Loss: 0.007758147275210435
Epoch: 1 Idx: 5000 Loss: 0.017444685150490052
Epoch: 2 Idx: 0 Loss: 0.01634697511080795
Epoch: 2 Idx: 5000 Loss: 0.015833329446315082
Epoch: 3 Idx: 0 Loss: 0.014491043715197967
Epoch: 3 Idx: 5000 Loss: 0.018225294590590406
Epoch: 4 Idx: 0 Loss: 0.02026249498568726
Epoch: 4 Idx: 5000 Loss: 0.008842479086027344
Epoch: 5 Idx: 0 Loss: 0.014719558934960504
Epoch: 5 Idx: 5000 Loss: 0.01413301925998418
Epoch: 6 Idx: 0 Loss: 0.015196226943908292
Epoch: 6 Idx: 5000 Loss: 0.025773653296726956
Epoch: 7 Idx: 0 Loss: 0.018735968050824094
Epoch: 7 Idx: 5000 Loss: 0.011016930264972843
Epoch: 8 Idx: 0 Loss: 0.014152155923413078
Epoch: 8 Idx: 5000 Loss: 0.013277264946378889
Epoch: 9 Idx: 0 Loss: 0.013353250495489872
Epoch: 9 Idx: 5000 Loss: 0.011362953812753245
Epoch: 10 Idx: 0 Loss: 0.048452441302207265
Epoch: 10 Idx: 5000 Loss: 0.015435914283092796
Epoch: 11 Idx: 0 Loss: 0.02080842639642
Epoch: 11 Idx: 5000 Loss: 0.012123946158124389
Epoch: 12 Idx: 0 Loss: 0.00806837862787222
Epoch: 12 Idx: 5000 Loss: 0.010361672241238469
Epoch: 13 Idx: 0 Loss: 0.014468939685684194
Epoch: 13 Idx: 5000 Loss: 0.007798917674970799
Epoch: 14 Idx: 0 Loss: 0.009157842816440165
Epoch: 14 Idx: 5000 Loss: 0.021599009027524447
Epoch: 15 Idx: 0 Loss: 0.016025064070908545
Epoch: 15 Idx: 5000 Loss: 0.021085726841033367
Epoch: 16 Idx: 0 Loss: 0.017268567285351144
Epoch: 16 Idx: 5000 Loss: 0.012529928234653315
Epoch: 17 Idx: 0 Loss: 0.009920563212821558
Epoch: 17 Idx: 5000 Loss: 0.02956298942877763
Epoch: 18 Idx: 0 Loss: 0.008240863642718728
Epoch: 18 Idx: 5000 Loss: 0.022582219593167006
Epoch: 19 Idx: 0 Loss: 0.039291813400140256
Epoch: 19 Idx: 5000 Loss: 0.02685412125245637
Epoch: 20 Idx: 0 Loss: 0.02749050349617287
Epoch: 20 Idx: 5000 Loss: 0.011580178946238015
Epoch: 21 Idx: 0 Loss: 0.018437647904586775
Epoch: 21 Idx: 5000 Loss: 0.0190102677281206
Epoch: 22 Idx: 0 Loss: 0.008947766686354003
Epoch: 22 Idx: 5000 Loss: 0.014408883029046773
Epoch: 23 Idx: 0 Loss: 0.015305398741845076
Epoch: 23 Idx: 5000 Loss: 0.020396120508142077
Epoch: 24 Idx: 0 Loss: 0.04673227059292266
Epoch: 24 Idx: 5000 Loss: 0.01136511357898898
Epoch: 25 Idx: 0 Loss: 0.014253075805512714
Epoch: 25 Idx: 5000 Loss: 0.01327885977809979
Epoch: 26 Idx: 0 Loss: 0.0114520439080469
Epoch: 26 Idx: 5000 Loss: 0.014098149433418182
Epoch: 27 Idx: 0 Loss: 0.019650452914690163
Epoch: 27 Idx: 5000 Loss: 0.011562332879432462
Epoch: 28 Idx: 0 Loss: 0.019409531546977096
Epoch: 28 Idx: 5000 Loss: 0.0068576168762872255
Epoch: 29 Idx: 0 Loss: 0.01579356570874448
Epoch: 29 Idx: 5000 Loss: 0.02618445379157096
Epoch: 30 Idx: 0 Loss: 0.021067863933043933
Epoch: 30 Idx: 5000 Loss: 0.014105747278791799
Epoch: 31 Idx: 0 Loss: 0.009612825670705968
Epoch: 31 Idx: 5000 Loss: 0.014737588125835891
Epoch: 32 Idx: 0 Loss: 0.009694342038181683
Epoch: 32 Idx: 5000 Loss: 0.01058073299374028
Epoch: 33 Idx: 0 Loss: 0.008393327792300061
Epoch: 33 Idx: 5000 Loss: 0.014658778057480433
Epoch: 34 Idx: 0 Loss: 0.015075778008338318
Epoch: 34 Idx: 5000 Loss: 0.009426415690435511
Epoch: 35 Idx: 0 Loss: 0.00552654924871097
Epoch: 35 Idx: 5000 Loss: 0.008891013800886994
Epoch: 36 Idx: 0 Loss: 0.020006412328762498
Epoch: 36 Idx: 5000 Loss: 0.035039293037818546
Epoch: 37 Idx: 0 Loss: 0.0271154574672048
Epoch: 37 Idx: 5000 Loss: 0.012918156108920453
Epoch: 38 Idx: 0 Loss: 0.009369810727937659
Epoch: 38 Idx: 5000 Loss: 0.021794029265659487
Epoch: 39 Idx: 0 Loss: 0.02608703725219161
Epoch: 39 Idx: 5000 Loss: 0.006779507116487599
Epoch: 40 Idx: 0 Loss: 0.0137876932281447
Epoch: 40 Idx: 5000 Loss: 0.021336846875301185
Epoch: 41 Idx: 0 Loss: 0.02428087538564295
Epoch: 41 Idx: 5000 Loss: 0.01115015607500414
Epoch: 42 Idx: 0 Loss: 0.021444816120205712
Epoch: 42 Idx: 5000 Loss: 0.019110270233863684
Epoch: 43 Idx: 0 Loss: 0.007331273081702809
Epoch: 43 Idx: 5000 Loss: 0.013777629086087814
Epoch: 44 Idx: 0 Loss: 0.02335101047762438
Epoch: 44 Idx: 5000 Loss: 0.020716791142023287
Epoch: 45 Idx: 0 Loss: 0.027686636395287453
Epoch: 45 Idx: 5000 Loss: 0.010634812738541324
Epoch: 46 Idx: 0 Loss: 0.012429402512186754
Epoch: 46 Idx: 5000 Loss: 0.024899501146197697
Epoch: 47 Idx: 0 Loss: 0.0068735328473723805
Epoch: 47 Idx: 5000 Loss: 0.009321963342964435
Epoch: 48 Idx: 0 Loss: 0.009183511336291458
Epoch: 48 Idx: 5000 Loss: 0.016112565980234292
Epoch: 49 Idx: 0 Loss: 0.008367779721636059
Epoch: 49 Idx: 5000 Loss: 0.017678110094735855
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.1761252687802318
Epoch: 0 Idx: 5000 Loss: 0.032663407155305864
Epoch: 1 Idx: 0 Loss: 0.01828796393396065
Epoch: 1 Idx: 5000 Loss: 0.01157769859194499
Epoch: 2 Idx: 0 Loss: 0.01017303362961534
Epoch: 2 Idx: 5000 Loss: 0.009080192140529795
Epoch: 3 Idx: 0 Loss: 0.010633261557566519
Epoch: 3 Idx: 5000 Loss: 0.011830278962019249
Epoch: 4 Idx: 0 Loss: 0.011000323970820826
Epoch: 4 Idx: 5000 Loss: 0.0062518441614103845
Epoch: 5 Idx: 0 Loss: 0.004855567424287778
Epoch: 5 Idx: 5000 Loss: 0.00945120814373827
Epoch: 6 Idx: 0 Loss: 0.020617799659403312
Epoch: 6 Idx: 5000 Loss: 0.01258011120014315
Epoch: 7 Idx: 0 Loss: 0.009588128140402568
Epoch: 7 Idx: 5000 Loss: 0.040843119606886816
Epoch: 8 Idx: 0 Loss: 0.03784449062301761
Epoch: 8 Idx: 5000 Loss: 0.007773576354508068
Epoch: 9 Idx: 0 Loss: 0.021763279908498703
Epoch: 9 Idx: 5000 Loss: 0.007559187335845978
Epoch: 10 Idx: 0 Loss: 0.02749110051737668
Epoch: 10 Idx: 5000 Loss: 0.03033153836220611
Epoch: 11 Idx: 0 Loss: 0.009178663087929436
Epoch: 11 Idx: 5000 Loss: 0.0203483609657936
Epoch: 12 Idx: 0 Loss: 0.02234124917423946
Epoch: 12 Idx: 5000 Loss: 0.014823460883629154
Epoch: 13 Idx: 0 Loss: 0.004517011813010166
Epoch: 13 Idx: 5000 Loss: 0.03651763484817229
Epoch: 14 Idx: 0 Loss: 0.0184455522756655
Epoch: 14 Idx: 5000 Loss: 0.017622413023982215
Epoch: 15 Idx: 0 Loss: 0.013004884443594687
Epoch: 15 Idx: 5000 Loss: 0.009185553182096049
Epoch: 16 Idx: 0 Loss: 0.010460694810556396
Epoch: 16 Idx: 5000 Loss: 0.0198479284745928
Epoch: 17 Idx: 0 Loss: 0.01315554827749147
Epoch: 17 Idx: 5000 Loss: 0.02874605551410546
Epoch: 18 Idx: 0 Loss: 0.01479632006856072
Epoch: 18 Idx: 5000 Loss: 0.018884129887688297
Epoch: 19 Idx: 0 Loss: 0.015664255074376916
Epoch: 19 Idx: 5000 Loss: 0.018036587186709634
Epoch: 20 Idx: 0 Loss: 0.026235715518824802
Epoch: 20 Idx: 5000 Loss: 0.010622497349613862
Epoch: 21 Idx: 0 Loss: 0.03455523990456313
Epoch: 21 Idx: 5000 Loss: 0.009147168760793278
Epoch: 22 Idx: 0 Loss: 0.005884805597396307
Epoch: 22 Idx: 5000 Loss: 0.025270047541726466
Epoch: 23 Idx: 0 Loss: 0.017386124712136672
Epoch: 23 Idx: 5000 Loss: 0.012836663734299128
Epoch: 24 Idx: 0 Loss: 0.016354936746128628
Epoch: 24 Idx: 5000 Loss: 0.004508918804800287
Epoch: 25 Idx: 0 Loss: 0.017192859189642314
Epoch: 25 Idx: 5000 Loss: 0.013305532861189177
Epoch: 26 Idx: 0 Loss: 0.005204176092577017
Epoch: 26 Idx: 5000 Loss: 0.010155606647577125
Epoch: 27 Idx: 0 Loss: 0.017879337190852267
Epoch: 27 Idx: 5000 Loss: 0.01318125716571944
Epoch: 28 Idx: 0 Loss: 0.01059204825245712
Epoch: 28 Idx: 5000 Loss: 0.006160672627054059
Epoch: 29 Idx: 0 Loss: 0.010773098904908494
Epoch: 29 Idx: 5000 Loss: 0.022833351722237494
Epoch: 30 Idx: 0 Loss: 0.012550995968925373
Epoch: 30 Idx: 5000 Loss: 0.019477539527328867
Epoch: 31 Idx: 0 Loss: 0.011555614332355484
Epoch: 31 Idx: 5000 Loss: 0.017504036475157334
Epoch: 32 Idx: 0 Loss: 0.018562625356132727
Epoch: 32 Idx: 5000 Loss: 0.01595514771376691
Epoch: 33 Idx: 0 Loss: 0.01205720584618876
Epoch: 33 Idx: 5000 Loss: 0.03956365784677319
Epoch: 34 Idx: 0 Loss: 0.011455399535825667
Epoch: 34 Idx: 5000 Loss: 0.015286213579027944
Epoch: 35 Idx: 0 Loss: 0.009316214351255618
Epoch: 35 Idx: 5000 Loss: 0.014649705235212002
Epoch: 36 Idx: 0 Loss: 0.024889567843650033
Epoch: 36 Idx: 5000 Loss: 0.01989383197455984
Epoch: 37 Idx: 0 Loss: 0.010023268984506815
Epoch: 37 Idx: 5000 Loss: 0.051828947357391755
Epoch: 38 Idx: 0 Loss: 0.02238664676611743
Epoch: 38 Idx: 5000 Loss: 0.007564757614830628
Epoch: 39 Idx: 0 Loss: 0.02182503707179756
Epoch: 39 Idx: 5000 Loss: 0.006867681140763202
Epoch: 40 Idx: 0 Loss: 0.006224823754196555
Epoch: 40 Idx: 5000 Loss: 0.00862292843936964
Epoch: 41 Idx: 0 Loss: 0.020084917355408884
Epoch: 41 Idx: 5000 Loss: 0.017877409157587197
Epoch: 42 Idx: 0 Loss: 0.01959716101446264
Epoch: 42 Idx: 5000 Loss: 0.011905179392728329
Epoch: 43 Idx: 0 Loss: 0.018288483643784888
Epoch: 43 Idx: 5000 Loss: 0.01821349286420546
Epoch: 44 Idx: 0 Loss: 0.009357001180583621
Epoch: 44 Idx: 5000 Loss: 0.02822094031063408
Epoch: 45 Idx: 0 Loss: 0.017594345023533325
Epoch: 45 Idx: 5000 Loss: 0.013730989716785508
Epoch: 46 Idx: 0 Loss: 0.02374081443653246
Epoch: 46 Idx: 5000 Loss: 0.02004587741486033
Epoch: 47 Idx: 0 Loss: 0.009047636208077216
Epoch: 47 Idx: 5000 Loss: 0.03414900698621911
Epoch: 48 Idx: 0 Loss: 0.011215640017163866
Epoch: 48 Idx: 5000 Loss: 0.027371369157395783
Epoch: 49 Idx: 0 Loss: 0.010127891881618205
Epoch: 49 Idx: 5000 Loss: 0.012639534807218947
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.1973697319033157
Epoch: 0 Idx: 5000 Loss: 0.030574357633163678
Epoch: 1 Idx: 0 Loss: 0.017176838520662412
Epoch: 1 Idx: 5000 Loss: 0.01642738688667974
Epoch: 2 Idx: 0 Loss: 0.013903943316917178
Epoch: 2 Idx: 5000 Loss: 0.014395564665924176
Epoch: 3 Idx: 0 Loss: 0.00457510874833115
Epoch: 3 Idx: 5000 Loss: 0.015938635250505796
Epoch: 4 Idx: 0 Loss: 0.024299536013605367
Epoch: 4 Idx: 5000 Loss: 0.013694863540397471
Epoch: 5 Idx: 0 Loss: 0.012501234268614783
Epoch: 5 Idx: 5000 Loss: 0.009610919331098136
Epoch: 6 Idx: 0 Loss: 0.015970383518232895
Epoch: 6 Idx: 5000 Loss: 0.040280419223648924
Epoch: 7 Idx: 0 Loss: 0.02768808427841177
Epoch: 7 Idx: 5000 Loss: 0.011232529173288174
Epoch: 8 Idx: 0 Loss: 0.016560690265260903
Epoch: 8 Idx: 5000 Loss: 0.02335261369642908
Epoch: 9 Idx: 0 Loss: 0.010789183041568388
Epoch: 9 Idx: 5000 Loss: 0.012692789705569064
Epoch: 10 Idx: 0 Loss: 0.015709008718305873
Epoch: 10 Idx: 5000 Loss: 0.018405645177454643
Epoch: 11 Idx: 0 Loss: 0.015275745605542321
Epoch: 11 Idx: 5000 Loss: 0.028211285235284194
Epoch: 12 Idx: 0 Loss: 0.00959635860086646
Epoch: 12 Idx: 5000 Loss: 0.021961876842062567
Epoch: 13 Idx: 0 Loss: 0.011250697794157757
Epoch: 13 Idx: 5000 Loss: 0.014861748528523296
Epoch: 14 Idx: 0 Loss: 0.009831935201684893
Epoch: 14 Idx: 5000 Loss: 0.018108257119224522
Epoch: 15 Idx: 0 Loss: 0.010239283124211093
Epoch: 15 Idx: 5000 Loss: 0.020015074018108144
Epoch: 16 Idx: 0 Loss: 0.008777115364137032
Epoch: 16 Idx: 5000 Loss: 0.011576545681180281
Epoch: 17 Idx: 0 Loss: 0.00938393281990773
Epoch: 17 Idx: 5000 Loss: 0.008830324979880263
Epoch: 18 Idx: 0 Loss: 0.027475387084932197
Epoch: 18 Idx: 5000 Loss: 0.010238668823821413
Epoch: 19 Idx: 0 Loss: 0.021894444687635864
Epoch: 19 Idx: 5000 Loss: 0.0170273097996032
Epoch: 20 Idx: 0 Loss: 0.014090201848120786
Epoch: 20 Idx: 5000 Loss: 0.016944470482061234
Epoch: 21 Idx: 0 Loss: 0.015415674280093963
Epoch: 21 Idx: 5000 Loss: 0.00767021506548335
Epoch: 22 Idx: 0 Loss: 0.008802280665978794
Epoch: 22 Idx: 5000 Loss: 0.0163927432144799
Epoch: 23 Idx: 0 Loss: 0.017800839316839
Epoch: 23 Idx: 5000 Loss: 0.024867003266180607
Epoch: 24 Idx: 0 Loss: 0.010600997499707089
Epoch: 24 Idx: 5000 Loss: 0.010918124464481978
Epoch: 25 Idx: 0 Loss: 0.0137394874733913
Epoch: 25 Idx: 5000 Loss: 0.006918738090148598
Epoch: 26 Idx: 0 Loss: 0.009004851752922911
Epoch: 26 Idx: 5000 Loss: 0.0184652651141023
Epoch: 27 Idx: 0 Loss: 0.01540308812033165
Epoch: 27 Idx: 5000 Loss: 0.01650085421710666
Epoch: 28 Idx: 0 Loss: 0.022037146836526463
Epoch: 28 Idx: 5000 Loss: 0.0077711700359231915
Epoch: 29 Idx: 0 Loss: 0.020830659640260336
Epoch: 29 Idx: 5000 Loss: 0.01053695526557168
Epoch: 30 Idx: 0 Loss: 0.02276616791852785
Epoch: 30 Idx: 5000 Loss: 0.015245105429341311
Epoch: 31 Idx: 0 Loss: 0.0199079921375803
Epoch: 31 Idx: 5000 Loss: 0.006380944303778179
Epoch: 32 Idx: 0 Loss: 0.018958376093147843
Epoch: 32 Idx: 5000 Loss: 0.011186767119904937
Epoch: 33 Idx: 0 Loss: 0.02687225147097779
Epoch: 33 Idx: 5000 Loss: 0.04725338872530846
Epoch: 34 Idx: 0 Loss: 0.017610999882060035
Epoch: 34 Idx: 5000 Loss: 0.026815367629072273
Epoch: 35 Idx: 0 Loss: 0.007513190885942726
Epoch: 35 Idx: 5000 Loss: 0.006983554832983188
Epoch: 36 Idx: 0 Loss: 0.015946412083479727
Epoch: 36 Idx: 5000 Loss: 0.023095894509418565
Epoch: 37 Idx: 0 Loss: 0.0233155252974439
Epoch: 37 Idx: 5000 Loss: 0.010661130407360104
Epoch: 38 Idx: 0 Loss: 0.008923162242574143
Epoch: 38 Idx: 5000 Loss: 0.015997139065920707
Epoch: 39 Idx: 0 Loss: 0.014648888490712345
Epoch: 39 Idx: 5000 Loss: 0.017357668716472444
Epoch: 40 Idx: 0 Loss: 0.02064246136873115
Epoch: 40 Idx: 5000 Loss: 0.014537563701442751
Epoch: 41 Idx: 0 Loss: 0.02645293507737546
Epoch: 41 Idx: 5000 Loss: 0.011067849346167913
Epoch: 42 Idx: 0 Loss: 0.0146943527719001
Epoch: 42 Idx: 5000 Loss: 0.009809595299904597
Epoch: 43 Idx: 0 Loss: 0.013412361641016264
Epoch: 43 Idx: 5000 Loss: 0.006915743984701543
Epoch: 44 Idx: 0 Loss: 0.01525603991885808
Epoch: 44 Idx: 5000 Loss: 0.024752136832932183
Epoch: 45 Idx: 0 Loss: 0.030333564422828505
Epoch: 45 Idx: 5000 Loss: 0.02328721138153362
Epoch: 46 Idx: 0 Loss: 0.011509854019641401
Epoch: 46 Idx: 5000 Loss: 0.00833510334094954
Epoch: 47 Idx: 0 Loss: 0.02691158451926431
Epoch: 47 Idx: 5000 Loss: 0.012626482829732201
Epoch: 48 Idx: 0 Loss: 0.02486668452378582
Epoch: 48 Idx: 5000 Loss: 0.01345522015400906
Epoch: 49 Idx: 0 Loss: 0.02321663190769193
Epoch: 49 Idx: 5000 Loss: 0.024006404982717666
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.20342551274191384
Epoch: 1 Idx: 0 Loss: 0.02440093093045298
Epoch: 2 Idx: 0 Loss: 0.017872316777045705
Epoch: 3 Idx: 0 Loss: 0.042014919562582326
Epoch: 4 Idx: 0 Loss: 0.009953446317601065
Epoch: 5 Idx: 0 Loss: 0.029262923930306932
Epoch: 6 Idx: 0 Loss: 0.013412837730580829
Epoch: 7 Idx: 0 Loss: 0.0076016469123899606
Epoch: 8 Idx: 0 Loss: 0.028924839095874892
Epoch: 9 Idx: 0 Loss: 0.0038961915927818776
Epoch: 10 Idx: 0 Loss: 0.009744928349975443
Epoch: 11 Idx: 0 Loss: 0.006393311468764657
Epoch: 12 Idx: 0 Loss: 0.009518438553334506
Epoch: 13 Idx: 0 Loss: 0.004748851399643192
Epoch: 14 Idx: 0 Loss: 0.02740453121566192
Epoch: 15 Idx: 0 Loss: 0.013742979836985166
Epoch: 16 Idx: 0 Loss: 0.028504405144271987
Epoch: 17 Idx: 0 Loss: 0.019389652207340506
Epoch: 18 Idx: 0 Loss: 0.010447642505257846
Epoch: 19 Idx: 0 Loss: 0.010362944554379482
Epoch: 20 Idx: 0 Loss: 0.00804878468605663
Epoch: 21 Idx: 0 Loss: 0.011484395232898086
Epoch: 22 Idx: 0 Loss: 0.00462816934127285
Epoch: 23 Idx: 0 Loss: 0.024731229483993703
Epoch: 24 Idx: 0 Loss: 0.027633485251842938
Epoch: 25 Idx: 0 Loss: 0.023978537708574665
Epoch: 26 Idx: 0 Loss: 0.017306813824918763
Epoch: 27 Idx: 0 Loss: 0.013491851636584326
Epoch: 28 Idx: 0 Loss: 0.00814691101139835
Epoch: 29 Idx: 0 Loss: 0.00937044049118815
Epoch: 30 Idx: 0 Loss: 0.011210601270952475
Epoch: 31 Idx: 0 Loss: 0.013303772247213675
Epoch: 32 Idx: 0 Loss: 0.015558811922015149
Epoch: 33 Idx: 0 Loss: 0.012206857048229006
Epoch: 34 Idx: 0 Loss: 0.0437861447510155
Epoch: 35 Idx: 0 Loss: 0.009880816850590661
Epoch: 36 Idx: 0 Loss: 0.051415876821665735
Epoch: 37 Idx: 0 Loss: 0.013728296138558888
Epoch: 38 Idx: 0 Loss: 0.014582869925980096
Epoch: 39 Idx: 0 Loss: 0.012826980164006702
Epoch: 40 Idx: 0 Loss: 0.014720780713488289
Epoch: 41 Idx: 0 Loss: 0.025395446503285637
Epoch: 42 Idx: 0 Loss: 0.021849691205542927
Epoch: 43 Idx: 0 Loss: 0.019475226037969286
Epoch: 44 Idx: 0 Loss: 0.01024990755984256
Epoch: 45 Idx: 0 Loss: 0.021847480743302082
Epoch: 46 Idx: 0 Loss: 0.007449312068434407
Epoch: 47 Idx: 0 Loss: 0.035546083893567615
Epoch: 48 Idx: 0 Loss: 0.01872417296784909
Epoch: 49 Idx: 0 Loss: 0.014933230367579393
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.15502977173996638
Epoch: 0 Idx: 5000 Loss: 0.010453943665173144
Epoch: 1 Idx: 0 Loss: 0.03784789717543338
Epoch: 1 Idx: 5000 Loss: 0.02501053427199669
Epoch: 2 Idx: 0 Loss: 0.009584383792445183
Epoch: 2 Idx: 5000 Loss: 0.00984672873837843
Epoch: 3 Idx: 0 Loss: 0.010522905717342086
Epoch: 3 Idx: 5000 Loss: 0.008346341893050866
Epoch: 4 Idx: 0 Loss: 0.013032821731686923
Epoch: 4 Idx: 5000 Loss: 0.010743867614432516
Epoch: 5 Idx: 0 Loss: 0.018564579527751215
Epoch: 5 Idx: 5000 Loss: 0.012073966593530945
Epoch: 6 Idx: 0 Loss: 0.015254971007569656
Epoch: 6 Idx: 5000 Loss: 0.005955058917841524
Epoch: 7 Idx: 0 Loss: 0.027428371364720962
Epoch: 7 Idx: 5000 Loss: 0.011957812071729461
Epoch: 8 Idx: 0 Loss: 0.013445134245861816
Epoch: 8 Idx: 5000 Loss: 0.020421089882661475
Epoch: 9 Idx: 0 Loss: 0.02313378387745431
Epoch: 9 Idx: 5000 Loss: 0.018013196201523293
Epoch: 10 Idx: 0 Loss: 0.01207127958019707
Epoch: 10 Idx: 5000 Loss: 0.02595036471053909
Epoch: 11 Idx: 0 Loss: 0.04523694357100765
Epoch: 11 Idx: 5000 Loss: 0.019745954666725025
Epoch: 12 Idx: 0 Loss: 0.008121530216144073
Epoch: 12 Idx: 5000 Loss: 0.024757941548190606
Epoch: 13 Idx: 0 Loss: 0.013881674104138254
Epoch: 13 Idx: 5000 Loss: 0.014260689158721494
Epoch: 14 Idx: 0 Loss: 0.03474298969581412
Epoch: 14 Idx: 5000 Loss: 0.014586731458870737
Epoch: 15 Idx: 0 Loss: 0.0210202566440318
Epoch: 15 Idx: 5000 Loss: 0.014353886467497915
Epoch: 16 Idx: 0 Loss: 0.02397357899812572
Epoch: 16 Idx: 5000 Loss: 0.023754613836924086
Epoch: 17 Idx: 0 Loss: 0.005878106028390879
Epoch: 17 Idx: 5000 Loss: 0.0113435528736203
Epoch: 18 Idx: 0 Loss: 0.01921300327224938
Epoch: 18 Idx: 5000 Loss: 0.026715496038181838
Epoch: 19 Idx: 0 Loss: 0.017596140701875373
Epoch: 19 Idx: 5000 Loss: 0.011591411484280636
Epoch: 20 Idx: 0 Loss: 0.026527090877857644
Epoch: 20 Idx: 5000 Loss: 0.01193750719680968
Epoch: 21 Idx: 0 Loss: 0.00819609618891693
Epoch: 21 Idx: 5000 Loss: 0.016502214625238213
Epoch: 22 Idx: 0 Loss: 0.013311316156924158
Epoch: 22 Idx: 5000 Loss: 0.018751277129414365
Epoch: 23 Idx: 0 Loss: 0.012763025816558131
Epoch: 23 Idx: 5000 Loss: 0.021772873164891265
Epoch: 24 Idx: 0 Loss: 0.008949915740210776
Epoch: 24 Idx: 5000 Loss: 0.01856875872439967
Epoch: 25 Idx: 0 Loss: 0.029986453543959363
Epoch: 25 Idx: 5000 Loss: 0.013063826825775447
Epoch: 26 Idx: 0 Loss: 0.007206523160764955
Epoch: 26 Idx: 5000 Loss: 0.03141939493345078
Epoch: 27 Idx: 0 Loss: 0.010493074826547719
Epoch: 27 Idx: 5000 Loss: 0.011526373142413275
Epoch: 28 Idx: 0 Loss: 0.012047708158073284
Epoch: 28 Idx: 5000 Loss: 0.01969907732262933
Epoch: 29 Idx: 0 Loss: 0.029754452741080017
Epoch: 29 Idx: 5000 Loss: 0.010112090141552031
Epoch: 30 Idx: 0 Loss: 0.013397394098153282
Epoch: 30 Idx: 5000 Loss: 0.0072287908995704135
Epoch: 31 Idx: 0 Loss: 0.008645288584668464
Epoch: 31 Idx: 5000 Loss: 0.016406302463140104
Epoch: 32 Idx: 0 Loss: 0.019081203935276923
Epoch: 32 Idx: 5000 Loss: 0.03787619714272284
Epoch: 33 Idx: 0 Loss: 0.009232474631609535
Epoch: 33 Idx: 5000 Loss: 0.01353412605566887
Epoch: 34 Idx: 0 Loss: 0.04306224515932505
Epoch: 34 Idx: 5000 Loss: 0.048321410468538724
Epoch: 35 Idx: 0 Loss: 0.012271546466289102
Epoch: 35 Idx: 5000 Loss: 0.03056467159120168
Epoch: 36 Idx: 0 Loss: 0.011881159818229757
Epoch: 36 Idx: 5000 Loss: 0.011205942874548442
Epoch: 37 Idx: 0 Loss: 0.020992759673972364
Epoch: 37 Idx: 5000 Loss: 0.015140237166106997
Epoch: 38 Idx: 0 Loss: 0.01880946645960184
Epoch: 38 Idx: 5000 Loss: 0.008887443805527473
Epoch: 39 Idx: 0 Loss: 0.01111389761907797
Epoch: 39 Idx: 5000 Loss: 0.009796216664331255
Epoch: 40 Idx: 0 Loss: 0.007392163278296722
Epoch: 40 Idx: 5000 Loss: 0.012440150612645364
Epoch: 41 Idx: 0 Loss: 0.021625262177903906
Epoch: 41 Idx: 5000 Loss: 0.008802777123543784
Epoch: 42 Idx: 0 Loss: 0.011942999775622628
Epoch: 42 Idx: 5000 Loss: 0.0148479628584741
Epoch: 43 Idx: 0 Loss: 0.042282792703033915
Epoch: 43 Idx: 5000 Loss: 0.014982340211961586
Epoch: 44 Idx: 0 Loss: 0.011608048988882888
Epoch: 44 Idx: 5000 Loss: 0.03137732496531334
Epoch: 45 Idx: 0 Loss: 0.009272167923554522
Epoch: 45 Idx: 5000 Loss: 0.019287521806921795
Epoch: 46 Idx: 0 Loss: 0.014335033810207978
Epoch: 46 Idx: 5000 Loss: 0.008108881424986766
Epoch: 47 Idx: 0 Loss: 0.015579045783166223
Epoch: 47 Idx: 5000 Loss: 0.0107905559242029
Epoch: 48 Idx: 0 Loss: 0.0123426375130531
Epoch: 48 Idx: 5000 Loss: 0.018131062861251757
Epoch: 49 Idx: 0 Loss: 0.017114031628976494
Epoch: 49 Idx: 5000 Loss: 0.009018950980933148
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.19996809923180914
Epoch: 1 Idx: 0 Loss: 0.016861984972864955
Epoch: 2 Idx: 0 Loss: 0.014548574991476326
Epoch: 3 Idx: 0 Loss: 0.010673804975143487
Epoch: 4 Idx: 0 Loss: 0.03811360101976125
Epoch: 5 Idx: 0 Loss: 0.010942484068396784
Epoch: 6 Idx: 0 Loss: 0.007633110064920666
Epoch: 7 Idx: 0 Loss: 0.009393569957751494
Epoch: 8 Idx: 0 Loss: 0.010742721925307428
Epoch: 9 Idx: 0 Loss: 0.024842020627910768
Epoch: 10 Idx: 0 Loss: 0.006506562209862357
Epoch: 11 Idx: 0 Loss: 0.013432619146670122
Epoch: 12 Idx: 0 Loss: 0.01955157614659912
Epoch: 13 Idx: 0 Loss: 0.01544671344293366
Epoch: 14 Idx: 0 Loss: 0.00870755023079882
Epoch: 15 Idx: 0 Loss: 0.009064175607369985
Epoch: 16 Idx: 0 Loss: 0.012965141492291101
Epoch: 17 Idx: 0 Loss: 0.0449206990414767
Epoch: 18 Idx: 0 Loss: 0.011329242780654652
Epoch: 19 Idx: 0 Loss: 0.00660508321156702
Epoch: 20 Idx: 0 Loss: 0.01127891512969087
Epoch: 21 Idx: 0 Loss: 0.009159207851784583
Epoch: 22 Idx: 0 Loss: 0.011149104386095773
Epoch: 23 Idx: 0 Loss: 0.020223658733684046
Epoch: 24 Idx: 0 Loss: 0.019503067867302916
Epoch: 25 Idx: 0 Loss: 0.010694496057959902
Epoch: 26 Idx: 0 Loss: 0.026941717819636946
Epoch: 27 Idx: 0 Loss: 0.01768960720491211
Epoch: 28 Idx: 0 Loss: 0.016440150934339107
Epoch: 29 Idx: 0 Loss: 0.013479330531122198
Epoch: 30 Idx: 0 Loss: 0.016336169106158267
Epoch: 31 Idx: 0 Loss: 0.008712633603370842
Epoch: 32 Idx: 0 Loss: 0.02299553904944595
Epoch: 33 Idx: 0 Loss: 0.007545620247345109
Epoch: 34 Idx: 0 Loss: 0.02341863430624814
Epoch: 35 Idx: 0 Loss: 0.016909120553609068
Epoch: 36 Idx: 0 Loss: 0.018234477547467206
Epoch: 37 Idx: 0 Loss: 0.0072018933653003915
Epoch: 38 Idx: 0 Loss: 0.011475957359826379
Epoch: 39 Idx: 0 Loss: 0.019953443099064112
Epoch: 40 Idx: 0 Loss: 0.010801832301644373
Epoch: 41 Idx: 0 Loss: 0.036414759538710775
Epoch: 42 Idx: 0 Loss: 0.0275355508653484
Epoch: 43 Idx: 0 Loss: 0.018339133387202642
Epoch: 44 Idx: 0 Loss: 0.010827371088804147
Epoch: 45 Idx: 0 Loss: 0.016537169224275866
Epoch: 46 Idx: 0 Loss: 0.020567328852639885
Epoch: 47 Idx: 0 Loss: 0.008336671562993378
Epoch: 48 Idx: 0 Loss: 0.009794167049815018
Epoch: 49 Idx: 0 Loss: 0.01066442018599887
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333)
Performance for  [('ekaw', 'sigkdd')] is : (0.7857142857142857, 1.0, 0.88, 0.9482758620689656, 0.8208955223880596)
Performance for  [('conference', 'edas')] is : (0.7777777777777778, 0.8235294117647058, 0.7999999999999999, 0.8139534883720929, 0.7865168539325843)
Performance for  [('cmt', 'ekaw')] is : (0.5, 0.5454545454545454, 0.5217391304347826, 0.5357142857142857, 0.5084745762711864)
Performance for  [('confOf', 'edas')] is : (0.631578947368421, 0.631578947368421, 0.631578947368421, 0.631578947368421, 0.631578947368421)
Performance for  [('iasted', 'sigkdd')] is : (0.5238095238095238, 0.7333333333333333, 0.611111111111111, 0.6790123456790123, 0.5555555555555556)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.6666666666666666, 0.8, 0.7142857142857142, 0.9090909090909091)
Final Results: [0.70745912 0.73341375 0.71110893 0.72230771 0.70649224]
Threshold:  0.893
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2b774ed09af0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc234>
Subject: Job 4142687: <python main.py 3 9 False False> in cluster <dcc> Done

Job <python main.py 3 9 False False> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:23 2020
Job was executed on host(s) <dccxc234>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 07:37:31 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:37:31 2020
Terminated at Wed Sep 16 13:34:58 2020
Results reported at Wed Sep 16 13:34:58 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 9 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   21402.60 sec.
    Max Memory :                                 4216 MB
    Average Memory :                             4052.76 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39201.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   21452 sec.
    Turnaround time :                            23795 sec.

The output (if any) is above this job summary.

