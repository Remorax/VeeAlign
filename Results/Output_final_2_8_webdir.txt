2020-09-16 10:11:14.441606: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:11:23.487817: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 10:11:23.601834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 10:11:23.601915: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:11:23.603864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 10:11:23.605353: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 10:11:23.605735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 10:11:23.607688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 10:11:23.609089: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 10:11:23.609245: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib
2020-09-16 10:11:23.609265: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 10:11:23.609753: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 10:11:23.652275: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600010000 Hz
2020-09-16 10:11:23.652620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56498e67a440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 10:11:23.652643: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 10:11:23.655540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 10:11:23.655574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/naveen9/arvind/VeeAlign/
Ontologies being aligned are:  [('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18403141360924286
Epoch: 0 Idx: 5000 Loss: 0.02462591992320772
Epoch: 1 Idx: 0 Loss: 0.04017470505480367
Epoch: 1 Idx: 5000 Loss: 0.017115101696491386
Epoch: 2 Idx: 0 Loss: 0.009421732317213962
Epoch: 2 Idx: 5000 Loss: 0.012206867395088365
Epoch: 3 Idx: 0 Loss: 0.007615172695962677
Epoch: 3 Idx: 5000 Loss: 0.013587351553697485
Epoch: 4 Idx: 0 Loss: 0.009734835105933261
Epoch: 4 Idx: 5000 Loss: 0.010588374911256986
Epoch: 5 Idx: 0 Loss: 0.014498472101076944
Epoch: 5 Idx: 5000 Loss: 0.013439516393148847
Epoch: 6 Idx: 0 Loss: 0.01983607775587994
Epoch: 6 Idx: 5000 Loss: 0.010752434825411845
Epoch: 7 Idx: 0 Loss: 0.014877991987332242
Epoch: 7 Idx: 5000 Loss: 0.01381442808864549
Epoch: 8 Idx: 0 Loss: 0.02349951330952483
Epoch: 8 Idx: 5000 Loss: 0.012481098211865837
Epoch: 9 Idx: 0 Loss: 0.006373019167439974
Epoch: 9 Idx: 5000 Loss: 0.007295009127505832
Epoch: 10 Idx: 0 Loss: 0.02408749129144102
Epoch: 10 Idx: 5000 Loss: 0.03593586482120505
Epoch: 11 Idx: 0 Loss: 0.026276737815116424
Epoch: 11 Idx: 5000 Loss: 0.014521399377373491
Epoch: 12 Idx: 0 Loss: 0.004753953821327584
Epoch: 12 Idx: 5000 Loss: 0.022077465730406642
Epoch: 13 Idx: 0 Loss: 0.02238870913973575
Epoch: 13 Idx: 5000 Loss: 0.005113416407007879
Epoch: 14 Idx: 0 Loss: 0.02555759442752689
Epoch: 14 Idx: 5000 Loss: 0.019256403657375746
Epoch: 15 Idx: 0 Loss: 0.01636081172340448
Epoch: 15 Idx: 5000 Loss: 0.012586544767046404
Epoch: 16 Idx: 0 Loss: 0.014969521604631646
Epoch: 16 Idx: 5000 Loss: 0.03671716029021028
Epoch: 17 Idx: 0 Loss: 0.013266312889411037
Epoch: 17 Idx: 5000 Loss: 0.010902703166082562
Epoch: 18 Idx: 0 Loss: 0.010776226462324658
Epoch: 18 Idx: 5000 Loss: 0.012256348809181528
Epoch: 19 Idx: 0 Loss: 0.015458383142411254
Epoch: 19 Idx: 5000 Loss: 0.023387091886946775
Epoch: 20 Idx: 0 Loss: 0.00669972615833734
Epoch: 20 Idx: 5000 Loss: 0.007190243154719673
Epoch: 21 Idx: 0 Loss: 0.01351904130280803
Epoch: 21 Idx: 5000 Loss: 0.019858327845863784
Epoch: 22 Idx: 0 Loss: 0.04019445861122601
Epoch: 22 Idx: 5000 Loss: 0.01470537201277077
Epoch: 23 Idx: 0 Loss: 0.010224844140823761
Epoch: 23 Idx: 5000 Loss: 0.017264470456516162
Epoch: 24 Idx: 0 Loss: 0.015454628290480171
Epoch: 24 Idx: 5000 Loss: 0.013523883747848079
Epoch: 25 Idx: 0 Loss: 0.010422690691262322
Epoch: 25 Idx: 5000 Loss: 0.011357946438011145
Epoch: 26 Idx: 0 Loss: 0.01225921390192912
Epoch: 26 Idx: 5000 Loss: 0.01565290240058768
Epoch: 27 Idx: 0 Loss: 0.01784451315104906
Epoch: 27 Idx: 5000 Loss: 0.0286646253771507
Epoch: 28 Idx: 0 Loss: 0.009521467464200592
Epoch: 28 Idx: 5000 Loss: 0.01588690691172366
Epoch: 29 Idx: 0 Loss: 0.012312445978539437
Epoch: 29 Idx: 5000 Loss: 0.009635586291955416
Epoch: 30 Idx: 0 Loss: 0.032612548086993445
Epoch: 30 Idx: 5000 Loss: 0.005174643367711061
Epoch: 31 Idx: 0 Loss: 0.025297017845432885
Epoch: 31 Idx: 5000 Loss: 0.02041997568838969
Epoch: 32 Idx: 0 Loss: 0.011280834761282277
Epoch: 32 Idx: 5000 Loss: 0.017469699695053954
Epoch: 33 Idx: 0 Loss: 0.016044217077161062
Epoch: 33 Idx: 5000 Loss: 0.0161816296385884
Epoch: 34 Idx: 0 Loss: 0.013297719252446908
Epoch: 34 Idx: 5000 Loss: 0.026560281773528337
Epoch: 35 Idx: 0 Loss: 0.006833462890222929
Epoch: 35 Idx: 5000 Loss: 0.015289965205652178
Epoch: 36 Idx: 0 Loss: 0.02466100053478282
Epoch: 36 Idx: 5000 Loss: 0.006653811250149337
Epoch: 37 Idx: 0 Loss: 0.02074649016846728
Epoch: 37 Idx: 5000 Loss: 0.03353624433272765
Epoch: 38 Idx: 0 Loss: 0.029077041640048488
Epoch: 38 Idx: 5000 Loss: 0.01508124156950027
Epoch: 39 Idx: 0 Loss: 0.0181288104958608
Epoch: 39 Idx: 5000 Loss: 0.016953151842799368
Epoch: 40 Idx: 0 Loss: 0.010076613564492003
Epoch: 40 Idx: 5000 Loss: 0.012078532728007208
Epoch: 41 Idx: 0 Loss: 0.020750610307222733
Epoch: 41 Idx: 5000 Loss: 0.03726833871787535
Epoch: 42 Idx: 0 Loss: 0.012247913256644719
Epoch: 42 Idx: 5000 Loss: 0.009892577852813769
Epoch: 43 Idx: 0 Loss: 0.007886884030385925
Epoch: 43 Idx: 5000 Loss: 0.01374240763309523
Epoch: 44 Idx: 0 Loss: 0.010380204920958803
Epoch: 44 Idx: 5000 Loss: 0.008873296597903708
Epoch: 45 Idx: 0 Loss: 0.01128921508323236
Epoch: 45 Idx: 5000 Loss: 0.024752507506971784
Epoch: 46 Idx: 0 Loss: 0.009207188873752756
Epoch: 46 Idx: 5000 Loss: 0.016395236153402385
Epoch: 47 Idx: 0 Loss: 0.018629199821784764
Epoch: 47 Idx: 5000 Loss: 0.007275819776798691
Epoch: 48 Idx: 0 Loss: 0.05508191807050296
Epoch: 48 Idx: 5000 Loss: 0.03907689482970702
Epoch: 49 Idx: 0 Loss: 0.014038714985200935
Epoch: 49 Idx: 5000 Loss: 0.02253280233172905
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.22605831705307686
Epoch: 0 Idx: 5000 Loss: 0.011014447728229092
Epoch: 1 Idx: 0 Loss: 0.014780244102615728
Epoch: 1 Idx: 5000 Loss: 0.018851622726886976
Epoch: 2 Idx: 0 Loss: 0.010334779847742418
Epoch: 2 Idx: 5000 Loss: 0.03722006324912444
Epoch: 3 Idx: 0 Loss: 0.01204904614249877
Epoch: 3 Idx: 5000 Loss: 0.04899572846283699
Epoch: 4 Idx: 0 Loss: 0.012048199057723903
Epoch: 4 Idx: 5000 Loss: 0.011686433577169638
Epoch: 5 Idx: 0 Loss: 0.008841575922650046
Epoch: 5 Idx: 5000 Loss: 0.02300143391956501
Epoch: 6 Idx: 0 Loss: 0.00924460671937893
Epoch: 6 Idx: 5000 Loss: 0.018684259723214802
Epoch: 7 Idx: 0 Loss: 0.007820753324299884
Epoch: 7 Idx: 5000 Loss: 0.01447189609384003
Epoch: 8 Idx: 0 Loss: 0.0078086510209904834
Epoch: 8 Idx: 5000 Loss: 0.010858003871988167
Epoch: 9 Idx: 0 Loss: 0.013451090941423653
Epoch: 9 Idx: 5000 Loss: 0.007898092419372366
Epoch: 10 Idx: 0 Loss: 0.017771939572149675
Epoch: 10 Idx: 5000 Loss: 0.020655926591025626
Epoch: 11 Idx: 0 Loss: 0.028261820350842327
Epoch: 11 Idx: 5000 Loss: 0.00970077960559513
Epoch: 12 Idx: 0 Loss: 0.038181233132661384
Epoch: 12 Idx: 5000 Loss: 0.009070662890898445
Epoch: 13 Idx: 0 Loss: 0.004212381031351143
Epoch: 13 Idx: 5000 Loss: 0.013901072232346729
Epoch: 14 Idx: 0 Loss: 0.015325054318953884
Epoch: 14 Idx: 5000 Loss: 0.022068714947337486
Epoch: 15 Idx: 0 Loss: 0.009088219854060112
Epoch: 15 Idx: 5000 Loss: 0.015357399943957056
Epoch: 16 Idx: 0 Loss: 0.01598857422521474
Epoch: 16 Idx: 5000 Loss: 0.02243293674906774
Epoch: 17 Idx: 0 Loss: 0.012791095367859159
Epoch: 17 Idx: 5000 Loss: 0.04354993436263234
Epoch: 18 Idx: 0 Loss: 0.009580744181228805
Epoch: 18 Idx: 5000 Loss: 0.012485118736189627
Epoch: 19 Idx: 0 Loss: 0.01692818625831067
Epoch: 19 Idx: 5000 Loss: 0.009142117155617755
Epoch: 20 Idx: 0 Loss: 0.022742690257336086
Epoch: 20 Idx: 5000 Loss: 0.009389609691539725
Epoch: 21 Idx: 0 Loss: 0.017237230168333065
Epoch: 21 Idx: 5000 Loss: 0.036272955180994076
Epoch: 22 Idx: 0 Loss: 0.011984108343181605
Epoch: 22 Idx: 5000 Loss: 0.012051282065443444
Epoch: 23 Idx: 0 Loss: 0.02933009681587273
Epoch: 23 Idx: 5000 Loss: 0.01817474211901932
Epoch: 24 Idx: 0 Loss: 0.018167665716846203
Epoch: 24 Idx: 5000 Loss: 0.008927388916116216
Epoch: 25 Idx: 0 Loss: 0.022550295540994067
Epoch: 25 Idx: 5000 Loss: 0.016422491487431672
Epoch: 26 Idx: 0 Loss: 0.011485420569163823
Epoch: 26 Idx: 5000 Loss: 0.011564679032178202
Epoch: 27 Idx: 0 Loss: 0.011564419918290278
Epoch: 27 Idx: 5000 Loss: 0.00605584595494614
Epoch: 28 Idx: 0 Loss: 0.007150323820981595
Epoch: 28 Idx: 5000 Loss: 0.022105019748420836
Epoch: 29 Idx: 0 Loss: 0.015465492338860508
Epoch: 29 Idx: 5000 Loss: 0.027467972245001374
Epoch: 30 Idx: 0 Loss: 0.007452972871315508
Epoch: 30 Idx: 5000 Loss: 0.014986161265832885
Epoch: 31 Idx: 0 Loss: 0.019939666878685917
Epoch: 31 Idx: 5000 Loss: 0.016550996157038818
Epoch: 32 Idx: 0 Loss: 0.012297993588881753
Epoch: 32 Idx: 5000 Loss: 0.009754702280672083
Epoch: 33 Idx: 0 Loss: 0.019602590083380785
Epoch: 33 Idx: 5000 Loss: 0.012179488487337225
Epoch: 34 Idx: 0 Loss: 0.020517929966095305
Epoch: 34 Idx: 5000 Loss: 0.01449684733777102
Epoch: 35 Idx: 0 Loss: 0.0169559650935448
Epoch: 35 Idx: 5000 Loss: 0.0067187175840224996
Epoch: 36 Idx: 0 Loss: 0.011067207083670948
Epoch: 36 Idx: 5000 Loss: 0.01132894695552291
Epoch: 37 Idx: 0 Loss: 0.012201162366953832
Epoch: 37 Idx: 5000 Loss: 0.01004025189766209
Epoch: 38 Idx: 0 Loss: 0.012140628509626931
Epoch: 38 Idx: 5000 Loss: 0.016510885021694913
Epoch: 39 Idx: 0 Loss: 0.02012920149920307
Epoch: 39 Idx: 5000 Loss: 0.010874891498681972
Epoch: 40 Idx: 0 Loss: 0.018034952578775423
Epoch: 40 Idx: 5000 Loss: 0.005189114438384975
Epoch: 41 Idx: 0 Loss: 0.0208131621901839
Epoch: 41 Idx: 5000 Loss: 0.01424937850162734
Epoch: 42 Idx: 0 Loss: 0.025261447223347548
Epoch: 42 Idx: 5000 Loss: 0.008292038516250207
Epoch: 43 Idx: 0 Loss: 0.015318641343232487
Epoch: 43 Idx: 5000 Loss: 0.030926198439110843
Epoch: 44 Idx: 0 Loss: 0.014102358248665483
Epoch: 44 Idx: 5000 Loss: 0.011508665395752803
Epoch: 45 Idx: 0 Loss: 0.012710086231731477
Epoch: 45 Idx: 5000 Loss: 0.017034935201450843
Epoch: 46 Idx: 0 Loss: 0.033351659036850334
Epoch: 46 Idx: 5000 Loss: 0.026834044037909968
Epoch: 47 Idx: 0 Loss: 0.013073236773056104
Epoch: 47 Idx: 5000 Loss: 0.01382563807037409
Epoch: 48 Idx: 0 Loss: 0.03806114598935486
Epoch: 48 Idx: 5000 Loss: 0.008637114934163602
Epoch: 49 Idx: 0 Loss: 0.017333662487048596
Epoch: 49 Idx: 5000 Loss: 0.00608023297267977
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.1667290933470923
Epoch: 0 Idx: 5000 Loss: 0.022910504967500862
Epoch: 1 Idx: 0 Loss: 0.007662792904900335
Epoch: 1 Idx: 5000 Loss: 0.015401552315064801
Epoch: 2 Idx: 0 Loss: 0.0147625487500932
Epoch: 2 Idx: 5000 Loss: 0.013308898479430004
Epoch: 3 Idx: 0 Loss: 0.007939262857427035
Epoch: 3 Idx: 5000 Loss: 0.012157118157036063
Epoch: 4 Idx: 0 Loss: 0.016306818038486246
Epoch: 4 Idx: 5000 Loss: 0.007905788275219587
Epoch: 5 Idx: 0 Loss: 0.009285791100096835
Epoch: 5 Idx: 5000 Loss: 0.009944876959978746
Epoch: 6 Idx: 0 Loss: 0.012194409959906297
Epoch: 6 Idx: 5000 Loss: 0.024359439542666225
Epoch: 7 Idx: 0 Loss: 0.00893761697747363
Epoch: 7 Idx: 5000 Loss: 0.01848483013322097
Epoch: 8 Idx: 0 Loss: 0.007840474457288778
Epoch: 8 Idx: 5000 Loss: 0.032132411481899686
Epoch: 9 Idx: 0 Loss: 0.020707260740621267
Epoch: 9 Idx: 5000 Loss: 0.013117611531479025
Epoch: 10 Idx: 0 Loss: 0.0058102018060459245
Epoch: 10 Idx: 5000 Loss: 0.010469778776256758
Epoch: 11 Idx: 0 Loss: 0.018759017057621962
Epoch: 11 Idx: 5000 Loss: 0.020558824743808206
Epoch: 12 Idx: 0 Loss: 0.020605125001837886
Epoch: 12 Idx: 5000 Loss: 0.03707445838280182
Epoch: 13 Idx: 0 Loss: 0.006875526207390731
Epoch: 13 Idx: 5000 Loss: 0.029168771952421103
Epoch: 14 Idx: 0 Loss: 0.007079203252874283
Epoch: 14 Idx: 5000 Loss: 0.015576051816131186
Epoch: 15 Idx: 0 Loss: 0.008354609382659556
Epoch: 15 Idx: 5000 Loss: 0.004558071244955602
Epoch: 16 Idx: 0 Loss: 0.013772231744500426
Epoch: 16 Idx: 5000 Loss: 0.01774074188213482
Epoch: 17 Idx: 0 Loss: 0.019197636516097478
Epoch: 17 Idx: 5000 Loss: 0.015540403411117152
Epoch: 18 Idx: 0 Loss: 0.010742865019708253
Epoch: 18 Idx: 5000 Loss: 0.00973143192213806
Epoch: 19 Idx: 0 Loss: 0.009874478422236016
Epoch: 19 Idx: 5000 Loss: 0.014311705971667322
Epoch: 20 Idx: 0 Loss: 0.04111355089747848
Epoch: 20 Idx: 5000 Loss: 0.014965718787676703
Epoch: 21 Idx: 0 Loss: 0.022624195473489955
Epoch: 21 Idx: 5000 Loss: 0.02837956351993056
Epoch: 22 Idx: 0 Loss: 0.009367265828981052
Epoch: 22 Idx: 5000 Loss: 0.010117374709133844
Epoch: 23 Idx: 0 Loss: 0.010035199947127552
Epoch: 23 Idx: 5000 Loss: 0.03310199452508865
Epoch: 24 Idx: 0 Loss: 0.024013474083254223
Epoch: 24 Idx: 5000 Loss: 0.005104477450904805
Epoch: 25 Idx: 0 Loss: 0.020768786421465336
Epoch: 25 Idx: 5000 Loss: 0.02201653927280344
Epoch: 26 Idx: 0 Loss: 0.03205557941588712
Epoch: 26 Idx: 5000 Loss: 0.014020109477516338
Epoch: 27 Idx: 0 Loss: 0.02207430235254479
Epoch: 27 Idx: 5000 Loss: 0.027480174611103414
Epoch: 28 Idx: 0 Loss: 0.007571858887451412
Epoch: 28 Idx: 5000 Loss: 0.025073637410138412
Epoch: 29 Idx: 0 Loss: 0.03540753985785415
Epoch: 29 Idx: 5000 Loss: 0.03866052172114689
Epoch: 30 Idx: 0 Loss: 0.030931125455712378
Epoch: 30 Idx: 5000 Loss: 0.013059098290060394
Epoch: 31 Idx: 0 Loss: 0.015332473107932107
Epoch: 31 Idx: 5000 Loss: 0.0261394247485366
Epoch: 32 Idx: 0 Loss: 0.010052845705695467
Epoch: 32 Idx: 5000 Loss: 0.03533225396822475
Epoch: 33 Idx: 0 Loss: 0.012397614886175622
Epoch: 33 Idx: 5000 Loss: 0.00929428541447072
Epoch: 34 Idx: 0 Loss: 0.010559012355253868
Epoch: 34 Idx: 5000 Loss: 0.01113445797203912
Epoch: 35 Idx: 0 Loss: 0.007061945686220195
Epoch: 35 Idx: 5000 Loss: 0.017946139502112844
Epoch: 36 Idx: 0 Loss: 0.02448779267646749
Epoch: 36 Idx: 5000 Loss: 0.011244138658632588
Epoch: 37 Idx: 0 Loss: 0.023086493452223387
Epoch: 37 Idx: 5000 Loss: 0.011726977603496707
Epoch: 38 Idx: 0 Loss: 0.05060560161456262
Epoch: 38 Idx: 5000 Loss: 0.014589902128078215
Epoch: 39 Idx: 0 Loss: 0.011868133476919032
Epoch: 39 Idx: 5000 Loss: 0.012282865524756706
Epoch: 40 Idx: 0 Loss: 0.004644684945680384
Epoch: 40 Idx: 5000 Loss: 0.012450984696671965
Epoch: 41 Idx: 0 Loss: 0.011607056355811657
Epoch: 41 Idx: 5000 Loss: 0.017235930705036803
Epoch: 42 Idx: 0 Loss: 0.00913955240242539
Epoch: 42 Idx: 5000 Loss: 0.008526632789186129
Epoch: 43 Idx: 0 Loss: 0.013700673427640118
Epoch: 43 Idx: 5000 Loss: 0.029995668977972144
Epoch: 44 Idx: 0 Loss: 0.035168279252904194
Epoch: 44 Idx: 5000 Loss: 0.013971546918449405
Epoch: 45 Idx: 0 Loss: 0.016502793198935824
Epoch: 45 Idx: 5000 Loss: 0.014983728550857712
Epoch: 46 Idx: 0 Loss: 0.006487757487723826
Epoch: 46 Idx: 5000 Loss: 0.012269046730768111
Epoch: 47 Idx: 0 Loss: 0.011073931459679647
Epoch: 47 Idx: 5000 Loss: 0.011667355517519407
Epoch: 48 Idx: 0 Loss: 0.022887379594985723
Epoch: 48 Idx: 5000 Loss: 0.017395283603085523
Epoch: 49 Idx: 0 Loss: 0.011528025844204886
Epoch: 49 Idx: 5000 Loss: 0.016909381230013825
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.19187530142486653
Epoch: 0 Idx: 5000 Loss: 0.00827407280968958
Epoch: 1 Idx: 0 Loss: 0.011457256606016712
Epoch: 1 Idx: 5000 Loss: 0.022984969002897853
Epoch: 2 Idx: 0 Loss: 0.010703133638214377
Epoch: 2 Idx: 5000 Loss: 0.031173650704803917
Epoch: 3 Idx: 0 Loss: 0.007615639143384252
Epoch: 3 Idx: 5000 Loss: 0.012350936566872283
Epoch: 4 Idx: 0 Loss: 0.011729404189743518
Epoch: 4 Idx: 5000 Loss: 0.04010914220783759
Epoch: 5 Idx: 0 Loss: 0.010650071989383957
Epoch: 5 Idx: 5000 Loss: 0.00542843002354398
Epoch: 6 Idx: 0 Loss: 0.012453204217924427
Epoch: 6 Idx: 5000 Loss: 0.026646471626258536
Epoch: 7 Idx: 0 Loss: 0.01703991636281227
Epoch: 7 Idx: 5000 Loss: 0.008433657738438943
Epoch: 8 Idx: 0 Loss: 0.014560518505645017
Epoch: 8 Idx: 5000 Loss: 0.019719464642229557
Epoch: 9 Idx: 0 Loss: 0.020708551354101084
Epoch: 9 Idx: 5000 Loss: 0.010089309731094181
Epoch: 10 Idx: 0 Loss: 0.020415202277712916
Epoch: 10 Idx: 5000 Loss: 0.017879521350609835
Epoch: 11 Idx: 0 Loss: 0.00809848391277151
Epoch: 11 Idx: 5000 Loss: 0.014003821802712257
Epoch: 12 Idx: 0 Loss: 0.008400986721945985
Epoch: 12 Idx: 5000 Loss: 0.015664525602498307
Epoch: 13 Idx: 0 Loss: 0.009726396620207196
Epoch: 13 Idx: 5000 Loss: 0.013506921942298604
Epoch: 14 Idx: 0 Loss: 0.03545199183456524
Epoch: 14 Idx: 5000 Loss: 0.012208266335783258
Epoch: 15 Idx: 0 Loss: 0.010647991000186575
Epoch: 15 Idx: 5000 Loss: 0.022555566693810467
Epoch: 16 Idx: 0 Loss: 0.010936346718392243
Epoch: 16 Idx: 5000 Loss: 0.021986518091312683
Epoch: 17 Idx: 0 Loss: 0.007924869477021326
Epoch: 17 Idx: 5000 Loss: 0.01827475831841479
Epoch: 18 Idx: 0 Loss: 0.01114183719581467
Epoch: 18 Idx: 5000 Loss: 0.016908186982674697
Epoch: 19 Idx: 0 Loss: 0.01957558653424676
Epoch: 19 Idx: 5000 Loss: 0.015293199069107085
Epoch: 20 Idx: 0 Loss: 0.008505171990630197
Epoch: 20 Idx: 5000 Loss: 0.023596074624159573
Epoch: 21 Idx: 0 Loss: 0.00792952167033016
Epoch: 21 Idx: 5000 Loss: 0.01607185436385565
Epoch: 22 Idx: 0 Loss: 0.03956208325280353
Epoch: 22 Idx: 5000 Loss: 0.019915868483131118
Epoch: 23 Idx: 0 Loss: 0.01604023559743463
Epoch: 23 Idx: 5000 Loss: 0.01021681895117901
Epoch: 24 Idx: 0 Loss: 0.050279601025838484
Epoch: 24 Idx: 5000 Loss: 0.01467039084156307
Epoch: 25 Idx: 0 Loss: 0.022245651429631506
Epoch: 25 Idx: 5000 Loss: 0.04012431388334993
Epoch: 26 Idx: 0 Loss: 0.009972628624950882
Epoch: 26 Idx: 5000 Loss: 0.027897410854083312
Epoch: 27 Idx: 0 Loss: 0.022559750552756122
Epoch: 27 Idx: 5000 Loss: 0.022716973803034855
Epoch: 28 Idx: 0 Loss: 0.017745545791594958
Epoch: 28 Idx: 5000 Loss: 0.012636123017100912
Epoch: 29 Idx: 0 Loss: 0.009575779018672327
Epoch: 29 Idx: 5000 Loss: 0.015462330303262878
Epoch: 30 Idx: 0 Loss: 0.02950890906211049
Epoch: 30 Idx: 5000 Loss: 0.023653974432007542
Epoch: 31 Idx: 0 Loss: 0.011875283579690584
Epoch: 31 Idx: 5000 Loss: 0.030339890130555214
Epoch: 32 Idx: 0 Loss: 0.022947955762290508
Epoch: 32 Idx: 5000 Loss: 0.011374681594659758
Epoch: 33 Idx: 0 Loss: 0.012510264852947432
Epoch: 33 Idx: 5000 Loss: 0.015006411902173215
Epoch: 34 Idx: 0 Loss: 0.023062500537323512
Epoch: 34 Idx: 5000 Loss: 0.00804688183733223
Epoch: 35 Idx: 0 Loss: 0.010409862787895992
Epoch: 35 Idx: 5000 Loss: 0.00969475757522645
Epoch: 36 Idx: 0 Loss: 0.015750591630034567
Epoch: 36 Idx: 5000 Loss: 0.009406235969226153
Epoch: 37 Idx: 0 Loss: 0.023997922418724806
Epoch: 37 Idx: 5000 Loss: 0.018828140249238748
Epoch: 38 Idx: 0 Loss: 0.012793496866842334
Epoch: 38 Idx: 5000 Loss: 0.0061253174393535595
Epoch: 39 Idx: 0 Loss: 0.008197007961664601
Epoch: 39 Idx: 5000 Loss: 0.016999018667263752
Epoch: 40 Idx: 0 Loss: 0.01541365124998764
Epoch: 40 Idx: 5000 Loss: 0.01637228027474904
Epoch: 41 Idx: 0 Loss: 0.028849181440195337
Epoch: 41 Idx: 5000 Loss: 0.010540507929162276
Epoch: 42 Idx: 0 Loss: 0.014238908757042585
Epoch: 42 Idx: 5000 Loss: 0.016253137910890614
Epoch: 43 Idx: 0 Loss: 0.023778928471213524
Epoch: 43 Idx: 5000 Loss: 0.019777876551696088
Epoch: 44 Idx: 0 Loss: 0.02349409459380822
Epoch: 44 Idx: 5000 Loss: 0.018943135842583024
Epoch: 45 Idx: 0 Loss: 0.005537443744417139
Epoch: 45 Idx: 5000 Loss: 0.02987649870086757
Epoch: 46 Idx: 0 Loss: 0.010444369457905356
Epoch: 46 Idx: 5000 Loss: 0.011246143505111713
Epoch: 47 Idx: 0 Loss: 0.022944606774195093
Epoch: 47 Idx: 5000 Loss: 0.011997799705382124
Epoch: 48 Idx: 0 Loss: 0.03324304792809804
Epoch: 48 Idx: 5000 Loss: 0.007297485755792858
Epoch: 49 Idx: 0 Loss: 0.02312196447482281
Epoch: 49 Idx: 5000 Loss: 0.026429221513520628
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.2147875738539512
Epoch: 1 Idx: 0 Loss: 0.015132923251736348
Epoch: 2 Idx: 0 Loss: 0.015499581470412582
Epoch: 3 Idx: 0 Loss: 0.010111413748105723
Epoch: 4 Idx: 0 Loss: 0.02614001006889407
Epoch: 5 Idx: 0 Loss: 0.006778930351123219
Epoch: 6 Idx: 0 Loss: 0.013338169312798449
Epoch: 7 Idx: 0 Loss: 0.006668287255531766
Epoch: 8 Idx: 0 Loss: 0.012172338445738328
Epoch: 9 Idx: 0 Loss: 0.005122403247015342
Epoch: 10 Idx: 0 Loss: 0.011775652411809475
Epoch: 11 Idx: 0 Loss: 0.011543386266535685
Epoch: 12 Idx: 0 Loss: 0.01835545728589784
Epoch: 13 Idx: 0 Loss: 0.02137330361995981
Epoch: 14 Idx: 0 Loss: 0.011375502886141843
Epoch: 15 Idx: 0 Loss: 0.012033715992160392
Epoch: 16 Idx: 0 Loss: 0.010812704056238923
Epoch: 17 Idx: 0 Loss: 0.009141985003526427
Epoch: 18 Idx: 0 Loss: 0.026437419099442538
Epoch: 19 Idx: 0 Loss: 0.0141661343063536
Epoch: 20 Idx: 0 Loss: 0.03324534572417395
Epoch: 21 Idx: 0 Loss: 0.05127477602119618
Epoch: 22 Idx: 0 Loss: 0.007524702379698716
Epoch: 23 Idx: 0 Loss: 0.00988044034636449
Epoch: 24 Idx: 0 Loss: 0.010688134234019805
Epoch: 25 Idx: 0 Loss: 0.011508158732338352
Epoch: 26 Idx: 0 Loss: 0.020671358816394193
Epoch: 27 Idx: 0 Loss: 0.013956765519974015
Epoch: 28 Idx: 0 Loss: 0.012408409984313739
Epoch: 29 Idx: 0 Loss: 0.011181952046406323
Epoch: 30 Idx: 0 Loss: 0.00878616231194591
Epoch: 31 Idx: 0 Loss: 0.00525077789126885
Epoch: 32 Idx: 0 Loss: 0.012177101531620663
Epoch: 33 Idx: 0 Loss: 0.0031719346916679754
Epoch: 34 Idx: 0 Loss: 0.005875354957698961
Epoch: 35 Idx: 0 Loss: 0.01117377623911452
Epoch: 36 Idx: 0 Loss: 0.02934275359006554
Epoch: 37 Idx: 0 Loss: 0.009575920076180864
Epoch: 38 Idx: 0 Loss: 0.01611866370799036
Epoch: 39 Idx: 0 Loss: 0.02496272640713781
Epoch: 40 Idx: 0 Loss: 0.026858904235403217
Epoch: 41 Idx: 0 Loss: 0.010323764915005126
Epoch: 42 Idx: 0 Loss: 0.006602722629554809
Epoch: 43 Idx: 0 Loss: 0.006249416651498321
Epoch: 44 Idx: 0 Loss: 0.009197845562842059
Epoch: 45 Idx: 0 Loss: 0.025143656347105286
Epoch: 46 Idx: 0 Loss: 0.024441905695216527
Epoch: 47 Idx: 0 Loss: 0.015538499151374245
Epoch: 48 Idx: 0 Loss: 0.008666500939054661
Epoch: 49 Idx: 0 Loss: 0.012174179207439155
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.1673526295484006
Epoch: 0 Idx: 5000 Loss: 0.04052556578612767
Epoch: 1 Idx: 0 Loss: 0.0194724317622043
Epoch: 1 Idx: 5000 Loss: 0.01918426570643841
Epoch: 2 Idx: 0 Loss: 0.005396079461123739
Epoch: 2 Idx: 5000 Loss: 0.013395447423252747
Epoch: 3 Idx: 0 Loss: 0.030426010373652168
Epoch: 3 Idx: 5000 Loss: 0.023902800960206028
Epoch: 4 Idx: 0 Loss: 0.009155851487922282
Epoch: 4 Idx: 5000 Loss: 0.03508913917382732
Epoch: 5 Idx: 0 Loss: 0.009565020239145176
Epoch: 5 Idx: 5000 Loss: 0.02029298624260218
Epoch: 6 Idx: 0 Loss: 0.016241736797362523
Epoch: 6 Idx: 5000 Loss: 0.02640480535268603
Epoch: 7 Idx: 0 Loss: 0.020895348374127435
Epoch: 7 Idx: 5000 Loss: 0.010303938809348613
Epoch: 8 Idx: 0 Loss: 0.020866784771360513
Epoch: 8 Idx: 5000 Loss: 0.015261463959365378
Epoch: 9 Idx: 0 Loss: 0.022440643006636674
Epoch: 9 Idx: 5000 Loss: 0.006276175189426243
Epoch: 10 Idx: 0 Loss: 0.012008678525294473
Epoch: 10 Idx: 5000 Loss: 0.02733993266800201
Epoch: 11 Idx: 0 Loss: 0.017414783140461264
Epoch: 11 Idx: 5000 Loss: 0.016383088292812147
Epoch: 12 Idx: 0 Loss: 0.02965210952116436
Epoch: 12 Idx: 5000 Loss: 0.02320791220799518
Epoch: 13 Idx: 0 Loss: 0.011276693898041631
Epoch: 13 Idx: 5000 Loss: 0.018080844430959753
Epoch: 14 Idx: 0 Loss: 0.013941667896773511
Epoch: 14 Idx: 5000 Loss: 0.01745030765272724
Epoch: 15 Idx: 0 Loss: 0.029190104664415285
Epoch: 15 Idx: 5000 Loss: 0.00772019862137182
Epoch: 16 Idx: 0 Loss: 0.011081785558064933
Epoch: 16 Idx: 5000 Loss: 0.026652518539720293
Epoch: 17 Idx: 0 Loss: 0.010571375865148799
Epoch: 17 Idx: 5000 Loss: 0.02190117054484357
Epoch: 18 Idx: 0 Loss: 0.012638876712599579
Epoch: 18 Idx: 5000 Loss: 0.013647334402394152
Epoch: 19 Idx: 0 Loss: 0.011002919581143359
Epoch: 19 Idx: 5000 Loss: 0.018507201979159227
Epoch: 20 Idx: 0 Loss: 0.004568363433196675
Epoch: 20 Idx: 5000 Loss: 0.006954178846679098
Epoch: 21 Idx: 0 Loss: 0.00781108915358616
Epoch: 21 Idx: 5000 Loss: 0.011835480222736915
Epoch: 22 Idx: 0 Loss: 0.010505796793969976
Epoch: 22 Idx: 5000 Loss: 0.008950950677232464
Epoch: 23 Idx: 0 Loss: 0.016296502102076046
Epoch: 23 Idx: 5000 Loss: 0.01518286022049872
Epoch: 24 Idx: 0 Loss: 0.012350788654360066
Epoch: 24 Idx: 5000 Loss: 0.013009675560679066
Epoch: 25 Idx: 0 Loss: 0.01341400242711678
Epoch: 25 Idx: 5000 Loss: 0.04153201141596423
Epoch: 26 Idx: 0 Loss: 0.01130953220271977
Epoch: 26 Idx: 5000 Loss: 0.010320996742657285
Epoch: 27 Idx: 0 Loss: 0.009633641215529065
Epoch: 27 Idx: 5000 Loss: 0.016341447030959813
Epoch: 28 Idx: 0 Loss: 0.007796125434458522
Epoch: 28 Idx: 5000 Loss: 0.03195917018090122
Epoch: 29 Idx: 0 Loss: 0.017479338454326337
Epoch: 29 Idx: 5000 Loss: 0.014880793935151843
Epoch: 30 Idx: 0 Loss: 0.007891293845671306
Epoch: 30 Idx: 5000 Loss: 0.007640552440543307
Epoch: 31 Idx: 0 Loss: 0.02254091146420424
Epoch: 31 Idx: 5000 Loss: 0.007335319459892598
Epoch: 32 Idx: 0 Loss: 0.018478298530721318
Epoch: 32 Idx: 5000 Loss: 0.011702742916769662
Epoch: 33 Idx: 0 Loss: 0.01446390194066979
Epoch: 33 Idx: 5000 Loss: 0.010752307383825526
Epoch: 34 Idx: 0 Loss: 0.012190271438390438
Epoch: 34 Idx: 5000 Loss: 0.008618368015896995
Epoch: 35 Idx: 0 Loss: 0.022477163517925988
Epoch: 35 Idx: 5000 Loss: 0.019471712977161274
Epoch: 36 Idx: 0 Loss: 0.016004612438484302
Epoch: 36 Idx: 5000 Loss: 0.016196771763555242
Epoch: 37 Idx: 0 Loss: 0.009469675350799227
Epoch: 37 Idx: 5000 Loss: 0.032541365479144956
Epoch: 38 Idx: 0 Loss: 0.017288278005421424
Epoch: 38 Idx: 5000 Loss: 0.01314879428350613
Epoch: 39 Idx: 0 Loss: 0.0032260651275470608
Epoch: 39 Idx: 5000 Loss: 0.018798444913587724
Epoch: 40 Idx: 0 Loss: 0.005394696274758123
Epoch: 40 Idx: 5000 Loss: 0.04491117142558951
Epoch: 41 Idx: 0 Loss: 0.0097942247789608
Epoch: 41 Idx: 5000 Loss: 0.011578012178975871
Epoch: 42 Idx: 0 Loss: 0.007919629402177006
Epoch: 42 Idx: 5000 Loss: 0.005830055898910407
Epoch: 43 Idx: 0 Loss: 0.03422104984092965
Epoch: 43 Idx: 5000 Loss: 0.01506466637953277
Epoch: 44 Idx: 0 Loss: 0.0032195614611510485
Epoch: 44 Idx: 5000 Loss: 0.029075037619248394
Epoch: 45 Idx: 0 Loss: 0.011019158193131935
Epoch: 45 Idx: 5000 Loss: 0.03836007409705161
Epoch: 46 Idx: 0 Loss: 0.013761198886159311
Epoch: 46 Idx: 5000 Loss: 0.021584853573771108
Epoch: 47 Idx: 0 Loss: 0.01181741928377713
Epoch: 47 Idx: 5000 Loss: 0.005224217082481886
Epoch: 48 Idx: 0 Loss: 0.022203622571565048
Epoch: 48 Idx: 5000 Loss: 0.03030396036763952
Epoch: 49 Idx: 0 Loss: 0.026331783512947224
Epoch: 49 Idx: 5000 Loss: 0.01925550388357914
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.19474162636947873
Epoch: 1 Idx: 0 Loss: 0.013075996201406034
Epoch: 2 Idx: 0 Loss: 0.008751453809666025
Epoch: 3 Idx: 0 Loss: 0.013135317568004368
Epoch: 4 Idx: 0 Loss: 0.017723957372814538
Epoch: 5 Idx: 0 Loss: 0.01832883906474525
Epoch: 6 Idx: 0 Loss: 0.0066419047463808
Epoch: 7 Idx: 0 Loss: 0.016854822092618765
Epoch: 8 Idx: 0 Loss: 0.009167168720952159
Epoch: 9 Idx: 0 Loss: 0.020280751199355213
Epoch: 10 Idx: 0 Loss: 0.043665276700200664
Epoch: 11 Idx: 0 Loss: 0.028485598668329504
Epoch: 12 Idx: 0 Loss: 0.01914376898578765
Epoch: 13 Idx: 0 Loss: 0.011073963404130924
Epoch: 14 Idx: 0 Loss: 0.008378865885600089
Epoch: 15 Idx: 0 Loss: 0.006672393915259234
Epoch: 16 Idx: 0 Loss: 0.03222105495929154
Epoch: 17 Idx: 0 Loss: 0.040977630787745474
Epoch: 18 Idx: 0 Loss: 0.010821935702094141
Epoch: 19 Idx: 0 Loss: 0.027198249643281668
Epoch: 20 Idx: 0 Loss: 0.009135823051116952
Epoch: 21 Idx: 0 Loss: 0.0076206785674624395
Epoch: 22 Idx: 0 Loss: 0.007673318863578112
Epoch: 23 Idx: 0 Loss: 0.004931101318277241
Epoch: 24 Idx: 0 Loss: 0.0057576709941288716
Epoch: 25 Idx: 0 Loss: 0.026554232155958448
Epoch: 26 Idx: 0 Loss: 0.013323924420380872
Epoch: 27 Idx: 0 Loss: 0.03378908019591265
Epoch: 28 Idx: 0 Loss: 0.005420974681144216
Epoch: 29 Idx: 0 Loss: 0.014168052250501897
Epoch: 30 Idx: 0 Loss: 0.00849684455533966
Epoch: 31 Idx: 0 Loss: 0.012444537555017182
Epoch: 32 Idx: 0 Loss: 0.012848138919995786
Epoch: 33 Idx: 0 Loss: 0.009431708958421981
Epoch: 34 Idx: 0 Loss: 0.01049387061225185
Epoch: 35 Idx: 0 Loss: 0.028212903146307432
Epoch: 36 Idx: 0 Loss: 0.006551118269468374
Epoch: 37 Idx: 0 Loss: 0.007851686990291228
Epoch: 38 Idx: 0 Loss: 0.005074428358102002
Epoch: 39 Idx: 0 Loss: 0.022387217731303973
Epoch: 40 Idx: 0 Loss: 0.018092918889786903
Epoch: 41 Idx: 0 Loss: 0.009871300290087745
Epoch: 42 Idx: 0 Loss: 0.010310765496303947
Epoch: 43 Idx: 0 Loss: 0.018072850539310834
Epoch: 44 Idx: 0 Loss: 0.017858303033836637
Epoch: 45 Idx: 0 Loss: 0.013538741258038023
Epoch: 46 Idx: 0 Loss: 0.014943358086783385
Epoch: 47 Idx: 0 Loss: 0.0085228245385463
Epoch: 48 Idx: 0 Loss: 0.013048577455648995
Epoch: 49 Idx: 0 Loss: 0.007861333916213253
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7692307692307693, 0.6666666666666666, 0.7142857142857142, 0.684931506849315, 0.7462686567164178)
Performance for  [('ekaw', 'sigkdd')] is : (0.8333333333333334, 0.9090909090909091, 0.8695652173913043, 0.8928571428571429, 0.8474576271186441)
Performance for  [('conference', 'edas')] is : (0.9285714285714286, 0.7647058823529411, 0.8387096774193549, 0.7926829268292683, 0.8904109589041096)
Performance for  [('cmt', 'ekaw')] is : (0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454)
Performance for  [('confOf', 'edas')] is : (0.5789473684210527, 0.5789473684210527, 0.5789473684210527, 0.5789473684210527, 0.5789473684210527)
Performance for  [('iasted', 'sigkdd')] is : (0.6111111111111112, 0.7333333333333333, 0.6666666666666666, 0.7051282051282052, 0.6321839080459771)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.75237837 0.67910775 0.70398784 0.68710826 0.72897029]
Threshold:  0.912

------------------------------------------------------------
Sender: LSF System <rer@dccxc234>
Subject: Job 4142632: <python main.py 8 2 False False> in cluster <dcc> Done

Job <python main.py 8 2 False False> was submitted from host <dccxl001> by user <naveen9> in cluster <dcc> at Wed Sep 16 06:55:14 2020
Job was executed on host(s) <dccxc234>, in queue <x86_24h>, as user <naveen9> in cluster <dcc> at Wed Sep 16 10:11:09 2020
</u/naveen9> was used as the home directory.
</u/naveen9/arvind/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 10:11:09 2020
Terminated at Thu Sep 17 01:28:49 2020
Results reported at Thu Sep 17 01:28:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 8 2 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   55048.28 sec.
    Max Memory :                                 2905 MB
    Average Memory :                             2748.24 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40512.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   55072 sec.
    Turnaround time :                            66815 sec.

The output (if any) is above this job summary.

