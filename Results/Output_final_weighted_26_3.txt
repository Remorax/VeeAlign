2020-09-15 15:48:42.616441: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.869664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.984091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.984154: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.986470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.005770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.041560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.097840: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.113694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.114190: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.114214: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.114665: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.151013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600070000 Hz
2020-09-15 15:48:50.151289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55882e571350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.151310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.154350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.154374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1857436463491155
Epoch: 0 Idx: 5000 Loss: 0.01216358975139634
Epoch: 1 Idx: 0 Loss: 0.012085931789416153
Epoch: 1 Idx: 5000 Loss: 0.0056325416037570665
Epoch: 2 Idx: 0 Loss: 0.023862438942888663
Epoch: 2 Idx: 5000 Loss: 0.03585232752291445
Epoch: 3 Idx: 0 Loss: 0.00990810584324259
Epoch: 3 Idx: 5000 Loss: 0.011533484074428283
Epoch: 4 Idx: 0 Loss: 0.013360603976594767
Epoch: 4 Idx: 5000 Loss: 0.024366992716119695
Epoch: 5 Idx: 0 Loss: 0.03121958049036904
Epoch: 5 Idx: 5000 Loss: 0.01386321310460321
Epoch: 6 Idx: 0 Loss: 0.008559312896819332
Epoch: 6 Idx: 5000 Loss: 0.02347414722352799
Epoch: 7 Idx: 0 Loss: 0.01626572946449889
Epoch: 7 Idx: 5000 Loss: 0.017479815436668655
Epoch: 8 Idx: 0 Loss: 0.011183567387997436
Epoch: 8 Idx: 5000 Loss: 0.0079432919863258
Epoch: 9 Idx: 0 Loss: 0.01731079971435833
Epoch: 9 Idx: 5000 Loss: 0.00928941310553861
Epoch: 10 Idx: 0 Loss: 0.016930989508818817
Epoch: 10 Idx: 5000 Loss: 0.015815228215710735
Epoch: 11 Idx: 0 Loss: 0.024241923933301827
Epoch: 11 Idx: 5000 Loss: 0.009156311804449058
Epoch: 12 Idx: 0 Loss: 0.01858953819323294
Epoch: 12 Idx: 5000 Loss: 0.013122052522819326
Epoch: 13 Idx: 0 Loss: 0.023734778691796275
Epoch: 13 Idx: 5000 Loss: 0.01106896639265111
Epoch: 14 Idx: 0 Loss: 0.011500550171227433
Epoch: 14 Idx: 5000 Loss: 0.007627032707919189
Epoch: 15 Idx: 0 Loss: 0.030857188206892105
Epoch: 15 Idx: 5000 Loss: 0.012790930434470802
Epoch: 16 Idx: 0 Loss: 0.015066995072800677
Epoch: 16 Idx: 5000 Loss: 0.019472273549201627
Epoch: 17 Idx: 0 Loss: 0.012761704501336617
Epoch: 17 Idx: 5000 Loss: 0.010620317533495353
Epoch: 18 Idx: 0 Loss: 0.018796189936875967
Epoch: 18 Idx: 5000 Loss: 0.009938055682872043
Epoch: 19 Idx: 0 Loss: 0.01872633023173006
Epoch: 19 Idx: 5000 Loss: 0.021295026800969986
Epoch: 20 Idx: 0 Loss: 0.004986252731624927
Epoch: 20 Idx: 5000 Loss: 0.018339153167261465
Epoch: 21 Idx: 0 Loss: 0.013533183305168828
Epoch: 21 Idx: 5000 Loss: 0.02124246969007329
Epoch: 22 Idx: 0 Loss: 0.006504571842236068
Epoch: 22 Idx: 5000 Loss: 0.00920848614000263
Epoch: 23 Idx: 0 Loss: 0.01095998505100991
Epoch: 23 Idx: 5000 Loss: 0.011256471394203084
Epoch: 24 Idx: 0 Loss: 0.016847919059913244
Epoch: 24 Idx: 5000 Loss: 0.009357183440337775
Epoch: 25 Idx: 0 Loss: 0.014457113029040422
Epoch: 25 Idx: 5000 Loss: 0.009532671653316725
Epoch: 26 Idx: 0 Loss: 0.033829407559412425
Epoch: 26 Idx: 5000 Loss: 0.012658461018298739
Epoch: 27 Idx: 0 Loss: 0.007135391095532683
Epoch: 27 Idx: 5000 Loss: 0.022285510554565
Epoch: 28 Idx: 0 Loss: 0.008811150076396008
Epoch: 28 Idx: 5000 Loss: 0.009960154076009331
Epoch: 29 Idx: 0 Loss: 0.012327932451947472
Epoch: 29 Idx: 5000 Loss: 0.010163726240565912
Epoch: 30 Idx: 0 Loss: 0.02724719037771329
Epoch: 30 Idx: 5000 Loss: 0.01180742829333105
Epoch: 31 Idx: 0 Loss: 0.023176153835326258
Epoch: 31 Idx: 5000 Loss: 0.02001300105616224
Epoch: 32 Idx: 0 Loss: 0.014529922919157381
Epoch: 32 Idx: 5000 Loss: 0.01866207991284055
Epoch: 33 Idx: 0 Loss: 0.013414736655899777
Epoch: 33 Idx: 5000 Loss: 0.02014422460731049
Epoch: 34 Idx: 0 Loss: 0.005920157821452995
Epoch: 34 Idx: 5000 Loss: 0.018400157336561255
Epoch: 35 Idx: 0 Loss: 0.012598122758493622
Epoch: 35 Idx: 5000 Loss: 0.0063085393748975585
Epoch: 36 Idx: 0 Loss: 0.019126856898484687
Epoch: 36 Idx: 5000 Loss: 0.008064937954976616
Epoch: 37 Idx: 0 Loss: 0.02230153553060568
Epoch: 37 Idx: 5000 Loss: 0.010819177048474564
Epoch: 38 Idx: 0 Loss: 0.017652694273788995
Epoch: 38 Idx: 5000 Loss: 0.01703788115253854
Epoch: 39 Idx: 0 Loss: 0.02187631614047944
Epoch: 39 Idx: 5000 Loss: 0.018249424421470338
Epoch: 40 Idx: 0 Loss: 0.011980024191618676
Epoch: 40 Idx: 5000 Loss: 0.009347438146957198
Epoch: 41 Idx: 0 Loss: 0.01933860395122545
Epoch: 41 Idx: 5000 Loss: 0.008525332090214874
Epoch: 42 Idx: 0 Loss: 0.010690067285144522
Epoch: 42 Idx: 5000 Loss: 0.024552312280723725
Epoch: 43 Idx: 0 Loss: 0.023444189632627548
Epoch: 43 Idx: 5000 Loss: 0.01648521214261044
Epoch: 44 Idx: 0 Loss: 0.0415655778665157
Epoch: 44 Idx: 5000 Loss: 0.00874654460068977
Epoch: 45 Idx: 0 Loss: 0.009201939962205571
Epoch: 45 Idx: 5000 Loss: 0.016077602532724885
Epoch: 46 Idx: 0 Loss: 0.013231842361701954
Epoch: 46 Idx: 5000 Loss: 0.012517802527809435
Epoch: 47 Idx: 0 Loss: 0.01514843697270419
Epoch: 47 Idx: 5000 Loss: 0.0057714804717666456
Epoch: 48 Idx: 0 Loss: 0.01762481841508217
Epoch: 48 Idx: 5000 Loss: 0.019138056714528763
Epoch: 49 Idx: 0 Loss: 0.00860118616898304
Epoch: 49 Idx: 5000 Loss: 0.009890538725637693
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14689773941290046
Epoch: 0 Idx: 5000 Loss: 0.01149669795026658
Epoch: 1 Idx: 0 Loss: 0.012325784608583098
Epoch: 1 Idx: 5000 Loss: 0.017379264170239585
Epoch: 2 Idx: 0 Loss: 0.009837344164288837
Epoch: 2 Idx: 5000 Loss: 0.011669223638963909
Epoch: 3 Idx: 0 Loss: 0.016908282819736938
Epoch: 3 Idx: 5000 Loss: 0.02576551857195111
Epoch: 4 Idx: 0 Loss: 0.02625534438032508
Epoch: 4 Idx: 5000 Loss: 0.030252843807726502
Epoch: 5 Idx: 0 Loss: 0.02898642234962991
Epoch: 5 Idx: 5000 Loss: 0.016394590991622833
Epoch: 6 Idx: 0 Loss: 0.011695232903079424
Epoch: 6 Idx: 5000 Loss: 0.031038622654270497
Epoch: 7 Idx: 0 Loss: 0.00963614930877249
Epoch: 7 Idx: 5000 Loss: 0.01329967158547655
Epoch: 8 Idx: 0 Loss: 0.020769648571757605
Epoch: 8 Idx: 5000 Loss: 0.02071463094577634
Epoch: 9 Idx: 0 Loss: 0.02671454474193147
Epoch: 9 Idx: 5000 Loss: 0.009119893853303054
Epoch: 10 Idx: 0 Loss: 0.03000706040200623
Epoch: 10 Idx: 5000 Loss: 0.013406335752511324
Epoch: 11 Idx: 0 Loss: 0.010882641737749561
Epoch: 11 Idx: 5000 Loss: 0.02841962152654809
Epoch: 12 Idx: 0 Loss: 0.011818851683052153
Epoch: 12 Idx: 5000 Loss: 0.014264679277942682
Epoch: 13 Idx: 0 Loss: 0.02734863577294635
Epoch: 13 Idx: 5000 Loss: 0.027446195093009877
Epoch: 14 Idx: 0 Loss: 0.014060337466417067
Epoch: 14 Idx: 5000 Loss: 0.02562651184513568
Epoch: 15 Idx: 0 Loss: 0.01952563414280519
Epoch: 15 Idx: 5000 Loss: 0.028526244964897238
Epoch: 16 Idx: 0 Loss: 0.02334370747820011
Epoch: 16 Idx: 5000 Loss: 0.006863109091861309
Epoch: 17 Idx: 0 Loss: 0.01821318737314426
Epoch: 17 Idx: 5000 Loss: 0.007842273690128358
Epoch: 18 Idx: 0 Loss: 0.01423400247379036
Epoch: 18 Idx: 5000 Loss: 0.015645193054983648
Epoch: 19 Idx: 0 Loss: 0.049383857115444615
Epoch: 19 Idx: 5000 Loss: 0.014832883281961267
Epoch: 20 Idx: 0 Loss: 0.017876412212722778
Epoch: 20 Idx: 5000 Loss: 0.019626174906357652
Epoch: 21 Idx: 0 Loss: 0.010868384191664937
Epoch: 21 Idx: 5000 Loss: 0.025711033330466926
Epoch: 22 Idx: 0 Loss: 0.030236096390339546
Epoch: 22 Idx: 5000 Loss: 0.011439370414973553
Epoch: 23 Idx: 0 Loss: 0.040946914361254055
Epoch: 23 Idx: 5000 Loss: 0.006529211523305141
Epoch: 24 Idx: 0 Loss: 0.0274976818736127
Epoch: 24 Idx: 5000 Loss: 0.02825545911259112
Epoch: 25 Idx: 0 Loss: 0.009587813520991677
Epoch: 25 Idx: 5000 Loss: 0.02976353794563314
Epoch: 26 Idx: 0 Loss: 0.02006804355977572
Epoch: 26 Idx: 5000 Loss: 0.020257682621046748
Epoch: 27 Idx: 0 Loss: 0.013946610073558834
Epoch: 27 Idx: 5000 Loss: 0.02602960147783216
Epoch: 28 Idx: 0 Loss: 0.015926832868400895
Epoch: 28 Idx: 5000 Loss: 0.011524620769925092
Epoch: 29 Idx: 0 Loss: 0.01794588442019461
Epoch: 29 Idx: 5000 Loss: 0.027301560957662153
Epoch: 30 Idx: 0 Loss: 0.01143029243357254
Epoch: 30 Idx: 5000 Loss: 0.012782581399145926
Epoch: 31 Idx: 0 Loss: 0.011944932252077775
Epoch: 31 Idx: 5000 Loss: 0.037010826433662644
Epoch: 32 Idx: 0 Loss: 0.022459142022657096
Epoch: 32 Idx: 5000 Loss: 0.014808001562394105
Epoch: 33 Idx: 0 Loss: 0.011550433619341797
Epoch: 33 Idx: 5000 Loss: 0.017843636525777362
Epoch: 34 Idx: 0 Loss: 0.011740572995814883
Epoch: 34 Idx: 5000 Loss: 0.032990103722905575
Epoch: 35 Idx: 0 Loss: 0.0033967759142875835
Epoch: 35 Idx: 5000 Loss: 0.013423905155384304
Epoch: 36 Idx: 0 Loss: 0.006409605196576562
Epoch: 36 Idx: 5000 Loss: 0.008926685588239665
Epoch: 37 Idx: 0 Loss: 0.01289087396899143
Epoch: 37 Idx: 5000 Loss: 0.008582816690479791
Epoch: 38 Idx: 0 Loss: 0.014515907277285212
Epoch: 38 Idx: 5000 Loss: 0.007032921739854387
Epoch: 39 Idx: 0 Loss: 0.011886109984837991
Epoch: 39 Idx: 5000 Loss: 0.008874733661612774
Epoch: 40 Idx: 0 Loss: 0.0056435958325679976
Epoch: 40 Idx: 5000 Loss: 0.01856199874619491
Epoch: 41 Idx: 0 Loss: 0.015848704117975405
Epoch: 41 Idx: 5000 Loss: 0.004683494950624003
Epoch: 42 Idx: 0 Loss: 0.016622788087437584
Epoch: 42 Idx: 5000 Loss: 0.011770976107724436
Epoch: 43 Idx: 0 Loss: 0.030036329815941183
Epoch: 43 Idx: 5000 Loss: 0.01864920020963566
Epoch: 44 Idx: 0 Loss: 0.018738092329785627
Epoch: 44 Idx: 5000 Loss: 0.0167794937896458
Epoch: 45 Idx: 0 Loss: 0.020898962120631602
Epoch: 45 Idx: 5000 Loss: 0.013250997089501247
Epoch: 46 Idx: 0 Loss: 0.031247543082732226
Epoch: 46 Idx: 5000 Loss: 0.0061353975319321085
Epoch: 47 Idx: 0 Loss: 0.009048705938167046
Epoch: 47 Idx: 5000 Loss: 0.0127575960599564
Epoch: 48 Idx: 0 Loss: 0.014843801627946313
Epoch: 48 Idx: 5000 Loss: 0.010565372349679877
Epoch: 49 Idx: 0 Loss: 0.018768413456741576
Epoch: 49 Idx: 5000 Loss: 0.014591998272948194
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13800122707239415
Epoch: 0 Idx: 5000 Loss: 0.016656353192195984
Epoch: 1 Idx: 0 Loss: 0.01623731830463108
Epoch: 1 Idx: 5000 Loss: 0.008095117635116441
Epoch: 2 Idx: 0 Loss: 0.014602109780102004
Epoch: 2 Idx: 5000 Loss: 0.015877336449042243
Epoch: 3 Idx: 0 Loss: 0.023130801363720966
Epoch: 3 Idx: 5000 Loss: 0.00880851377644565
Epoch: 4 Idx: 0 Loss: 0.014143506861304384
Epoch: 4 Idx: 5000 Loss: 0.027860659967505114
Epoch: 5 Idx: 0 Loss: 0.013417734872421762
Epoch: 5 Idx: 5000 Loss: 0.006662304160386444
Epoch: 6 Idx: 0 Loss: 0.02368870142121003
Epoch: 6 Idx: 5000 Loss: 0.050967716397104706
Epoch: 7 Idx: 0 Loss: 0.03164065349324667
Epoch: 7 Idx: 5000 Loss: 0.009594332861380808
Epoch: 8 Idx: 0 Loss: 0.009551606445974848
Epoch: 8 Idx: 5000 Loss: 0.005329510000654549
Epoch: 9 Idx: 0 Loss: 0.015879714114079513
Epoch: 9 Idx: 5000 Loss: 0.009226708786857902
Epoch: 10 Idx: 0 Loss: 0.01793861289950695
Epoch: 10 Idx: 5000 Loss: 0.013790535967815864
Epoch: 11 Idx: 0 Loss: 0.007201440169350705
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc233>
Subject: Job 4066809: <python main.py 3 26 False True> in cluster <dcc> Exited

Job <python main.py 3 26 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
Job was executed on host(s) <dccxc233>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:37 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 26 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46186.60 sec.
    Max Memory :                                 2946 MB
    Average Memory :                             2735.74 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40471.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46202 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

