2020-09-15 15:49:41.607749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:44.878823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:44.995779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:44.995847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:44.997846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:44.999431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:44.999910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.001933: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.003366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.003579: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.003603: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.003919: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.011935: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599810000 Hz
2020-09-15 15:49:45.012102: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56471cd3a960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.012124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.014025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.014049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1973155092967436
Epoch: 0 Idx: 5000 Loss: 0.009758654884879769
Epoch: 1 Idx: 0 Loss: 0.02267084402583732
Epoch: 1 Idx: 5000 Loss: 0.026895740461819514
Epoch: 2 Idx: 0 Loss: 0.010895135629143383
Epoch: 2 Idx: 5000 Loss: 0.007298105772356428
Epoch: 3 Idx: 0 Loss: 0.019097983431212807
Epoch: 3 Idx: 5000 Loss: 0.022256251433575215
Epoch: 4 Idx: 0 Loss: 0.012630065025151137
Epoch: 4 Idx: 5000 Loss: 0.02351928183499135
Epoch: 5 Idx: 0 Loss: 0.014540902508552304
Epoch: 5 Idx: 5000 Loss: 0.011011128471147717
Epoch: 6 Idx: 0 Loss: 0.02316965446183535
Epoch: 6 Idx: 5000 Loss: 0.012412395637378212
Epoch: 7 Idx: 0 Loss: 0.007556795705260056
Epoch: 7 Idx: 5000 Loss: 0.030788804785333003
Epoch: 8 Idx: 0 Loss: 0.014514572041239661
Epoch: 8 Idx: 5000 Loss: 0.01303251289088475
Epoch: 9 Idx: 0 Loss: 0.020750891051233046
Epoch: 9 Idx: 5000 Loss: 0.022239684454347222
Epoch: 10 Idx: 0 Loss: 0.01059938407448801
Epoch: 10 Idx: 5000 Loss: 0.014821212107986075
Epoch: 11 Idx: 0 Loss: 0.008814175344987778
Epoch: 11 Idx: 5000 Loss: 0.009932932663628215
Epoch: 12 Idx: 0 Loss: 0.0039003414254864515
Epoch: 12 Idx: 5000 Loss: 0.010588623108558005
Epoch: 13 Idx: 0 Loss: 0.011820048011897757
Epoch: 13 Idx: 5000 Loss: 0.009202478113799298
Epoch: 14 Idx: 0 Loss: 0.02328875151037522
Epoch: 14 Idx: 5000 Loss: 0.008495537446729958
Epoch: 15 Idx: 0 Loss: 0.020829823435346756
Epoch: 15 Idx: 5000 Loss: 0.011308570434829215
Epoch: 16 Idx: 0 Loss: 0.01875086032622654
Epoch: 16 Idx: 5000 Loss: 0.025446416943423728
Epoch: 17 Idx: 0 Loss: 0.02041983024206318
Epoch: 17 Idx: 5000 Loss: 0.03289124217483648
Epoch: 18 Idx: 0 Loss: 0.013699468529198268
Epoch: 18 Idx: 5000 Loss: 0.01129155985526014
Epoch: 19 Idx: 0 Loss: 0.017443417341080573
Epoch: 19 Idx: 5000 Loss: 0.016226784377765827
Epoch: 20 Idx: 0 Loss: 0.007929092403146966
Epoch: 20 Idx: 5000 Loss: 0.013647132782755
Epoch: 21 Idx: 0 Loss: 0.013416757334972503
Epoch: 21 Idx: 5000 Loss: 0.02331180767318735
Epoch: 22 Idx: 0 Loss: 0.03808059458713253
Epoch: 22 Idx: 5000 Loss: 0.016839706405534546
Epoch: 23 Idx: 0 Loss: 0.012185602602126519
Epoch: 23 Idx: 5000 Loss: 0.01733534873780024
Epoch: 24 Idx: 0 Loss: 0.008670615702361946
Epoch: 24 Idx: 5000 Loss: 0.015573462312217451
Epoch: 25 Idx: 0 Loss: 0.008266120519730762
Epoch: 25 Idx: 5000 Loss: 0.031783729672185956
Epoch: 26 Idx: 0 Loss: 0.008865501570979898
Epoch: 26 Idx: 5000 Loss: 0.017140078734503662
Epoch: 27 Idx: 0 Loss: 0.01583786566217362
Epoch: 27 Idx: 5000 Loss: 0.01238680190501381
Epoch: 28 Idx: 0 Loss: 0.011708920836356777
Epoch: 28 Idx: 5000 Loss: 0.02631084442959936
Epoch: 29 Idx: 0 Loss: 0.020965934997240837
Epoch: 29 Idx: 5000 Loss: 0.010046843813772126
Epoch: 30 Idx: 0 Loss: 0.025129252982056257
Epoch: 30 Idx: 5000 Loss: 0.04006232168169424
Epoch: 31 Idx: 0 Loss: 0.01610621457124903
Epoch: 31 Idx: 5000 Loss: 0.016819065826810458
Epoch: 32 Idx: 0 Loss: 0.006192070008884616
Epoch: 32 Idx: 5000 Loss: 0.016336386936736398
Epoch: 33 Idx: 0 Loss: 0.02797086492905161
Epoch: 33 Idx: 5000 Loss: 0.010790702420442257
Epoch: 34 Idx: 0 Loss: 0.021936639036914354
Epoch: 34 Idx: 5000 Loss: 0.01176085918971253
Epoch: 35 Idx: 0 Loss: 0.02012482307227066
Epoch: 35 Idx: 5000 Loss: 0.006694529248886215
Epoch: 36 Idx: 0 Loss: 0.02081332746135158
Epoch: 36 Idx: 5000 Loss: 0.009173881020067002
Epoch: 37 Idx: 0 Loss: 0.022121267493856928
Epoch: 37 Idx: 5000 Loss: 0.00819797294017881
Epoch: 38 Idx: 0 Loss: 0.008627349334858595
Epoch: 38 Idx: 5000 Loss: 0.02976450022426974
Epoch: 39 Idx: 0 Loss: 0.017157144864725846
Epoch: 39 Idx: 5000 Loss: 0.024650082751362202
Epoch: 40 Idx: 0 Loss: 0.021787957930685546
Epoch: 40 Idx: 5000 Loss: 0.018857574937675866
Epoch: 41 Idx: 0 Loss: 0.026703438027952105
Epoch: 41 Idx: 5000 Loss: 0.014935938349360295
Epoch: 42 Idx: 0 Loss: 0.013458138496865842
Epoch: 42 Idx: 5000 Loss: 0.024603687919228005
Epoch: 43 Idx: 0 Loss: 0.014313815394937306
Epoch: 43 Idx: 5000 Loss: 0.024233170394437255
Epoch: 44 Idx: 0 Loss: 0.00932357267823417
Epoch: 44 Idx: 5000 Loss: 0.012048871116620927
Epoch: 45 Idx: 0 Loss: 0.013274473209685216
Epoch: 45 Idx: 5000 Loss: 0.023494325154335638
Epoch: 46 Idx: 0 Loss: 0.015379636775357615
Epoch: 46 Idx: 5000 Loss: 0.04493902961635743
Epoch: 47 Idx: 0 Loss: 0.014785052887141109
Epoch: 47 Idx: 5000 Loss: 0.027560794291917722
Epoch: 48 Idx: 0 Loss: 0.010338881543613038
Epoch: 48 Idx: 5000 Loss: 0.01601616903632562
Epoch: 49 Idx: 0 Loss: 0.010300027621580452
Epoch: 49 Idx: 5000 Loss: 0.005562406988859379
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14222083637112728
Epoch: 0 Idx: 5000 Loss: 0.01823695632127564
Epoch: 1 Idx: 0 Loss: 0.01537980750929197
Epoch: 1 Idx: 5000 Loss: 0.014960888529169374
Epoch: 2 Idx: 0 Loss: 0.018556447361249475
Epoch: 2 Idx: 5000 Loss: 0.031649981925067565
Epoch: 3 Idx: 0 Loss: 0.015316832238806685
Epoch: 3 Idx: 5000 Loss: 0.016557984521756185
Epoch: 4 Idx: 0 Loss: 0.012720142506889975
Epoch: 4 Idx: 5000 Loss: 0.01245158664440176
Epoch: 5 Idx: 0 Loss: 0.01151135756355225
Epoch: 5 Idx: 5000 Loss: 0.02119145978739977
Epoch: 6 Idx: 0 Loss: 0.013291908289675584
Epoch: 6 Idx: 5000 Loss: 0.027730907149176743
Epoch: 7 Idx: 0 Loss: 0.020063813267410763
Epoch: 7 Idx: 5000 Loss: 0.023328080011738125
Epoch: 8 Idx: 0 Loss: 0.016362618490035546
Epoch: 8 Idx: 5000 Loss: 0.015496544016647126
Epoch: 9 Idx: 0 Loss: 0.025280263353900313
Epoch: 9 Idx: 5000 Loss: 0.03832800105078193
Epoch: 10 Idx: 0 Loss: 0.011747133720095653
Epoch: 10 Idx: 5000 Loss: 0.00936852898426742
Epoch: 11 Idx: 0 Loss: 0.0317821147008215
Epoch: 11 Idx: 5000 Loss: 0.010379813894642228
Epoch: 12 Idx: 0 Loss: 0.014641213848858156
Epoch: 12 Idx: 5000 Loss: 0.023643460718540066
Epoch: 13 Idx: 0 Loss: 0.006339596459636758
Epoch: 13 Idx: 5000 Loss: 0.017332011656464048
Epoch: 14 Idx: 0 Loss: 0.018113891493374553
Epoch: 14 Idx: 5000 Loss: 0.013961951575419298
Epoch: 15 Idx: 0 Loss: 0.005853412827972403
Epoch: 15 Idx: 5000 Loss: 0.01245765139292241
Epoch: 16 Idx: 0 Loss: 0.023677559338015776
Epoch: 16 Idx: 5000 Loss: 0.024754195381713494
Epoch: 17 Idx: 0 Loss: 0.01755456379501706
Epoch: 17 Idx: 5000 Loss: 0.0062147371458686216
Epoch: 18 Idx: 0 Loss: 0.010850321733245688
Epoch: 18 Idx: 5000 Loss: 0.007868393884642128
Epoch: 19 Idx: 0 Loss: 0.03208953153288746
Epoch: 19 Idx: 5000 Loss: 0.010734252604464554
Epoch: 20 Idx: 0 Loss: 0.021702465944170836
Epoch: 20 Idx: 5000 Loss: 0.029249487517070495
Epoch: 21 Idx: 0 Loss: 0.013322631360642132
Epoch: 21 Idx: 5000 Loss: 0.021719698312455474
Epoch: 22 Idx: 0 Loss: 0.011950804306780721
Epoch: 22 Idx: 5000 Loss: 0.015994229101783247
Epoch: 23 Idx: 0 Loss: 0.022650288643024867
Epoch: 23 Idx: 5000 Loss: 0.008136925131534564
Epoch: 24 Idx: 0 Loss: 0.01328374204727289
Epoch: 24 Idx: 5000 Loss: 0.03915332005912212
Epoch: 25 Idx: 0 Loss: 0.010252115665474642
Epoch: 25 Idx: 5000 Loss: 0.011258646033748453
Epoch: 26 Idx: 0 Loss: 0.0285566294447363
Epoch: 26 Idx: 5000 Loss: 0.0065738304255392056
Epoch: 27 Idx: 0 Loss: 0.052407593428128514
Epoch: 27 Idx: 5000 Loss: 0.020865631338665546
Epoch: 28 Idx: 0 Loss: 0.04421336700715053
Epoch: 28 Idx: 5000 Loss: 0.00948447599805187
Epoch: 29 Idx: 0 Loss: 0.016831296162496824
Epoch: 29 Idx: 5000 Loss: 0.020295718297227917
Epoch: 30 Idx: 0 Loss: 0.02191927771112236
Epoch: 30 Idx: 5000 Loss: 0.013618905451855623
Epoch: 31 Idx: 0 Loss: 0.010515981350602213
Epoch: 31 Idx: 5000 Loss: 0.0163719963529045
Epoch: 32 Idx: 0 Loss: 0.01650781803766412
Epoch: 32 Idx: 5000 Loss: 0.010042614903552956
Epoch: 33 Idx: 0 Loss: 0.016344845517243974
Epoch: 33 Idx: 5000 Loss: 0.02135807303297522
Epoch: 34 Idx: 0 Loss: 0.039984262224408804
Epoch: 34 Idx: 5000 Loss: 0.005544424381756794
Epoch: 35 Idx: 0 Loss: 0.005570702827682501
Epoch: 35 Idx: 5000 Loss: 0.0183120690949221
Epoch: 36 Idx: 0 Loss: 0.012656674112585316
Epoch: 36 Idx: 5000 Loss: 0.01962994850660226
Epoch: 37 Idx: 0 Loss: 0.030634333967108223
Epoch: 37 Idx: 5000 Loss: 0.012953575550058952
Epoch: 38 Idx: 0 Loss: 0.006147028438418545
Epoch: 38 Idx: 5000 Loss: 0.0059856051535599015
Epoch: 39 Idx: 0 Loss: 0.013610151358939608
Epoch: 39 Idx: 5000 Loss: 0.012035383491161046
Epoch: 40 Idx: 0 Loss: 0.017972694587413036
Epoch: 40 Idx: 5000 Loss: 0.020148597615897414
Epoch: 41 Idx: 0 Loss: 0.02043906125393531
Epoch: 41 Idx: 5000 Loss: 0.027587782986238124
Epoch: 42 Idx: 0 Loss: 0.03391645083616543
Epoch: 42 Idx: 5000 Loss: 0.026073459071896603
Epoch: 43 Idx: 0 Loss: 0.016261057589338043
Epoch: 43 Idx: 5000 Loss: 0.007915547217077722
Epoch: 44 Idx: 0 Loss: 0.009038744973412498
Epoch: 44 Idx: 5000 Loss: 0.01554250927172322
Epoch: 45 Idx: 0 Loss: 0.015026946855378549
Epoch: 45 Idx: 5000 Loss: 0.004398849649052063
Epoch: 46 Idx: 0 Loss: 0.015856947464809954
Epoch: 46 Idx: 5000 Loss: 0.015818483626589042
Epoch: 47 Idx: 0 Loss: 0.009969885201983513
Epoch: 47 Idx: 5000 Loss: 0.019965760042057745
Epoch: 48 Idx: 0 Loss: 0.011440445292416015
Epoch: 48 Idx: 5000 Loss: 0.01964141161468814
Epoch: 49 Idx: 0 Loss: 0.006967623343156121
Epoch: 49 Idx: 5000 Loss: 0.005749281480933292
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13657276611588118
Epoch: 0 Idx: 5000 Loss: 0.006657572629947356
Epoch: 1 Idx: 0 Loss: 0.015141267762327907
Epoch: 1 Idx: 5000 Loss: 0.015033614590290043
Epoch: 2 Idx: 0 Loss: 0.033023554717181956
Epoch: 2 Idx: 5000 Loss: 0.030268451223752216
Epoch: 3 Idx: 0 Loss: 0.009223199521321581
Epoch: 3 Idx: 5000 Loss: 0.019080227385965775
Epoch: 4 Idx: 0 Loss: 0.013803251850558244
Epoch: 4 Idx: 5000 Loss: 0.03235833143754137
Epoch: 5 Idx: 0 Loss: 0.014018640421300145
Epoch: 5 Idx: 5000 Loss: 0.010190541979041522
Epoch: 6 Idx: 0 Loss: 0.012552324100793422
Epoch: 6 Idx: 5000 Loss: 0.03914553038460174
Epoch: 7 Idx: 0 Loss: 0.03274488738881345
Epoch: 7 Idx: 5000 Loss: 0.010431891054603635
Epoch: 8 Idx: 0 Loss: 0.011971125304779735
Epoch: 8 Idx: 5000 Loss: 0.0065765793305608755
Epoch: 9 Idx: 0 Loss: 0.018596342076900352
Epoch: 9 Idx: 5000 Loss: 0.012494292655024535
Epoch: 10 Idx: 0 Loss: 0.02900816831497071
Epoch: 10 Idx: 5000 Loss: 0.039989930405010664
Epoch: 11 Idx: 0 Loss: 0.011464889060415583
Epoch: 11 Idx: 5000 Loss: 0.010245623860763988
Epoch: 12 Idx: 0 Loss: 0.015935525239557755
Epoch: 12 Idx: 5000 Loss: 0.010911958099461553
Epoch: 13 Idx: 0 Loss: 0.010305649520921487
Epoch: 13 Idx: 5000 Loss: 0.02567035602453124
Epoch: 14 Idx: 0 Loss: 0.04001961662575275
Epoch: 14 Idx: 5000 Loss: 0.022062417226314468
Epoch: 15 Idx: 0 Loss: 0.009352401362984063
Epoch: 15 Idx: 5000 Loss: 0.023993660272807478
Epoch: 16 Idx: 0 Loss: 0.022296509180069146
Epoch: 16 Idx: 5000 Loss: 0.01280052295175637
Epoch: 17 Idx: 0 Loss: 0.01001328804735489
Epoch: 17 Idx: 5000 Loss: 0.015902106021216354
Epoch: 18 Idx: 0 Loss: 0.01795018307448111
Epoch: 18 Idx: 5000 Loss: 0.010726566087582993
Epoch: 19 Idx: 0 Loss: 0.026732441502202355
Epoch: 19 Idx: 5000 Loss: 0.030841488772001564
Epoch: 20 Idx: 0 Loss: 0.0068131785802312455
Epoch: 20 Idx: 5000 Loss: 0.03361041994525218
Epoch: 21 Idx: 0 Loss: 0.014602258192134662
Epoch: 21 Idx: 5000 Loss: 0.019361879070773923
Epoch: 22 Idx: 0 Loss: 0.01495776030523734
Epoch: 22 Idx: 5000 Loss: 0.017049246208663358
Epoch: 23 Idx: 0 Loss: 0.06482408120956809
Epoch: 23 Idx: 5000 Loss: 0.019488692028490115
Epoch: 24 Idx: 0 Loss: 0.011046419166469085
Traceback (most recent call last):
  File "main.py", line 513, in <module>
    optimizer.zero_grad()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/optimizer.py", line 172, in zero_grad
    p.grad.zero_()
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc202>
Subject: Job 4066911: <python main.py 26 2 True False> in cluster <dcc> Exited

Job <python main.py 26 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc202>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 26 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   45983.85 sec.
    Max Memory :                                 2910 MB
    Average Memory :                             2688.33 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40507.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46139 sec.
    Turnaround time :                            46198 sec.

The output (if any) is above this job summary.

