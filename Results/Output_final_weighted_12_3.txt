2020-09-15 15:48:41.850599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.381732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.495101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.495206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.498015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.504396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.514399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.523923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.530219: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.530767: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.530792: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.531259: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.571695: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600160000 Hz
2020-09-15 15:48:49.571990: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5624cbb9f0d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.572015: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.574553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.574594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18017410043917656
Epoch: 0 Idx: 5000 Loss: 0.01140761856143066
Epoch: 1 Idx: 0 Loss: 0.028733994765996723
Epoch: 1 Idx: 5000 Loss: 0.009985990106873411
Epoch: 2 Idx: 0 Loss: 0.013920353312744443
Epoch: 2 Idx: 5000 Loss: 0.018308463822071724
Epoch: 3 Idx: 0 Loss: 0.012264006018631916
Epoch: 3 Idx: 5000 Loss: 0.025099505881496197
Epoch: 4 Idx: 0 Loss: 0.012150994197500025
Epoch: 4 Idx: 5000 Loss: 0.012835522916790021
Epoch: 5 Idx: 0 Loss: 0.012761266152553689
Epoch: 5 Idx: 5000 Loss: 0.030186735124284447
Epoch: 6 Idx: 0 Loss: 0.02118946266421142
Epoch: 6 Idx: 5000 Loss: 0.023030614555540806
Epoch: 7 Idx: 0 Loss: 0.020563171569335233
Epoch: 7 Idx: 5000 Loss: 0.021123733414568635
Epoch: 8 Idx: 0 Loss: 0.013046876654965366
Epoch: 8 Idx: 5000 Loss: 0.022329219613396747
Epoch: 9 Idx: 0 Loss: 0.025058546636639624
Epoch: 9 Idx: 5000 Loss: 0.010657315984803479
Epoch: 10 Idx: 0 Loss: 0.02699816385226637
Epoch: 10 Idx: 5000 Loss: 0.013966891053962557
Epoch: 11 Idx: 0 Loss: 0.023687755073518522
Epoch: 11 Idx: 5000 Loss: 0.02585175830558422
Epoch: 12 Idx: 0 Loss: 0.00811031976799224
Epoch: 12 Idx: 5000 Loss: 0.009672647754869996
Epoch: 13 Idx: 0 Loss: 0.01095144444022412
Epoch: 13 Idx: 5000 Loss: 0.01006783370217675
Epoch: 14 Idx: 0 Loss: 0.023464595995405846
Epoch: 14 Idx: 5000 Loss: 0.02917318745362347
Epoch: 15 Idx: 0 Loss: 0.017257487343881488
Epoch: 15 Idx: 5000 Loss: 0.023692881083906398
Epoch: 16 Idx: 0 Loss: 0.010542269875784799
Epoch: 16 Idx: 5000 Loss: 0.00655544330868299
Epoch: 17 Idx: 0 Loss: 0.010940998860412193
Epoch: 17 Idx: 5000 Loss: 0.015255979973738803
Epoch: 18 Idx: 0 Loss: 0.02489130517602316
Epoch: 18 Idx: 5000 Loss: 0.01847107927878929
Epoch: 19 Idx: 0 Loss: 0.03004876401345185
Epoch: 19 Idx: 5000 Loss: 0.02002962883336945
Epoch: 20 Idx: 0 Loss: 0.0076141301706320295
Epoch: 20 Idx: 5000 Loss: 0.005962172151690775
Epoch: 21 Idx: 0 Loss: 0.015005806636779428
Epoch: 21 Idx: 5000 Loss: 0.019146072307403457
Epoch: 22 Idx: 0 Loss: 0.01293714316662865
Epoch: 22 Idx: 5000 Loss: 0.019965650315193848
Epoch: 23 Idx: 0 Loss: 0.012326815422789107
Epoch: 23 Idx: 5000 Loss: 0.010593742330190486
Epoch: 24 Idx: 0 Loss: 0.019105839967137963
Epoch: 24 Idx: 5000 Loss: 0.016295980449572534
Epoch: 25 Idx: 0 Loss: 0.037531401677314884
Epoch: 25 Idx: 5000 Loss: 0.020310585618917795
Epoch: 26 Idx: 0 Loss: 0.004852290405311471
Epoch: 26 Idx: 5000 Loss: 0.03606937844140564
Epoch: 27 Idx: 0 Loss: 0.010009651515562169
Epoch: 27 Idx: 5000 Loss: 0.02059216381020265
Epoch: 28 Idx: 0 Loss: 0.0360138684767824
Epoch: 28 Idx: 5000 Loss: 0.01452920868956676
Epoch: 29 Idx: 0 Loss: 0.024853617620984314
Epoch: 29 Idx: 5000 Loss: 0.008203932266637357
Epoch: 30 Idx: 0 Loss: 0.019337822901102683
Epoch: 30 Idx: 5000 Loss: 0.022680104660588212
Epoch: 31 Idx: 0 Loss: 0.018314819397324617
Epoch: 31 Idx: 5000 Loss: 0.030686060126005502
Epoch: 32 Idx: 0 Loss: 0.015490995482563934
Epoch: 32 Idx: 5000 Loss: 0.005783761099795571
Epoch: 33 Idx: 0 Loss: 0.026464382860508787
Epoch: 33 Idx: 5000 Loss: 0.026347244451776632
Epoch: 34 Idx: 0 Loss: 0.025667101443960345
Epoch: 34 Idx: 5000 Loss: 0.0141774200085008
Epoch: 35 Idx: 0 Loss: 0.019702803590135945
Epoch: 35 Idx: 5000 Loss: 0.012522117318414863
Epoch: 36 Idx: 0 Loss: 0.02162128976952029
Epoch: 36 Idx: 5000 Loss: 0.010748065168335196
Epoch: 37 Idx: 0 Loss: 0.021062771937043066
Epoch: 37 Idx: 5000 Loss: 0.029803584575886024
Epoch: 38 Idx: 0 Loss: 0.018648065388560644
Epoch: 38 Idx: 5000 Loss: 0.04048019167362722
Epoch: 39 Idx: 0 Loss: 0.018592395097738874
Epoch: 39 Idx: 5000 Loss: 0.010228936873150102
Epoch: 40 Idx: 0 Loss: 0.007129451512682405
Epoch: 40 Idx: 5000 Loss: 0.018642008943686506
Epoch: 41 Idx: 0 Loss: 0.01420439797003696
Epoch: 41 Idx: 5000 Loss: 0.01705521149693582
Epoch: 42 Idx: 0 Loss: 0.010103193084722406
Epoch: 42 Idx: 5000 Loss: 0.02001151100781339
Epoch: 43 Idx: 0 Loss: 0.011281849316580307
Epoch: 43 Idx: 5000 Loss: 0.04462578989393311
Epoch: 44 Idx: 0 Loss: 0.02764666022934705
Epoch: 44 Idx: 5000 Loss: 0.011148719509251412
Epoch: 45 Idx: 0 Loss: 0.0071769699113623684
Epoch: 45 Idx: 5000 Loss: 0.018490726626100226
Epoch: 46 Idx: 0 Loss: 0.011322493555842172
Epoch: 46 Idx: 5000 Loss: 0.01034050304373907
Epoch: 47 Idx: 0 Loss: 0.009648650248333333
Epoch: 47 Idx: 5000 Loss: 0.012494322331599911
Epoch: 48 Idx: 0 Loss: 0.014565909756316121
Epoch: 48 Idx: 5000 Loss: 0.030274042920166416
Epoch: 49 Idx: 0 Loss: 0.010904469303888394
Epoch: 49 Idx: 5000 Loss: 0.0269457378961784
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15417433214741108
Epoch: 0 Idx: 5000 Loss: 0.020058352123869347
Epoch: 1 Idx: 0 Loss: 0.015407622780872092
Epoch: 1 Idx: 5000 Loss: 0.028821253511846407
Epoch: 2 Idx: 0 Loss: 0.046891226660622495
Epoch: 2 Idx: 5000 Loss: 0.0372244649715103
Epoch: 3 Idx: 0 Loss: 0.006673828738716853
Epoch: 3 Idx: 5000 Loss: 0.01685776117645365
Epoch: 4 Idx: 0 Loss: 0.030809718511798735
Epoch: 4 Idx: 5000 Loss: 0.014352613550308991
Epoch: 5 Idx: 0 Loss: 0.02033263547199775
Epoch: 5 Idx: 5000 Loss: 0.01363363154400998
Epoch: 6 Idx: 0 Loss: 0.011949180106287838
Epoch: 6 Idx: 5000 Loss: 0.01072777378100805
Epoch: 7 Idx: 0 Loss: 0.008040344214293872
Epoch: 7 Idx: 5000 Loss: 0.011290981709311254
Epoch: 8 Idx: 0 Loss: 0.02395235073653804
Epoch: 8 Idx: 5000 Loss: 0.009445138586567738
Epoch: 9 Idx: 0 Loss: 0.019900022735379795
Epoch: 9 Idx: 5000 Loss: 0.03443468240610359
Epoch: 10 Idx: 0 Loss: 0.021349892702935705
Epoch: 10 Idx: 5000 Loss: 0.011160210538957832
Epoch: 11 Idx: 0 Loss: 0.010502631933868526
Epoch: 11 Idx: 5000 Loss: 0.004829187484855972
Epoch: 12 Idx: 0 Loss: 0.009606160323950327
Epoch: 12 Idx: 5000 Loss: 0.009095128591944501
Epoch: 13 Idx: 0 Loss: 0.012347544914621195
Epoch: 13 Idx: 5000 Loss: 0.01298610105317655
Epoch: 14 Idx: 0 Loss: 0.010485608809900304
Epoch: 14 Idx: 5000 Loss: 0.023057857332253906
Epoch: 15 Idx: 0 Loss: 0.022517791147876783
Epoch: 15 Idx: 5000 Loss: 0.011734911573843848
Epoch: 16 Idx: 0 Loss: 0.024756795676556777
Epoch: 16 Idx: 5000 Loss: 0.017519911312239442
Epoch: 17 Idx: 0 Loss: 0.03652230000546288
Epoch: 17 Idx: 5000 Loss: 0.02048766167413621
Epoch: 18 Idx: 0 Loss: 0.03395224327400306
Epoch: 18 Idx: 5000 Loss: 0.042224451598923955
Epoch: 19 Idx: 0 Loss: 0.0235347819336753
Epoch: 19 Idx: 5000 Loss: 0.024573374844985965
Epoch: 20 Idx: 0 Loss: 0.013346162664153149
Epoch: 20 Idx: 5000 Loss: 0.014064492096956035
Epoch: 21 Idx: 0 Loss: 0.03616824333604475
Epoch: 21 Idx: 5000 Loss: 0.023460052108593334
Epoch: 22 Idx: 0 Loss: 0.012368498589254024
Epoch: 22 Idx: 5000 Loss: 0.011333874022415126
Epoch: 23 Idx: 0 Loss: 0.012630527895607821
Epoch: 23 Idx: 5000 Loss: 0.02163905209211093
Epoch: 24 Idx: 0 Loss: 0.020194511937079437
Epoch: 24 Idx: 5000 Loss: 0.012882741246687838
Epoch: 25 Idx: 0 Loss: 0.02006594649821755
Epoch: 25 Idx: 5000 Loss: 0.030918316687672188
Epoch: 26 Idx: 0 Loss: 0.02048152421784425
Epoch: 26 Idx: 5000 Loss: 0.029349909651368845
Epoch: 27 Idx: 0 Loss: 0.019406920906571777
Epoch: 27 Idx: 5000 Loss: 0.011584883514414028
Epoch: 28 Idx: 0 Loss: 0.02101849897511261
Epoch: 28 Idx: 5000 Loss: 0.04584654700210157
Epoch: 29 Idx: 0 Loss: 0.015205533474015428
Epoch: 29 Idx: 5000 Loss: 0.017756364121856574
Epoch: 30 Idx: 0 Loss: 0.01938309056534734
Epoch: 30 Idx: 5000 Loss: 0.021216352195237115
Epoch: 31 Idx: 0 Loss: 0.009836277294772029
Epoch: 31 Idx: 5000 Loss: 0.028364378937685147
Epoch: 32 Idx: 0 Loss: 0.023571757120015614
Epoch: 32 Idx: 5000 Loss: 0.013718800202286857
Epoch: 33 Idx: 0 Loss: 0.015563549830838854
Epoch: 33 Idx: 5000 Loss: 0.015238867654008968
Epoch: 34 Idx: 0 Loss: 0.01720101705400154
Epoch: 34 Idx: 5000 Loss: 0.007270365842794842
Epoch: 35 Idx: 0 Loss: 0.019094339539715916
Epoch: 35 Idx: 5000 Loss: 0.004417244881013688
Epoch: 36 Idx: 0 Loss: 0.017673892103367488
Epoch: 36 Idx: 5000 Loss: 0.012183191196648853
Epoch: 37 Idx: 0 Loss: 0.008350218947879216
Epoch: 37 Idx: 5000 Loss: 0.009725182017877804
Epoch: 38 Idx: 0 Loss: 0.014291259006093102
Epoch: 38 Idx: 5000 Loss: 0.009690417646814456
Epoch: 39 Idx: 0 Loss: 0.021992457532752197
Epoch: 39 Idx: 5000 Loss: 0.012654868926620617
Epoch: 40 Idx: 0 Loss: 0.010522983546586798
Epoch: 40 Idx: 5000 Loss: 0.014844952913826984
Epoch: 41 Idx: 0 Loss: 0.008392286288689089
Epoch: 41 Idx: 5000 Loss: 0.022348420270615177
Epoch: 42 Idx: 0 Loss: 0.012348931263699089
Epoch: 42 Idx: 5000 Loss: 0.012967720592296863
Epoch: 43 Idx: 0 Loss: 0.010931190938185563
Epoch: 43 Idx: 5000 Loss: 0.00822654839798217
Epoch: 44 Idx: 0 Loss: 0.023810237566804348
Epoch: 44 Idx: 5000 Loss: 0.006636593446662952
Epoch: 45 Idx: 0 Loss: 0.007669231839807478
Epoch: 45 Idx: 5000 Loss: 0.009162789674829298
Epoch: 46 Idx: 0 Loss: 0.01285266428306074
Epoch: 46 Idx: 5000 Loss: 0.012988785045701067
Epoch: 47 Idx: 0 Loss: 0.01206397815445432
Epoch: 47 Idx: 5000 Loss: 0.032185465966868214
Epoch: 48 Idx: 0 Loss: 0.025208513691225738
Epoch: 48 Idx: 5000 Loss: 0.009982570888350677
Epoch: 49 Idx: 0 Loss: 0.011943970579250257
Epoch: 49 Idx: 5000 Loss: 0.011378800827462301
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1498326660948041
Epoch: 0 Idx: 5000 Loss: 0.015424336155088514
Epoch: 1 Idx: 0 Loss: 0.011953274955952282
Epoch: 1 Idx: 5000 Loss: 0.011552917135143753
Epoch: 2 Idx: 0 Loss: 0.01812769307271132
Epoch: 2 Idx: 5000 Loss: 0.016724113542312357
Epoch: 3 Idx: 0 Loss: 0.014643915384295648
Epoch: 3 Idx: 5000 Loss: 0.018847933884876874
Epoch: 4 Idx: 0 Loss: 0.0138581030563424
Epoch: 4 Idx: 5000 Loss: 0.0066101379040408685
Epoch: 5 Idx: 0 Loss: 0.022925037131844357
Epoch: 5 Idx: 5000 Loss: 0.009945834501798572
Epoch: 6 Idx: 0 Loss: 0.010150464697387304
Epoch: 6 Idx: 5000 Loss: 0.016109912908823548
Epoch: 7 Idx: 0 Loss: 0.013777050583929855
Epoch: 7 Idx: 5000 Loss: 0.01000650132486619
Epoch: 8 Idx: 0 Loss: 0.01902802807809804
Epoch: 8 Idx: 5000 Loss: 0.011739553236848794
Epoch: 9 Idx: 0 Loss: 0.015835858922787282
Epoch: 9 Idx: 5000 Loss: 0.009016640752654344
Epoch: 10 Idx: 0 Loss: 0.0072191261151016255
Epoch: 10 Idx: 5000 Loss: 0.02879787327270437
Epoch: 11 Idx: 0 Loss: 0.01890798915464487
Epoch: 11 Idx: 5000 Loss: 0.01804148464623665
Epoch: 12 Idx: 0 Loss: 0.01158323194609337
Epoch: 12 Idx: 5000 Loss: 0.03162185027299931
Epoch: 13 Idx: 0 Loss: 0.012224771043499939
Epoch: 13 Idx: 5000 Loss: 0.007798578830677279
Epoch: 14 Idx: 0 Loss: 0.017931097524678113
Epoch: 14 Idx: 5000 Loss: 0.008214263712704322
Epoch: 15 Idx: 0 Loss: 0.012220675384506288
Epoch: 15 Idx: 5000 Loss: 0.02140046831765781
Epoch: 16 Idx: 0 Loss: 0.02271145444328996
Epoch: 16 Idx: 5000 Loss: 0.008992837625984122
Epoch: 17 Idx: 0 Loss: 0.009687363260427139
Epoch: 17 Idx: 5000 Loss: 0.012696201621480309
Epoch: 18 Idx: 0 Loss: 0.0064066928693561715
Epoch: 18 Idx: 5000 Loss: 0.011230163231359854
Epoch: 19 Idx: 0 Loss: 0.017365254538790023
Epoch: 19 Idx: 5000 Loss: 0.0071139182365895
Epoch: 20 Idx: 0 Loss: 0.007905951847808661
Epoch: 20 Idx: 5000 Loss: 0.015054920927022741
Epoch: 21 Idx: 0 Loss: 0.01848715303948025
Epoch: 21 Idx: 5000 Loss: 0.02203238065371807
Epoch: 22 Idx: 0 Loss: 0.013860143432482083
Epoch: 22 Idx: 5000 Loss: 0.015293198642598444
Epoch: 23 Idx: 0 Loss: 0.0111152695920769
Epoch: 23 Idx: 5000 Loss: 0.012587928051204487
Epoch: 24 Idx: 0 Loss: 0.00822367932572952
Epoch: 24 Idx: 5000 Loss: 0.009941493389240351
Epoch: 25 Idx: 0 Loss: 0.034036770790244565
Epoch: 25 Idx: 5000 Loss: 0.014243470349761426
Epoch: 26 Idx: 0 Loss: 0.022854264497131335
Epoch: 26 Idx: 5000 Loss: 0.01653912712900997
Epoch: 27 Idx: 0 Loss: 0.0097036827274283
Epoch: 27 Idx: 5000 Loss: 0.01894960879288976
Epoch: 28 Idx: 0 Loss: 0.017140407179254316
Epoch: 28 Idx: 5000 Loss: 0.011609847526607372
Epoch: 29 Idx: 0 Loss: 0.009622821785359755
Epoch: 29 Idx: 5000 Loss: 0.021898789639978298
Epoch: 30 Idx: 0 Loss: 0.016688681031837096
Epoch: 30 Idx: 5000 Loss: 0.013011182283512841
Epoch: 31 Idx: 0 Loss: 0.014767480550444322
Epoch: 31 Idx: 5000 Loss: 0.015267136395102932
Epoch: 32 Idx: 0 Loss: 0.006928825648549168
Epoch: 32 Idx: 5000 Loss: 0.010675892783934469
Epoch: 33 Idx: 0 Loss: 0.008561889598699886
Epoch: 33 Idx: 5000 Loss: 0.022683110902302805
Epoch: 34 Idx: 0 Loss: 0.014436484525023175
Epoch: 34 Idx: 5000 Loss: 0.011353368400382284
Epoch: 35 Idx: 0 Loss: 0.01629933799705189
Epoch: 35 Idx: 5000 Loss: 0.012540740069878155
Epoch: 36 Idx: 0 Loss: 0.010272617691277863
Epoch: 36 Idx: 5000 Loss: 0.011514403588072066
Epoch: 37 Idx: 0 Loss: 0.007774111786430238
Epoch: 37 Idx: 5000 Loss: 0.018331347162230227
Epoch: 38 Idx: 0 Loss: 0.011587972017656042
Epoch: 38 Idx: 5000 Loss: 0.018091206101552307
Epoch: 39 Idx: 0 Loss: 0.011106087149747281
Epoch: 39 Idx: 5000 Loss: 0.00963033194621353
Epoch: 40 Idx: 0 Loss: 0.02709563223303125
Epoch: 40 Idx: 5000 Loss: 0.029459499566052462
Epoch: 41 Idx: 0 Loss: 0.009918661873012543
Epoch: 41 Idx: 5000 Loss: 0.010760239345261918
Epoch: 42 Idx: 0 Loss: 0.023294518868463447
Epoch: 42 Idx: 5000 Loss: 0.019276293767672186
Epoch: 43 Idx: 0 Loss: 0.0105161431330781
Epoch: 43 Idx: 5000 Loss: 0.013107971402946053
Epoch: 44 Idx: 0 Loss: 0.03528130820993379
Epoch: 44 Idx: 5000 Loss: 0.03941067508271206
Epoch: 45 Idx: 0 Loss: 0.03085223480304897
Epoch: 45 Idx: 5000 Loss: 0.014405456972286006
Epoch: 46 Idx: 0 Loss: 0.032024408938760456
Epoch: 46 Idx: 5000 Loss: 0.008386970209862425
Epoch: 47 Idx: 0 Loss: 0.014229606623005698
Epoch: 47 Idx: 5000 Loss: 0.019100143801401084
Epoch: 48 Idx: 0 Loss: 0.01599020028396479
Epoch: 48 Idx: 5000 Loss: 0.014757885772889633
Epoch: 49 Idx: 0 Loss: 0.019926686055386434
Epoch: 49 Idx: 5000 Loss: 0.006989318639720571
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.21576410057909373
Epoch: 0 Idx: 5000 Loss: 0.040245417800694544
Epoch: 1 Idx: 0 Loss: 0.005348183691791214
Epoch: 1 Idx: 5000 Loss: 0.02456754421547415
Epoch: 2 Idx: 0 Loss: 0.014333317438147624
Epoch: 2 Idx: 5000 Loss: 0.014133585637385667
Epoch: 3 Idx: 0 Loss: 0.009853572134346724
Epoch: 3 Idx: 5000 Loss: 0.04057444133665418
Epoch: 4 Idx: 0 Loss: 0.012002553567935306
Epoch: 4 Idx: 5000 Loss: 0.01340492533824327
Epoch: 5 Idx: 0 Loss: 0.015620895179446334
Epoch: 5 Idx: 5000 Loss: 0.009870946859926021
Epoch: 6 Idx: 0 Loss: 0.026601275174423678
Epoch: 6 Idx: 5000 Loss: 0.012549803105816717
Epoch: 7 Idx: 0 Loss: 0.015428630058407139
Epoch: 7 Idx: 5000 Loss: 0.00905846385383761
Epoch: 8 Idx: 0 Loss: 0.014764008700405402
Epoch: 8 Idx: 5000 Loss: 0.013707448566808807
Epoch: 9 Idx: 0 Loss: 0.016156493453857883
Epoch: 9 Idx: 5000 Loss: 0.010200164724517334
Epoch: 10 Idx: 0 Loss: 0.012862968118238354
Epoch: 10 Idx: 5000 Loss: 0.017808826347237818
Epoch: 11 Idx: 0 Loss: 0.00428853916013091
Epoch: 11 Idx: 5000 Loss: 0.011137421217771759
Epoch: 12 Idx: 0 Loss: 0.023136392376683808
Epoch: 12 Idx: 5000 Loss: 0.02891355950014417
Epoch: 13 Idx: 0 Loss: 0.016925740005411687
Epoch: 13 Idx: 5000 Loss: 0.034061482038145185
Epoch: 14 Idx: 0 Loss: 0.007519871135034294
Epoch: 14 Idx: 5000 Loss: 0.018527123759212435
Epoch: 15 Idx: 0 Loss: 0.026116520986262194
Epoch: 15 Idx: 5000 Loss: 0.003920004283996613
Epoch: 16 Idx: 0 Loss: 0.013472990320827712
Epoch: 16 Idx: 5000 Loss: 0.03304916445870227
Epoch: 17 Idx: 0 Loss: 0.00917558092041443
Epoch: 17 Idx: 5000 Loss: 0.024864398063038542
Epoch: 18 Idx: 0 Loss: 0.009979823063602677
Epoch: 18 Idx: 5000 Loss: 0.020392690393775895
Epoch: 19 Idx: 0 Loss: 0.006575271937520524
Epoch: 19 Idx: 5000 Loss: 0.014264338297583147
Epoch: 20 Idx: 0 Loss: 0.014052406134842757
Epoch: 20 Idx: 5000 Loss: 0.007732547836432773
Epoch: 21 Idx: 0 Loss: 0.007010742418753527
Epoch: 21 Idx: 5000 Loss: 0.009997371860561462
Epoch: 22 Idx: 0 Loss: 0.04407619309949204
Epoch: 22 Idx: 5000 Loss: 0.011348372030870437
Epoch: 23 Idx: 0 Loss: 0.010482710483432488
Epoch: 23 Idx: 5000 Loss: 0.01628578019259264
Epoch: 24 Idx: 0 Loss: 0.013410335016916809
Epoch: 24 Idx: 5000 Loss: 0.009501175427303846
Epoch: 25 Idx: 0 Loss: 0.009252107866688052
Epoch: 25 Idx: 5000 Loss: 0.021676956975420207
Epoch: 26 Idx: 0 Loss: 0.010687245105043017
Epoch: 26 Idx: 5000 Loss: 0.014381383986995894
Epoch: 27 Idx: 0 Loss: 0.012798129753671159
Epoch: 27 Idx: 5000 Loss: 0.016714269081418025
Epoch: 28 Idx: 0 Loss: 0.014569375610818742
Epoch: 28 Idx: 5000 Loss: 0.011182082908986781
Epoch: 29 Idx: 0 Loss: 0.009130374737673806
Epoch: 29 Idx: 5000 Loss: 0.041009813535538044
Epoch: 30 Idx: 0 Loss: 0.02082131039573228
Epoch: 30 Idx: 5000 Loss: 0.01564044447414601
Epoch: 31 Idx: 0 Loss: 0.009159912573464692
Epoch: 31 Idx: 5000 Loss: 0.02293260367320819
Epoch: 32 Idx: 0 Loss: 0.008880827401091503
Epoch: 32 Idx: 5000 Loss: 0.018373549757673656
Epoch: 33 Idx: 0 Loss: 0.010881666409949637
Epoch: 33 Idx: 5000 Loss: 0.027925271558995837
Epoch: 34 Idx: 0 Loss: 0.02326301877073106
Epoch: 34 Idx: 5000 Loss: 0.008768890360430256
Epoch: 35 Idx: 0 Loss: 0.0071784544937919465
Epoch: 35 Idx: 5000 Loss: 0.010816581811895407
Epoch: 36 Idx: 0 Loss: 0.01131516795379415
Epoch: 36 Idx: 5000 Loss: 0.0044168084622936195
Epoch: 37 Idx: 0 Loss: 0.011899244734615004
Epoch: 37 Idx: 5000 Loss: 0.008910875598750846
Epoch: 38 Idx: 0 Loss: 0.015335579909503572
Epoch: 38 Idx: 5000 Loss: 0.007983830322633008
Epoch: 39 Idx: 0 Loss: 0.00961810850331692
Epoch: 39 Idx: 5000 Loss: 0.021864610867970896
Epoch: 40 Idx: 0 Loss: 0.0197614081920462
Epoch: 40 Idx: 5000 Loss: 0.028957559586604592
Epoch: 41 Idx: 0 Loss: 0.009190562397730948
Epoch: 41 Idx: 5000 Loss: 0.017825615104482478
Epoch: 42 Idx: 0 Loss: 0.008329410956915154
Epoch: 42 Idx: 5000 Loss: 0.015276635700754784
Epoch: 43 Idx: 0 Loss: 0.019434598843132388
Epoch: 43 Idx: 5000 Loss: 0.03355139554539478
Epoch: 44 Idx: 0 Loss: 0.023315615310025732
Epoch: 44 Idx: 5000 Loss: 0.021871093980905927
Epoch: 45 Idx: 0 Loss: 0.010999002807075485
Epoch: 45 Idx: 5000 Loss: 0.007269483894265643
Epoch: 46 Idx: 0 Loss: 0.00960574367801182
Epoch: 46 Idx: 5000 Loss: 0.02826641004629496
Epoch: 47 Idx: 0 Loss: 0.036251565516618026
Epoch: 47 Idx: 5000 Loss: 0.010088374256515958
Epoch: 48 Idx: 0 Loss: 0.02370015224836824
Epoch: 48 Idx: 5000 Loss: 0.04180757208321308
Epoch: 49 Idx: 0 Loss: 0.011751302186859552
Epoch: 49 Idx: 5000 Loss: 0.016038361185360384
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.20781125950626217
Epoch: 0 Idx: 5000 Loss: 0.01228150059066999
Epoch: 1 Idx: 0 Loss: 0.018191464905668156
Epoch: 1 Idx: 5000 Loss: 0.027217825992970526
Epoch: 2 Idx: 0 Loss: 0.01055767532124179
Epoch: 2 Idx: 5000 Loss: 0.02329352991679892
Epoch: 3 Idx: 0 Loss: 0.013467198163325308
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 387, in to_feature
    for elem in inputs_lenpadded]
  File "main.py", line 387, in <listcomp>
    for elem in inputs_lenpadded]
  File "main.py", line 386, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "main.py", line 386, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "main.py", line 385, in <listcomp>
    for i in range(max_paths - len(nbr_type))]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc226>
Subject: Job 4066799: <python main.py 3 12 False True> in cluster <dcc> Exited

Job <python main.py 3 12 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc226>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:36 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 12 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46173.51 sec.
    Max Memory :                                 2909 MB
    Average Memory :                             2727.97 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40508.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46203 sec.
    Turnaround time :                            46204 sec.

The output (if any) is above this job summary.

