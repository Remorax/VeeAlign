2020-09-15 15:48:41.601007: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:48.821696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:48.930721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:48.930785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:48.933234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:48.953440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:48.993735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.041297: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.066899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.067481: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.067505: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.067952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.109721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz
2020-09-15 15:48:49.109989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562130ff6650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.110010: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.112807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.112836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1714393856633654
Epoch: 0 Idx: 5000 Loss: 0.010195488893926612
Epoch: 1 Idx: 0 Loss: 0.019101297857400713
Epoch: 1 Idx: 5000 Loss: 0.03629829669066238
Epoch: 2 Idx: 0 Loss: 0.009610067464904323
Epoch: 2 Idx: 5000 Loss: 0.011866669668014354
Epoch: 3 Idx: 0 Loss: 0.014823125677263502
Epoch: 3 Idx: 5000 Loss: 0.010216732071385525
Epoch: 4 Idx: 0 Loss: 0.008646981856076902
Epoch: 4 Idx: 5000 Loss: 0.021699749322669278
Epoch: 5 Idx: 0 Loss: 0.020523527640031857
Epoch: 5 Idx: 5000 Loss: 0.013361270629208173
Epoch: 6 Idx: 0 Loss: 0.007729972192663861
Epoch: 6 Idx: 5000 Loss: 0.007334292769309652
Epoch: 7 Idx: 0 Loss: 0.035819173295474155
Epoch: 7 Idx: 5000 Loss: 0.021434796078735847
Epoch: 8 Idx: 0 Loss: 0.025381739128303722
Epoch: 8 Idx: 5000 Loss: 0.005112676976424379
Epoch: 9 Idx: 0 Loss: 0.010421274976044738
Epoch: 9 Idx: 5000 Loss: 0.009482784250408462
Epoch: 10 Idx: 0 Loss: 0.017504366472110698
Epoch: 10 Idx: 5000 Loss: 0.029706375937826664
Epoch: 11 Idx: 0 Loss: 0.03542556349127652
Epoch: 11 Idx: 5000 Loss: 0.022230708350320844
Epoch: 12 Idx: 0 Loss: 0.01313801832660243
Epoch: 12 Idx: 5000 Loss: 0.010093706618243091
Epoch: 13 Idx: 0 Loss: 0.006615829432809101
Epoch: 13 Idx: 5000 Loss: 0.009911120015181497
Epoch: 14 Idx: 0 Loss: 0.026146165136801163
Epoch: 14 Idx: 5000 Loss: 0.01539721662249458
Epoch: 15 Idx: 0 Loss: 0.0052398597840630935
Epoch: 15 Idx: 5000 Loss: 0.008357882176643336
Epoch: 16 Idx: 0 Loss: 0.013058615180576416
Epoch: 16 Idx: 5000 Loss: 0.015475248750611455
Epoch: 17 Idx: 0 Loss: 0.03345397888840057
Epoch: 17 Idx: 5000 Loss: 0.013136086787858072
Epoch: 18 Idx: 0 Loss: 0.027042677496620933
Epoch: 18 Idx: 5000 Loss: 0.008407791432780583
Epoch: 19 Idx: 0 Loss: 0.014858942106021119
Epoch: 19 Idx: 5000 Loss: 0.026712121397317025
Epoch: 20 Idx: 0 Loss: 0.00829753430207509
Epoch: 20 Idx: 5000 Loss: 0.01267560021874569
Epoch: 21 Idx: 0 Loss: 0.011085434210983338
Epoch: 21 Idx: 5000 Loss: 0.011017512909225268
Epoch: 22 Idx: 0 Loss: 0.02478420652224089
Epoch: 22 Idx: 5000 Loss: 0.026064047701459883
Epoch: 23 Idx: 0 Loss: 0.00969729316059295
Epoch: 23 Idx: 5000 Loss: 0.015987207443603553
Epoch: 24 Idx: 0 Loss: 0.03681759533210746
Epoch: 24 Idx: 5000 Loss: 0.006624123254813389
Epoch: 25 Idx: 0 Loss: 0.017273425285842324
Epoch: 25 Idx: 5000 Loss: 0.02911055447931518
Epoch: 26 Idx: 0 Loss: 0.011522443657582516
Epoch: 26 Idx: 5000 Loss: 0.016632750620782386
Epoch: 27 Idx: 0 Loss: 0.007953298842234079
Epoch: 27 Idx: 5000 Loss: 0.029123639915716364
Epoch: 28 Idx: 0 Loss: 0.023541081082126408
Epoch: 28 Idx: 5000 Loss: 0.013495839149117577
Epoch: 29 Idx: 0 Loss: 0.04297560907671152
Epoch: 29 Idx: 5000 Loss: 0.010951396821809433
Epoch: 30 Idx: 0 Loss: 0.019778918819984375
Epoch: 30 Idx: 5000 Loss: 0.004561271223391257
Epoch: 31 Idx: 0 Loss: 0.013598820757559055
Epoch: 31 Idx: 5000 Loss: 0.021625965106537106
Epoch: 32 Idx: 0 Loss: 0.019538457657655453
Epoch: 32 Idx: 5000 Loss: 0.02630477311969093
Epoch: 33 Idx: 0 Loss: 0.024152343674582893
Epoch: 33 Idx: 5000 Loss: 0.025830801582089356
Epoch: 34 Idx: 0 Loss: 0.009879461989826088
Epoch: 34 Idx: 5000 Loss: 0.009534384987586882
Epoch: 35 Idx: 0 Loss: 0.023395525509093747
Epoch: 35 Idx: 5000 Loss: 0.05898841297133778
Epoch: 36 Idx: 0 Loss: 0.02758861744336219
Epoch: 36 Idx: 5000 Loss: 0.02641916480711721
Epoch: 37 Idx: 0 Loss: 0.017903838183941374
Epoch: 37 Idx: 5000 Loss: 0.028711391583168898
Epoch: 38 Idx: 0 Loss: 0.009787554550343417
Epoch: 38 Idx: 5000 Loss: 0.02030931887985586
Epoch: 39 Idx: 0 Loss: 0.01775225379226359
Epoch: 39 Idx: 5000 Loss: 0.015969562079858887
Epoch: 40 Idx: 0 Loss: 0.006059845665500273
Epoch: 40 Idx: 5000 Loss: 0.01870456473374169
Epoch: 41 Idx: 0 Loss: 0.009192565647603634
Epoch: 41 Idx: 5000 Loss: 0.009665528871680807
Epoch: 42 Idx: 0 Loss: 0.012627958553339577
Epoch: 42 Idx: 5000 Loss: 0.009728279415516431
Epoch: 43 Idx: 0 Loss: 0.016039346874745637
Epoch: 43 Idx: 5000 Loss: 0.023712625310581693
Epoch: 44 Idx: 0 Loss: 0.005714774691542354
Epoch: 44 Idx: 5000 Loss: 0.042401847546549645
Epoch: 45 Idx: 0 Loss: 0.03242023281089011
Epoch: 45 Idx: 5000 Loss: 0.013864725751910955
Epoch: 46 Idx: 0 Loss: 0.010732140296955583
Epoch: 46 Idx: 5000 Loss: 0.019124737056340727
Epoch: 47 Idx: 0 Loss: 0.017103078864565725
Epoch: 47 Idx: 5000 Loss: 0.021133302246443546
Epoch: 48 Idx: 0 Loss: 0.014612855351723448
Epoch: 48 Idx: 5000 Loss: 0.028733428742799806
Epoch: 49 Idx: 0 Loss: 0.007765134839491443
Epoch: 49 Idx: 5000 Loss: 0.020533813947627114
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.16223090887092645
Epoch: 0 Idx: 5000 Loss: 0.023280578642539136
Epoch: 1 Idx: 0 Loss: 0.008105422428572602
Epoch: 1 Idx: 5000 Loss: 0.03684159138029012
Epoch: 2 Idx: 0 Loss: 0.028816803879500336
Epoch: 2 Idx: 5000 Loss: 0.014350826190587276
Epoch: 3 Idx: 0 Loss: 0.028359880092658774
Epoch: 3 Idx: 5000 Loss: 0.011552097048610347
Epoch: 4 Idx: 0 Loss: 0.008607679636503432
Epoch: 4 Idx: 5000 Loss: 0.01635031078897157
Epoch: 5 Idx: 0 Loss: 0.010622056002939882
Epoch: 5 Idx: 5000 Loss: 0.011529568725883121
Epoch: 6 Idx: 0 Loss: 0.01582383972521818
Epoch: 6 Idx: 5000 Loss: 0.024054158299423443
Epoch: 7 Idx: 0 Loss: 0.011318802774391588
Epoch: 7 Idx: 5000 Loss: 0.03071369101144586
Epoch: 8 Idx: 0 Loss: 0.013911904400022726
Epoch: 8 Idx: 5000 Loss: 0.022970207851442048
Epoch: 9 Idx: 0 Loss: 0.013382763733394854
Epoch: 9 Idx: 5000 Loss: 0.016987971368508947
Epoch: 10 Idx: 0 Loss: 0.01361166753572643
Epoch: 10 Idx: 5000 Loss: 0.009622036321468371
Epoch: 11 Idx: 0 Loss: 0.016030715341809998
Epoch: 11 Idx: 5000 Loss: 0.019058386328441722
Epoch: 12 Idx: 0 Loss: 0.014909889397758001
Epoch: 12 Idx: 5000 Loss: 0.017695044125712194
Epoch: 13 Idx: 0 Loss: 0.02194815690558494
Epoch: 13 Idx: 5000 Loss: 0.01640404071046572
Epoch: 14 Idx: 0 Loss: 0.010503707251105119
Epoch: 14 Idx: 5000 Loss: 0.009637693631342675
Epoch: 15 Idx: 0 Loss: 0.016293313793269558
Epoch: 15 Idx: 5000 Loss: 0.013864432497611927
Epoch: 16 Idx: 0 Loss: 0.011835767790784005
Epoch: 16 Idx: 5000 Loss: 0.027204191634172606
Epoch: 17 Idx: 0 Loss: 0.013202184182452524
Epoch: 17 Idx: 5000 Loss: 0.0174509132236415
Epoch: 18 Idx: 0 Loss: 0.010532770481126105
Epoch: 18 Idx: 5000 Loss: 0.03876152082834169
Epoch: 19 Idx: 0 Loss: 0.027937315124542984
Epoch: 19 Idx: 5000 Loss: 0.018496405467395956
Epoch: 20 Idx: 0 Loss: 0.028221821567654567
Epoch: 20 Idx: 5000 Loss: 0.02934593503802625
Epoch: 21 Idx: 0 Loss: 0.006751819013567868
Epoch: 21 Idx: 5000 Loss: 0.01150585095457251
Epoch: 22 Idx: 0 Loss: 0.006876184168095672
Epoch: 22 Idx: 5000 Loss: 0.01320502401360938
Epoch: 23 Idx: 0 Loss: 0.01371406606917594
Epoch: 23 Idx: 5000 Loss: 0.021463516460683823
Epoch: 24 Idx: 0 Loss: 0.017573128076224034
Epoch: 24 Idx: 5000 Loss: 0.008676249734825699
Epoch: 25 Idx: 0 Loss: 0.00554247713271981
Epoch: 25 Idx: 5000 Loss: 0.009053851787762069
Epoch: 26 Idx: 0 Loss: 0.02534841739063913
Epoch: 26 Idx: 5000 Loss: 0.0075911331132668914
Epoch: 27 Idx: 0 Loss: 0.015011534332103447
Epoch: 27 Idx: 5000 Loss: 0.00873396697051176
Epoch: 28 Idx: 0 Loss: 0.029586931166629922
Epoch: 28 Idx: 5000 Loss: 0.0136787485419175
Epoch: 29 Idx: 0 Loss: 0.01951402930559918
Epoch: 29 Idx: 5000 Loss: 0.02046686521114582
Epoch: 30 Idx: 0 Loss: 0.024639839364057566
Epoch: 30 Idx: 5000 Loss: 0.012170045844704935
Epoch: 31 Idx: 0 Loss: 0.011942316678388373
Epoch: 31 Idx: 5000 Loss: 0.01680145858996335
Epoch: 32 Idx: 0 Loss: 0.024423382861207668
Epoch: 32 Idx: 5000 Loss: 0.01647119896972869
Epoch: 33 Idx: 0 Loss: 0.016216541319960594
Epoch: 33 Idx: 5000 Loss: 0.01246506396734228
Epoch: 34 Idx: 0 Loss: 0.008746747353079157
Epoch: 34 Idx: 5000 Loss: 0.012184986143500366
Epoch: 35 Idx: 0 Loss: 0.01642894878155523
Epoch: 35 Idx: 5000 Loss: 0.025791015004129732
Epoch: 36 Idx: 0 Loss: 0.01575683713048862
Epoch: 36 Idx: 5000 Loss: 0.013765193068646705
Epoch: 37 Idx: 0 Loss: 0.027984141177744823
Epoch: 37 Idx: 5000 Loss: 0.014786217524434672
Epoch: 38 Idx: 0 Loss: 0.011176036004318112
Epoch: 38 Idx: 5000 Loss: 0.01441917110113583
Epoch: 39 Idx: 0 Loss: 0.039250322685289614
Epoch: 39 Idx: 5000 Loss: 0.019895182605470667
Epoch: 40 Idx: 0 Loss: 0.008212211593401457
Epoch: 40 Idx: 5000 Loss: 0.03844270733149116
Epoch: 41 Idx: 0 Loss: 0.01662154439532934
Epoch: 41 Idx: 5000 Loss: 0.009020219722575044
Epoch: 42 Idx: 0 Loss: 0.012599089835258667
Epoch: 42 Idx: 5000 Loss: 0.01595675001292288
Epoch: 43 Idx: 0 Loss: 0.017472053793784907
Epoch: 43 Idx: 5000 Loss: 0.007365240354607375
Epoch: 44 Idx: 0 Loss: 0.04115728179369174
Epoch: 44 Idx: 5000 Loss: 0.014540754397189173
Epoch: 45 Idx: 0 Loss: 0.01168352851086983
Epoch: 45 Idx: 5000 Loss: 0.013351484007094294
Epoch: 46 Idx: 0 Loss: 0.010534977512210638
Epoch: 46 Idx: 5000 Loss: 0.00834158550400279
Epoch: 47 Idx: 0 Loss: 0.012172250324043263
Epoch: 47 Idx: 5000 Loss: 0.016418692475409814
Epoch: 48 Idx: 0 Loss: 0.01472884232385194
Epoch: 48 Idx: 5000 Loss: 0.011461876510030576
Epoch: 49 Idx: 0 Loss: 0.017992954951929256
Epoch: 49 Idx: 5000 Loss: 0.02082348027163302
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1434723588435514
Epoch: 0 Idx: 5000 Loss: 0.020926801011330525
Epoch: 1 Idx: 0 Loss: 0.024287911401166554
Epoch: 1 Idx: 5000 Loss: 0.010928427589528975
Epoch: 2 Idx: 0 Loss: 0.012518851061422708
Epoch: 2 Idx: 5000 Loss: 0.021806820566804636
Epoch: 3 Idx: 0 Loss: 0.01963674691616974
Epoch: 3 Idx: 5000 Loss: 0.029048241126049493
Epoch: 4 Idx: 0 Loss: 0.025073996920880994
Epoch: 4 Idx: 5000 Loss: 0.013164040577690538
Epoch: 5 Idx: 0 Loss: 0.033941809999218905
Epoch: 5 Idx: 5000 Loss: 0.017149363060305123
Epoch: 6 Idx: 0 Loss: 0.035588365635163356
Epoch: 6 Idx: 5000 Loss: 0.01794978694455747
Epoch: 7 Idx: 0 Loss: 0.010696253998227484
Epoch: 7 Idx: 5000 Loss: 0.020743398811076643
Epoch: 8 Idx: 0 Loss: 0.012914864720644108
Epoch: 8 Idx: 5000 Loss: 0.01724283167202629
Epoch: 9 Idx: 0 Loss: 0.017251476240961596
Epoch: 9 Idx: 5000 Loss: 0.0297028287943536
Epoch: 10 Idx: 0 Loss: 0.019120028783372798
Epoch: 10 Idx: 5000 Loss: 0.005915396048825779
Epoch: 11 Idx: 0 Loss: 0.010473709177693333
Epoch: 11 Idx: 5000 Loss: 0.005513935915302496
Epoch: 12 Idx: 0 Loss: 0.005991277358360432
Epoch: 12 Idx: 5000 Loss: 0.01717409482365653
Epoch: 13 Idx: 0 Loss: 0.013859986103318681
Epoch: 13 Idx: 5000 Loss: 0.006325164339383385
Epoch: 14 Idx: 0 Loss: 0.017217720299386164
Epoch: 14 Idx: 5000 Loss: 0.014478058511493636
Epoch: 15 Idx: 0 Loss: 0.006468874259368504
Epoch: 15 Idx: 5000 Loss: 0.011276472730027923
Epoch: 16 Idx: 0 Loss: 0.00885399837990352
Epoch: 16 Idx: 5000 Loss: 0.012493531130426621
Epoch: 17 Idx: 0 Loss: 0.02033561289019374
Epoch: 17 Idx: 5000 Loss: 0.026276723547483234
Epoch: 18 Idx: 0 Loss: 0.0049738360377075885
Epoch: 18 Idx: 5000 Loss: 0.0053697936985654775
Epoch: 19 Idx: 0 Loss: 0.03500247749017411
Epoch: 19 Idx: 5000 Loss: 0.013980369771779537
Epoch: 20 Idx: 0 Loss: 0.008867982964663599
Epoch: 20 Idx: 5000 Loss: 0.010590265165336758
Epoch: 21 Idx: 0 Loss: 0.013003148877909727
Epoch: 21 Idx: 5000 Loss: 0.020889115286933463
Epoch: 22 Idx: 0 Loss: 0.010111639198738323
Epoch: 22 Idx: 5000 Loss: 0.00974169541074731
Epoch: 23 Idx: 0 Loss: 0.020017433750200223
Epoch: 23 Idx: 5000 Loss: 0.021220478019396537
Epoch: 24 Idx: 0 Loss: 0.0161326797515802
Epoch: 24 Idx: 5000 Loss: 0.025885813533759815
Epoch: 25 Idx: 0 Loss: 0.009812501368035867
Epoch: 25 Idx: 5000 Loss: 0.022179059417450454
Epoch: 26 Idx: 0 Loss: 0.01209358933595887
Epoch: 26 Idx: 5000 Loss: 0.015224701243028622
Epoch: 27 Idx: 0 Loss: 0.02739347402922689
Epoch: 27 Idx: 5000 Loss: 0.01210828298072197
Epoch: 28 Idx: 0 Loss: 0.008970033813873683
Epoch: 28 Idx: 5000 Loss: 0.015708497888455207
Epoch: 29 Idx: 0 Loss: 0.017288385706486366
Epoch: 29 Idx: 5000 Loss: 0.010310866209233412
Epoch: 30 Idx: 0 Loss: 0.012011535121196688
Epoch: 30 Idx: 5000 Loss: 0.013415003654216027
Epoch: 31 Idx: 0 Loss: 0.01851336582822864
Epoch: 31 Idx: 5000 Loss: 0.021600236816308547
Epoch: 32 Idx: 0 Loss: 0.04619813400329126
Epoch: 32 Idx: 5000 Loss: 0.0030679903081327637
Epoch: 33 Idx: 0 Loss: 0.018995791770524365
Epoch: 33 Idx: 5000 Loss: 0.00865062697078942
Epoch: 34 Idx: 0 Loss: 0.008224039771729058
Epoch: 34 Idx: 5000 Loss: 0.016369865023121467
Epoch: 35 Idx: 0 Loss: 0.010080653186738921
Epoch: 35 Idx: 5000 Loss: 0.02360806335872629
Epoch: 36 Idx: 0 Loss: 0.011699025458434266
Epoch: 36 Idx: 5000 Loss: 0.01726290630680424
Epoch: 37 Idx: 0 Loss: 0.009926267933659891
Epoch: 37 Idx: 5000 Loss: 0.018431700032431865
Epoch: 38 Idx: 0 Loss: 0.010048321935691391
Epoch: 38 Idx: 5000 Loss: 0.04970541364162028
Epoch: 39 Idx: 0 Loss: 0.04287171410346491
Epoch: 39 Idx: 5000 Loss: 0.0122890380913559
Epoch: 40 Idx: 0 Loss: 0.0264765091401405
Epoch: 40 Idx: 5000 Loss: 0.009251839652612946
Epoch: 41 Idx: 0 Loss: 0.027177860394416973
Epoch: 41 Idx: 5000 Loss: 0.02059987918058655
Epoch: 42 Idx: 0 Loss: 0.03173752146475348
Epoch: 42 Idx: 5000 Loss: 0.00985742215672983
Epoch: 43 Idx: 0 Loss: 0.016078178652556147
Epoch: 43 Idx: 5000 Loss: 0.020933916317163865
Epoch: 44 Idx: 0 Loss: 0.019962439024225356
Epoch: 44 Idx: 5000 Loss: 0.014543671995505986
Epoch: 45 Idx: 0 Loss: 0.0087081883743748
Epoch: 45 Idx: 5000 Loss: 0.011371841407909495
Epoch: 46 Idx: 0 Loss: 0.01596206228635109
Epoch: 46 Idx: 5000 Loss: 0.012215500451298157
Epoch: 47 Idx: 0 Loss: 0.011329190954648367
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 379, in to_feature
    inputs_lenpadded = [[[[path[:max_pathlen] + [0 for i in range(max_pathlen -len(path[:max_pathlen]))]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc262>
Subject: Job 4066801: <python main.py 3 18 False True> in cluster <dcc> Exited

Job <python main.py 3 18 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc262>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:36 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 18 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46129.65 sec.
    Max Memory :                                 2936 MB
    Average Memory :                             2730.66 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40481.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46205 sec.
    Turnaround time :                            46206 sec.

The output (if any) is above this job summary.

