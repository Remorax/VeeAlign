2020-09-15 15:49:40.247133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:48.893420: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:49.012208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:49.012303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:49.014533: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:49.016069: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:49.016557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:49.018456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:49.020010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:49.020327: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:49.020351: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:49.020728: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:49.028596: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600250000 Hz
2020-09-15 15:49:49.028804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56232d9c9b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:49.028824: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:49.030819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:49.030871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.2124699617531452
Epoch: 0 Idx: 5000 Loss: 0.010179722505585699
Epoch: 1 Idx: 0 Loss: 0.02211559118354671
Epoch: 1 Idx: 5000 Loss: 0.012647566793272625
Epoch: 2 Idx: 0 Loss: 0.015114047795777212
Epoch: 2 Idx: 5000 Loss: 0.010023075161255354
Epoch: 3 Idx: 0 Loss: 0.014571263925436558
Epoch: 3 Idx: 5000 Loss: 0.014735602971297534
Epoch: 4 Idx: 0 Loss: 0.008588137900903636
Epoch: 4 Idx: 5000 Loss: 0.012291795202709774
Epoch: 5 Idx: 0 Loss: 0.026971622547213997
Epoch: 5 Idx: 5000 Loss: 0.015600479606233434
Epoch: 6 Idx: 0 Loss: 0.025546125456837827
Epoch: 6 Idx: 5000 Loss: 0.04670776128083447
Epoch: 7 Idx: 0 Loss: 0.012628808516007353
Epoch: 7 Idx: 5000 Loss: 0.019354909232966355
Epoch: 8 Idx: 0 Loss: 0.01569317491590517
Epoch: 8 Idx: 5000 Loss: 0.00650221183999911
Epoch: 9 Idx: 0 Loss: 0.011703753032769125
Epoch: 9 Idx: 5000 Loss: 0.017212917839352075
Epoch: 10 Idx: 0 Loss: 0.015820338526082313
Epoch: 10 Idx: 5000 Loss: 0.01188255711225742
Epoch: 11 Idx: 0 Loss: 0.010307238962201731
Epoch: 11 Idx: 5000 Loss: 0.0319229302767379
Epoch: 12 Idx: 0 Loss: 0.00905519676916423
Epoch: 12 Idx: 5000 Loss: 0.00809989838745524
Epoch: 13 Idx: 0 Loss: 0.008950951661417525
Epoch: 13 Idx: 5000 Loss: 0.007367308748228588
Epoch: 14 Idx: 0 Loss: 0.014227134722424572
Epoch: 14 Idx: 5000 Loss: 0.009354649552093598
Epoch: 15 Idx: 0 Loss: 0.016497733351284703
Epoch: 15 Idx: 5000 Loss: 0.019147396934519438
Epoch: 16 Idx: 0 Loss: 0.015349263490802297
Epoch: 16 Idx: 5000 Loss: 0.013024467027405971
Epoch: 17 Idx: 0 Loss: 0.010434268866567613
Epoch: 17 Idx: 5000 Loss: 0.022411937193222226
Epoch: 18 Idx: 0 Loss: 0.029143560688392016
Epoch: 18 Idx: 5000 Loss: 0.010314733195866614
Epoch: 19 Idx: 0 Loss: 0.01296898118487826
Epoch: 19 Idx: 5000 Loss: 0.016903915610591975
Epoch: 20 Idx: 0 Loss: 0.005886504849110605
Epoch: 20 Idx: 5000 Loss: 0.009849398462914334
Epoch: 21 Idx: 0 Loss: 0.006365356211375731
Epoch: 21 Idx: 5000 Loss: 0.007630106533263091
Epoch: 22 Idx: 0 Loss: 0.015160410861026959
Epoch: 22 Idx: 5000 Loss: 0.023526669035276067
Epoch: 23 Idx: 0 Loss: 0.009250878267261575
Epoch: 23 Idx: 5000 Loss: 0.011301240820644692
Epoch: 24 Idx: 0 Loss: 0.012765831921700466
Epoch: 24 Idx: 5000 Loss: 0.0158346823744588
Epoch: 25 Idx: 0 Loss: 0.012354211348874477
Epoch: 25 Idx: 5000 Loss: 0.024697138441476973
Epoch: 26 Idx: 0 Loss: 0.020903660654977462
Epoch: 26 Idx: 5000 Loss: 0.009753490886142097
Epoch: 27 Idx: 0 Loss: 0.00914499628340076
Epoch: 27 Idx: 5000 Loss: 0.024335215718866075
Epoch: 28 Idx: 0 Loss: 0.031621458332674546
Epoch: 28 Idx: 5000 Loss: 0.013946985429328339
Epoch: 29 Idx: 0 Loss: 0.022839047942197627
Epoch: 29 Idx: 5000 Loss: 0.018011909643353523
Epoch: 30 Idx: 0 Loss: 0.01941064955417497
Epoch: 30 Idx: 5000 Loss: 0.010703210096380526
Epoch: 31 Idx: 0 Loss: 0.04040326388551255
Epoch: 31 Idx: 5000 Loss: 0.008190003142834475
Epoch: 32 Idx: 0 Loss: 0.016333653859235762
Epoch: 32 Idx: 5000 Loss: 0.008546357307492728
Epoch: 33 Idx: 0 Loss: 0.016612951242879242
Epoch: 33 Idx: 5000 Loss: 0.030160064559317017
Epoch: 34 Idx: 0 Loss: 0.009961145042797909
Epoch: 34 Idx: 5000 Loss: 0.02152482508489275
Epoch: 35 Idx: 0 Loss: 0.010966560459687337
Epoch: 35 Idx: 5000 Loss: 0.010735848658419039
Epoch: 36 Idx: 0 Loss: 0.021386024507487653
Epoch: 36 Idx: 5000 Loss: 0.007364264341875721
Epoch: 37 Idx: 0 Loss: 0.028598588148154733
Epoch: 37 Idx: 5000 Loss: 0.00854406122438372
Epoch: 38 Idx: 0 Loss: 0.008811056653084688
Epoch: 38 Idx: 5000 Loss: 0.023845049311714273
Epoch: 39 Idx: 0 Loss: 0.006839302368647826
Epoch: 39 Idx: 5000 Loss: 0.02133586440041247
Epoch: 40 Idx: 0 Loss: 0.005006896524467561
Epoch: 40 Idx: 5000 Loss: 0.011009529643472729
Epoch: 41 Idx: 0 Loss: 0.01165165676418862
Epoch: 41 Idx: 5000 Loss: 0.03398012194134702
Epoch: 42 Idx: 0 Loss: 0.018206787231064565
Epoch: 42 Idx: 5000 Loss: 0.01031346169923011
Epoch: 43 Idx: 0 Loss: 0.026052465928535905
Epoch: 43 Idx: 5000 Loss: 0.014970758356640333
Epoch: 44 Idx: 0 Loss: 0.011907668121923532
Epoch: 44 Idx: 5000 Loss: 0.01798639250091721
Epoch: 45 Idx: 0 Loss: 0.012633656393611997
Epoch: 45 Idx: 5000 Loss: 0.059291496760302764
Epoch: 46 Idx: 0 Loss: 0.02214860391594657
Epoch: 46 Idx: 5000 Loss: 0.009082127268652334
Epoch: 47 Idx: 0 Loss: 0.0061131740836565295
Epoch: 47 Idx: 5000 Loss: 0.01644217002094248
Epoch: 48 Idx: 0 Loss: 0.0272743834578233
Epoch: 48 Idx: 5000 Loss: 0.029714396011383083
Epoch: 49 Idx: 0 Loss: 0.008425121755982704
Epoch: 49 Idx: 5000 Loss: 0.021866590371932313
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.13565976659052692
Epoch: 0 Idx: 5000 Loss: 0.027074088269501088
Epoch: 1 Idx: 0 Loss: 0.013476091341702339
Epoch: 1 Idx: 5000 Loss: 0.037052611333348376
Epoch: 2 Idx: 0 Loss: 0.014846296280433468
Epoch: 2 Idx: 5000 Loss: 0.02381092742465335
Epoch: 3 Idx: 0 Loss: 0.008142224179784989
Epoch: 3 Idx: 5000 Loss: 0.012231357277499688
Epoch: 4 Idx: 0 Loss: 0.016885941304568337
Epoch: 4 Idx: 5000 Loss: 0.010758295768104692
Epoch: 5 Idx: 0 Loss: 0.03517384174997915
Epoch: 5 Idx: 5000 Loss: 0.03146682220012229
Epoch: 6 Idx: 0 Loss: 0.010742106835276915
Epoch: 6 Idx: 5000 Loss: 0.027918226116983434
Epoch: 7 Idx: 0 Loss: 0.011175949700096891
Epoch: 7 Idx: 5000 Loss: 0.01815869127715591
Epoch: 8 Idx: 0 Loss: 0.00705066565235796
Epoch: 8 Idx: 5000 Loss: 0.024769265834789136
Epoch: 9 Idx: 0 Loss: 0.027012295942038574
Epoch: 9 Idx: 5000 Loss: 0.012860431690046359
Epoch: 10 Idx: 0 Loss: 0.013358853723302413
Epoch: 10 Idx: 5000 Loss: 0.007645807312674078
Epoch: 11 Idx: 0 Loss: 0.012616688086799997
Epoch: 11 Idx: 5000 Loss: 0.00943000230430754
Epoch: 12 Idx: 0 Loss: 0.010950138436205134
Epoch: 12 Idx: 5000 Loss: 0.023636328484033648
Epoch: 13 Idx: 0 Loss: 0.016471571863529485
Epoch: 13 Idx: 5000 Loss: 0.013041010280682533
Epoch: 14 Idx: 0 Loss: 0.00934897848596992
Epoch: 14 Idx: 5000 Loss: 0.008738832776432212
Epoch: 15 Idx: 0 Loss: 0.007949167451525739
Epoch: 15 Idx: 5000 Loss: 0.018893040816581535
Epoch: 16 Idx: 0 Loss: 0.03198343038448493
Epoch: 16 Idx: 5000 Loss: 0.0258804331901915
Epoch: 17 Idx: 0 Loss: 0.03282088458547211
Epoch: 17 Idx: 5000 Loss: 0.011897260148146984
Epoch: 18 Idx: 0 Loss: 0.01818343001070629
Epoch: 18 Idx: 5000 Loss: 0.021132230869068964
Epoch: 19 Idx: 0 Loss: 0.013421917459613578
Epoch: 19 Idx: 5000 Loss: 0.008695659076052133
Epoch: 20 Idx: 0 Loss: 0.007785863498995462
Epoch: 20 Idx: 5000 Loss: 0.010506724595329767
Epoch: 21 Idx: 0 Loss: 0.009752559820382381
Epoch: 21 Idx: 5000 Loss: 0.013946107404158048
Epoch: 22 Idx: 0 Loss: 0.007805859568172549
Epoch: 22 Idx: 5000 Loss: 0.005960635226309383
Epoch: 23 Idx: 0 Loss: 0.008604842463186272
Epoch: 23 Idx: 5000 Loss: 0.008510280007234017
Epoch: 24 Idx: 0 Loss: 0.0194591852828598
Epoch: 24 Idx: 5000 Loss: 0.014888830592686728
Epoch: 25 Idx: 0 Loss: 0.023291950687909166
Epoch: 25 Idx: 5000 Loss: 0.028045800104402788
Epoch: 26 Idx: 0 Loss: 0.009956843216357925
Epoch: 26 Idx: 5000 Loss: 0.02581171949468652
Epoch: 27 Idx: 0 Loss: 0.014410730601711854
Epoch: 27 Idx: 5000 Loss: 0.04474355703942727
Epoch: 28 Idx: 0 Loss: 0.03679394547317494
Epoch: 28 Idx: 5000 Loss: 0.012566839493935614
Epoch: 29 Idx: 0 Loss: 0.01816147814867076
Epoch: 29 Idx: 5000 Loss: 0.028257849930205164
Epoch: 30 Idx: 0 Loss: 0.027690198832387127
Epoch: 30 Idx: 5000 Loss: 0.017702406286465522
Epoch: 31 Idx: 0 Loss: 0.009235144933464558
Epoch: 31 Idx: 5000 Loss: 0.008818820702221283
Epoch: 32 Idx: 0 Loss: 0.016809570413622108
Epoch: 32 Idx: 5000 Loss: 0.01622708769757603
Epoch: 33 Idx: 0 Loss: 0.01435389126421536
Epoch: 33 Idx: 5000 Loss: 0.008536612156856176
Epoch: 34 Idx: 0 Loss: 0.005788525971222027
Epoch: 34 Idx: 5000 Loss: 0.0071810659612131815
Epoch: 35 Idx: 0 Loss: 0.012601180894735053
Epoch: 35 Idx: 5000 Loss: 0.012282538859321715
Epoch: 36 Idx: 0 Loss: 0.022797469000130032
Epoch: 36 Idx: 5000 Loss: 0.031735301081892556
Epoch: 37 Idx: 0 Loss: 0.007551247353437557
Epoch: 37 Idx: 5000 Loss: 0.015597232645900586
Epoch: 38 Idx: 0 Loss: 0.015722616926216057
Epoch: 38 Idx: 5000 Loss: 0.011960439696891536
Epoch: 39 Idx: 0 Loss: 0.008547920374862336
Epoch: 39 Idx: 5000 Loss: 0.006302959018650895
Epoch: 40 Idx: 0 Loss: 0.009411472926972827
Epoch: 40 Idx: 5000 Loss: 0.018159519557469077
Epoch: 41 Idx: 0 Loss: 0.01653872988665185
Epoch: 41 Idx: 5000 Loss: 0.008025124497111348
Epoch: 42 Idx: 0 Loss: 0.008619301250127278
Epoch: 42 Idx: 5000 Loss: 0.01787344074125829
Epoch: 43 Idx: 0 Loss: 0.01197225402370931
Epoch: 43 Idx: 5000 Loss: 0.008099517492098777
Epoch: 44 Idx: 0 Loss: 0.009650328415690834
Epoch: 44 Idx: 5000 Loss: 0.020530083460523246
Epoch: 45 Idx: 0 Loss: 0.00943652179249833
Epoch: 45 Idx: 5000 Loss: 0.01603967912454124
Epoch: 46 Idx: 0 Loss: 0.009345344623536108
Epoch: 46 Idx: 5000 Loss: 0.014500878255197611
Epoch: 47 Idx: 0 Loss: 0.006611508500327278
Epoch: 47 Idx: 5000 Loss: 0.009221071977113906
Epoch: 48 Idx: 0 Loss: 0.014624800082301378
Epoch: 48 Idx: 5000 Loss: 0.02476421770709443
Epoch: 49 Idx: 0 Loss: 0.024628150452143286
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 312, in forward
    feature_emb = self.name_embedding(features[i]) #  dim: (2, batch_size, max_types, max_paths, max_pathlen, 512)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1814, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc240>
Subject: Job 4066889: <python main.py 6 20 False False> in cluster <dcc> Exited

Job <python main.py 6 20 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc240>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 20 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46129.49 sec.
    Max Memory :                                 3035 MB
    Average Memory :                             2778.90 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40382.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46170 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

