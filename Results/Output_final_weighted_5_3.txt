2020-09-15 15:48:40.343590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:48.682531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:48.798206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:48.798290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:48.800595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:48.802263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:48.802743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:48.804787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:48.806314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:48.806612: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:48.806635: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:48.807113: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:48.843178: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600075000 Hz
2020-09-15 15:48:48.843486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556241dd1590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:48.843508: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:48.846554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:48.846579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19882874636416495
Epoch: 0 Idx: 5000 Loss: 0.010373460220950518
Epoch: 1 Idx: 0 Loss: 0.012830949904250854
Epoch: 1 Idx: 5000 Loss: 0.01307948173534023
Epoch: 2 Idx: 0 Loss: 0.010083038301228864
Epoch: 2 Idx: 5000 Loss: 0.02101399225922462
Epoch: 3 Idx: 0 Loss: 0.01639683225551184
Epoch: 3 Idx: 5000 Loss: 0.020641278210976437
Epoch: 4 Idx: 0 Loss: 0.014276217889916426
Epoch: 4 Idx: 5000 Loss: 0.008155742544264287
Epoch: 5 Idx: 0 Loss: 0.009329356039454168
Epoch: 5 Idx: 5000 Loss: 0.013618297567578312
Epoch: 6 Idx: 0 Loss: 0.01449849737757178
Epoch: 6 Idx: 5000 Loss: 0.016291505847429284
Epoch: 7 Idx: 0 Loss: 0.012130487973962925
Epoch: 7 Idx: 5000 Loss: 0.006728841163652504
Epoch: 8 Idx: 0 Loss: 0.02486914418354657
Epoch: 8 Idx: 5000 Loss: 0.017836141690624165
Epoch: 9 Idx: 0 Loss: 0.008525863429859656
Epoch: 9 Idx: 5000 Loss: 0.010792403247547464
Epoch: 10 Idx: 0 Loss: 0.012064185403367617
Epoch: 10 Idx: 5000 Loss: 0.03348725929762621
Epoch: 11 Idx: 0 Loss: 0.009764599669512847
Epoch: 11 Idx: 5000 Loss: 0.013573769524367252
Epoch: 12 Idx: 0 Loss: 0.017377802067193984
Epoch: 12 Idx: 5000 Loss: 0.01056263057903433
Epoch: 13 Idx: 0 Loss: 0.02542038207014454
Epoch: 13 Idx: 5000 Loss: 0.011748517252907811
Epoch: 14 Idx: 0 Loss: 0.02349770909150617
Epoch: 14 Idx: 5000 Loss: 0.005625362980521765
Epoch: 15 Idx: 0 Loss: 0.010519734064297785
Epoch: 15 Idx: 5000 Loss: 0.010459075891393147
Epoch: 16 Idx: 0 Loss: 0.009002527396827345
Epoch: 16 Idx: 5000 Loss: 0.010518183015140613
Epoch: 17 Idx: 0 Loss: 0.017238912678854877
Epoch: 17 Idx: 5000 Loss: 0.041248424007035975
Epoch: 18 Idx: 0 Loss: 0.007079066739196109
Epoch: 18 Idx: 5000 Loss: 0.014653269867758098
Epoch: 19 Idx: 0 Loss: 0.012894879145252565
Epoch: 19 Idx: 5000 Loss: 0.011349783461967957
Epoch: 20 Idx: 0 Loss: 0.0053916304959079
Epoch: 20 Idx: 5000 Loss: 0.012199052104109213
Epoch: 21 Idx: 0 Loss: 0.010514094570805307
Epoch: 21 Idx: 5000 Loss: 0.013100316891368185
Epoch: 22 Idx: 0 Loss: 0.012187230215250894
Epoch: 22 Idx: 5000 Loss: 0.01666366950420395
Epoch: 23 Idx: 0 Loss: 0.025389212015438315
Epoch: 23 Idx: 5000 Loss: 0.014247173327363988
Epoch: 24 Idx: 0 Loss: 0.008850505579950978
Epoch: 24 Idx: 5000 Loss: 0.02060958759043981
Epoch: 25 Idx: 0 Loss: 0.01419560688917521
Epoch: 25 Idx: 5000 Loss: 0.013578892078707529
Epoch: 26 Idx: 0 Loss: 0.024911492163927768
Epoch: 26 Idx: 5000 Loss: 0.01549954022617405
Epoch: 27 Idx: 0 Loss: 0.004585764850739057
Epoch: 27 Idx: 5000 Loss: 0.014933557286681881
Epoch: 28 Idx: 0 Loss: 0.010779700340491949
Epoch: 28 Idx: 5000 Loss: 0.04909526876137365
Epoch: 29 Idx: 0 Loss: 0.02426075797691608
Epoch: 29 Idx: 5000 Loss: 0.020800990613156347
Epoch: 30 Idx: 0 Loss: 0.013940633824607924
Epoch: 30 Idx: 5000 Loss: 0.005848923140792376
Epoch: 31 Idx: 0 Loss: 0.011805470937390046
Epoch: 31 Idx: 5000 Loss: 0.0192001420771611
Epoch: 32 Idx: 0 Loss: 0.0212591499873056
Epoch: 32 Idx: 5000 Loss: 0.021569801650339292
Epoch: 33 Idx: 0 Loss: 0.01420509218118975
Epoch: 33 Idx: 5000 Loss: 0.01183573197364559
Epoch: 34 Idx: 0 Loss: 0.01042250368027559
Epoch: 34 Idx: 5000 Loss: 0.016471059837444887
Epoch: 35 Idx: 0 Loss: 0.010731017352320885
Epoch: 35 Idx: 5000 Loss: 0.011841771089231463
Epoch: 36 Idx: 0 Loss: 0.041274072387665825
Epoch: 36 Idx: 5000 Loss: 0.020708436474130294
Epoch: 37 Idx: 0 Loss: 0.0199036028823646
Epoch: 37 Idx: 5000 Loss: 0.018009668602686192
Epoch: 38 Idx: 0 Loss: 0.017629604621920376
Epoch: 38 Idx: 5000 Loss: 0.038856534591471176
Epoch: 39 Idx: 0 Loss: 0.022907222115867452
Epoch: 39 Idx: 5000 Loss: 0.0162599554413391
Epoch: 40 Idx: 0 Loss: 0.0448721459658433
Epoch: 40 Idx: 5000 Loss: 0.008592581926027498
Epoch: 41 Idx: 0 Loss: 0.01023676731310718
Epoch: 41 Idx: 5000 Loss: 0.00843083122368426
Epoch: 42 Idx: 0 Loss: 0.01070574572456271
Epoch: 42 Idx: 5000 Loss: 0.015843868779620122
Epoch: 43 Idx: 0 Loss: 0.00862222751778593
Epoch: 43 Idx: 5000 Loss: 0.02019142458745847
Epoch: 44 Idx: 0 Loss: 0.02958195382240725
Epoch: 44 Idx: 5000 Loss: 0.02070142075537532
Epoch: 45 Idx: 0 Loss: 0.015056739702797993
Epoch: 45 Idx: 5000 Loss: 0.012445042556908285
Epoch: 46 Idx: 0 Loss: 0.01086560598715441
Epoch: 46 Idx: 5000 Loss: 0.01090038390732611
Epoch: 47 Idx: 0 Loss: 0.02356701568010174
Epoch: 47 Idx: 5000 Loss: 0.012578615554052692
Epoch: 48 Idx: 0 Loss: 0.009921871803555013
Epoch: 48 Idx: 5000 Loss: 0.017028521288992723
Epoch: 49 Idx: 0 Loss: 0.006958866839467311
Epoch: 49 Idx: 5000 Loss: 0.023100727803493527
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1450618152012917
Epoch: 0 Idx: 5000 Loss: 0.013621081004166691
Epoch: 1 Idx: 0 Loss: 0.014107771844129067
Epoch: 1 Idx: 5000 Loss: 0.014763994641995968
Epoch: 2 Idx: 0 Loss: 0.013335158006666794
Epoch: 2 Idx: 5000 Loss: 0.010866601099648295
Epoch: 3 Idx: 0 Loss: 0.016947489977084156
Epoch: 3 Idx: 5000 Loss: 0.016149715199919718
Epoch: 4 Idx: 0 Loss: 0.01093250526609688
Epoch: 4 Idx: 5000 Loss: 0.021290591066583334
Epoch: 5 Idx: 0 Loss: 0.020516523668711074
Epoch: 5 Idx: 5000 Loss: 0.02616755143515338
Epoch: 6 Idx: 0 Loss: 0.01688959879667163
Epoch: 6 Idx: 5000 Loss: 0.036844735263939485
Epoch: 7 Idx: 0 Loss: 0.011966562095503008
Epoch: 7 Idx: 5000 Loss: 0.025763639896904222
Epoch: 8 Idx: 0 Loss: 0.009899195250041126
Epoch: 8 Idx: 5000 Loss: 0.028154941903272317
Epoch: 9 Idx: 0 Loss: 0.00976209719684049
Epoch: 9 Idx: 5000 Loss: 0.020566229537584607
Epoch: 10 Idx: 0 Loss: 0.022740284149067404
Epoch: 10 Idx: 5000 Loss: 0.013404923271563209
Epoch: 11 Idx: 0 Loss: 0.016675247146233918
Epoch: 11 Idx: 5000 Loss: 0.009765798463775247
Epoch: 12 Idx: 0 Loss: 0.020695460975773305
Epoch: 12 Idx: 5000 Loss: 0.01159845375668243
Epoch: 13 Idx: 0 Loss: 0.018835033395409
Epoch: 13 Idx: 5000 Loss: 0.025848220020285268
Epoch: 14 Idx: 0 Loss: 0.011280120809315737
Epoch: 14 Idx: 5000 Loss: 0.01785873388084085
Epoch: 15 Idx: 0 Loss: 0.015224016812374331
Epoch: 15 Idx: 5000 Loss: 0.022325656653034653
Epoch: 16 Idx: 0 Loss: 0.0240324872477828
Epoch: 16 Idx: 5000 Loss: 0.02948006397634702
Epoch: 17 Idx: 0 Loss: 0.02870322540195438
Epoch: 17 Idx: 5000 Loss: 0.017820195269686395
Epoch: 18 Idx: 0 Loss: 0.012896012774242007
Epoch: 18 Idx: 5000 Loss: 0.02056068561187939
Epoch: 19 Idx: 0 Loss: 0.014758760860288671
Epoch: 19 Idx: 5000 Loss: 0.031237524930521215
Epoch: 20 Idx: 0 Loss: 0.014025236219891712
Epoch: 20 Idx: 5000 Loss: 0.011985097322767408
Epoch: 21 Idx: 0 Loss: 0.018485158824966832
Epoch: 21 Idx: 5000 Loss: 0.01808930781898273
Epoch: 22 Idx: 0 Loss: 0.011362182819713225
Epoch: 22 Idx: 5000 Loss: 0.00955963942309623
Epoch: 23 Idx: 0 Loss: 0.035149377471188605
Epoch: 23 Idx: 5000 Loss: 0.013724637032165067
Epoch: 24 Idx: 0 Loss: 0.016814935616406478
Epoch: 24 Idx: 5000 Loss: 0.012831914138499862
Epoch: 25 Idx: 0 Loss: 0.014206713456392203
Epoch: 25 Idx: 5000 Loss: 0.00918237692057543
Epoch: 26 Idx: 0 Loss: 0.016499309783634935
Epoch: 26 Idx: 5000 Loss: 0.00821941689438152
Epoch: 27 Idx: 0 Loss: 0.02677452024104486
Epoch: 27 Idx: 5000 Loss: 0.010677020153740294
Epoch: 28 Idx: 0 Loss: 0.012554794949495277
Epoch: 28 Idx: 5000 Loss: 0.009595643653848004
Epoch: 29 Idx: 0 Loss: 0.03180923386816299
Epoch: 29 Idx: 5000 Loss: 0.03539965546813997
Epoch: 30 Idx: 0 Loss: 0.008810170792224598
Epoch: 30 Idx: 5000 Loss: 0.013315593849761982
Epoch: 31 Idx: 0 Loss: 0.026049003733672305
Epoch: 31 Idx: 5000 Loss: 0.03693903656382576
Epoch: 32 Idx: 0 Loss: 0.010278602655466856
Epoch: 32 Idx: 5000 Loss: 0.01778069190678047
Epoch: 33 Idx: 0 Loss: 0.011917369971786461
Epoch: 33 Idx: 5000 Loss: 0.010699018937367626
Epoch: 34 Idx: 0 Loss: 0.015372673111265778
Epoch: 34 Idx: 5000 Loss: 0.0031314586635707476
Epoch: 35 Idx: 0 Loss: 0.016877301095132635
Epoch: 35 Idx: 5000 Loss: 0.015298056569398005
Epoch: 36 Idx: 0 Loss: 0.028749322674880277
Epoch: 36 Idx: 5000 Loss: 0.009600434209054952
Epoch: 37 Idx: 0 Loss: 0.013716836424283275
Epoch: 37 Idx: 5000 Loss: 0.01148369483938625
Epoch: 38 Idx: 0 Loss: 0.019791944448797907
Epoch: 38 Idx: 5000 Loss: 0.008689848900757559
Epoch: 39 Idx: 0 Loss: 0.0294701289410088
Epoch: 39 Idx: 5000 Loss: 0.007617206116297349
Epoch: 40 Idx: 0 Loss: 0.013562467492299614
Epoch: 40 Idx: 5000 Loss: 0.011469232979356871
Epoch: 41 Idx: 0 Loss: 0.018700549194675432
Epoch: 41 Idx: 5000 Loss: 0.010419832582554089
Epoch: 42 Idx: 0 Loss: 0.014920232055992704
Epoch: 42 Idx: 5000 Loss: 0.011899048876891558
Epoch: 43 Idx: 0 Loss: 0.014244637098520148
Epoch: 43 Idx: 5000 Loss: 0.006209273292772231
Epoch: 44 Idx: 0 Loss: 0.012252924541390785
Epoch: 44 Idx: 5000 Loss: 0.02283283231203489
Epoch: 45 Idx: 0 Loss: 0.031066026573933852
Epoch: 45 Idx: 5000 Loss: 0.016582796623274745
Epoch: 46 Idx: 0 Loss: 0.016349105647950127
Epoch: 46 Idx: 5000 Loss: 0.016130043067548547
Epoch: 47 Idx: 0 Loss: 0.007480826784454006
Epoch: 47 Idx: 5000 Loss: 0.0034306640191614874
Epoch: 48 Idx: 0 Loss: 0.012951860000107066
Epoch: 48 Idx: 5000 Loss: 0.01388329097025904
Epoch: 49 Idx: 0 Loss: 0.006508720947677675
Epoch: 49 Idx: 5000 Loss: 0.017614755654598007
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13193541461374655
Epoch: 0 Idx: 5000 Loss: 0.013041063011180423
Epoch: 1 Idx: 0 Loss: 0.011753281134249536
Epoch: 1 Idx: 5000 Loss: 0.004742951910400869
Epoch: 2 Idx: 0 Loss: 0.01589091111828397
Epoch: 2 Idx: 5000 Loss: 0.031195471573147435
Epoch: 3 Idx: 0 Loss: 0.0185359239351682
Epoch: 3 Idx: 5000 Loss: 0.012587342505067536
Epoch: 4 Idx: 0 Loss: 0.020392707038073273
Epoch: 4 Idx: 5000 Loss: 0.015036330328670668
Epoch: 5 Idx: 0 Loss: 0.02046170451739723
Epoch: 5 Idx: 5000 Loss: 0.010755055542357186
Epoch: 6 Idx: 0 Loss: 0.009475444217591012
Epoch: 6 Idx: 5000 Loss: 0.01821346646891105
Epoch: 7 Idx: 0 Loss: 0.0123943128197561
Epoch: 7 Idx: 5000 Loss: 0.00929708302007065
Epoch: 8 Idx: 0 Loss: 0.007671030480373368
Epoch: 8 Idx: 5000 Loss: 0.010547646937101078
Epoch: 9 Idx: 0 Loss: 0.05270067682896759
Epoch: 9 Idx: 5000 Loss: 0.015276036375559243
Epoch: 10 Idx: 0 Loss: 0.008661536559417253
Epoch: 10 Idx: 5000 Loss: 0.025163662975037648
Epoch: 11 Idx: 0 Loss: 0.027615657971714357
Epoch: 11 Idx: 5000 Loss: 0.010719223881258535
Epoch: 12 Idx: 0 Loss: 0.0102919753325326
Epoch: 12 Idx: 5000 Loss: 0.011248695874172354
Epoch: 13 Idx: 0 Loss: 0.031077336043532536
Epoch: 13 Idx: 5000 Loss: 0.006656870449755563
Epoch: 14 Idx: 0 Loss: 0.0251890395165344
Epoch: 14 Idx: 5000 Loss: 0.026006250158919594
Epoch: 15 Idx: 0 Loss: 0.012275513121655087
Epoch: 15 Idx: 5000 Loss: 0.026231551391527667
Epoch: 16 Idx: 0 Loss: 0.011613923929708926
Epoch: 16 Idx: 5000 Loss: 0.01227277748777714
Epoch: 17 Idx: 0 Loss: 0.007966266383521332
Epoch: 17 Idx: 5000 Loss: 0.012668191122527105
Epoch: 18 Idx: 0 Loss: 0.009027798554380143
Epoch: 18 Idx: 5000 Loss: 0.013657623158058189
Epoch: 19 Idx: 0 Loss: 0.019561175647177492
Epoch: 19 Idx: 5000 Loss: 0.015926461611546625
Epoch: 20 Idx: 0 Loss: 0.012891780488413728
Epoch: 20 Idx: 5000 Loss: 0.01670867331465617
Epoch: 21 Idx: 0 Loss: 0.01799741735590001
Epoch: 21 Idx: 5000 Loss: 0.015942259589348057
Epoch: 22 Idx: 0 Loss: 0.016394043967124697
Epoch: 22 Idx: 5000 Loss: 0.023841678802284397
Epoch: 23 Idx: 0 Loss: 0.03436375115054456
Epoch: 23 Idx: 5000 Loss: 0.01711749211143245
Epoch: 24 Idx: 0 Loss: 0.016719068756940875
Epoch: 24 Idx: 5000 Loss: 0.006202483810838785
Epoch: 25 Idx: 0 Loss: 0.007727212828178964
Epoch: 25 Idx: 5000 Loss: 0.009920824589212169
Epoch: 26 Idx: 0 Loss: 0.016068564301940307
Epoch: 26 Idx: 5000 Loss: 0.028410631639490702
Epoch: 27 Idx: 0 Loss: 0.012937931964728226
Epoch: 27 Idx: 5000 Loss: 0.007628931601443669
Epoch: 28 Idx: 0 Loss: 0.029144187056223573
Epoch: 28 Idx: 5000 Loss: 0.009674732192334376
Epoch: 29 Idx: 0 Loss: 0.010593073370347235
Epoch: 29 Idx: 5000 Loss: 0.006041873653689597
Epoch: 30 Idx: 0 Loss: 0.008310225357579833
Epoch: 30 Idx: 5000 Loss: 0.011864228004695013
Epoch: 31 Idx: 0 Loss: 0.03860005978391838
Epoch: 31 Idx: 5000 Loss: 0.021287088039454505
Epoch: 32 Idx: 0 Loss: 0.006347646641782925
Epoch: 32 Idx: 5000 Loss: 0.02224867558578781
Epoch: 33 Idx: 0 Loss: 0.007976076670650577
Epoch: 33 Idx: 5000 Loss: 0.021276872305362356
Epoch: 34 Idx: 0 Loss: 0.027346076979088335
Epoch: 34 Idx: 5000 Loss: 0.01708170469444944
Epoch: 35 Idx: 0 Loss: 0.012639380289492404
Epoch: 35 Idx: 5000 Loss: 0.015210294090695948
Epoch: 36 Idx: 0 Loss: 0.007785382048514098
Epoch: 36 Idx: 5000 Loss: 0.029306207155923032
Epoch: 37 Idx: 0 Loss: 0.008107594812509458
Epoch: 37 Idx: 5000 Loss: 0.01653419066377892
Epoch: 38 Idx: 0 Loss: 0.011364413665652849
Epoch: 38 Idx: 5000 Loss: 0.010465709670783613
Epoch: 39 Idx: 0 Loss: 0.034913381429718386
Epoch: 39 Idx: 5000 Loss: 0.036794199488813885
Epoch: 40 Idx: 0 Loss: 0.012778206977383928
Epoch: 40 Idx: 5000 Loss: 0.014191732414723584
Epoch: 41 Idx: 0 Loss: 0.016246871771129295
Epoch: 41 Idx: 5000 Loss: 0.0093218620182711
Epoch: 42 Idx: 0 Loss: 0.009312580606645787
Epoch: 42 Idx: 5000 Loss: 0.012599201485016248
Epoch: 43 Idx: 0 Loss: 0.003693617374753541
Epoch: 43 Idx: 5000 Loss: 0.015671658430362403
Epoch: 44 Idx: 0 Loss: 0.01439450348328787
Epoch: 44 Idx: 5000 Loss: 0.015574022496762024
Epoch: 45 Idx: 0 Loss: 0.016578287623426866
Epoch: 45 Idx: 5000 Loss: 0.027107650330847947
Epoch: 46 Idx: 0 Loss: 0.0238755001874489
Epoch: 46 Idx: 5000 Loss: 0.013633689161892459
Epoch: 47 Idx: 0 Loss: 0.033655493962047825
Epoch: 47 Idx: 5000 Loss: 0.013271972835188169
Epoch: 48 Idx: 0 Loss: 0.015361749355144387
Epoch: 48 Idx: 5000 Loss: 0.006703753698191699
Epoch: 49 Idx: 0 Loss: 0.024329914414601955
Epoch: 49 Idx: 5000 Loss: 0.020101058555591106
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.2213859428630236
Epoch: 0 Idx: 5000 Loss: 0.02698231416200421
Epoch: 1 Idx: 0 Loss: 0.0204535819113707
Epoch: 1 Idx: 5000 Loss: 0.01897329965917939
Epoch: 2 Idx: 0 Loss: 0.009628808661789131
Epoch: 2 Idx: 5000 Loss: 0.02659698905176637
Epoch: 3 Idx: 0 Loss: 0.00950591864106159
Epoch: 3 Idx: 5000 Loss: 0.006822423966381748
Epoch: 4 Idx: 0 Loss: 0.02059033157022255
Epoch: 4 Idx: 5000 Loss: 0.01564452290421456
Epoch: 5 Idx: 0 Loss: 0.01216351518364072
Epoch: 5 Idx: 5000 Loss: 0.016131448537545903
Epoch: 6 Idx: 0 Loss: 0.029070740430447436
Epoch: 6 Idx: 5000 Loss: 0.005852863564080898
Epoch: 7 Idx: 0 Loss: 0.03549920443553125
Epoch: 7 Idx: 5000 Loss: 0.01589267471790633
Epoch: 8 Idx: 0 Loss: 0.012726994822591422
Epoch: 8 Idx: 5000 Loss: 0.02236257377947664
Epoch: 9 Idx: 0 Loss: 0.02626522305007477
Epoch: 9 Idx: 5000 Loss: 0.015791082761282615
Epoch: 10 Idx: 0 Loss: 0.021483815287861807
Epoch: 10 Idx: 5000 Loss: 0.010910902039385835
Epoch: 11 Idx: 0 Loss: 0.015415510332813506
Epoch: 11 Idx: 5000 Loss: 0.012355407214036643
Epoch: 12 Idx: 0 Loss: 0.008507614907430416
Epoch: 12 Idx: 5000 Loss: 0.026539007213534336
Epoch: 13 Idx: 0 Loss: 0.01958660350080257
Epoch: 13 Idx: 5000 Loss: 0.00970225271157528
Epoch: 14 Idx: 0 Loss: 0.011889937992064456
Epoch: 14 Idx: 5000 Loss: 0.013010092201154105
Epoch: 15 Idx: 0 Loss: 0.0243531218976892
Epoch: 15 Idx: 5000 Loss: 0.012878062520766342
Epoch: 16 Idx: 0 Loss: 0.021542382388324136
Epoch: 16 Idx: 5000 Loss: 0.016915502723683314
Epoch: 17 Idx: 0 Loss: 0.029120917368820682
Epoch: 17 Idx: 5000 Loss: 0.014307502986421448
Epoch: 18 Idx: 0 Loss: 0.004682913130886023
Epoch: 18 Idx: 5000 Loss: 0.01885848764935781
Epoch: 19 Idx: 0 Loss: 0.010688142730272155
Epoch: 19 Idx: 5000 Loss: 0.015751849064734258
Epoch: 20 Idx: 0 Loss: 0.015247408427403839
Epoch: 20 Idx: 5000 Loss: 0.012802782253354107
Epoch: 21 Idx: 0 Loss: 0.01012742952405051
Epoch: 21 Idx: 5000 Loss: 0.012487565389480277
Epoch: 22 Idx: 0 Loss: 0.022113000555298905
Epoch: 22 Idx: 5000 Loss: 0.024213689471381278
Epoch: 23 Idx: 0 Loss: 0.02444360762049613
Epoch: 23 Idx: 5000 Loss: 0.014850726249083684
Epoch: 24 Idx: 0 Loss: 0.011310339744574769
Epoch: 24 Idx: 5000 Loss: 0.014377438394760082
Epoch: 25 Idx: 0 Loss: 0.008921654252605275
Epoch: 25 Idx: 5000 Loss: 0.025036457856102624
Epoch: 26 Idx: 0 Loss: 0.015468643394458793
Epoch: 26 Idx: 5000 Loss: 0.023152458373401446
Epoch: 27 Idx: 0 Loss: 0.016895754053729412
Epoch: 27 Idx: 5000 Loss: 0.008105119782401318
Epoch: 28 Idx: 0 Loss: 0.011346520345606698
Epoch: 28 Idx: 5000 Loss: 0.0161572057086853
Epoch: 29 Idx: 0 Loss: 0.025152217519364688
Epoch: 29 Idx: 5000 Loss: 0.016349141257945614
Epoch: 30 Idx: 0 Loss: 0.021684454708744378
Epoch: 30 Idx: 5000 Loss: 0.008953510643220669
Epoch: 31 Idx: 0 Loss: 0.005323432684040151
Epoch: 31 Idx: 5000 Loss: 0.010968364984277347
Epoch: 32 Idx: 0 Loss: 0.007097697635662531
Epoch: 32 Idx: 5000 Loss: 0.017207809140281482
Epoch: 33 Idx: 0 Loss: 0.00973122263970606
Epoch: 33 Idx: 5000 Loss: 0.010106399293548602
Epoch: 34 Idx: 0 Loss: 0.017721771470164713
Epoch: 34 Idx: 5000 Loss: 0.009548172779278974
Epoch: 35 Idx: 0 Loss: 0.006096820489714451
Epoch: 35 Idx: 5000 Loss: 0.030560463484566123
Epoch: 36 Idx: 0 Loss: 0.020113482036392707
Epoch: 36 Idx: 5000 Loss: 0.005214860334826016
Epoch: 37 Idx: 0 Loss: 0.044159678145816186
Epoch: 37 Idx: 5000 Loss: 0.015610520976651023
Epoch: 38 Idx: 0 Loss: 0.03859847693182972
Epoch: 38 Idx: 5000 Loss: 0.008888917514810043
Epoch: 39 Idx: 0 Loss: 0.011183136063179425
Epoch: 39 Idx: 5000 Loss: 0.008900647598041756
Epoch: 40 Idx: 0 Loss: 0.027954984019460827
Epoch: 40 Idx: 5000 Loss: 0.035191153044686736
Epoch: 41 Idx: 0 Loss: 0.007497183086994132
Epoch: 41 Idx: 5000 Loss: 0.014342369683104227
Epoch: 42 Idx: 0 Loss: 0.005506412936458889
Epoch: 42 Idx: 5000 Loss: 0.013083618262823204
Epoch: 43 Idx: 0 Loss: 0.00821385213168374
Epoch: 43 Idx: 5000 Loss: 0.008587000612599998
Epoch: 44 Idx: 0 Loss: 0.030444323227292076
Epoch: 44 Idx: 5000 Loss: 0.024202003760537594
Epoch: 45 Idx: 0 Loss: 0.013182044791521314
Epoch: 45 Idx: 5000 Loss: 0.009340592021550957
Epoch: 46 Idx: 0 Loss: 0.01393217317330303
Epoch: 46 Idx: 5000 Loss: 0.02763395009277774
Epoch: 47 Idx: 0 Loss: 0.017281178356648268
Epoch: 47 Idx: 5000 Loss: 0.012662563110293668
Epoch: 48 Idx: 0 Loss: 0.012129382796671275
Epoch: 48 Idx: 5000 Loss: 0.048631546346130296
Epoch: 49 Idx: 0 Loss: 0.0062670083179653035
Epoch: 49 Idx: 5000 Loss: 0.02214013772196955
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.22691408750976322
Epoch: 0 Idx: 5000 Loss: 0.017588530150680536
Epoch: 1 Idx: 0 Loss: 0.012415418352651142
Epoch: 1 Idx: 5000 Loss: 0.017733863724163475
Epoch: 2 Idx: 0 Loss: 0.018526850982093356
Epoch: 2 Idx: 5000 Loss: 0.007529929634538005
Epoch: 3 Idx: 0 Loss: 0.010126641561924466
Epoch: 3 Idx: 5000 Loss: 0.027130281468478533
Epoch: 4 Idx: 0 Loss: 0.014714827726610584
Epoch: 4 Idx: 5000 Loss: 0.008619586367060065
Epoch: 5 Idx: 0 Loss: 0.01953985470556511
Epoch: 5 Idx: 5000 Loss: 0.012700287462619263
Epoch: 6 Idx: 0 Loss: 0.011962252496429338
Epoch: 6 Idx: 5000 Loss: 0.022341397530592073
Epoch: 7 Idx: 0 Loss: 0.01566315678977439
Epoch: 7 Idx: 5000 Loss: 0.040118857864616546
Epoch: 8 Idx: 0 Loss: 0.0074534964482249125
Epoch: 8 Idx: 5000 Loss: 0.01671596132207017
Epoch: 9 Idx: 0 Loss: 0.02755087886352699
Epoch: 9 Idx: 5000 Loss: 0.00981610845584471
Epoch: 10 Idx: 0 Loss: 0.008530932947171698
Epoch: 10 Idx: 5000 Loss: 0.009411708863229108
Epoch: 11 Idx: 0 Loss: 0.018734070117023296
Epoch: 11 Idx: 5000 Loss: 0.022510660926266857
Epoch: 12 Idx: 0 Loss: 0.02645780856731082
Epoch: 12 Idx: 5000 Loss: 0.014271940060912126
Epoch: 13 Idx: 0 Loss: 0.013922610071221562
Epoch: 13 Idx: 5000 Loss: 0.022550612380636038
Epoch: 14 Idx: 0 Loss: 0.01078717495257132
Epoch: 14 Idx: 5000 Loss: 0.014245239001876102
Epoch: 15 Idx: 0 Loss: 0.0331819040490082
Epoch: 15 Idx: 5000 Loss: 0.008017780189779847
Epoch: 16 Idx: 0 Loss: 0.015215365252221651
Epoch: 16 Idx: 5000 Loss: 0.035841018667354986
Epoch: 17 Idx: 0 Loss: 0.014011729344289238
Epoch: 17 Idx: 5000 Loss: 0.011462036636320548
Epoch: 18 Idx: 0 Loss: 0.019483682617675583
Epoch: 18 Idx: 5000 Loss: 0.01485652499358123
Epoch: 19 Idx: 0 Loss: 0.010649771082463812
Epoch: 19 Idx: 5000 Loss: 0.00804458556347474
Epoch: 20 Idx: 0 Loss: 0.018203771537549367
Epoch: 20 Idx: 5000 Loss: 0.01794087486624662
Epoch: 21 Idx: 0 Loss: 0.00909691334187057
Epoch: 21 Idx: 5000 Loss: 0.014336807683688509
Epoch: 22 Idx: 0 Loss: 0.01321142396203943
Epoch: 22 Idx: 5000 Loss: 0.007602614620704543
Epoch: 23 Idx: 0 Loss: 0.011350520059284448
Epoch: 23 Idx: 5000 Loss: 0.012475097415650654
Epoch: 24 Idx: 0 Loss: 0.014270001623588267
Epoch: 24 Idx: 5000 Loss: 0.03838068192301792
Epoch: 25 Idx: 0 Loss: 0.0057745185894133196
Epoch: 25 Idx: 5000 Loss: 0.02474066364210565
Epoch: 26 Idx: 0 Loss: 0.049857702457322635
Epoch: 26 Idx: 5000 Loss: 0.017938274988979964
Epoch: 27 Idx: 0 Loss: 0.025678042767484165
Epoch: 27 Idx: 5000 Loss: 0.008044081297411462
Epoch: 28 Idx: 0 Loss: 0.020019252119150146
Epoch: 28 Idx: 5000 Loss: 0.013192367820962662
Epoch: 29 Idx: 0 Loss: 0.01377257149276966
Epoch: 29 Idx: 5000 Loss: 0.02388835542562408
Epoch: 30 Idx: 0 Loss: 0.026984419233194362
Epoch: 30 Idx: 5000 Loss: 0.01710794117628995
Epoch: 31 Idx: 0 Loss: 0.007900969300908247
Epoch: 31 Idx: 5000 Loss: 0.007009561134277667
Epoch: 32 Idx: 0 Loss: 0.020756263439309468
Epoch: 32 Idx: 5000 Loss: 0.009846005831161873
Epoch: 33 Idx: 0 Loss: 0.017349642214508715
Epoch: 33 Idx: 5000 Loss: 0.02011781156424288
Epoch: 34 Idx: 0 Loss: 0.01813428949054207
Epoch: 34 Idx: 5000 Loss: 0.023155272097906035
Epoch: 35 Idx: 0 Loss: 0.016544003912768154
Epoch: 35 Idx: 5000 Loss: 0.01175906199520526
Epoch: 36 Idx: 0 Loss: 0.020293715357870848
Epoch: 36 Idx: 5000 Loss: 0.009231014664087538
Epoch: 37 Idx: 0 Loss: 0.011814580506076425
Epoch: 37 Idx: 5000 Loss: 0.02391963627905493
Epoch: 38 Idx: 0 Loss: 0.03562196851909867
Epoch: 38 Idx: 5000 Loss: 0.02486478575024406
Epoch: 39 Idx: 0 Loss: 0.04772321305862585
Epoch: 39 Idx: 5000 Loss: 0.009735648091563721
Epoch: 40 Idx: 0 Loss: 0.014463227635145121
Epoch: 40 Idx: 5000 Loss: 0.012856979885565337
Epoch: 41 Idx: 0 Loss: 0.026160734986652313
Epoch: 41 Idx: 5000 Loss: 0.010717733362714902
Epoch: 42 Idx: 0 Loss: 0.027705712689158328
Epoch: 42 Idx: 5000 Loss: 0.011262091114732514
Epoch: 43 Idx: 0 Loss: 0.011860201238560223
Epoch: 43 Idx: 5000 Loss: 0.011350878942973435
Epoch: 44 Idx: 0 Loss: 0.008086641530969338
Epoch: 44 Idx: 5000 Loss: 0.012499180834995158
Epoch: 45 Idx: 0 Loss: 0.014888285986299692
Epoch: 45 Idx: 5000 Loss: 0.007298323580548856
Epoch: 46 Idx: 0 Loss: 0.028705572324547023
Epoch: 46 Idx: 5000 Loss: 0.009928910706379471
Epoch: 47 Idx: 0 Loss: 0.01275690502043267
Epoch: 47 Idx: 5000 Loss: 0.009982314750645323
Epoch: 48 Idx: 0 Loss: 0.03500557331275603
Epoch: 48 Idx: 5000 Loss: 0.0049106823217669555
Epoch: 49 Idx: 0 Loss: 0.011368190301704516
Epoch: 49 Idx: 5000 Loss: 0.008066474885662752
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.21488705241106096
Epoch: 0 Idx: 5000 Loss: 0.015758849327357338
Epoch: 1 Idx: 0 Loss: 0.02436324965097488
Epoch: 1 Idx: 5000 Loss: 0.009719252224478992
Epoch: 2 Idx: 0 Loss: 0.011748239462433594
Epoch: 2 Idx: 5000 Loss: 0.009051650017083076
Epoch: 3 Idx: 0 Loss: 0.02900511731593865
Epoch: 3 Idx: 5000 Loss: 0.016251725266498172
Epoch: 4 Idx: 0 Loss: 0.016261092844157533
Epoch: 4 Idx: 5000 Loss: 0.00853813284063109
Epoch: 5 Idx: 0 Loss: 0.013822443446523218
Epoch: 5 Idx: 5000 Loss: 0.018883732917573462
Epoch: 6 Idx: 0 Loss: 0.02912151524166255
Epoch: 6 Idx: 5000 Loss: 0.01977506544059116
Epoch: 7 Idx: 0 Loss: 0.014723083184093296
Epoch: 7 Idx: 5000 Loss: 0.015040841889347475
Epoch: 8 Idx: 0 Loss: 0.009964629838102926
Epoch: 8 Idx: 5000 Loss: 0.01005822223024674
Epoch: 9 Idx: 0 Loss: 0.015327106016498806
Epoch: 9 Idx: 5000 Loss: 0.022067945287362715
Epoch: 10 Idx: 0 Loss: 0.006218187856764219
Epoch: 10 Idx: 5000 Loss: 0.008129122478344778
Epoch: 11 Idx: 0 Loss: 0.0057783379281692695
Epoch: 11 Idx: 5000 Loss: 0.011854719654587526
Epoch: 12 Idx: 0 Loss: 0.03324620407073655
Epoch: 12 Idx: 5000 Loss: 0.02221678066851462
Epoch: 13 Idx: 0 Loss: 0.005999657336008133
Epoch: 13 Idx: 5000 Loss: 0.015215941293484156
Epoch: 14 Idx: 0 Loss: 0.009635357580461348
Epoch: 14 Idx: 5000 Loss: 0.02316670856930602
Epoch: 15 Idx: 0 Loss: 0.009992724482877694
Epoch: 15 Idx: 5000 Loss: 0.04286693376900789
Epoch: 16 Idx: 0 Loss: 0.010339513457671277
Epoch: 16 Idx: 5000 Loss: 0.01752341996640295
Epoch: 17 Idx: 0 Loss: 0.013500613264741126
Epoch: 17 Idx: 5000 Loss: 0.010243859997676238
Epoch: 18 Idx: 0 Loss: 0.017672459731639452
Epoch: 18 Idx: 5000 Loss: 0.011797662266257962
Epoch: 19 Idx: 0 Loss: 0.008492958362269943
Epoch: 19 Idx: 5000 Loss: 0.009201517720522297
Epoch: 20 Idx: 0 Loss: 0.009717995802218288
Epoch: 20 Idx: 5000 Loss: 0.011695593716811285
Epoch: 21 Idx: 0 Loss: 0.021900906115244336
Epoch: 21 Idx: 5000 Loss: 0.02009922242472959
Epoch: 22 Idx: 0 Loss: 0.011610003092538002
Epoch: 22 Idx: 5000 Loss: 0.01926820970910579
Epoch: 23 Idx: 0 Loss: 0.02481902732144434
Epoch: 23 Idx: 5000 Loss: 0.009401749056505107
Epoch: 24 Idx: 0 Loss: 0.015750909209042027
Epoch: 24 Idx: 5000 Loss: 0.014924786007473243
Epoch: 25 Idx: 0 Loss: 0.022375880816467394
Epoch: 25 Idx: 5000 Loss: 0.013804074373219687
Epoch: 26 Idx: 0 Loss: 0.0131793808052608
Epoch: 26 Idx: 5000 Loss: 0.009482529032541065
Epoch: 27 Idx: 0 Loss: 0.027399424698129525
Epoch: 27 Idx: 5000 Loss: 0.0074966065242237055
Epoch: 28 Idx: 0 Loss: 0.014836024952423706
Epoch: 28 Idx: 5000 Loss: 0.028012119655305805
Epoch: 29 Idx: 0 Loss: 0.009764053741218866
Epoch: 29 Idx: 5000 Loss: 0.012345096807599399
Epoch: 30 Idx: 0 Loss: 0.01149161996343984
Epoch: 30 Idx: 5000 Loss: 0.009986920306669039
Epoch: 31 Idx: 0 Loss: 0.022449081320573917
Epoch: 31 Idx: 5000 Loss: 0.008643115852915627
Epoch: 32 Idx: 0 Loss: 0.012573893259975582
Epoch: 32 Idx: 5000 Loss: 0.009416870581909646
Epoch: 33 Idx: 0 Loss: 0.006184009951386784
Epoch: 33 Idx: 5000 Loss: 0.024860284923691408
Epoch: 34 Idx: 0 Loss: 0.019346973932186446
Epoch: 34 Idx: 5000 Loss: 0.007771701855994077
Epoch: 35 Idx: 0 Loss: 0.013048789203545352
Epoch: 35 Idx: 5000 Loss: 0.017305894521462764
Epoch: 36 Idx: 0 Loss: 0.0098404516888262
Epoch: 36 Idx: 5000 Loss: 0.013562942740666654
Epoch: 37 Idx: 0 Loss: 0.03215036051250644
Epoch: 37 Idx: 5000 Loss: 0.02163579157264329
Epoch: 38 Idx: 0 Loss: 0.017456436949122446
Epoch: 38 Idx: 5000 Loss: 0.015494160990600667
Epoch: 39 Idx: 0 Loss: 0.006050666091730446
Epoch: 39 Idx: 5000 Loss: 0.013377124304432612
Epoch: 40 Idx: 0 Loss: 0.015859997918933614
Epoch: 40 Idx: 5000 Loss: 0.02386012277194903
Epoch: 41 Idx: 0 Loss: 0.012984107381332669
Epoch: 41 Idx: 5000 Loss: 0.011356598392486848
Epoch: 42 Idx: 0 Loss: 0.012199916356220407
Epoch: 42 Idx: 5000 Loss: 0.007351913926892787
Epoch: 43 Idx: 0 Loss: 0.013578777369808961
Epoch: 43 Idx: 5000 Loss: 0.010186751958542045
Epoch: 44 Idx: 0 Loss: 0.00937413564353069
Epoch: 44 Idx: 5000 Loss: 0.00688517468234864
Epoch: 45 Idx: 0 Loss: 0.0309975834234056
Epoch: 45 Idx: 5000 Loss: 0.02575096054912347
Epoch: 46 Idx: 0 Loss: 0.024825148496590795
Epoch: 46 Idx: 5000 Loss: 0.03187534156969987
Epoch: 47 Idx: 0 Loss: 0.011098001701739227
Epoch: 47 Idx: 5000 Loss: 0.007516752082650541
Epoch: 48 Idx: 0 Loss: 0.011069284046478249
Epoch: 48 Idx: 5000 Loss: 0.013708262765551107
Epoch: 49 Idx: 0 Loss: 0.013236107840628956
Epoch: 49 Idx: 5000 Loss: 0.017975189697418396
Len (direct inputs):  1690
Inputs len 10074 10 11464
Len (direct inputs):  1400
Starting sliding window evaluation...
Step 12/7
Val onto:  [('conference', 'iasted')] test_onto:  [('confof', 'edas')]
Training size: 104813 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.19137319860288565
Epoch: 0 Idx: 5000 Loss: 0.015295760059318195
Epoch: 1 Idx: 0 Loss: 0.012674507143589623
Epoch: 1 Idx: 5000 Loss: 0.022758872668964876
Epoch: 2 Idx: 0 Loss: 0.02129952305244641
Epoch: 2 Idx: 5000 Loss: 0.02352787018150986
Epoch: 3 Idx: 0 Loss: 0.015241852385341056
Epoch: 3 Idx: 5000 Loss: 0.01877474241760612
Epoch: 4 Idx: 0 Loss: 0.015913890324248357
Epoch: 4 Idx: 5000 Loss: 0.015243519319996995
Epoch: 5 Idx: 0 Loss: 0.01047057105625672
Epoch: 5 Idx: 5000 Loss: 0.031225466923173868
Epoch: 6 Idx: 0 Loss: 0.011409698104325591
Epoch: 6 Idx: 5000 Loss: 0.014145883765649618
Epoch: 7 Idx: 0 Loss: 0.016572661251507078
Epoch: 7 Idx: 5000 Loss: 0.011375036119917296
Epoch: 8 Idx: 0 Loss: 0.023060398173431036
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc265>
Subject: Job 4066791: <python main.py 3 5 False True> in cluster <dcc> Exited

Job <python main.py 3 5 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc265>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:35 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 5 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46191.45 sec.
    Max Memory :                                 2887 MB
    Average Memory :                             2736.26 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40530.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46203 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

