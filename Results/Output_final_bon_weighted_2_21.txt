2020-09-15 15:49:41.874756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.157052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.319417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.319511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.322046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.323503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.323858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.325775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.327169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.327378: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.327408: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.327714: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.335072: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600005000 Hz
2020-09-15 15:49:45.335245: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a36bb07420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.335267: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.336965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.336991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20125946160904448
Epoch: 0 Idx: 5000 Loss: 0.006345318780665084
Epoch: 1 Idx: 0 Loss: 0.015116122717448267
Epoch: 1 Idx: 5000 Loss: 0.008017889019190722
Epoch: 2 Idx: 0 Loss: 0.008483052432118776
Epoch: 2 Idx: 5000 Loss: 0.013018474000330219
Epoch: 3 Idx: 0 Loss: 0.01482487484401078
Epoch: 3 Idx: 5000 Loss: 0.016906256917198395
Epoch: 4 Idx: 0 Loss: 0.0235179543198985
Epoch: 4 Idx: 5000 Loss: 0.014526532122480895
Epoch: 5 Idx: 0 Loss: 0.006741352660457287
Epoch: 5 Idx: 5000 Loss: 0.014604649181705417
Epoch: 6 Idx: 0 Loss: 0.007923717929485945
Epoch: 6 Idx: 5000 Loss: 0.009886068952023777
Epoch: 7 Idx: 0 Loss: 0.012197076418568351
Epoch: 7 Idx: 5000 Loss: 0.0044336093691340565
Epoch: 8 Idx: 0 Loss: 0.010390042392726798
Epoch: 8 Idx: 5000 Loss: 0.025732657991978
Epoch: 9 Idx: 0 Loss: 0.009981595096120996
Epoch: 9 Idx: 5000 Loss: 0.012254475614161806
Epoch: 10 Idx: 0 Loss: 0.018824768622041712
Epoch: 10 Idx: 5000 Loss: 0.014950596277993914
Epoch: 11 Idx: 0 Loss: 0.014364481467464304
Epoch: 11 Idx: 5000 Loss: 0.018987833345204503
Epoch: 12 Idx: 0 Loss: 0.008082590147401855
Epoch: 12 Idx: 5000 Loss: 0.014142447360485567
Epoch: 13 Idx: 0 Loss: 0.013490031467044432
Epoch: 13 Idx: 5000 Loss: 0.01005430362796181
Epoch: 14 Idx: 0 Loss: 0.01848304658948979
Epoch: 14 Idx: 5000 Loss: 0.007064631360764803
Epoch: 15 Idx: 0 Loss: 0.03867483264507472
Epoch: 15 Idx: 5000 Loss: 0.009964325011085575
Epoch: 16 Idx: 0 Loss: 0.05037004438575216
Epoch: 16 Idx: 5000 Loss: 0.013974075186523334
Epoch: 17 Idx: 0 Loss: 0.047181818190002035
Epoch: 17 Idx: 5000 Loss: 0.014992784816674288
Epoch: 18 Idx: 0 Loss: 0.012934573449689287
Epoch: 18 Idx: 5000 Loss: 0.0053060468249610734
Epoch: 19 Idx: 0 Loss: 0.02719848183824112
Epoch: 19 Idx: 5000 Loss: 0.012666454912013982
Epoch: 20 Idx: 0 Loss: 0.0052718553592344015
Epoch: 20 Idx: 5000 Loss: 0.009157380900590456
Epoch: 21 Idx: 0 Loss: 0.007640839461425327
Epoch: 21 Idx: 5000 Loss: 0.026143878562465778
Epoch: 22 Idx: 0 Loss: 0.024697821410665163
Epoch: 22 Idx: 5000 Loss: 0.012469685683985165
Epoch: 23 Idx: 0 Loss: 0.024063955267792154
Epoch: 23 Idx: 5000 Loss: 0.021633708614792406
Epoch: 24 Idx: 0 Loss: 0.022239952082926714
Epoch: 24 Idx: 5000 Loss: 0.007485578076747632
Epoch: 25 Idx: 0 Loss: 0.008294723613400069
Epoch: 25 Idx: 5000 Loss: 0.011767639474113373
Epoch: 26 Idx: 0 Loss: 0.015351328963243933
Epoch: 26 Idx: 5000 Loss: 0.02685299256603861
Epoch: 27 Idx: 0 Loss: 0.018131896142487645
Epoch: 27 Idx: 5000 Loss: 0.012920451915569056
Epoch: 28 Idx: 0 Loss: 0.007992468336407094
Epoch: 28 Idx: 5000 Loss: 0.023369268061464783
Epoch: 29 Idx: 0 Loss: 0.01803207999266725
Epoch: 29 Idx: 5000 Loss: 0.022460637290618885
Epoch: 30 Idx: 0 Loss: 0.020182280459658006
Epoch: 30 Idx: 5000 Loss: 0.01579703992844385
Epoch: 31 Idx: 0 Loss: 0.0063368896185628945
Epoch: 31 Idx: 5000 Loss: 0.0294812898780062
Epoch: 32 Idx: 0 Loss: 0.030602482054896733
Epoch: 32 Idx: 5000 Loss: 0.014010747795923473
Epoch: 33 Idx: 0 Loss: 0.017979922054443338
Epoch: 33 Idx: 5000 Loss: 0.005387661241796618
Epoch: 34 Idx: 0 Loss: 0.012213472093209658
Epoch: 34 Idx: 5000 Loss: 0.010792893390066822
Epoch: 35 Idx: 0 Loss: 0.009613716882543442
Epoch: 35 Idx: 5000 Loss: 0.01362228743093111
Epoch: 36 Idx: 0 Loss: 0.017489347812602515
Epoch: 36 Idx: 5000 Loss: 0.013940718592449379
Epoch: 37 Idx: 0 Loss: 0.012432353481878076
Epoch: 37 Idx: 5000 Loss: 0.021643664473226278
Epoch: 38 Idx: 0 Loss: 0.013340392384391508
Epoch: 38 Idx: 5000 Loss: 0.030732030682028646
Epoch: 39 Idx: 0 Loss: 0.01006667379890849
Epoch: 39 Idx: 5000 Loss: 0.01764176442710007
Epoch: 40 Idx: 0 Loss: 0.0253489748903932
Epoch: 40 Idx: 5000 Loss: 0.016940982390220842
Epoch: 41 Idx: 0 Loss: 0.0072896268105357665
Epoch: 41 Idx: 5000 Loss: 0.015636640467215343
Epoch: 42 Idx: 0 Loss: 0.011380667210143594
Epoch: 42 Idx: 5000 Loss: 0.030346620732700946
Epoch: 43 Idx: 0 Loss: 0.014930213547813277
Epoch: 43 Idx: 5000 Loss: 0.00864246324816552
Epoch: 44 Idx: 0 Loss: 0.010582334862262904
Epoch: 44 Idx: 5000 Loss: 0.016727070402557276
Epoch: 45 Idx: 0 Loss: 0.011349395737419488
Epoch: 45 Idx: 5000 Loss: 0.017983864375294426
Epoch: 46 Idx: 0 Loss: 0.018862837535264135
Epoch: 46 Idx: 5000 Loss: 0.011229361194102146
Epoch: 47 Idx: 0 Loss: 0.006985264586460778
Epoch: 47 Idx: 5000 Loss: 0.012107086951245443
Epoch: 48 Idx: 0 Loss: 0.010129868790619103
Epoch: 48 Idx: 5000 Loss: 0.04927904421783298
Epoch: 49 Idx: 0 Loss: 0.019764911833865043
Epoch: 49 Idx: 5000 Loss: 0.008766888575539032
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14130520567526747
Epoch: 0 Idx: 5000 Loss: 0.021886698386595654
Epoch: 1 Idx: 0 Loss: 0.017165765425124616
Epoch: 1 Idx: 5000 Loss: 0.02064254169285518
Epoch: 2 Idx: 0 Loss: 0.015809604469960256
Epoch: 2 Idx: 5000 Loss: 0.006310213322200711
Epoch: 3 Idx: 0 Loss: 0.011236905215468499
Epoch: 3 Idx: 5000 Loss: 0.01723089463958127
Epoch: 4 Idx: 0 Loss: 0.021745235175714563
Epoch: 4 Idx: 5000 Loss: 0.010645762768642214
Epoch: 5 Idx: 0 Loss: 0.019093072658721167
Epoch: 5 Idx: 5000 Loss: 0.016389014984805987
Epoch: 6 Idx: 0 Loss: 0.007516714154202979
Epoch: 6 Idx: 5000 Loss: 0.011053648941255542
Epoch: 7 Idx: 0 Loss: 0.013724817734163907
Epoch: 7 Idx: 5000 Loss: 0.011140427473175958
Epoch: 8 Idx: 0 Loss: 0.016631731869626083
Epoch: 8 Idx: 5000 Loss: 0.0130469537940869
Epoch: 9 Idx: 0 Loss: 0.021343091325412147
Epoch: 9 Idx: 5000 Loss: 0.029032649561925535
Epoch: 10 Idx: 0 Loss: 0.007587687183243209
Epoch: 10 Idx: 5000 Loss: 0.013875391892620607
Epoch: 11 Idx: 0 Loss: 0.0321066476626887
Epoch: 11 Idx: 5000 Loss: 0.015054357960041821
Epoch: 12 Idx: 0 Loss: 0.01344261809764775
Epoch: 12 Idx: 5000 Loss: 0.018374723661157142
Epoch: 13 Idx: 0 Loss: 0.007576447555917888
Epoch: 13 Idx: 5000 Loss: 0.01902521724998733
Epoch: 14 Idx: 0 Loss: 0.010972063108474841
Epoch: 14 Idx: 5000 Loss: 0.00916787001511652
Epoch: 15 Idx: 0 Loss: 0.01334289066089267
Epoch: 15 Idx: 5000 Loss: 0.014727730379007736
Epoch: 16 Idx: 0 Loss: 0.02427541841221491
Epoch: 16 Idx: 5000 Loss: 0.0151860916660349
Epoch: 17 Idx: 0 Loss: 0.011862770547639248
Epoch: 17 Idx: 5000 Loss: 0.013043013469185627
Epoch: 18 Idx: 0 Loss: 0.012498937909475389
Epoch: 18 Idx: 5000 Loss: 0.016224784269093667
Epoch: 19 Idx: 0 Loss: 0.043082708460920285
Epoch: 19 Idx: 5000 Loss: 0.007791551949554927
Epoch: 20 Idx: 0 Loss: 0.015327851685562692
Epoch: 20 Idx: 5000 Loss: 0.03159038110134812
Epoch: 21 Idx: 0 Loss: 0.0171601838555889
Epoch: 21 Idx: 5000 Loss: 0.058977853796802
Epoch: 22 Idx: 0 Loss: 0.01707385651442738
Epoch: 22 Idx: 5000 Loss: 0.024704813251691476
Epoch: 23 Idx: 0 Loss: 0.00972404857712373
Epoch: 23 Idx: 5000 Loss: 0.02229412832568782
Epoch: 24 Idx: 0 Loss: 0.010578876117416825
Epoch: 24 Idx: 5000 Loss: 0.014525873855687751
Epoch: 25 Idx: 0 Loss: 0.008864272704531568
Epoch: 25 Idx: 5000 Loss: 0.03657502279205258
Epoch: 26 Idx: 0 Loss: 0.011908716763970649
Epoch: 26 Idx: 5000 Loss: 0.029342657913669752
Epoch: 27 Idx: 0 Loss: 0.009367036980937039
Epoch: 27 Idx: 5000 Loss: 0.020655854599001537
Epoch: 28 Idx: 0 Loss: 0.017058881505175517
Epoch: 28 Idx: 5000 Loss: 0.019923501139315417
Epoch: 29 Idx: 0 Loss: 0.010267176548321832
Epoch: 29 Idx: 5000 Loss: 0.024480608728317477
Epoch: 30 Idx: 0 Loss: 0.018100331840519693
Epoch: 30 Idx: 5000 Loss: 0.011988220872536086
Epoch: 31 Idx: 0 Loss: 0.018015517251453932
Epoch: 31 Idx: 5000 Loss: 0.013102050631276898
Epoch: 32 Idx: 0 Loss: 0.032105705344325663
Epoch: 32 Idx: 5000 Loss: 0.010123844635662363
Epoch: 33 Idx: 0 Loss: 0.02208446487288388
Epoch: 33 Idx: 5000 Loss: 0.012964220972569732
Epoch: 34 Idx: 0 Loss: 0.03037885000663934
Epoch: 34 Idx: 5000 Loss: 0.014120830054516066
Epoch: 35 Idx: 0 Loss: 0.00791713322876853
Epoch: 35 Idx: 5000 Loss: 0.016068004030349154
Epoch: 36 Idx: 0 Loss: 0.02095007373620191
Epoch: 36 Idx: 5000 Loss: 0.012956081248821758
Epoch: 37 Idx: 0 Loss: 0.0175326096363114
Epoch: 37 Idx: 5000 Loss: 0.018115116702982857
Epoch: 38 Idx: 0 Loss: 0.01752429623225873
Epoch: 38 Idx: 5000 Loss: 0.034851884305195
Epoch: 39 Idx: 0 Loss: 0.008770704705920604
Epoch: 39 Idx: 5000 Loss: 0.009443300613019434
Epoch: 40 Idx: 0 Loss: 0.008644209390826699
Epoch: 40 Idx: 5000 Loss: 0.019101096311494554
Epoch: 41 Idx: 0 Loss: 0.03667133378457024
Epoch: 41 Idx: 5000 Loss: 0.008345568036318194
Epoch: 42 Idx: 0 Loss: 0.00844578400915507
Epoch: 42 Idx: 5000 Loss: 0.01367668336433368
Epoch: 43 Idx: 0 Loss: 0.014801338139397626
Epoch: 43 Idx: 5000 Loss: 0.03858772125585617
Epoch: 44 Idx: 0 Loss: 0.02892308267863888
Epoch: 44 Idx: 5000 Loss: 0.018656118841626886
Epoch: 45 Idx: 0 Loss: 0.02500132088142759
Epoch: 45 Idx: 5000 Loss: 0.013990993992854864
Epoch: 46 Idx: 0 Loss: 0.015898712092612323
Epoch: 46 Idx: 5000 Loss: 0.02532066132932905
Epoch: 47 Idx: 0 Loss: 0.01651409627297421
Epoch: 47 Idx: 5000 Loss: 0.012417909809248
Epoch: 48 Idx: 0 Loss: 0.02111852301718007
Epoch: 48 Idx: 5000 Loss: 0.014084009700167908
Epoch: 49 Idx: 0 Loss: 0.0250718824181642
Epoch: 49 Idx: 5000 Loss: 0.008720879916708918
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.16913631639998916
Epoch: 0 Idx: 5000 Loss: 0.014251217372542167
Epoch: 1 Idx: 0 Loss: 0.019355744372357334
Epoch: 1 Idx: 5000 Loss: 0.009318640916993567
Epoch: 2 Idx: 0 Loss: 0.03359132593283676
Epoch: 2 Idx: 5000 Loss: 0.0094638290303646
Epoch: 3 Idx: 0 Loss: 0.03990758203613192
Epoch: 3 Idx: 5000 Loss: 0.025189587085494014
Epoch: 4 Idx: 0 Loss: 0.008428382348301292
Epoch: 4 Idx: 5000 Loss: 0.018963277461918313
Epoch: 5 Idx: 0 Loss: 0.01471008851702715
Epoch: 5 Idx: 5000 Loss: 0.009927735441596634
Epoch: 6 Idx: 0 Loss: 0.013023580548822846
Epoch: 6 Idx: 5000 Loss: 0.01750868244424033
Epoch: 7 Idx: 0 Loss: 0.008057964169924717
Epoch: 7 Idx: 5000 Loss: 0.02222572527059923
Epoch: 8 Idx: 0 Loss: 0.020218035522845266
Epoch: 8 Idx: 5000 Loss: 0.012014994095602936
Epoch: 9 Idx: 0 Loss: 0.023062195547584333
Epoch: 9 Idx: 5000 Loss: 0.013385161422004016
Epoch: 10 Idx: 0 Loss: 0.021753206311477646
Epoch: 10 Idx: 5000 Loss: 0.010990343828490349
Epoch: 11 Idx: 0 Loss: 0.017435939003325775
Epoch: 11 Idx: 5000 Loss: 0.01106801508109288
Epoch: 12 Idx: 0 Loss: 0.009186009874292758
Epoch: 12 Idx: 5000 Loss: 0.01724852517009227
Epoch: 13 Idx: 0 Loss: 0.012958656463962537
Epoch: 13 Idx: 5000 Loss: 0.012382466576695268
Epoch: 14 Idx: 0 Loss: 0.0116065385502063
Epoch: 14 Idx: 5000 Loss: 0.026753704132003578
Epoch: 15 Idx: 0 Loss: 0.012010529801955206
Epoch: 15 Idx: 5000 Loss: 0.013421205894604663
Epoch: 16 Idx: 0 Loss: 0.01896250995213191
Epoch: 16 Idx: 5000 Loss: 0.009601379808836649
Epoch: 17 Idx: 0 Loss: 0.015811929140173448
Epoch: 17 Idx: 5000 Loss: 0.010119689373455122
Epoch: 18 Idx: 0 Loss: 0.007189669406481339
Epoch: 18 Idx: 5000 Loss: 0.017669993302032696
Epoch: 19 Idx: 0 Loss: 0.03328272328752139
Epoch: 19 Idx: 5000 Loss: 0.021052371909025466
Epoch: 20 Idx: 0 Loss: 0.03300729572086781
Epoch: 20 Idx: 5000 Loss: 0.009160005077543618
Epoch: 21 Idx: 0 Loss: 0.008868527426583131
Epoch: 21 Idx: 5000 Loss: 0.022119481615911273
Epoch: 22 Idx: 0 Loss: 0.011255055204625473
Epoch: 22 Idx: 5000 Loss: 0.015613995940190263
Epoch: 23 Idx: 0 Loss: 0.011877519709174559
Epoch: 23 Idx: 5000 Loss: 0.02230250118288726
Epoch: 24 Idx: 0 Loss: 0.027266878696707263
Epoch: 24 Idx: 5000 Loss: 0.022443263795119458
Epoch: 25 Idx: 0 Loss: 0.026903591193309342
Epoch: 25 Idx: 5000 Loss: 0.013665044596809693
Epoch: 26 Idx: 0 Loss: 0.02354365105589847
Epoch: 26 Idx: 5000 Loss: 0.045377136534428736
Epoch: 27 Idx: 0 Loss: 0.03048571597969804
Epoch: 27 Idx: 5000 Loss: 0.018865425881656656
Epoch: 28 Idx: 0 Loss: 0.012078741844257605
Epoch: 28 Idx: 5000 Loss: 0.014997944192914179
Epoch: 29 Idx: 0 Loss: 0.015008506462147606
Epoch: 29 Idx: 5000 Loss: 0.014208810153846719
Epoch: 30 Idx: 0 Loss: 0.011273453729119885
Epoch: 30 Idx: 5000 Loss: 0.01369427050754415
Epoch: 31 Idx: 0 Loss: 0.01352885681788154
Epoch: 31 Idx: 5000 Loss: 0.013237021612169036
Epoch: 32 Idx: 0 Loss: 0.0067568117787505586
Epoch: 32 Idx: 5000 Loss: 0.014763242731494014
Epoch: 33 Idx: 0 Loss: 0.011315529836930897
Epoch: 33 Idx: 5000 Loss: 0.012869113939020994
Epoch: 34 Idx: 0 Loss: 0.01350264573104744
Epoch: 34 Idx: 5000 Loss: 0.007506479909087914
Epoch: 35 Idx: 0 Loss: 0.006140273290596486
Epoch: 35 Idx: 5000 Loss: 0.012755676919917523
Epoch: 36 Idx: 0 Loss: 0.01792316700670767
Epoch: 36 Idx: 5000 Loss: 0.032556726541657255
Epoch: 37 Idx: 0 Loss: 0.026228405459745405
Epoch: 37 Idx: 5000 Loss: 0.012674659400826786
Epoch: 38 Idx: 0 Loss: 0.0186421814470943
Epoch: 38 Idx: 5000 Loss: 0.007661751182902999
Epoch: 39 Idx: 0 Loss: 0.014732897277174192
Epoch: 39 Idx: 5000 Loss: 0.008274001742635692
Epoch: 40 Idx: 0 Loss: 0.01669631696539395
Epoch: 40 Idx: 5000 Loss: 0.008135177265898708
Epoch: 41 Idx: 0 Loss: 0.013356035970817684
Epoch: 41 Idx: 5000 Loss: 0.008667172330556944
Epoch: 42 Idx: 0 Loss: 0.025855803015271225
Epoch: 42 Idx: 5000 Loss: 0.01396306390194883
Epoch: 43 Idx: 0 Loss: 0.004656372964313272
Epoch: 43 Idx: 5000 Loss: 0.016132561573449743
Epoch: 44 Idx: 0 Loss: 0.01597739191602943
Epoch: 44 Idx: 5000 Loss: 0.020448079355244043
Epoch: 45 Idx: 0 Loss: 0.02732020064347659
Epoch: 45 Idx: 5000 Loss: 0.01927402156922598
Epoch: 46 Idx: 0 Loss: 0.01714567819978696
Epoch: 46 Idx: 5000 Loss: 0.012824404790247547
Epoch: 47 Idx: 0 Loss: 0.013627468291794892
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc211>
Subject: Job 4066906: <python main.py 21 2 True True> in cluster <dcc> Exited

Job <python main.py 21 2 True True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc211>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 21 2 True True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   45984.71 sec.
    Max Memory :                                 2874 MB
    Average Memory :                             2696.92 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40543.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46140 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

