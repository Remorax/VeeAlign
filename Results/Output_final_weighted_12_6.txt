2020-09-15 15:49:38.843787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:41.945428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:42.071466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:42.071574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.073682: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:42.075207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:42.075740: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:42.077592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:42.079042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:42.079331: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:42.079356: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:42.079685: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:42.087556: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600180000 Hz
2020-09-15 15:49:42.087764: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591738f64b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:42.087784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:42.089771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:42.089819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1980000278028439
Epoch: 0 Idx: 5000 Loss: 0.006851255013483564
Epoch: 1 Idx: 0 Loss: 0.011892350381784121
Epoch: 1 Idx: 5000 Loss: 0.018339559419964572
Epoch: 2 Idx: 0 Loss: 0.007337024646977146
Epoch: 2 Idx: 5000 Loss: 0.013026774860897884
Epoch: 3 Idx: 0 Loss: 0.008967799504279002
Epoch: 3 Idx: 5000 Loss: 0.022213752822876312
Epoch: 4 Idx: 0 Loss: 0.010959418274556694
Epoch: 4 Idx: 5000 Loss: 0.021966650770476055
Epoch: 5 Idx: 0 Loss: 0.018425830284754703
Epoch: 5 Idx: 5000 Loss: 0.03453793550241285
Epoch: 6 Idx: 0 Loss: 0.00927533389607253
Epoch: 6 Idx: 5000 Loss: 0.008186759311201082
Epoch: 7 Idx: 0 Loss: 0.02307295479848825
Epoch: 7 Idx: 5000 Loss: 0.009643968593613172
Epoch: 8 Idx: 0 Loss: 0.02666585451826552
Epoch: 8 Idx: 5000 Loss: 0.019575401286783225
Epoch: 9 Idx: 0 Loss: 0.01421513211283344
Epoch: 9 Idx: 5000 Loss: 0.01352803791862778
Epoch: 10 Idx: 0 Loss: 0.033428680189712776
Epoch: 10 Idx: 5000 Loss: 0.011121223070844018
Epoch: 11 Idx: 0 Loss: 0.008651488222739628
Epoch: 11 Idx: 5000 Loss: 0.02706249287031623
Epoch: 12 Idx: 0 Loss: 0.007241728703985757
Epoch: 12 Idx: 5000 Loss: 0.010554324088761518
Epoch: 13 Idx: 0 Loss: 0.025398579981226077
Epoch: 13 Idx: 5000 Loss: 0.007695891915868511
Epoch: 14 Idx: 0 Loss: 0.015776263406633118
Epoch: 14 Idx: 5000 Loss: 0.012142135978586207
Epoch: 15 Idx: 0 Loss: 0.01741953293723683
Epoch: 15 Idx: 5000 Loss: 0.0167759558847604
Epoch: 16 Idx: 0 Loss: 0.024301828608284143
Epoch: 16 Idx: 5000 Loss: 0.006168310075272413
Epoch: 17 Idx: 0 Loss: 0.02415377710172151
Epoch: 17 Idx: 5000 Loss: 0.009884447802118106
Epoch: 18 Idx: 0 Loss: 0.01470625912180647
Epoch: 18 Idx: 5000 Loss: 0.013898380401439077
Epoch: 19 Idx: 0 Loss: 0.012810565276709535
Epoch: 19 Idx: 5000 Loss: 0.009876836635040766
Epoch: 20 Idx: 0 Loss: 0.005328941967930306
Epoch: 20 Idx: 5000 Loss: 0.009254300895898706
Epoch: 21 Idx: 0 Loss: 0.014341645669698332
Epoch: 21 Idx: 5000 Loss: 0.01553744654901541
Epoch: 22 Idx: 0 Loss: 0.025345209277930877
Epoch: 22 Idx: 5000 Loss: 0.02321961751206469
Epoch: 23 Idx: 0 Loss: 0.014774217503413144
Epoch: 23 Idx: 5000 Loss: 0.030679194150506087
Epoch: 24 Idx: 0 Loss: 0.007704258877225173
Epoch: 24 Idx: 5000 Loss: 0.008785076140924053
Epoch: 25 Idx: 0 Loss: 0.025472469178277123
Epoch: 25 Idx: 5000 Loss: 0.011331076576529424
Epoch: 26 Idx: 0 Loss: 0.010314607892310316
Epoch: 26 Idx: 5000 Loss: 0.024136219557399946
Epoch: 27 Idx: 0 Loss: 0.006750599448381289
Epoch: 27 Idx: 5000 Loss: 0.02200418764476881
Epoch: 28 Idx: 0 Loss: 0.04889759732244165
Epoch: 28 Idx: 5000 Loss: 0.019934836139505568
Epoch: 29 Idx: 0 Loss: 0.013550990659044925
Epoch: 29 Idx: 5000 Loss: 0.014655329776248532
Epoch: 30 Idx: 0 Loss: 0.03239567985231737
Epoch: 30 Idx: 5000 Loss: 0.009987698082464563
Epoch: 31 Idx: 0 Loss: 0.01357156048808757
Epoch: 31 Idx: 5000 Loss: 0.01386293909045054
Epoch: 32 Idx: 0 Loss: 0.011150465645214994
Epoch: 32 Idx: 5000 Loss: 0.007478311523304299
Epoch: 33 Idx: 0 Loss: 0.01577066838449967
Epoch: 33 Idx: 5000 Loss: 0.01609810455176517
Epoch: 34 Idx: 0 Loss: 0.02112650820461983
Epoch: 34 Idx: 5000 Loss: 0.014819587239698472
Epoch: 35 Idx: 0 Loss: 0.013876842233549564
Epoch: 35 Idx: 5000 Loss: 0.02060375637904656
Epoch: 36 Idx: 0 Loss: 0.013699703489409572
Epoch: 36 Idx: 5000 Loss: 0.013819463116855621
Epoch: 37 Idx: 0 Loss: 0.013927767813808823
Epoch: 37 Idx: 5000 Loss: 0.025709497394023877
Epoch: 38 Idx: 0 Loss: 0.011562757639856956
Epoch: 38 Idx: 5000 Loss: 0.022365528092768292
Epoch: 39 Idx: 0 Loss: 0.009601561977535703
Epoch: 39 Idx: 5000 Loss: 0.016909712761653345
Epoch: 40 Idx: 0 Loss: 0.01002831435689313
Epoch: 40 Idx: 5000 Loss: 0.02875120242745783
Epoch: 41 Idx: 0 Loss: 0.010218764996552152
Epoch: 41 Idx: 5000 Loss: 0.021510200907708256
Epoch: 42 Idx: 0 Loss: 0.006769668210145564
Epoch: 42 Idx: 5000 Loss: 0.012297796218849895
Epoch: 43 Idx: 0 Loss: 0.01994925989774289
Epoch: 43 Idx: 5000 Loss: 0.009424412536741972
Epoch: 44 Idx: 0 Loss: 0.008361230941046321
Epoch: 44 Idx: 5000 Loss: 0.007071553059174997
Epoch: 45 Idx: 0 Loss: 0.007212546340907288
Epoch: 45 Idx: 5000 Loss: 0.01013138352277905
Epoch: 46 Idx: 0 Loss: 0.0214405994909031
Epoch: 46 Idx: 5000 Loss: 0.01660705157360568
Epoch: 47 Idx: 0 Loss: 0.014877545651435916
Epoch: 47 Idx: 5000 Loss: 0.008513212221582241
Epoch: 48 Idx: 0 Loss: 0.0025258431774543323
Epoch: 48 Idx: 5000 Loss: 0.01534372975500291
Epoch: 49 Idx: 0 Loss: 0.01960178228632726
Epoch: 49 Idx: 5000 Loss: 0.006054592791442528
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15220248554799484
Epoch: 0 Idx: 5000 Loss: 0.02633191078901292
Epoch: 1 Idx: 0 Loss: 0.012715081822045749
Epoch: 1 Idx: 5000 Loss: 0.016403260679999643
Epoch: 2 Idx: 0 Loss: 0.017479493312407834
Epoch: 2 Idx: 5000 Loss: 0.010064921345940506
Epoch: 3 Idx: 0 Loss: 0.018729178962029656
Epoch: 3 Idx: 5000 Loss: 0.02552906125472082
Epoch: 4 Idx: 0 Loss: 0.011494166885484047
Epoch: 4 Idx: 5000 Loss: 0.02762750400216534
Epoch: 5 Idx: 0 Loss: 0.01231909357354374
Epoch: 5 Idx: 5000 Loss: 0.023254310264568215
Epoch: 6 Idx: 0 Loss: 0.00794756778995959
Epoch: 6 Idx: 5000 Loss: 0.017452267804912578
Epoch: 7 Idx: 0 Loss: 0.01776066145487525
Epoch: 7 Idx: 5000 Loss: 0.022436896898084625
Epoch: 8 Idx: 0 Loss: 0.008506487770421973
Epoch: 8 Idx: 5000 Loss: 0.014606417156416883
Epoch: 9 Idx: 0 Loss: 0.01584907984584305
Epoch: 9 Idx: 5000 Loss: 0.01592349216384633
Epoch: 10 Idx: 0 Loss: 0.008740213820372515
Epoch: 10 Idx: 5000 Loss: 0.019293990066639864
Epoch: 11 Idx: 0 Loss: 0.01879510593181401
Epoch: 11 Idx: 5000 Loss: 0.010365761395761744
Epoch: 12 Idx: 0 Loss: 0.012398031110783076
Epoch: 12 Idx: 5000 Loss: 0.010318014185283626
Epoch: 13 Idx: 0 Loss: 0.004991182551785182
Epoch: 13 Idx: 5000 Loss: 0.01087651215046533
Epoch: 14 Idx: 0 Loss: 0.011504289052292935
Epoch: 14 Idx: 5000 Loss: 0.02392963270862395
Epoch: 15 Idx: 0 Loss: 0.00929009603549674
Epoch: 15 Idx: 5000 Loss: 0.01493050406942241
Epoch: 16 Idx: 0 Loss: 0.019537584993827704
Epoch: 16 Idx: 5000 Loss: 0.018938253696816933
Epoch: 17 Idx: 0 Loss: 0.015311039239143958
Epoch: 17 Idx: 5000 Loss: 0.012833346300671001
Epoch: 18 Idx: 0 Loss: 0.012438067806430014
Epoch: 18 Idx: 5000 Loss: 0.014949492927258553
Epoch: 19 Idx: 0 Loss: 0.02329172912179423
Epoch: 19 Idx: 5000 Loss: 0.01085227012345798
Epoch: 20 Idx: 0 Loss: 0.007827190177054997
Epoch: 20 Idx: 5000 Loss: 0.019176212425089552
Epoch: 21 Idx: 0 Loss: 0.01269321648768381
Epoch: 21 Idx: 5000 Loss: 0.01669172779915431
Epoch: 22 Idx: 0 Loss: 0.013009878685864104
Epoch: 22 Idx: 5000 Loss: 0.019394331393065335
Epoch: 23 Idx: 0 Loss: 0.014769042549419546
Epoch: 23 Idx: 5000 Loss: 0.01729987566810565
Epoch: 24 Idx: 0 Loss: 0.008857753077963035
Epoch: 24 Idx: 5000 Loss: 0.010033316391115762
Epoch: 25 Idx: 0 Loss: 0.01298182265131581
Epoch: 25 Idx: 5000 Loss: 0.014189997553813847
Epoch: 26 Idx: 0 Loss: 0.005455485358807867
Epoch: 26 Idx: 5000 Loss: 0.009251446719051976
Epoch: 27 Idx: 0 Loss: 0.021398066715759678
Epoch: 27 Idx: 5000 Loss: 0.010502989110109353
Epoch: 28 Idx: 0 Loss: 0.012382548066159578
Epoch: 28 Idx: 5000 Loss: 0.008816294504533891
Epoch: 29 Idx: 0 Loss: 0.016029385337634386
Epoch: 29 Idx: 5000 Loss: 0.013821457169572532
Epoch: 30 Idx: 0 Loss: 0.027656320312156694
Epoch: 30 Idx: 5000 Loss: 0.020782577213218852
Epoch: 31 Idx: 0 Loss: 0.02917005440417267
Epoch: 31 Idx: 5000 Loss: 0.00900172863325717
Epoch: 32 Idx: 0 Loss: 0.013549269151716638
Epoch: 32 Idx: 5000 Loss: 0.0333076322985298
Epoch: 33 Idx: 0 Loss: 0.006810267337366739
Epoch: 33 Idx: 5000 Loss: 0.016747836091304084
Epoch: 34 Idx: 0 Loss: 0.007398475703636099
Epoch: 34 Idx: 5000 Loss: 0.007874190442247582
Epoch: 35 Idx: 0 Loss: 0.02318468287471496
Epoch: 35 Idx: 5000 Loss: 0.028350030404156637
Epoch: 36 Idx: 0 Loss: 0.017317512815856896
Epoch: 36 Idx: 5000 Loss: 0.006572549287901269
Epoch: 37 Idx: 0 Loss: 0.01660716166121642
Epoch: 37 Idx: 5000 Loss: 0.03756311518771803
Epoch: 38 Idx: 0 Loss: 0.026191853188635893
Epoch: 38 Idx: 5000 Loss: 0.0070409199317626545
Epoch: 39 Idx: 0 Loss: 0.013187266988962481
Epoch: 39 Idx: 5000 Loss: 0.010479168602317504
Epoch: 40 Idx: 0 Loss: 0.004784400336903709
Epoch: 40 Idx: 5000 Loss: 0.014665294296096112
Epoch: 41 Idx: 0 Loss: 0.015038897358918215
Epoch: 41 Idx: 5000 Loss: 0.009380617158918981
Epoch: 42 Idx: 0 Loss: 0.044413442284907505
Epoch: 42 Idx: 5000 Loss: 0.012728571536954244
Epoch: 43 Idx: 0 Loss: 0.015413659145731291
Epoch: 43 Idx: 5000 Loss: 0.009296490361044416
Epoch: 44 Idx: 0 Loss: 0.021154323458546426
Epoch: 44 Idx: 5000 Loss: 0.020459984800536776
Epoch: 45 Idx: 0 Loss: 0.020127585727446905
Epoch: 45 Idx: 5000 Loss: 0.01611862452600796
Epoch: 46 Idx: 0 Loss: 0.01392586130473689
Epoch: 46 Idx: 5000 Loss: 0.010857207871182956
Epoch: 47 Idx: 0 Loss: 0.016543623831858745
Epoch: 47 Idx: 5000 Loss: 0.009837623700744185
Epoch: 48 Idx: 0 Loss: 0.005841178763154224
Epoch: 48 Idx: 5000 Loss: 0.03926990223401677
Epoch: 49 Idx: 0 Loss: 0.014941030363078152
Epoch: 49 Idx: 5000 Loss: 0.01024557871062631
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13471094213720883
Epoch: 0 Idx: 5000 Loss: 0.0233248121751545
Epoch: 1 Idx: 0 Loss: 0.026716241729540804
Epoch: 1 Idx: 5000 Loss: 0.012860607570435337
Epoch: 2 Idx: 0 Loss: 0.018937163850392836
Epoch: 2 Idx: 5000 Loss: 0.02676681501514382
Epoch: 3 Idx: 0 Loss: 0.018678095903435415
Epoch: 3 Idx: 5000 Loss: 0.015426786748366448
Epoch: 4 Idx: 0 Loss: 0.016440772246462676
Epoch: 4 Idx: 5000 Loss: 0.03025212257306726
Epoch: 5 Idx: 0 Loss: 0.016709738738214068
Epoch: 5 Idx: 5000 Loss: 0.02233309131652838
Epoch: 6 Idx: 0 Loss: 0.016328082060019074
Epoch: 6 Idx: 5000 Loss: 0.026694534904769633
Epoch: 7 Idx: 0 Loss: 0.015009682521927263
Epoch: 7 Idx: 5000 Loss: 0.01091552744672668
Epoch: 8 Idx: 0 Loss: 0.016235526888227984
Epoch: 8 Idx: 5000 Loss: 0.013203886911563614
Epoch: 9 Idx: 0 Loss: 0.015048903108371765
Epoch: 9 Idx: 5000 Loss: 0.025389175499748087
Epoch: 10 Idx: 0 Loss: 0.018914487096608396
Epoch: 10 Idx: 5000 Loss: 0.010865952392603706
Epoch: 11 Idx: 0 Loss: 0.02341850838442688
Epoch: 11 Idx: 5000 Loss: 0.012696345821117734
Epoch: 12 Idx: 0 Loss: 0.022194799573824375
Epoch: 12 Idx: 5000 Loss: 0.006601529041347179
Epoch: 13 Idx: 0 Loss: 0.014665250466955418
Epoch: 13 Idx: 5000 Loss: 0.006934191690196005
Epoch: 14 Idx: 0 Loss: 0.026474962027622447
Epoch: 14 Idx: 5000 Loss: 0.01310407184960842
Epoch: 15 Idx: 0 Loss: 0.023615452607998473
Epoch: 15 Idx: 5000 Loss: 0.014865110322880154
Epoch: 16 Idx: 0 Loss: 0.009375700308809055
Epoch: 16 Idx: 5000 Loss: 0.022348117127495754
Epoch: 17 Idx: 0 Loss: 0.009129698758169755
Epoch: 17 Idx: 5000 Loss: 0.018962365458625962
Epoch: 18 Idx: 0 Loss: 0.01812320282222779
Epoch: 18 Idx: 5000 Loss: 0.007986700831416987
Epoch: 19 Idx: 0 Loss: 0.01301349656095239
Epoch: 19 Idx: 5000 Loss: 0.020440287337291505
Epoch: 20 Idx: 0 Loss: 0.024668033058805182
Epoch: 20 Idx: 5000 Loss: 0.0075254476736276105
Epoch: 21 Idx: 0 Loss: 0.026498171891216914
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 323, in forward
    best_path = torch.bmm(path_weights.reshape(-1, 1, self.max_paths), feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc252>
Subject: Job 4066886: <python main.py 6 12 False True> in cluster <dcc> Exited

Job <python main.py 6 12 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc252>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 12 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46076.36 sec.
    Max Memory :                                 2959 MB
    Average Memory :                             2738.91 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40458.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46168 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

