2020-09-15 15:49:36.965579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.124989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:40.251452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:40.251579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.253693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:40.255218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:40.255575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:40.257457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:40.258773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:40.258994: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:40.259015: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:40.259317: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:40.267258: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599930000 Hz
2020-09-15 15:49:40.267462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555aa5eb52f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:40.267483: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:40.269430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:40.269472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.196002134423367
Epoch: 0 Idx: 5000 Loss: 0.011601004115115504
Epoch: 1 Idx: 0 Loss: 0.0327844100591663
Epoch: 1 Idx: 5000 Loss: 0.018502128306496352
Epoch: 2 Idx: 0 Loss: 0.013620602862277667
Epoch: 2 Idx: 5000 Loss: 0.014011952841524622
Epoch: 3 Idx: 0 Loss: 0.011880660886049731
Epoch: 3 Idx: 5000 Loss: 0.022418262703957102
Epoch: 4 Idx: 0 Loss: 0.02290280467342902
Epoch: 4 Idx: 5000 Loss: 0.009714308439436834
Epoch: 5 Idx: 0 Loss: 0.018917766055979605
Epoch: 5 Idx: 5000 Loss: 0.022467794176833075
Epoch: 6 Idx: 0 Loss: 0.022559884678061963
Epoch: 6 Idx: 5000 Loss: 0.01221975610749514
Epoch: 7 Idx: 0 Loss: 0.016956876075315964
Epoch: 7 Idx: 5000 Loss: 0.020762772331378486
Epoch: 8 Idx: 0 Loss: 0.01744013168031004
Epoch: 8 Idx: 5000 Loss: 0.008108870135845036
Epoch: 9 Idx: 0 Loss: 0.011293825856356993
Epoch: 9 Idx: 5000 Loss: 0.0365424259877915
Epoch: 10 Idx: 0 Loss: 0.012033261563791902
Epoch: 10 Idx: 5000 Loss: 0.014571655638900866
Epoch: 11 Idx: 0 Loss: 0.008262412706300609
Epoch: 11 Idx: 5000 Loss: 0.01080221145455762
Epoch: 12 Idx: 0 Loss: 0.008698508746307244
Epoch: 12 Idx: 5000 Loss: 0.0197023773855677
Epoch: 13 Idx: 0 Loss: 0.013795454004342865
Epoch: 13 Idx: 5000 Loss: 0.01796126892718136
Epoch: 14 Idx: 0 Loss: 0.05085874766771159
Epoch: 14 Idx: 5000 Loss: 0.012487877778590332
Epoch: 15 Idx: 0 Loss: 0.009569064174919938
Epoch: 15 Idx: 5000 Loss: 0.029886782080072855
Epoch: 16 Idx: 0 Loss: 0.014550732715123225
Epoch: 16 Idx: 5000 Loss: 0.012449542003033442
Epoch: 17 Idx: 0 Loss: 0.010544688185391338
Epoch: 17 Idx: 5000 Loss: 0.022324107182558697
Epoch: 18 Idx: 0 Loss: 0.01641766662610368
Epoch: 18 Idx: 5000 Loss: 0.014178967781016781
Epoch: 19 Idx: 0 Loss: 0.014442103194160748
Epoch: 19 Idx: 5000 Loss: 0.010003550562963155
Epoch: 20 Idx: 0 Loss: 0.004178550692501592
Epoch: 20 Idx: 5000 Loss: 0.017376372164880853
Epoch: 21 Idx: 0 Loss: 0.01211813144209747
Epoch: 21 Idx: 5000 Loss: 0.028735782216175974
Epoch: 22 Idx: 0 Loss: 0.012150887980948938
Epoch: 22 Idx: 5000 Loss: 0.007359271863008913
Epoch: 23 Idx: 0 Loss: 0.04146938499976933
Epoch: 23 Idx: 5000 Loss: 0.02475528478692235
Epoch: 24 Idx: 0 Loss: 0.008935577641211645
Epoch: 24 Idx: 5000 Loss: 0.011138619128280135
Epoch: 25 Idx: 0 Loss: 0.016013356806440258
Epoch: 25 Idx: 5000 Loss: 0.011950876132454335
Epoch: 26 Idx: 0 Loss: 0.009120154249324877
Epoch: 26 Idx: 5000 Loss: 0.01412043341837117
Epoch: 27 Idx: 0 Loss: 0.008642783479057115
Epoch: 27 Idx: 5000 Loss: 0.026718023819574308
Epoch: 28 Idx: 0 Loss: 0.015636398499332033
Epoch: 28 Idx: 5000 Loss: 0.02207842921253174
Epoch: 29 Idx: 0 Loss: 0.01649212638307513
Epoch: 29 Idx: 5000 Loss: 0.011331115697815487
Epoch: 30 Idx: 0 Loss: 0.03391540779939721
Epoch: 30 Idx: 5000 Loss: 0.007174334225293824
Epoch: 31 Idx: 0 Loss: 0.026471433778230705
Epoch: 31 Idx: 5000 Loss: 0.023141169134803158
Epoch: 32 Idx: 0 Loss: 0.03204907663796197
Epoch: 32 Idx: 5000 Loss: 0.007283061960004454
Epoch: 33 Idx: 0 Loss: 0.013531398832781778
Epoch: 33 Idx: 5000 Loss: 0.017134790481359297
Epoch: 34 Idx: 0 Loss: 0.008758891793326576
Epoch: 34 Idx: 5000 Loss: 0.016521926890970855
Epoch: 35 Idx: 0 Loss: 0.012239045523768961
Epoch: 35 Idx: 5000 Loss: 0.01822821218373492
Epoch: 36 Idx: 0 Loss: 0.011238520088476499
Epoch: 36 Idx: 5000 Loss: 0.013969315294884734
Epoch: 37 Idx: 0 Loss: 0.027180518085672956
Epoch: 37 Idx: 5000 Loss: 0.015154174027839806
Epoch: 38 Idx: 0 Loss: 0.024246432871182912
Epoch: 38 Idx: 5000 Loss: 0.028560861897368187
Epoch: 39 Idx: 0 Loss: 0.012402416470110172
Epoch: 39 Idx: 5000 Loss: 0.03289754420365687
Epoch: 40 Idx: 0 Loss: 0.018347953932940086
Epoch: 40 Idx: 5000 Loss: 0.006638041068924419
Epoch: 41 Idx: 0 Loss: 0.011408843329752155
Epoch: 41 Idx: 5000 Loss: 0.03163816100298463
Epoch: 42 Idx: 0 Loss: 0.01569374829989071
Epoch: 42 Idx: 5000 Loss: 0.010677637244452455
Epoch: 43 Idx: 0 Loss: 0.02051116386862739
Epoch: 43 Idx: 5000 Loss: 0.014751585034431748
Epoch: 44 Idx: 0 Loss: 0.011210236334318686
Epoch: 44 Idx: 5000 Loss: 0.0134436533791524
Epoch: 45 Idx: 0 Loss: 0.005158694566669569
Epoch: 45 Idx: 5000 Loss: 0.01077486843602212
Epoch: 46 Idx: 0 Loss: 0.0139165897987644
Epoch: 46 Idx: 5000 Loss: 0.03824046301288907
Epoch: 47 Idx: 0 Loss: 0.00877943561775605
Epoch: 47 Idx: 5000 Loss: 0.011523077050094244
Epoch: 48 Idx: 0 Loss: 0.024098446629329383
Epoch: 48 Idx: 5000 Loss: 0.01640466270817623
Epoch: 49 Idx: 0 Loss: 0.010704550513875907
Epoch: 49 Idx: 5000 Loss: 0.04203530956371521
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14120141879809853
Epoch: 0 Idx: 5000 Loss: 0.023489168427515004
Epoch: 1 Idx: 0 Loss: 0.018757276153554252
Epoch: 1 Idx: 5000 Loss: 0.007661302501135896
Epoch: 2 Idx: 0 Loss: 0.008171852928722823
Epoch: 2 Idx: 5000 Loss: 0.018893445384952284
Epoch: 3 Idx: 0 Loss: 0.014297820861743206
Epoch: 3 Idx: 5000 Loss: 0.018405430670887707
Epoch: 4 Idx: 0 Loss: 0.008403596905001103
Epoch: 4 Idx: 5000 Loss: 0.02135196993895834
Epoch: 5 Idx: 0 Loss: 0.011806607123180685
Epoch: 5 Idx: 5000 Loss: 0.013519159990653607
Epoch: 6 Idx: 0 Loss: 0.013471008943948133
Epoch: 6 Idx: 5000 Loss: 0.00462788791290561
Epoch: 7 Idx: 0 Loss: 0.006507658144506867
Epoch: 7 Idx: 5000 Loss: 0.017938395611740366
Epoch: 8 Idx: 0 Loss: 0.016695301681535348
Epoch: 8 Idx: 5000 Loss: 0.025326146376720496
Epoch: 9 Idx: 0 Loss: 0.040507277735583415
Epoch: 9 Idx: 5000 Loss: 0.0259407199153694
Epoch: 10 Idx: 0 Loss: 0.007210704755313405
Epoch: 10 Idx: 5000 Loss: 0.009477254277223667
Epoch: 11 Idx: 0 Loss: 0.013964364734545886
Epoch: 11 Idx: 5000 Loss: 0.024121715049018288
Epoch: 12 Idx: 0 Loss: 0.025196217514481836
Epoch: 12 Idx: 5000 Loss: 0.017031831122305358
Epoch: 13 Idx: 0 Loss: 0.012383723432541826
Epoch: 13 Idx: 5000 Loss: 0.010340167149148347
Epoch: 14 Idx: 0 Loss: 0.006398221658537217
Epoch: 14 Idx: 5000 Loss: 0.006897250936003174
Epoch: 15 Idx: 0 Loss: 0.009778069037824324
Epoch: 15 Idx: 5000 Loss: 0.027225377297594246
Epoch: 16 Idx: 0 Loss: 0.03658824141187594
Epoch: 16 Idx: 5000 Loss: 0.010655769468421963
Epoch: 17 Idx: 0 Loss: 0.010381959732496025
Epoch: 17 Idx: 5000 Loss: 0.014295330756767482
Epoch: 18 Idx: 0 Loss: 0.015220421884921776
Epoch: 18 Idx: 5000 Loss: 0.009418210076281543
Epoch: 19 Idx: 0 Loss: 0.023580967824980162
Epoch: 19 Idx: 5000 Loss: 0.008430951723531968
Epoch: 20 Idx: 0 Loss: 0.019218336583826243
Epoch: 20 Idx: 5000 Loss: 0.007850104648435418
Epoch: 21 Idx: 0 Loss: 0.008921087914239468
Epoch: 21 Idx: 5000 Loss: 0.024738018054021656
Epoch: 22 Idx: 0 Loss: 0.006866932968480538
Epoch: 22 Idx: 5000 Loss: 0.02065771677558284
Epoch: 23 Idx: 0 Loss: 0.008964234602500546
Epoch: 23 Idx: 5000 Loss: 0.025033905363275242
Epoch: 24 Idx: 0 Loss: 0.007761996965397329
Epoch: 24 Idx: 5000 Loss: 0.014754452612730734
Epoch: 25 Idx: 0 Loss: 0.008725089170090182
Epoch: 25 Idx: 5000 Loss: 0.017029780156181354
Epoch: 26 Idx: 0 Loss: 0.028574194060966777
Epoch: 26 Idx: 5000 Loss: 0.016610946491563278
Epoch: 27 Idx: 0 Loss: 0.04616136948001826
Epoch: 27 Idx: 5000 Loss: 0.01099355048606793
Epoch: 28 Idx: 0 Loss: 0.01828950762605723
Epoch: 28 Idx: 5000 Loss: 0.0335627794865715
Epoch: 29 Idx: 0 Loss: 0.019339619125219944
Epoch: 29 Idx: 5000 Loss: 0.011811641257693638
Epoch: 30 Idx: 0 Loss: 0.015680556094813097
Epoch: 30 Idx: 5000 Loss: 0.015470408293322179
Epoch: 31 Idx: 0 Loss: 0.017260414163267006
Epoch: 31 Idx: 5000 Loss: 0.01876179514270344
Epoch: 32 Idx: 0 Loss: 0.009359217332019576
Epoch: 32 Idx: 5000 Loss: 0.017834207115899343
Epoch: 33 Idx: 0 Loss: 0.021466861137179574
Epoch: 33 Idx: 5000 Loss: 0.0058987713089087524
Epoch: 34 Idx: 0 Loss: 0.014382792836914573
Epoch: 34 Idx: 5000 Loss: 0.0072905013455939775
Epoch: 35 Idx: 0 Loss: 0.004430423261910885
Epoch: 35 Idx: 5000 Loss: 0.012248806656043072
Epoch: 36 Idx: 0 Loss: 0.02614581734823565
Epoch: 36 Idx: 5000 Loss: 0.005297881773453755
Epoch: 37 Idx: 0 Loss: 0.013816685051461624
Epoch: 37 Idx: 5000 Loss: 0.011543699961325884
Epoch: 38 Idx: 0 Loss: 0.027043617869395343
Epoch: 38 Idx: 5000 Loss: 0.013214736165504838
Epoch: 39 Idx: 0 Loss: 0.008642709368623243
Epoch: 39 Idx: 5000 Loss: 0.01993077952073738
Epoch: 40 Idx: 0 Loss: 0.007841984632358709
Epoch: 40 Idx: 5000 Loss: 0.019211300886246112
Epoch: 41 Idx: 0 Loss: 0.03260253741208359
Epoch: 41 Idx: 5000 Loss: 0.01115032172410307
Epoch: 42 Idx: 0 Loss: 0.0078115531393025146
Epoch: 42 Idx: 5000 Loss: 0.030062717327910108
Epoch: 43 Idx: 0 Loss: 0.009064928432098399
Epoch: 43 Idx: 5000 Loss: 0.016219208964423266
Epoch: 44 Idx: 0 Loss: 0.03257865123080511
Epoch: 44 Idx: 5000 Loss: 0.007903802123859166
Epoch: 45 Idx: 0 Loss: 0.016638213909819812
Epoch: 45 Idx: 5000 Loss: 0.004991487468457846
Epoch: 46 Idx: 0 Loss: 0.01972999541712445
Epoch: 46 Idx: 5000 Loss: 0.02283183701858668
Epoch: 47 Idx: 0 Loss: 0.021087315756237533
Epoch: 47 Idx: 5000 Loss: 0.017884041441802254
Epoch: 48 Idx: 0 Loss: 0.0096424094728959
Epoch: 48 Idx: 5000 Loss: 0.02477000132238505
Epoch: 49 Idx: 0 Loss: 0.009699156440777004
Epoch: 49 Idx: 5000 Loss: 0.01562647944128446
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.15399956909385393
Epoch: 0 Idx: 5000 Loss: 0.0186389234629249
Epoch: 1 Idx: 0 Loss: 0.007739846420870788
Epoch: 1 Idx: 5000 Loss: 0.005933544653082973
Epoch: 2 Idx: 0 Loss: 0.010589992292369541
Epoch: 2 Idx: 5000 Loss: 0.008891794154883984
Epoch: 3 Idx: 0 Loss: 0.0183055868443328
Epoch: 3 Idx: 5000 Loss: 0.012719419477805523
Epoch: 4 Idx: 0 Loss: 0.01826510953610339
Epoch: 4 Idx: 5000 Loss: 0.006909243517460506
Epoch: 5 Idx: 0 Loss: 0.007759643584405321
Epoch: 5 Idx: 5000 Loss: 0.005890916758946376
Epoch: 6 Idx: 0 Loss: 0.010821532477656059
Epoch: 6 Idx: 5000 Loss: 0.016945958891387183
Epoch: 7 Idx: 0 Loss: 0.033966397454639294
Epoch: 7 Idx: 5000 Loss: 0.01947096409784813
Epoch: 8 Idx: 0 Loss: 0.013614317397241133
Epoch: 8 Idx: 5000 Loss: 0.024693530745173844
Epoch: 9 Idx: 0 Loss: 0.028802807012804986
Epoch: 9 Idx: 5000 Loss: 0.009086761379279964
Epoch: 10 Idx: 0 Loss: 0.020752006930488846
Epoch: 10 Idx: 5000 Loss: 0.022809725023275038
Epoch: 11 Idx: 0 Loss: 0.012968305502538727
Epoch: 11 Idx: 5000 Loss: 0.015329585766000377
Epoch: 12 Idx: 0 Loss: 0.00623881761534879
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 315, in forward
    path_weights = torch.bmm(node_emb[:, None, :], feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc254>
Subject: Job 4066863: <python main.py 5 20 False False> in cluster <dcc> Exited

Job <python main.py 5 20 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc254>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:35 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 20 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46138.20 sec.
    Max Memory :                                 2971 MB
    Average Memory :                             2749.89 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40446.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46170 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

