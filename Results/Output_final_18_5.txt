2020-09-15 15:49:37.788697: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:41.152306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:41.272536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:41.272632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:41.274714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:41.276263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:41.276721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:41.278688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:41.280202: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:41.280458: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:41.280479: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:41.280800: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:41.287834: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599810000 Hz
2020-09-15 15:49:41.288048: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d452bfc30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:41.288069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:41.289943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:41.289978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1969902692248706
Epoch: 0 Idx: 5000 Loss: 0.016948505799618954
Epoch: 1 Idx: 0 Loss: 0.011781234687068246
Epoch: 1 Idx: 5000 Loss: 0.011929489205904888
Epoch: 2 Idx: 0 Loss: 0.01832756407827122
Epoch: 2 Idx: 5000 Loss: 0.01771335069729707
Epoch: 3 Idx: 0 Loss: 0.021487916633352894
Epoch: 3 Idx: 5000 Loss: 0.007171902410494979
Epoch: 4 Idx: 0 Loss: 0.017933342728399887
Epoch: 4 Idx: 5000 Loss: 0.039928034815522755
Epoch: 5 Idx: 0 Loss: 0.030400246268915698
Epoch: 5 Idx: 5000 Loss: 0.013155796191425775
Epoch: 6 Idx: 0 Loss: 0.008838450940134954
Epoch: 6 Idx: 5000 Loss: 0.0114700477449319
Epoch: 7 Idx: 0 Loss: 0.009709346207466982
Epoch: 7 Idx: 5000 Loss: 0.014542614255899712
Epoch: 8 Idx: 0 Loss: 0.01643809780778357
Epoch: 8 Idx: 5000 Loss: 0.03815287227251632
Epoch: 9 Idx: 0 Loss: 0.0098926983513688
Epoch: 9 Idx: 5000 Loss: 0.02235892490397969
Epoch: 10 Idx: 0 Loss: 0.013607762616721425
Epoch: 10 Idx: 5000 Loss: 0.019927968920820088
Epoch: 11 Idx: 0 Loss: 0.006550907621228988
Epoch: 11 Idx: 5000 Loss: 0.02254882778535943
Epoch: 12 Idx: 0 Loss: 0.021726912911588098
Epoch: 12 Idx: 5000 Loss: 0.01404341701046503
Epoch: 13 Idx: 0 Loss: 0.02011499954913521
Epoch: 13 Idx: 5000 Loss: 0.011737496430528129
Epoch: 14 Idx: 0 Loss: 0.02456635925366564
Epoch: 14 Idx: 5000 Loss: 0.017220069664385548
Epoch: 15 Idx: 0 Loss: 0.01043705422505941
Epoch: 15 Idx: 5000 Loss: 0.04699442033865554
Epoch: 16 Idx: 0 Loss: 0.01770240211175286
Epoch: 16 Idx: 5000 Loss: 0.024473742797055702
Epoch: 17 Idx: 0 Loss: 0.03360892731502088
Epoch: 17 Idx: 5000 Loss: 0.015022967321676354
Epoch: 18 Idx: 0 Loss: 0.015303681407779799
Epoch: 18 Idx: 5000 Loss: 0.016293052989789787
Epoch: 19 Idx: 0 Loss: 0.03024238163154338
Epoch: 19 Idx: 5000 Loss: 0.009712723946376255
Epoch: 20 Idx: 0 Loss: 0.005871654352850773
Epoch: 20 Idx: 5000 Loss: 0.01815375601528532
Epoch: 21 Idx: 0 Loss: 0.016564943807347094
Epoch: 21 Idx: 5000 Loss: 0.015453806141592316
Epoch: 22 Idx: 0 Loss: 0.011483901660452244
Epoch: 22 Idx: 5000 Loss: 0.012427522201242117
Epoch: 23 Idx: 0 Loss: 0.033784816988552666
Epoch: 23 Idx: 5000 Loss: 0.006746916130359111
Epoch: 24 Idx: 0 Loss: 0.024796410241306473
Epoch: 24 Idx: 5000 Loss: 0.011070837046876683
Epoch: 25 Idx: 0 Loss: 0.011844690219758001
Epoch: 25 Idx: 5000 Loss: 0.013112538912816815
Epoch: 26 Idx: 0 Loss: 0.011637638631803279
Epoch: 26 Idx: 5000 Loss: 0.008712146763406373
Epoch: 27 Idx: 0 Loss: 0.01909030512534321
Epoch: 27 Idx: 5000 Loss: 0.011249694976907178
Epoch: 28 Idx: 0 Loss: 0.012200033403065684
Epoch: 28 Idx: 5000 Loss: 0.013781451835362793
Epoch: 29 Idx: 0 Loss: 0.014489732673623858
Epoch: 29 Idx: 5000 Loss: 0.02358598521476669
Epoch: 30 Idx: 0 Loss: 0.025156532394917944
Epoch: 30 Idx: 5000 Loss: 0.007870250193298442
Epoch: 31 Idx: 0 Loss: 0.01552063713156944
Epoch: 31 Idx: 5000 Loss: 0.008574315235099621
Epoch: 32 Idx: 0 Loss: 0.03217036374492387
Epoch: 32 Idx: 5000 Loss: 0.023636046304915555
Epoch: 33 Idx: 0 Loss: 0.016508939230726258
Epoch: 33 Idx: 5000 Loss: 0.009184766423908433
Epoch: 34 Idx: 0 Loss: 0.019572211778464684
Epoch: 34 Idx: 5000 Loss: 0.00855515854074452
Epoch: 35 Idx: 0 Loss: 0.0067787363869848145
Epoch: 35 Idx: 5000 Loss: 0.008241528987677799
Epoch: 36 Idx: 0 Loss: 0.00986837898573586
Epoch: 36 Idx: 5000 Loss: 0.010301085573535108
Epoch: 37 Idx: 0 Loss: 0.023248995332288476
Epoch: 37 Idx: 5000 Loss: 0.012465020412690889
Epoch: 38 Idx: 0 Loss: 0.015389249523256404
Epoch: 38 Idx: 5000 Loss: 0.0123002699273877
Epoch: 39 Idx: 0 Loss: 0.023376305657425007
Epoch: 39 Idx: 5000 Loss: 0.026069112900335416
Epoch: 40 Idx: 0 Loss: 0.008957914416334124
Epoch: 40 Idx: 5000 Loss: 0.02472688988702778
Epoch: 41 Idx: 0 Loss: 0.009707700740632774
Epoch: 41 Idx: 5000 Loss: 0.01725351177675471
Epoch: 42 Idx: 0 Loss: 0.012934364798326933
Epoch: 42 Idx: 5000 Loss: 0.008557306968173719
Epoch: 43 Idx: 0 Loss: 0.028890126821893753
Epoch: 43 Idx: 5000 Loss: 0.013163719271056619
Epoch: 44 Idx: 0 Loss: 0.01358139344988947
Epoch: 44 Idx: 5000 Loss: 0.018463244424077135
Epoch: 45 Idx: 0 Loss: 0.005579143864988716
Epoch: 45 Idx: 5000 Loss: 0.012324169084876567
Epoch: 46 Idx: 0 Loss: 0.008058366825026895
Epoch: 46 Idx: 5000 Loss: 0.018164404306907498
Epoch: 47 Idx: 0 Loss: 0.01537558416496763
Epoch: 47 Idx: 5000 Loss: 0.030566016626024126
Epoch: 48 Idx: 0 Loss: 0.027375855455621767
Epoch: 48 Idx: 5000 Loss: 0.039221431049026284
Epoch: 49 Idx: 0 Loss: 0.050620335788471665
Epoch: 49 Idx: 5000 Loss: 0.011985390160309379
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14282229317180495
Epoch: 0 Idx: 5000 Loss: 0.00831350016227813
Epoch: 1 Idx: 0 Loss: 0.012398834688169665
Epoch: 1 Idx: 5000 Loss: 0.013256947412649368
Epoch: 2 Idx: 0 Loss: 0.010785489958058676
Epoch: 2 Idx: 5000 Loss: 0.0065738189796286615
Epoch: 3 Idx: 0 Loss: 0.014607380512650248
Epoch: 3 Idx: 5000 Loss: 0.033793596062241964
Epoch: 4 Idx: 0 Loss: 0.007721781601100314
Epoch: 4 Idx: 5000 Loss: 0.01671318503960309
Epoch: 5 Idx: 0 Loss: 0.008873270643050855
Epoch: 5 Idx: 5000 Loss: 0.007927104282571979
Epoch: 6 Idx: 0 Loss: 0.03197395078544863
Epoch: 6 Idx: 5000 Loss: 0.03287302093313316
Epoch: 7 Idx: 0 Loss: 0.010731872641596729
Epoch: 7 Idx: 5000 Loss: 0.020293240875136447
Epoch: 8 Idx: 0 Loss: 0.007758345521489185
Epoch: 8 Idx: 5000 Loss: 0.01273081308217456
Epoch: 9 Idx: 0 Loss: 0.02795783944303809
Epoch: 9 Idx: 5000 Loss: 0.030654233354185705
Epoch: 10 Idx: 0 Loss: 0.007916130043129622
Epoch: 10 Idx: 5000 Loss: 0.012828622095135543
Epoch: 11 Idx: 0 Loss: 0.02611335412534963
Epoch: 11 Idx: 5000 Loss: 0.012743660308198285
Epoch: 12 Idx: 0 Loss: 0.011356651195175616
Epoch: 12 Idx: 5000 Loss: 0.007133165128447468
Epoch: 13 Idx: 0 Loss: 0.01253167709294116
Epoch: 13 Idx: 5000 Loss: 0.01586555249133092
Epoch: 14 Idx: 0 Loss: 0.02790979718075247
Epoch: 14 Idx: 5000 Loss: 0.012427696004744991
Epoch: 15 Idx: 0 Loss: 0.0146486814080584
Epoch: 15 Idx: 5000 Loss: 0.014958504838005577
Epoch: 16 Idx: 0 Loss: 0.011516247857199804
Epoch: 16 Idx: 5000 Loss: 0.022471008586863298
Epoch: 17 Idx: 0 Loss: 0.03701934338461885
Epoch: 17 Idx: 5000 Loss: 0.04416930876938914
Epoch: 18 Idx: 0 Loss: 0.009173671908265086
Epoch: 18 Idx: 5000 Loss: 0.04126031534971989
Epoch: 19 Idx: 0 Loss: 0.029083328118166035
Epoch: 19 Idx: 5000 Loss: 0.0070195047335238694
Epoch: 20 Idx: 0 Loss: 0.017529711900809097
Epoch: 20 Idx: 5000 Loss: 0.01735858139293093
Epoch: 21 Idx: 0 Loss: 0.00988905387187725
Epoch: 21 Idx: 5000 Loss: 0.008343856341118228
Epoch: 22 Idx: 0 Loss: 0.011260781024009923
Epoch: 22 Idx: 5000 Loss: 0.025758623307106533
Epoch: 23 Idx: 0 Loss: 0.0203035557826584
Epoch: 23 Idx: 5000 Loss: 0.015876365493773456
Epoch: 24 Idx: 0 Loss: 0.008983465578883635
Epoch: 24 Idx: 5000 Loss: 0.011578272840566063
Epoch: 25 Idx: 0 Loss: 0.009947530452765379
Epoch: 25 Idx: 5000 Loss: 0.013810422210391244
Epoch: 26 Idx: 0 Loss: 0.008308037371265129
Epoch: 26 Idx: 5000 Loss: 0.017633899023087537
Epoch: 27 Idx: 0 Loss: 0.015768729570396364
Epoch: 27 Idx: 5000 Loss: 0.012116306982450708
Epoch: 28 Idx: 0 Loss: 0.011850453117335433
Epoch: 28 Idx: 5000 Loss: 0.014553888123771393
Epoch: 29 Idx: 0 Loss: 0.024901782190714383
Epoch: 29 Idx: 5000 Loss: 0.012469506584322311
Epoch: 30 Idx: 0 Loss: 0.018573897332787834
Epoch: 30 Idx: 5000 Loss: 0.01683697702603151
Epoch: 31 Idx: 0 Loss: 0.03571974680239464
Epoch: 31 Idx: 5000 Loss: 0.010015377006852899
Epoch: 32 Idx: 0 Loss: 0.006407779622320087
Epoch: 32 Idx: 5000 Loss: 0.009584972328748735
Epoch: 33 Idx: 0 Loss: 0.009836136927900635
Epoch: 33 Idx: 5000 Loss: 0.014829859236953914
Epoch: 34 Idx: 0 Loss: 0.009054360780263476
Epoch: 34 Idx: 5000 Loss: 0.009126745255972792
Epoch: 35 Idx: 0 Loss: 0.018907217594749497
Epoch: 35 Idx: 5000 Loss: 0.011252878071492525
Epoch: 36 Idx: 0 Loss: 0.014674489996978282
Epoch: 36 Idx: 5000 Loss: 0.013252474265139279
Epoch: 37 Idx: 0 Loss: 0.008411379912613952
Epoch: 37 Idx: 5000 Loss: 0.01666706368209544
Epoch: 38 Idx: 0 Loss: 0.01643192857957915
Epoch: 38 Idx: 5000 Loss: 0.017588001039524823
Epoch: 39 Idx: 0 Loss: 0.013448883257902253
Epoch: 39 Idx: 5000 Loss: 0.012764385743399992
Epoch: 40 Idx: 0 Loss: 0.04971327982926732
Epoch: 40 Idx: 5000 Loss: 0.020080172883900335
Epoch: 41 Idx: 0 Loss: 0.013122380301625842
Epoch: 41 Idx: 5000 Loss: 0.005377136747136293
Epoch: 42 Idx: 0 Loss: 0.010149718757378898
Epoch: 42 Idx: 5000 Loss: 0.034111773395808724
Epoch: 43 Idx: 0 Loss: 0.016479273928240508
Epoch: 43 Idx: 5000 Loss: 0.01055389976548372
Epoch: 44 Idx: 0 Loss: 0.01630080569782383
Epoch: 44 Idx: 5000 Loss: 0.02479563703637795
Epoch: 45 Idx: 0 Loss: 0.031070095230346085
Epoch: 45 Idx: 5000 Loss: 0.004234558730470907
Epoch: 46 Idx: 0 Loss: 0.022719040122575952
Epoch: 46 Idx: 5000 Loss: 0.022111050251664485
Epoch: 47 Idx: 0 Loss: 0.034363093583789625
Epoch: 47 Idx: 5000 Loss: 0.022158965372660416
Epoch: 48 Idx: 0 Loss: 0.021036338124941115
Epoch: 48 Idx: 5000 Loss: 0.012005258464097045
Epoch: 49 Idx: 0 Loss: 0.008574863607259156
Epoch: 49 Idx: 5000 Loss: 0.009013422941125358
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1514646564705975
Epoch: 0 Idx: 5000 Loss: 0.020934706205139486
Epoch: 1 Idx: 0 Loss: 0.015425688841869052
Epoch: 1 Idx: 5000 Loss: 0.006765398105224347
Epoch: 2 Idx: 0 Loss: 0.013857921252165256
Epoch: 2 Idx: 5000 Loss: 0.008480652377995258
Epoch: 3 Idx: 0 Loss: 0.015495805011402866
Epoch: 3 Idx: 5000 Loss: 0.013479915178615137
Epoch: 4 Idx: 0 Loss: 0.02149069461640367
Epoch: 4 Idx: 5000 Loss: 0.03986549651728129
Epoch: 5 Idx: 0 Loss: 0.021765000824388564
Epoch: 5 Idx: 5000 Loss: 0.008353203305600233
Epoch: 6 Idx: 0 Loss: 0.022296671579348625
Epoch: 6 Idx: 5000 Loss: 0.012266567942724942
Epoch: 7 Idx: 0 Loss: 0.0100398940386986
Epoch: 7 Idx: 5000 Loss: 0.028183689979258367
Epoch: 8 Idx: 0 Loss: 0.0055548430700648604
Epoch: 8 Idx: 5000 Loss: 0.011148728097738361
Epoch: 9 Idx: 0 Loss: 0.020729240304564182
Epoch: 9 Idx: 5000 Loss: 0.028912494097491942
Epoch: 10 Idx: 0 Loss: 0.028052808225497498
Epoch: 10 Idx: 5000 Loss: 0.011121127212985462
Epoch: 11 Idx: 0 Loss: 0.01729064865255009
Epoch: 11 Idx: 5000 Loss: 0.013931732948875489
Epoch: 12 Idx: 0 Loss: 0.009622973789448916
Epoch: 12 Idx: 5000 Loss: 0.01710572515547601
Epoch: 13 Idx: 0 Loss: 0.011584603052689942
Epoch: 13 Idx: 5000 Loss: 0.00868098359540233
Epoch: 14 Idx: 0 Loss: 0.020552973577016406
Epoch: 14 Idx: 5000 Loss: 0.01883783008007841
Epoch: 15 Idx: 0 Loss: 0.011526544452295444
Epoch: 15 Idx: 5000 Loss: 0.013210757034673256
Epoch: 16 Idx: 0 Loss: 0.0153537332360673
Epoch: 16 Idx: 5000 Loss: 0.015207347805098545
Epoch: 17 Idx: 0 Loss: 0.011101360791832887
Epoch: 17 Idx: 5000 Loss: 0.014046389762288464
Epoch: 18 Idx: 0 Loss: 0.010252092159663929
Epoch: 18 Idx: 5000 Loss: 0.015388102790724334
Epoch: 19 Idx: 0 Loss: 0.01981445558457732
Epoch: 19 Idx: 5000 Loss: 0.025793244593257887
Epoch: 20 Idx: 0 Loss: 0.02090936048847084
Epoch: 20 Idx: 5000 Loss: 0.010520717407122897
Epoch: 21 Idx: 0 Loss: 0.022235027299359486
Epoch: 21 Idx: 5000 Loss: 0.014980489032246969
Epoch: 22 Idx: 0 Loss: 0.019263959213575613
Epoch: 22 Idx: 5000 Loss: 0.031801528112708845
Epoch: 23 Idx: 0 Loss: 0.01540325794633648
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc261>
Subject: Job 4066861: <python main.py 5 18 False False> in cluster <dcc> Exited

Job <python main.py 5 18 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc261>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:35 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 18 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46121.07 sec.
    Max Memory :                                 2986 MB
    Average Memory :                             2751.78 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40431.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46145 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

