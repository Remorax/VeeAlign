2020-09-15 15:49:41.989767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.164669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.283057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.283144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.285216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.286656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.287579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.289564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.291087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.291395: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.291418: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.291741: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.299707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599950000 Hz
2020-09-15 15:49:45.299913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56264b7b5560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.299943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.302016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.302055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1757578693577236
Epoch: 0 Idx: 5000 Loss: 0.0073563064452053725
Epoch: 1 Idx: 0 Loss: 0.010058401194386151
Epoch: 1 Idx: 5000 Loss: 0.01056781473975213
Epoch: 2 Idx: 0 Loss: 0.010380474332394989
Epoch: 2 Idx: 5000 Loss: 0.015437204769339548
Epoch: 3 Idx: 0 Loss: 0.015340301945910571
Epoch: 3 Idx: 5000 Loss: 0.021143465024444794
Epoch: 4 Idx: 0 Loss: 0.010049736667361111
Epoch: 4 Idx: 5000 Loss: 0.008348579635217835
Epoch: 5 Idx: 0 Loss: 0.023948529232290936
Epoch: 5 Idx: 5000 Loss: 0.014646490101834607
Epoch: 6 Idx: 0 Loss: 0.006070244915169625
Epoch: 6 Idx: 5000 Loss: 0.016876406075773766
Epoch: 7 Idx: 0 Loss: 0.006124283520591514
Epoch: 7 Idx: 5000 Loss: 0.011804255682432341
Epoch: 8 Idx: 0 Loss: 0.006748922694227336
Epoch: 8 Idx: 5000 Loss: 0.010733872500216811
Epoch: 9 Idx: 0 Loss: 0.005290536752924295
Epoch: 9 Idx: 5000 Loss: 0.009994259839912461
Epoch: 10 Idx: 0 Loss: 0.007368244612487943
Epoch: 10 Idx: 5000 Loss: 0.02880860535364772
Epoch: 11 Idx: 0 Loss: 0.012224604287194345
Epoch: 11 Idx: 5000 Loss: 0.016373554773237348
Epoch: 12 Idx: 0 Loss: 0.006892138865986766
Epoch: 12 Idx: 5000 Loss: 0.010673607992457871
Epoch: 13 Idx: 0 Loss: 0.029925078147204524
Epoch: 13 Idx: 5000 Loss: 0.009274512325257323
Epoch: 14 Idx: 0 Loss: 0.028415779086706207
Epoch: 14 Idx: 5000 Loss: 0.00878801523693878
Epoch: 15 Idx: 0 Loss: 0.019289740610244153
Epoch: 15 Idx: 5000 Loss: 0.01246206028011453
Epoch: 16 Idx: 0 Loss: 0.006586185699809757
Epoch: 16 Idx: 5000 Loss: 0.015553211534018441
Epoch: 17 Idx: 0 Loss: 0.027971290920748904
Epoch: 17 Idx: 5000 Loss: 0.014026759772336953
Epoch: 18 Idx: 0 Loss: 0.02408607317326631
Epoch: 18 Idx: 5000 Loss: 0.017070732519281036
Epoch: 19 Idx: 0 Loss: 0.0075779887583406055
Epoch: 19 Idx: 5000 Loss: 0.011448221506130441
Epoch: 20 Idx: 0 Loss: 0.007583396536329716
Epoch: 20 Idx: 5000 Loss: 0.013339020340556586
Epoch: 21 Idx: 0 Loss: 0.00829023932924501
Epoch: 21 Idx: 5000 Loss: 0.013416809374508275
Epoch: 22 Idx: 0 Loss: 0.023398407676918878
Epoch: 22 Idx: 5000 Loss: 0.022208313536341992
Epoch: 23 Idx: 0 Loss: 0.02016741244343486
Epoch: 23 Idx: 5000 Loss: 0.015055228451310278
Epoch: 24 Idx: 0 Loss: 0.023522051633246766
Epoch: 24 Idx: 5000 Loss: 0.009630140168189229
Epoch: 25 Idx: 0 Loss: 0.008340040255844318
Epoch: 25 Idx: 5000 Loss: 0.012546619009498099
Epoch: 26 Idx: 0 Loss: 0.006054944807476409
Epoch: 26 Idx: 5000 Loss: 0.03923343192847936
Epoch: 27 Idx: 0 Loss: 0.013627115539800932
Epoch: 27 Idx: 5000 Loss: 0.0395792603871212
Epoch: 28 Idx: 0 Loss: 0.019141488803246735
Epoch: 28 Idx: 5000 Loss: 0.01629497348214099
Epoch: 29 Idx: 0 Loss: 0.014861609694975216
Epoch: 29 Idx: 5000 Loss: 0.01525732867907571
Epoch: 30 Idx: 0 Loss: 0.0021976943433626014
Epoch: 30 Idx: 5000 Loss: 0.007255810909304592
Epoch: 31 Idx: 0 Loss: 0.012281537963389495
Epoch: 31 Idx: 5000 Loss: 0.0067589417022459915
Epoch: 32 Idx: 0 Loss: 0.015113488181054232
Epoch: 32 Idx: 5000 Loss: 0.006364801942021912
Epoch: 33 Idx: 0 Loss: 0.014162325724038013
Epoch: 33 Idx: 5000 Loss: 0.00782891568752132
Epoch: 34 Idx: 0 Loss: 0.009800044397898817
Epoch: 34 Idx: 5000 Loss: 0.0223832619109171
Epoch: 35 Idx: 0 Loss: 0.0064291031570208705
Epoch: 35 Idx: 5000 Loss: 0.008367739506938317
Epoch: 36 Idx: 0 Loss: 0.018759226456231563
Epoch: 36 Idx: 5000 Loss: 0.0057220312439658656
Epoch: 37 Idx: 0 Loss: 0.013771319183583559
Epoch: 37 Idx: 5000 Loss: 0.030467786748415226
Epoch: 38 Idx: 0 Loss: 0.010530033735237098
Epoch: 38 Idx: 5000 Loss: 0.02837454663483907
Epoch: 39 Idx: 0 Loss: 0.009175841138586615
Epoch: 39 Idx: 5000 Loss: 0.010784233417872794
Epoch: 40 Idx: 0 Loss: 0.015312828229127846
Epoch: 40 Idx: 5000 Loss: 0.020780772812324863
Epoch: 41 Idx: 0 Loss: 0.026868337975375065
Epoch: 41 Idx: 5000 Loss: 0.023306858418181954
Epoch: 42 Idx: 0 Loss: 0.006157418805199056
Epoch: 42 Idx: 5000 Loss: 0.006214604134773778
Epoch: 43 Idx: 0 Loss: 0.01454827937628149
Epoch: 43 Idx: 5000 Loss: 0.01542523191858916
Epoch: 44 Idx: 0 Loss: 0.029698427659607812
Epoch: 44 Idx: 5000 Loss: 0.0164529974067883
Epoch: 45 Idx: 0 Loss: 0.011645954414199616
Epoch: 45 Idx: 5000 Loss: 0.018368416805575237
Epoch: 46 Idx: 0 Loss: 0.013783640413697729
Epoch: 46 Idx: 5000 Loss: 0.012040355761945943
Epoch: 47 Idx: 0 Loss: 0.012239696401235005
Epoch: 47 Idx: 5000 Loss: 0.0097960931522236
Epoch: 48 Idx: 0 Loss: 0.01584641816217209
Epoch: 48 Idx: 5000 Loss: 0.014874287970210169
Epoch: 49 Idx: 0 Loss: 0.007001937246277901
Epoch: 49 Idx: 5000 Loss: 0.021717883161110958
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1474725202156727
Epoch: 0 Idx: 5000 Loss: 0.01221666692716563
Epoch: 1 Idx: 0 Loss: 0.011044368730999371
Epoch: 1 Idx: 5000 Loss: 0.01287378656866531
Epoch: 2 Idx: 0 Loss: 0.00994675553666365
Epoch: 2 Idx: 5000 Loss: 0.02402302218142813
Epoch: 3 Idx: 0 Loss: 0.015125532066705919
Epoch: 3 Idx: 5000 Loss: 0.0161415040175375
Epoch: 4 Idx: 0 Loss: 0.01701789385352647
Epoch: 4 Idx: 5000 Loss: 0.0187664022969432
Epoch: 5 Idx: 0 Loss: 0.026812021104668366
Epoch: 5 Idx: 5000 Loss: 0.036411828503543915
Epoch: 6 Idx: 0 Loss: 0.017490050462381668
Epoch: 6 Idx: 5000 Loss: 0.04661098384704307
Epoch: 7 Idx: 0 Loss: 0.01123147594794003
Epoch: 7 Idx: 5000 Loss: 0.015174780069836427
Epoch: 8 Idx: 0 Loss: 0.019284874246366997
Epoch: 8 Idx: 5000 Loss: 0.012039347917457208
Epoch: 9 Idx: 0 Loss: 0.026391251789514136
Epoch: 9 Idx: 5000 Loss: 0.011896715823551073
Epoch: 10 Idx: 0 Loss: 0.01067673064051394
Epoch: 10 Idx: 5000 Loss: 0.00919375811135665
Epoch: 11 Idx: 0 Loss: 0.03467394262786117
Epoch: 11 Idx: 5000 Loss: 0.009048688449199848
Epoch: 12 Idx: 0 Loss: 0.0331044175213052
Epoch: 12 Idx: 5000 Loss: 0.028908824588396404
Epoch: 13 Idx: 0 Loss: 0.016294355622315883
Epoch: 13 Idx: 5000 Loss: 0.015595570664475599
Epoch: 14 Idx: 0 Loss: 0.01429165115964285
Epoch: 14 Idx: 5000 Loss: 0.018075499908135013
Epoch: 15 Idx: 0 Loss: 0.013216753251202688
Epoch: 15 Idx: 5000 Loss: 0.0065869596722232145
Epoch: 16 Idx: 0 Loss: 0.014895713632728225
Epoch: 16 Idx: 5000 Loss: 0.04819709902908331
Epoch: 17 Idx: 0 Loss: 0.014964926502958735
Epoch: 17 Idx: 5000 Loss: 0.01130005525868431
Epoch: 18 Idx: 0 Loss: 0.04447663431863945
Epoch: 18 Idx: 5000 Loss: 0.01154684361805446
Epoch: 19 Idx: 0 Loss: 0.017083281434210344
Epoch: 19 Idx: 5000 Loss: 0.00786783097025064
Epoch: 20 Idx: 0 Loss: 0.018950175706625133
Epoch: 20 Idx: 5000 Loss: 0.017074373574195258
Epoch: 21 Idx: 0 Loss: 0.007284508087977707
Epoch: 21 Idx: 5000 Loss: 0.02198712919225001
Epoch: 22 Idx: 0 Loss: 0.009144309730808904
Epoch: 22 Idx: 5000 Loss: 0.006568367384763402
Epoch: 23 Idx: 0 Loss: 0.009278124009471275
Epoch: 23 Idx: 5000 Loss: 0.009048348782959494
Epoch: 24 Idx: 0 Loss: 0.013628851615382423
Epoch: 24 Idx: 5000 Loss: 0.042500000531189255
Epoch: 25 Idx: 0 Loss: 0.014923601377950318
Epoch: 25 Idx: 5000 Loss: 0.014516945904384536
Epoch: 26 Idx: 0 Loss: 0.041514229484106525
Epoch: 26 Idx: 5000 Loss: 0.02347894483238319
Epoch: 27 Idx: 0 Loss: 0.0272904329102012
Epoch: 27 Idx: 5000 Loss: 0.006797097162716275
Epoch: 28 Idx: 0 Loss: 0.020536023587836592
Epoch: 28 Idx: 5000 Loss: 0.01200027143380103
Epoch: 29 Idx: 0 Loss: 0.015963061522113436
Epoch: 29 Idx: 5000 Loss: 0.03553147115199777
Epoch: 30 Idx: 0 Loss: 0.03039735818651254
Epoch: 30 Idx: 5000 Loss: 0.02120441392764716
Epoch: 31 Idx: 0 Loss: 0.022176202178206723
Epoch: 31 Idx: 5000 Loss: 0.017437788204918203
Epoch: 32 Idx: 0 Loss: 0.00899817879559779
Epoch: 32 Idx: 5000 Loss: 0.016624668853167438
Epoch: 33 Idx: 0 Loss: 0.01565769812590625
Epoch: 33 Idx: 5000 Loss: 0.014500187552210452
Epoch: 34 Idx: 0 Loss: 0.017932031508977472
Epoch: 34 Idx: 5000 Loss: 0.021585787194904314
Epoch: 35 Idx: 0 Loss: 0.024945978793718675
Epoch: 35 Idx: 5000 Loss: 0.009033153602057985
Epoch: 36 Idx: 0 Loss: 0.013739187763976122
Epoch: 36 Idx: 5000 Loss: 0.010761008853611032
Epoch: 37 Idx: 0 Loss: 0.012865665688106957
Epoch: 37 Idx: 5000 Loss: 0.009775806403708748
Epoch: 38 Idx: 0 Loss: 0.03190858946849186
Epoch: 38 Idx: 5000 Loss: 0.030349450695999335
Epoch: 39 Idx: 0 Loss: 0.016317417581791355
Epoch: 39 Idx: 5000 Loss: 0.008512474224145547
Epoch: 40 Idx: 0 Loss: 0.0126519165833545
Epoch: 40 Idx: 5000 Loss: 0.015985998805648834
Epoch: 41 Idx: 0 Loss: 0.016682781503339975
Epoch: 41 Idx: 5000 Loss: 0.010657769171861254
Epoch: 42 Idx: 0 Loss: 0.02467881472518281
Epoch: 42 Idx: 5000 Loss: 0.01831513793678798
Epoch: 43 Idx: 0 Loss: 0.022599373008889378
Epoch: 43 Idx: 5000 Loss: 0.006660268320873753
Epoch: 44 Idx: 0 Loss: 0.0379247759239659
Epoch: 44 Idx: 5000 Loss: 0.016534220951430437
Epoch: 45 Idx: 0 Loss: 0.00988596638127262
Epoch: 45 Idx: 5000 Loss: 0.00808887168392505
Epoch: 46 Idx: 0 Loss: 0.019203459025095404
Epoch: 46 Idx: 5000 Loss: 0.010661710204304769
Epoch: 47 Idx: 0 Loss: 0.006772084436911186
Epoch: 47 Idx: 5000 Loss: 0.025131452372270286
Epoch: 48 Idx: 0 Loss: 0.010129992533113929
Epoch: 48 Idx: 5000 Loss: 0.026272928238447825
Epoch: 49 Idx: 0 Loss: 0.014106430033750545
Epoch: 49 Idx: 5000 Loss: 0.016967274031658153
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.16225611912970633
Epoch: 0 Idx: 5000 Loss: 0.015495428287295844
Epoch: 1 Idx: 0 Loss: 0.016802504285809233
Epoch: 1 Idx: 5000 Loss: 0.005997877159037735
Epoch: 2 Idx: 0 Loss: 0.014956145109839225
Epoch: 2 Idx: 5000 Loss: 0.009613343086092577
Epoch: 3 Idx: 0 Loss: 0.01566396415506574
Epoch: 3 Idx: 5000 Loss: 0.009687761712590602
Epoch: 4 Idx: 0 Loss: 0.012078751776495143
Epoch: 4 Idx: 5000 Loss: 0.0077904865402098735
Epoch: 5 Idx: 0 Loss: 0.03316538644654342
Epoch: 5 Idx: 5000 Loss: 0.00980773896997216
Epoch: 6 Idx: 0 Loss: 0.013536708150034833
Epoch: 6 Idx: 5000 Loss: 0.03544161541944982
Epoch: 7 Idx: 0 Loss: 0.01790816644220385
Epoch: 7 Idx: 5000 Loss: 0.029021099126296218
Epoch: 8 Idx: 0 Loss: 0.01743651792688102
Epoch: 8 Idx: 5000 Loss: 0.008141975055077213
Epoch: 9 Idx: 0 Loss: 0.011295117498056569
Epoch: 9 Idx: 5000 Loss: 0.007949488606823136
Epoch: 10 Idx: 0 Loss: 0.012771500389645606
Epoch: 10 Idx: 5000 Loss: 0.009947172874716432
Epoch: 11 Idx: 0 Loss: 0.012646916340380765
Epoch: 11 Idx: 5000 Loss: 0.04718887852887227
Epoch: 12 Idx: 0 Loss: 0.01153448959673597
Epoch: 12 Idx: 5000 Loss: 0.00986702008206223
Epoch: 13 Idx: 0 Loss: 0.006086940064696255
Epoch: 13 Idx: 5000 Loss: 0.006768909215488634
Epoch: 14 Idx: 0 Loss: 0.037635677883623035
Epoch: 14 Idx: 5000 Loss: 0.0177418060262447
Epoch: 15 Idx: 0 Loss: 0.008355669142913994
Epoch: 15 Idx: 5000 Loss: 0.021777365068027917
Epoch: 16 Idx: 0 Loss: 0.03437241360771831
Epoch: 16 Idx: 5000 Loss: 0.019596614260070134
Epoch: 17 Idx: 0 Loss: 0.02538594970736828
Epoch: 17 Idx: 5000 Loss: 0.022631609700379588
Epoch: 18 Idx: 0 Loss: 0.016523844711009542
Epoch: 18 Idx: 5000 Loss: 0.02384058591060175
Epoch: 19 Idx: 0 Loss: 0.042353643344573255
Epoch: 19 Idx: 5000 Loss: 0.015673045172100716
Epoch: 20 Idx: 0 Loss: 0.01471990075900926
Epoch: 20 Idx: 5000 Loss: 0.011289936027927102
Epoch: 21 Idx: 0 Loss: 0.011935365559009498
Epoch: 21 Idx: 5000 Loss: 0.015561109682593248
Epoch: 22 Idx: 0 Loss: 0.01820735387227132
Epoch: 22 Idx: 5000 Loss: 0.022864458561614797
Epoch: 23 Idx: 0 Loss: 0.012499303762791285
Epoch: 23 Idx: 5000 Loss: 0.032109741647158484
Epoch: 24 Idx: 0 Loss: 0.013445644550051697
Epoch: 24 Idx: 5000 Loss: 0.01857691581183903
Epoch: 25 Idx: 0 Loss: 0.011153823890129406
Epoch: 25 Idx: 5000 Loss: 0.005419891479103028
Epoch: 26 Idx: 0 Loss: 0.02364888662758896
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc275>
Subject: Job 4066909: <python main.py 24 2 True False> in cluster <dcc> Exited

Job <python main.py 24 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc275>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 24 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   89502.61 sec.
    Max Memory :                                 2914 MB
    Average Memory :                             2717.06 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40503.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                17
    Run time :                                   46167 sec.
    Turnaround time :                            46198 sec.

The output (if any) is above this job summary.

