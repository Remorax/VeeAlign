2020-09-15 15:49:39.237487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.458316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:42.575031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:42.575131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.577252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:42.578770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:42.579659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:42.581576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:42.583005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:42.583248: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:42.583271: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:42.583562: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:42.590640: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599855000 Hz
2020-09-15 15:49:42.590849: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5584630ec5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:42.590868: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:42.592797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:42.592834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20485848045391744
Epoch: 0 Idx: 5000 Loss: 0.012760512743315997
Epoch: 1 Idx: 0 Loss: 0.01614512815793654
Epoch: 1 Idx: 5000 Loss: 0.019231232064037276
Epoch: 2 Idx: 0 Loss: 0.010705606648987384
Epoch: 2 Idx: 5000 Loss: 0.020029814349200037
Epoch: 3 Idx: 0 Loss: 0.01798395502725579
Epoch: 3 Idx: 5000 Loss: 0.006104963260738155
Epoch: 4 Idx: 0 Loss: 0.0062968605809253925
Epoch: 4 Idx: 5000 Loss: 0.019238807887538404
Epoch: 5 Idx: 0 Loss: 0.018343887905338644
Epoch: 5 Idx: 5000 Loss: 0.019806267564802898
Epoch: 6 Idx: 0 Loss: 0.01218323775405344
Epoch: 6 Idx: 5000 Loss: 0.01371217846865799
Epoch: 7 Idx: 0 Loss: 0.006513428072386705
Epoch: 7 Idx: 5000 Loss: 0.014595118363119249
Epoch: 8 Idx: 0 Loss: 0.015934475999324196
Epoch: 8 Idx: 5000 Loss: 0.02776592206584285
Epoch: 9 Idx: 0 Loss: 0.03970433433402962
Epoch: 9 Idx: 5000 Loss: 0.010035878347936341
Epoch: 10 Idx: 0 Loss: 0.015895211376518455
Epoch: 10 Idx: 5000 Loss: 0.05499495442782876
Epoch: 11 Idx: 0 Loss: 0.0350515106444334
Epoch: 11 Idx: 5000 Loss: 0.016951420219910023
Epoch: 12 Idx: 0 Loss: 0.02026556414161039
Epoch: 12 Idx: 5000 Loss: 0.02364206282877784
Epoch: 13 Idx: 0 Loss: 0.014804852618094739
Epoch: 13 Idx: 5000 Loss: 0.023438971018371953
Epoch: 14 Idx: 0 Loss: 0.018371656325903384
Epoch: 14 Idx: 5000 Loss: 0.01835064306721162
Epoch: 15 Idx: 0 Loss: 0.020186734072241398
Epoch: 15 Idx: 5000 Loss: 0.03201653461835944
Epoch: 16 Idx: 0 Loss: 0.014322131479519348
Epoch: 16 Idx: 5000 Loss: 0.010298239750672986
Epoch: 17 Idx: 0 Loss: 0.013484609700073789
Epoch: 17 Idx: 5000 Loss: 0.006792820514877489
Epoch: 18 Idx: 0 Loss: 0.010560567025780988
Epoch: 18 Idx: 5000 Loss: 0.014909938344440076
Epoch: 19 Idx: 0 Loss: 0.01423530316317938
Epoch: 19 Idx: 5000 Loss: 0.023919205391685114
Epoch: 20 Idx: 0 Loss: 0.005374671160760892
Epoch: 20 Idx: 5000 Loss: 0.008403479925763837
Epoch: 21 Idx: 0 Loss: 0.01166363583623142
Epoch: 21 Idx: 5000 Loss: 0.012453005252412292
Epoch: 22 Idx: 0 Loss: 0.006769136926118663
Epoch: 22 Idx: 5000 Loss: 0.01978819008748441
Epoch: 23 Idx: 0 Loss: 0.0068568197747777195
Epoch: 23 Idx: 5000 Loss: 0.01345787837156824
Epoch: 24 Idx: 0 Loss: 0.016987703775232933
Epoch: 24 Idx: 5000 Loss: 0.01060346195045251
Epoch: 25 Idx: 0 Loss: 0.009444886570288184
Epoch: 25 Idx: 5000 Loss: 0.04106474966698059
Epoch: 26 Idx: 0 Loss: 0.009023122325959854
Epoch: 26 Idx: 5000 Loss: 0.03166820934038319
Epoch: 27 Idx: 0 Loss: 0.020813520629371904
Epoch: 27 Idx: 5000 Loss: 0.03513934737835538
Epoch: 28 Idx: 0 Loss: 0.0204734201305238
Epoch: 28 Idx: 5000 Loss: 0.049187651989856716
Epoch: 29 Idx: 0 Loss: 0.009003560127530738
Epoch: 29 Idx: 5000 Loss: 0.03355375871540989
Epoch: 30 Idx: 0 Loss: 0.020389258183931686
Epoch: 30 Idx: 5000 Loss: 0.010247909490680484
Epoch: 31 Idx: 0 Loss: 0.011055852389626933
Epoch: 31 Idx: 5000 Loss: 0.023382380157436877
Epoch: 32 Idx: 0 Loss: 0.018604556074587764
Epoch: 32 Idx: 5000 Loss: 0.007198757622832749
Epoch: 33 Idx: 0 Loss: 0.004195673762744205
Epoch: 33 Idx: 5000 Loss: 0.008146890440238133
Epoch: 34 Idx: 0 Loss: 0.009585127332901133
Epoch: 34 Idx: 5000 Loss: 0.01035569359639366
Epoch: 35 Idx: 0 Loss: 0.018834111001455333
Epoch: 35 Idx: 5000 Loss: 0.014544078199070215
Epoch: 36 Idx: 0 Loss: 0.00801145606673968
Epoch: 36 Idx: 5000 Loss: 0.014778346900441768
Epoch: 37 Idx: 0 Loss: 0.015036977634047495
Epoch: 37 Idx: 5000 Loss: 0.017923586207404692
Epoch: 38 Idx: 0 Loss: 0.007522339618051908
Epoch: 38 Idx: 5000 Loss: 0.02895157634897421
Epoch: 39 Idx: 0 Loss: 0.02647430139233064
Epoch: 39 Idx: 5000 Loss: 0.018846575273380572
Epoch: 40 Idx: 0 Loss: 0.015193509439951465
Epoch: 40 Idx: 5000 Loss: 0.026352581822540348
Epoch: 41 Idx: 0 Loss: 0.01238937436444721
Epoch: 41 Idx: 5000 Loss: 0.020201312193033987
Epoch: 42 Idx: 0 Loss: 0.014087724441090174
Epoch: 42 Idx: 5000 Loss: 0.013592494588225604
Epoch: 43 Idx: 0 Loss: 0.011123579855000095
Epoch: 43 Idx: 5000 Loss: 0.015642506000056428
Epoch: 44 Idx: 0 Loss: 0.011379713960604741
Epoch: 44 Idx: 5000 Loss: 0.028825860313151347
Epoch: 45 Idx: 0 Loss: 0.008843036549071644
Epoch: 45 Idx: 5000 Loss: 0.0120615677019702
Epoch: 46 Idx: 0 Loss: 0.020538579604151834
Epoch: 46 Idx: 5000 Loss: 0.03328098195609839
Epoch: 47 Idx: 0 Loss: 0.013322217489863328
Epoch: 47 Idx: 5000 Loss: 0.01809843311836221
Epoch: 48 Idx: 0 Loss: 0.0069308051036292735
Epoch: 48 Idx: 5000 Loss: 0.01899277966121253
Epoch: 49 Idx: 0 Loss: 0.01895470953216907
Epoch: 49 Idx: 5000 Loss: 0.01588709574292749
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15011253727935836
Epoch: 0 Idx: 5000 Loss: 0.011275199539414247
Epoch: 1 Idx: 0 Loss: 0.009777891652912294
Epoch: 1 Idx: 5000 Loss: 0.04382862152215877
Epoch: 2 Idx: 0 Loss: 0.009823441960477542
Epoch: 2 Idx: 5000 Loss: 0.022128693953458387
Epoch: 3 Idx: 0 Loss: 0.01819677020892674
Epoch: 3 Idx: 5000 Loss: 0.011220242805412872
Epoch: 4 Idx: 0 Loss: 0.008715210940221908
Epoch: 4 Idx: 5000 Loss: 0.020005877199508384
Epoch: 5 Idx: 0 Loss: 0.02247191869377892
Epoch: 5 Idx: 5000 Loss: 0.01380782542703729
Epoch: 6 Idx: 0 Loss: 0.007829372787290696
Epoch: 6 Idx: 5000 Loss: 0.016990375871240592
Epoch: 7 Idx: 0 Loss: 0.03071330095256804
Epoch: 7 Idx: 5000 Loss: 0.031334328385932274
Epoch: 8 Idx: 0 Loss: 0.012019294276675776
Epoch: 8 Idx: 5000 Loss: 0.03584415773423115
Epoch: 9 Idx: 0 Loss: 0.00963371868323434
Epoch: 9 Idx: 5000 Loss: 0.016943152624323644
Epoch: 10 Idx: 0 Loss: 0.012906312911437162
Epoch: 10 Idx: 5000 Loss: 0.015881939292399262
Epoch: 11 Idx: 0 Loss: 0.014098891077182044
Epoch: 11 Idx: 5000 Loss: 0.009593066126739198
Epoch: 12 Idx: 0 Loss: 0.007974957330937102
Epoch: 12 Idx: 5000 Loss: 0.00565567384265824
Epoch: 13 Idx: 0 Loss: 0.009596361535718908
Epoch: 13 Idx: 5000 Loss: 0.02121576144271206
Epoch: 14 Idx: 0 Loss: 0.016326802285167186
Epoch: 14 Idx: 5000 Loss: 0.005887469668481617
Epoch: 15 Idx: 0 Loss: 0.004831958522704117
Epoch: 15 Idx: 5000 Loss: 0.023097794639822748
Epoch: 16 Idx: 0 Loss: 0.022110829479146665
Epoch: 16 Idx: 5000 Loss: 0.012750872478211349
Epoch: 17 Idx: 0 Loss: 0.0470490070261691
Epoch: 17 Idx: 5000 Loss: 0.012793473457063671
Epoch: 18 Idx: 0 Loss: 0.009092366706044862
Epoch: 18 Idx: 5000 Loss: 0.01231373381742333
Epoch: 19 Idx: 0 Loss: 0.01636490129255376
Epoch: 19 Idx: 5000 Loss: 0.0231628009325892
Epoch: 20 Idx: 0 Loss: 0.011617396344758099
Epoch: 20 Idx: 5000 Loss: 0.018569347152503475
Epoch: 21 Idx: 0 Loss: 0.012793709952471302
Epoch: 21 Idx: 5000 Loss: 0.009321999278020405
Epoch: 22 Idx: 0 Loss: 0.014888400575916083
Epoch: 22 Idx: 5000 Loss: 0.010478352321574425
Epoch: 23 Idx: 0 Loss: 0.014517849149481362
Epoch: 23 Idx: 5000 Loss: 0.01957332604594922
Epoch: 24 Idx: 0 Loss: 0.01589647392893898
Epoch: 24 Idx: 5000 Loss: 0.017319461674798024
Epoch: 25 Idx: 0 Loss: 0.006637798452371059
Epoch: 25 Idx: 5000 Loss: 0.03632918658236299
Epoch: 26 Idx: 0 Loss: 0.016157515904928373
Epoch: 26 Idx: 5000 Loss: 0.01508784175170838
Epoch: 27 Idx: 0 Loss: 0.016651991890774345
Epoch: 27 Idx: 5000 Loss: 0.010842616450073447
Epoch: 28 Idx: 0 Loss: 0.019511779607508273
Epoch: 28 Idx: 5000 Loss: 0.023027622216321063
Epoch: 29 Idx: 0 Loss: 0.013263144457095062
Epoch: 29 Idx: 5000 Loss: 0.012974832920243897
Epoch: 30 Idx: 0 Loss: 0.026491613112191753
Epoch: 30 Idx: 5000 Loss: 0.021956840272300104
Epoch: 31 Idx: 0 Loss: 0.010070911722469836
Epoch: 31 Idx: 5000 Loss: 0.029944793132138506
Epoch: 32 Idx: 0 Loss: 0.009449835040501096
Epoch: 32 Idx: 5000 Loss: 0.018689138767595814
Epoch: 33 Idx: 0 Loss: 0.028664988813835432
Epoch: 33 Idx: 5000 Loss: 0.009470704481484536
Epoch: 34 Idx: 0 Loss: 0.009560079162346129
Epoch: 34 Idx: 5000 Loss: 0.017179311354449504
Epoch: 35 Idx: 0 Loss: 0.03289999524669329
Epoch: 35 Idx: 5000 Loss: 0.008830754818972004
Epoch: 36 Idx: 0 Loss: 0.01454396242489081
Epoch: 36 Idx: 5000 Loss: 0.0068545358171388255
Epoch: 37 Idx: 0 Loss: 0.007918128162609261
Epoch: 37 Idx: 5000 Loss: 0.007477917764027536
Epoch: 38 Idx: 0 Loss: 0.018652843190932935
Epoch: 38 Idx: 5000 Loss: 0.017765881507753125
Epoch: 39 Idx: 0 Loss: 0.01131764580654187
Epoch: 39 Idx: 5000 Loss: 0.020705165970934705
Epoch: 40 Idx: 0 Loss: 0.01610680670839331
Epoch: 40 Idx: 5000 Loss: 0.04343691819187338
Epoch: 41 Idx: 0 Loss: 0.01442406235156668
Epoch: 41 Idx: 5000 Loss: 0.015462897749564152
Epoch: 42 Idx: 0 Loss: 0.010629468647127611
Epoch: 42 Idx: 5000 Loss: 0.019311497530275022
Epoch: 43 Idx: 0 Loss: 0.011725179115157743
Epoch: 43 Idx: 5000 Loss: 0.01038182830501068
Epoch: 44 Idx: 0 Loss: 0.011562400404446381
Epoch: 44 Idx: 5000 Loss: 0.013328429991176364
Epoch: 45 Idx: 0 Loss: 0.02068353472726465
Epoch: 45 Idx: 5000 Loss: 0.005775822920591939
Epoch: 46 Idx: 0 Loss: 0.012051762466927067
Epoch: 46 Idx: 5000 Loss: 0.008794240106487852
Epoch: 47 Idx: 0 Loss: 0.007311753890968876
Epoch: 47 Idx: 5000 Loss: 0.029256420342470696
Epoch: 48 Idx: 0 Loss: 0.023641051524264597
Epoch: 48 Idx: 5000 Loss: 0.006685220138776605
Epoch: 49 Idx: 0 Loss: 0.03069531066195277
Epoch: 49 Idx: 5000 Loss: 0.010355655866566296
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.15765183315253578
Epoch: 0 Idx: 5000 Loss: 0.02591090779524867
Epoch: 1 Idx: 0 Loss: 0.010973578928317382
Epoch: 1 Idx: 5000 Loss: 0.007346581445226202
Epoch: 2 Idx: 0 Loss: 0.009961664564874847
Epoch: 2 Idx: 5000 Loss: 0.018441067844997258
Epoch: 3 Idx: 0 Loss: 0.014041290471938235
Epoch: 3 Idx: 5000 Loss: 0.013387476565901264
Epoch: 4 Idx: 0 Loss: 0.012397631621076691
Epoch: 4 Idx: 5000 Loss: 0.013473147413304746
Epoch: 5 Idx: 0 Loss: 0.029027347810353175
Epoch: 5 Idx: 5000 Loss: 0.023369381480846108
Epoch: 6 Idx: 0 Loss: 0.013124222740711643
Epoch: 6 Idx: 5000 Loss: 0.009409662422156299
Epoch: 7 Idx: 0 Loss: 0.017379575139548714
Epoch: 7 Idx: 5000 Loss: 0.009935289360920063
Epoch: 8 Idx: 0 Loss: 0.010802882917107464
Epoch: 8 Idx: 5000 Loss: 0.03266130436475194
Epoch: 9 Idx: 0 Loss: 0.021263894166996894
Epoch: 9 Idx: 5000 Loss: 0.026696698084243704
Epoch: 10 Idx: 0 Loss: 0.00802969918842304
Epoch: 10 Idx: 5000 Loss: 0.015479363096370134
Epoch: 11 Idx: 0 Loss: 0.008524703547076991
Epoch: 11 Idx: 5000 Loss: 0.02102983599529602
Epoch: 12 Idx: 0 Loss: 0.013123736324976185
Epoch: 12 Idx: 5000 Loss: 0.012461981688457118
Epoch: 13 Idx: 0 Loss: 0.012832100150200603
Epoch: 13 Idx: 5000 Loss: 0.012158385401867729
Epoch: 14 Idx: 0 Loss: 0.032656637515373343
Epoch: 14 Idx: 5000 Loss: 0.007785660671168018
Epoch: 15 Idx: 0 Loss: 0.017788400121188982
Epoch: 15 Idx: 5000 Loss: 0.012834787452205966
Epoch: 16 Idx: 0 Loss: 0.012814346112646903
Epoch: 16 Idx: 5000 Loss: 0.007222245526005492
Epoch: 17 Idx: 0 Loss: 0.010738760207508174
Epoch: 17 Idx: 5000 Loss: 0.013233629590799966
Epoch: 18 Idx: 0 Loss: 0.008496028543469019
Epoch: 18 Idx: 5000 Loss: 0.018299068254100364
Epoch: 19 Idx: 0 Loss: 0.014488602607585308
Epoch: 19 Idx: 5000 Loss: 0.007656380267004757
Epoch: 20 Idx: 0 Loss: 0.016558396405686217
Epoch: 20 Idx: 5000 Loss: 0.019306755473372184
Epoch: 21 Idx: 0 Loss: 0.005476598741669534
Epoch: 21 Idx: 5000 Loss: 0.06372855480879155
Epoch: 22 Idx: 0 Loss: 0.013440177016934795
Epoch: 22 Idx: 5000 Loss: 0.019301233901294033
Epoch: 23 Idx: 0 Loss: 0.007116208363500045
Epoch: 23 Idx: 5000 Loss: 0.021982087851786253
Epoch: 24 Idx: 0 Loss: 0.0072174622130649155
Epoch: 24 Idx: 5000 Loss: 0.010877879955596352
Epoch: 25 Idx: 0 Loss: 0.009313893095826448
Epoch: 25 Idx: 5000 Loss: 0.01111924074314567
Epoch: 26 Idx: 0 Loss: 0.02888245491505876
Epoch: 26 Idx: 5000 Loss: 0.013343044771321099
Epoch: 27 Idx: 0 Loss: 0.032835514244203744
Epoch: 27 Idx: 5000 Loss: 0.007465692805678945
Epoch: 28 Idx: 0 Loss: 0.015386959620398842
Epoch: 28 Idx: 5000 Loss: 0.010910272260464149
Epoch: 29 Idx: 0 Loss: 0.02385530218486506
Epoch: 29 Idx: 5000 Loss: 0.022648948246989133
Epoch: 30 Idx: 0 Loss: 0.007575036027867615
Epoch: 30 Idx: 5000 Loss: 0.016961105034147023
Epoch: 31 Idx: 0 Loss: 0.02353710829410202
Epoch: 31 Idx: 5000 Loss: 0.04287379180008806
Epoch: 32 Idx: 0 Loss: 0.007300804158429338
Epoch: 32 Idx: 5000 Loss: 0.016415497549687304
Epoch: 33 Idx: 0 Loss: 0.007089873796596063
Epoch: 33 Idx: 5000 Loss: 0.030896554828234123
Epoch: 34 Idx: 0 Loss: 0.010945387546683706
Epoch: 34 Idx: 5000 Loss: 0.019680120096614368
Epoch: 35 Idx: 0 Loss: 0.01973649191816926
Epoch: 35 Idx: 5000 Loss: 0.023131827489207453
Epoch: 36 Idx: 0 Loss: 0.01945303612230414
Epoch: 36 Idx: 5000 Loss: 0.01782801828558867
Epoch: 37 Idx: 0 Loss: 0.011644334270254953
Epoch: 37 Idx: 5000 Loss: 0.013782236015436076
Epoch: 38 Idx: 0 Loss: 0.022802267589994117
Epoch: 38 Idx: 5000 Loss: 0.003586316099897879
Epoch: 39 Idx: 0 Loss: 0.022215194711361498
Epoch: 39 Idx: 5000 Loss: 0.015025283433577893
Epoch: 40 Idx: 0 Loss: 0.011924408502787118
Epoch: 40 Idx: 5000 Loss: 0.015711268208112212
Epoch: 41 Idx: 0 Loss: 0.030909322832827744
Epoch: 41 Idx: 5000 Loss: 0.014460880392539548
Epoch: 42 Idx: 0 Loss: 0.020729812209613518
Epoch: 42 Idx: 5000 Loss: 0.011044774560304492
Epoch: 43 Idx: 0 Loss: 0.012629331904335014
Epoch: 43 Idx: 5000 Loss: 0.014051982160102398
Epoch: 44 Idx: 0 Loss: 0.018464605634902743
Epoch: 44 Idx: 5000 Loss: 0.017509503384811945
Epoch: 45 Idx: 0 Loss: 0.013393257334470422
Epoch: 45 Idx: 5000 Loss: 0.008331375787417848
Epoch: 46 Idx: 0 Loss: 0.011911266563901391
Epoch: 46 Idx: 5000 Loss: 0.007134903371075121
Epoch: 47 Idx: 0 Loss: 0.024475602214034605
Epoch: 47 Idx: 5000 Loss: 0.018324946346846567
Epoch: 48 Idx: 0 Loss: 0.009222534852484482
Epoch: 48 Idx: 5000 Loss: 0.02001585644574963
Epoch: 49 Idx: 0 Loss: 0.01785610771945728
Epoch: 49 Idx: 5000 Loss: 0.009639093534202222
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.24340338223227775
Epoch: 0 Idx: 5000 Loss: 0.012241262347211236
Epoch: 1 Idx: 0 Loss: 0.007493194153422497
Epoch: 1 Idx: 5000 Loss: 0.013651608899465947
Epoch: 2 Idx: 0 Loss: 0.008102604029225583
Epoch: 2 Idx: 5000 Loss: 0.02251753586083058
Epoch: 3 Idx: 0 Loss: 0.015211682972157851
Epoch: 3 Idx: 5000 Loss: 0.0205338139846403
Epoch: 4 Idx: 0 Loss: 0.02328810303630001
Epoch: 4 Idx: 5000 Loss: 0.013557817506611234
Epoch: 5 Idx: 0 Loss: 0.0185158495859284
Epoch: 5 Idx: 5000 Loss: 0.008907991936153522
Epoch: 6 Idx: 0 Loss: 0.006724654834586273
Epoch: 6 Idx: 5000 Loss: 0.0148065420859614
Epoch: 7 Idx: 0 Loss: 0.010216133514370881
Epoch: 7 Idx: 5000 Loss: 0.034757963885947915
Epoch: 8 Idx: 0 Loss: 0.011564901353753706
Epoch: 8 Idx: 5000 Loss: 0.014780564555313364
Epoch: 9 Idx: 0 Loss: 0.019890603320800372
Epoch: 9 Idx: 5000 Loss: 0.014212492981885637
Epoch: 10 Idx: 0 Loss: 0.01704304247336657
Epoch: 10 Idx: 5000 Loss: 0.009188637477923648
Epoch: 11 Idx: 0 Loss: 0.021851794638586157
Epoch: 11 Idx: 5000 Loss: 0.01257078404860006
Epoch: 12 Idx: 0 Loss: 0.012911398623504112
Epoch: 12 Idx: 5000 Loss: 0.007966538502244483
Epoch: 13 Idx: 0 Loss: 0.01145684039830336
Epoch: 13 Idx: 5000 Loss: 0.030334594432550446
Epoch: 14 Idx: 0 Loss: 0.01670582962939294
Epoch: 14 Idx: 5000 Loss: 0.009594175233074011
Epoch: 15 Idx: 0 Loss: 0.01466666242453496
Epoch: 15 Idx: 5000 Loss: 0.00882153920580363
Epoch: 16 Idx: 0 Loss: 0.013632799404801107
Epoch: 16 Idx: 5000 Loss: 0.012886466299476177
Epoch: 17 Idx: 0 Loss: 0.0111778354670862
Epoch: 17 Idx: 5000 Loss: 0.005874175600463833
Epoch: 18 Idx: 0 Loss: 0.014867197524199863
Epoch: 18 Idx: 5000 Loss: 0.021724988013533005
Epoch: 19 Idx: 0 Loss: 0.013600184323772975
Epoch: 19 Idx: 5000 Loss: 0.0106688194471617
Epoch: 20 Idx: 0 Loss: 0.005277818217084432
Epoch: 20 Idx: 5000 Loss: 0.018636155635233183
Epoch: 21 Idx: 0 Loss: 0.007501165858917427
Epoch: 21 Idx: 5000 Loss: 0.0238409501736803
Epoch: 22 Idx: 0 Loss: 0.016936101092477326
Epoch: 22 Idx: 5000 Loss: 0.025557180161068754
Epoch: 23 Idx: 0 Loss: 0.011550365443146079
Epoch: 23 Idx: 5000 Loss: 0.029904839735691434
Epoch: 24 Idx: 0 Loss: 0.010345585777022381
Epoch: 24 Idx: 5000 Loss: 0.018140719194473253
Epoch: 25 Idx: 0 Loss: 0.0348678776376497
Epoch: 25 Idx: 5000 Loss: 0.02068701552638355
Epoch: 26 Idx: 0 Loss: 0.011036033171350122
Epoch: 26 Idx: 5000 Loss: 0.00823420700748338
Epoch: 27 Idx: 0 Loss: 0.020989202468393565
Epoch: 27 Idx: 5000 Loss: 0.020478317173715625
Epoch: 28 Idx: 0 Loss: 0.010879843181614455
Epoch: 28 Idx: 5000 Loss: 0.016821613538381824
Epoch: 29 Idx: 0 Loss: 0.02510021754977327
Epoch: 29 Idx: 5000 Loss: 0.033021284838632335
Epoch: 30 Idx: 0 Loss: 0.00967030684778456
Epoch: 30 Idx: 5000 Loss: 0.012257505862847436
Epoch: 31 Idx: 0 Loss: 0.012897772846540525
Epoch: 31 Idx: 5000 Loss: 0.015700930992324606
Epoch: 32 Idx: 0 Loss: 0.025187345232616346
Epoch: 32 Idx: 5000 Loss: 0.013142076394366924
Epoch: 33 Idx: 0 Loss: 0.010526227673947258
Epoch: 33 Idx: 5000 Loss: 0.026934325081308753
Epoch: 34 Idx: 0 Loss: 0.01234551150535622
Epoch: 34 Idx: 5000 Loss: 0.04353993406403766
Epoch: 35 Idx: 0 Loss: 0.009178526641292341
Epoch: 35 Idx: 5000 Loss: 0.0354097999941807
Epoch: 36 Idx: 0 Loss: 0.018643703632746908
Epoch: 36 Idx: 5000 Loss: 0.008466786828585086
Epoch: 37 Idx: 0 Loss: 0.009003681350557624
Epoch: 37 Idx: 5000 Loss: 0.01762064844456384
Epoch: 38 Idx: 0 Loss: 0.047402238259345884
Epoch: 38 Idx: 5000 Loss: 0.00723760309723661
Epoch: 39 Idx: 0 Loss: 0.014227308131224864
Epoch: 39 Idx: 5000 Loss: 0.02179873607671836
Epoch: 40 Idx: 0 Loss: 0.03604550495014732
Epoch: 40 Idx: 5000 Loss: 0.01486359879629554
Epoch: 41 Idx: 0 Loss: 0.010699763225822025
Epoch: 41 Idx: 5000 Loss: 0.004563852803519657
Epoch: 42 Idx: 0 Loss: 0.02376095999079286
Epoch: 42 Idx: 5000 Loss: 0.017891581681412836
Epoch: 43 Idx: 0 Loss: 0.015875653941742108
Epoch: 43 Idx: 5000 Loss: 0.033003691285258555
Epoch: 44 Idx: 0 Loss: 0.008113326821682294
Epoch: 44 Idx: 5000 Loss: 0.013297985813672102
Epoch: 45 Idx: 0 Loss: 0.011290959706858386
Epoch: 45 Idx: 5000 Loss: 0.020694365975831422
Epoch: 46 Idx: 0 Loss: 0.009915071331616513
Epoch: 46 Idx: 5000 Loss: 0.021428222687442083
Epoch: 47 Idx: 0 Loss: 0.012777853887395536
Epoch: 47 Idx: 5000 Loss: 0.012765571957670821
Epoch: 48 Idx: 0 Loss: 0.03718817369170376
Epoch: 48 Idx: 5000 Loss: 0.009205752922200303
Epoch: 49 Idx: 0 Loss: 0.007895082034452564
Epoch: 49 Idx: 5000 Loss: 0.011401350992680494
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.18545153941614764
Epoch: 0 Idx: 5000 Loss: 0.00835678530062942
Epoch: 1 Idx: 0 Loss: 0.017613252246306103
Epoch: 1 Idx: 5000 Loss: 0.017930757193784112
Epoch: 2 Idx: 0 Loss: 0.010680317513026522
Epoch: 2 Idx: 5000 Loss: 0.010295037387299285
Epoch: 3 Idx: 0 Loss: 0.027840152976514376
Epoch: 3 Idx: 5000 Loss: 0.013556268229492453
Epoch: 4 Idx: 0 Loss: 0.04055276728070596
Epoch: 4 Idx: 5000 Loss: 0.010640535770259961
Epoch: 5 Idx: 0 Loss: 0.007943826930919136
Epoch: 5 Idx: 5000 Loss: 0.030338332587941864
Epoch: 6 Idx: 0 Loss: 0.021911902994167242
Epoch: 6 Idx: 5000 Loss: 0.01652896664709054
Epoch: 7 Idx: 0 Loss: 0.014027006275767842
Epoch: 7 Idx: 5000 Loss: 0.017070566514684166
Epoch: 8 Idx: 0 Loss: 0.011411640967280296
Epoch: 8 Idx: 5000 Loss: 0.00901974997164775
Epoch: 9 Idx: 0 Loss: 0.01246559694589075
Epoch: 9 Idx: 5000 Loss: 0.011171952707574834
Epoch: 10 Idx: 0 Loss: 0.011897468644260563
Epoch: 10 Idx: 5000 Loss: 0.012080948243155285
Epoch: 11 Idx: 0 Loss: 0.04205020656189269
Epoch: 11 Idx: 5000 Loss: 0.019614483559901384
Epoch: 12 Idx: 0 Loss: 0.013664361636399626
Epoch: 12 Idx: 5000 Loss: 0.012336873330014554
Epoch: 13 Idx: 0 Loss: 0.009560339189873566
Epoch: 13 Idx: 5000 Loss: 0.027168544438224376
Epoch: 14 Idx: 0 Loss: 0.02358703158263842
Epoch: 14 Idx: 5000 Loss: 0.04354509701867213
Epoch: 15 Idx: 0 Loss: 0.010340326608236501
Epoch: 15 Idx: 5000 Loss: 0.014971325290034625
Epoch: 16 Idx: 0 Loss: 0.010147492946868416
Epoch: 16 Idx: 5000 Loss: 0.021395628227904043
Epoch: 17 Idx: 0 Loss: 0.006346515835062791
Epoch: 17 Idx: 5000 Loss: 0.029398327890001387
Epoch: 18 Idx: 0 Loss: 0.008418527954605428
Epoch: 18 Idx: 5000 Loss: 0.036424256227668886
Epoch: 19 Idx: 0 Loss: 0.01931532015712823
Epoch: 19 Idx: 5000 Loss: 0.018938599407078913
Epoch: 20 Idx: 0 Loss: 0.016489305552210603
Epoch: 20 Idx: 5000 Loss: 0.030377054698652244
Epoch: 21 Idx: 0 Loss: 0.01563504085146708
Epoch: 21 Idx: 5000 Loss: 0.029763403498529788
Epoch: 22 Idx: 0 Loss: 0.01418028976730353
Epoch: 22 Idx: 5000 Loss: 0.012939810479197168
Epoch: 23 Idx: 0 Loss: 0.008158133784009897
Epoch: 23 Idx: 5000 Loss: 0.020064933766553866
Epoch: 24 Idx: 0 Loss: 0.014839253774909498
Epoch: 24 Idx: 5000 Loss: 0.06070908790047228
Epoch: 25 Idx: 0 Loss: 0.013762805008588817
Epoch: 25 Idx: 5000 Loss: 0.05106094613688495
Epoch: 26 Idx: 0 Loss: 0.020939901971106414
Epoch: 26 Idx: 5000 Loss: 0.010445764280412545
Epoch: 27 Idx: 0 Loss: 0.009930982799102605
Epoch: 27 Idx: 5000 Loss: 0.01492914098982737
Epoch: 28 Idx: 0 Loss: 0.019707432529960545
Epoch: 28 Idx: 5000 Loss: 0.010982014009889232
Epoch: 29 Idx: 0 Loss: 0.012275144314110885
Epoch: 29 Idx: 5000 Loss: 0.012713198723018931
Epoch: 30 Idx: 0 Loss: 0.02296425042803261
Epoch: 30 Idx: 5000 Loss: 0.009424124193899541
Epoch: 31 Idx: 0 Loss: 0.043340984988823286
Epoch: 31 Idx: 5000 Loss: 0.028268402185274488
Epoch: 32 Idx: 0 Loss: 0.021078738367416944
Epoch: 32 Idx: 5000 Loss: 0.02547153961957525
Epoch: 33 Idx: 0 Loss: 0.016188376303354998
Epoch: 33 Idx: 5000 Loss: 0.02072137983938715
Epoch: 34 Idx: 0 Loss: 0.006837729281107449
Epoch: 34 Idx: 5000 Loss: 0.009653513121190966
Epoch: 35 Idx: 0 Loss: 0.011481361467382007
Epoch: 35 Idx: 5000 Loss: 0.019027584476504534
Epoch: 36 Idx: 0 Loss: 0.022141786965832338
Epoch: 36 Idx: 5000 Loss: 0.011376764051126826
Epoch: 37 Idx: 0 Loss: 0.011802886795801767
Epoch: 37 Idx: 5000 Loss: 0.006749161193551024
Epoch: 38 Idx: 0 Loss: 0.015577988253165604
Epoch: 38 Idx: 5000 Loss: 0.012174505835656267
Epoch: 39 Idx: 0 Loss: 0.014123165508807765
Epoch: 39 Idx: 5000 Loss: 0.022954663616903
Epoch: 40 Idx: 0 Loss: 0.011781685961388401
Epoch: 40 Idx: 5000 Loss: 0.0161118421601176
Epoch: 41 Idx: 0 Loss: 0.010725620785919598
Epoch: 41 Idx: 5000 Loss: 0.01238034503346798
Epoch: 42 Idx: 0 Loss: 0.014087989355700905
Epoch: 42 Idx: 5000 Loss: 0.013536573897380786
Epoch: 43 Idx: 0 Loss: 0.022449365657314528
Epoch: 43 Idx: 5000 Loss: 0.008746438366274034
Epoch: 44 Idx: 0 Loss: 0.014782045845647396
Epoch: 44 Idx: 5000 Loss: 0.03430892726391035
Epoch: 45 Idx: 0 Loss: 0.007442785114417725
Epoch: 45 Idx: 5000 Loss: 0.02009280181543538
Epoch: 46 Idx: 0 Loss: 0.01269015023419263
Epoch: 46 Idx: 5000 Loss: 0.00960095282829258
Epoch: 47 Idx: 0 Loss: 0.02648352160884646
Epoch: 47 Idx: 5000 Loss: 0.007707270294370016
Epoch: 48 Idx: 0 Loss: 0.01032522985157025
Epoch: 48 Idx: 5000 Loss: 0.04796889385973976
Epoch: 49 Idx: 0 Loss: 0.013359202339321846
Epoch: 49 Idx: 5000 Loss: 0.016059877878168753
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.20317766217895722
Epoch: 0 Idx: 5000 Loss: 0.016685181179252224
Epoch: 1 Idx: 0 Loss: 0.013063133231545971
Epoch: 1 Idx: 5000 Loss: 0.024898463275977945
Epoch: 2 Idx: 0 Loss: 0.006262814634468023
Epoch: 2 Idx: 5000 Loss: 0.011856035095280828
Epoch: 3 Idx: 0 Loss: 0.024390845630132146
Epoch: 3 Idx: 5000 Loss: 0.014621633163283571
Epoch: 4 Idx: 0 Loss: 0.047204167718410586
Epoch: 4 Idx: 5000 Loss: 0.010101448788588369
Epoch: 5 Idx: 0 Loss: 0.018651941503653947
Epoch: 5 Idx: 5000 Loss: 0.012334658867811066
Epoch: 6 Idx: 0 Loss: 0.02267480491677582
Epoch: 6 Idx: 5000 Loss: 0.01609465481116163
Epoch: 7 Idx: 0 Loss: 0.00646256550390663
Epoch: 7 Idx: 5000 Loss: 0.010119901938314937
Epoch: 8 Idx: 0 Loss: 0.005576060394846472
Epoch: 8 Idx: 5000 Loss: 0.016588641479419453
Epoch: 9 Idx: 0 Loss: 0.006785174921633719
Epoch: 9 Idx: 5000 Loss: 0.014179326098515181
Epoch: 10 Idx: 0 Loss: 0.01386823243225184
Epoch: 10 Idx: 5000 Loss: 0.007792128954515054
Epoch: 11 Idx: 0 Loss: 0.015072292645214798
Epoch: 11 Idx: 5000 Loss: 0.012798326248082584
Epoch: 12 Idx: 0 Loss: 0.028541493174510654
Epoch: 12 Idx: 5000 Loss: 0.026590156816912465
Epoch: 13 Idx: 0 Loss: 0.02652389537076062
Epoch: 13 Idx: 5000 Loss: 0.006542435531882966
Epoch: 14 Idx: 0 Loss: 0.02462201959071251
Epoch: 14 Idx: 5000 Loss: 0.010586588457468129
Epoch: 15 Idx: 0 Loss: 0.021968076837089276
Epoch: 15 Idx: 5000 Loss: 0.02290315006398519
Epoch: 16 Idx: 0 Loss: 0.022079727584998043
Epoch: 16 Idx: 5000 Loss: 0.013730584599241036
Epoch: 17 Idx: 0 Loss: 0.012020970867812529
Epoch: 17 Idx: 5000 Loss: 0.026750994912841865
Epoch: 18 Idx: 0 Loss: 0.00855685454463629
Epoch: 18 Idx: 5000 Loss: 0.010090063579180387
Epoch: 19 Idx: 0 Loss: 0.01455099796739718
Epoch: 19 Idx: 5000 Loss: 0.01546045910232161
Epoch: 20 Idx: 0 Loss: 0.025921588456775495
Epoch: 20 Idx: 5000 Loss: 0.012699101989354086
Epoch: 21 Idx: 0 Loss: 0.020616640260373124
Epoch: 21 Idx: 5000 Loss: 0.012769177882886767
Epoch: 22 Idx: 0 Loss: 0.020245658610450412
Epoch: 22 Idx: 5000 Loss: 0.011328355711034369
Epoch: 23 Idx: 0 Loss: 0.013090488843369769
Epoch: 23 Idx: 5000 Loss: 0.01701407897610146
Epoch: 24 Idx: 0 Loss: 0.03216714207593907
Epoch: 24 Idx: 5000 Loss: 0.008547279077908306
Epoch: 25 Idx: 0 Loss: 0.006861562159808224
Epoch: 25 Idx: 5000 Loss: 0.031060092498239232
Epoch: 26 Idx: 0 Loss: 0.017435393695992722
Epoch: 26 Idx: 5000 Loss: 0.015314734341170571
Epoch: 27 Idx: 0 Loss: 0.021415698813680793
Epoch: 27 Idx: 5000 Loss: 0.0192230225750631
Epoch: 28 Idx: 0 Loss: 0.007749410407630437
Epoch: 28 Idx: 5000 Loss: 0.018097863064936444
Epoch: 29 Idx: 0 Loss: 0.006309875445670618
Epoch: 29 Idx: 5000 Loss: 0.010340236335351959
Epoch: 30 Idx: 0 Loss: 0.021586922353537534
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 359, in forward
    sim = self.cosine_sim_layer(results[0], results[1])
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 719, in _call_impl
    if torch._C._get_tracing_state():
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc257>
Subject: Job 4066873: <python main.py 6 3 False False> in cluster <dcc> Exited

Job <python main.py 6 3 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc257>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 3 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46055.16 sec.
    Max Memory :                                 2904 MB
    Average Memory :                             2749.67 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40513.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46170 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

