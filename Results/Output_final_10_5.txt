2020-09-15 15:48:44.769466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.139799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:52.255681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:52.255781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.258157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:52.278433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:52.342706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:52.386587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:52.450036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:52.450569: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:52.450594: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:52.450998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:52.488984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599810000 Hz
2020-09-15 15:48:52.489290: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564dd67ac700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:52.489316: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:52.492744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:52.492799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18859289731098464
Epoch: 0 Idx: 5000 Loss: 0.016155035812350706
Epoch: 1 Idx: 0 Loss: 0.00998859229893212
Epoch: 1 Idx: 5000 Loss: 0.011941695836355747
Epoch: 2 Idx: 0 Loss: 0.010020979533865534
Epoch: 2 Idx: 5000 Loss: 0.017967271246602846
Epoch: 3 Idx: 0 Loss: 0.019621916209693745
Epoch: 3 Idx: 5000 Loss: 0.05026912586214999
Epoch: 4 Idx: 0 Loss: 0.006423493955485797
Epoch: 4 Idx: 5000 Loss: 0.015203502010438517
Epoch: 5 Idx: 0 Loss: 0.014567407037918168
Epoch: 5 Idx: 5000 Loss: 0.01769175151061647
Epoch: 6 Idx: 0 Loss: 0.014225713028268869
Epoch: 6 Idx: 5000 Loss: 0.010550127470619439
Epoch: 7 Idx: 0 Loss: 0.01332442897581512
Epoch: 7 Idx: 5000 Loss: 0.025631436570043995
Epoch: 8 Idx: 0 Loss: 0.024689970968843893
Epoch: 8 Idx: 5000 Loss: 0.013346354692037328
Epoch: 9 Idx: 0 Loss: 0.013053913176476407
Epoch: 9 Idx: 5000 Loss: 0.018467437725255987
Epoch: 10 Idx: 0 Loss: 0.012508427545396082
Epoch: 10 Idx: 5000 Loss: 0.044970499232996605
Epoch: 11 Idx: 0 Loss: 0.012358678955768976
Epoch: 11 Idx: 5000 Loss: 0.06104666495654519
Epoch: 12 Idx: 0 Loss: 0.005599385020026593
Epoch: 12 Idx: 5000 Loss: 0.020460241458157058
Epoch: 13 Idx: 0 Loss: 0.019388959315354733
Epoch: 13 Idx: 5000 Loss: 0.003129485597278194
Epoch: 14 Idx: 0 Loss: 0.022673530130892208
Epoch: 14 Idx: 5000 Loss: 0.016527857544366316
Epoch: 15 Idx: 0 Loss: 0.02130414685515815
Epoch: 15 Idx: 5000 Loss: 0.012245850699690947
Epoch: 16 Idx: 0 Loss: 0.022950652365710537
Epoch: 16 Idx: 5000 Loss: 0.015486079636199244
Epoch: 17 Idx: 0 Loss: 0.008180394138156018
Epoch: 17 Idx: 5000 Loss: 0.014585002141281842
Epoch: 18 Idx: 0 Loss: 0.0181254005731461
Epoch: 18 Idx: 5000 Loss: 0.013975418164182508
Epoch: 19 Idx: 0 Loss: 0.019548486190446804
Epoch: 19 Idx: 5000 Loss: 0.01336564694113393
Epoch: 20 Idx: 0 Loss: 0.014471532572038738
Epoch: 20 Idx: 5000 Loss: 0.0201086089737714
Epoch: 21 Idx: 0 Loss: 0.025577095430740254
Epoch: 21 Idx: 5000 Loss: 0.008466544846259041
Epoch: 22 Idx: 0 Loss: 0.019875439860118624
Epoch: 22 Idx: 5000 Loss: 0.028206924702617715
Epoch: 23 Idx: 0 Loss: 0.0263520759429057
Epoch: 23 Idx: 5000 Loss: 0.01926221293094171
Epoch: 24 Idx: 0 Loss: 0.014207819085842847
Epoch: 24 Idx: 5000 Loss: 0.015762700583731193
Epoch: 25 Idx: 0 Loss: 0.028745876345962314
Epoch: 25 Idx: 5000 Loss: 0.016044725331797915
Epoch: 26 Idx: 0 Loss: 0.009702728906480615
Epoch: 26 Idx: 5000 Loss: 0.018460117021237062
Epoch: 27 Idx: 0 Loss: 0.008891312587709298
Epoch: 27 Idx: 5000 Loss: 0.016470589267653723
Epoch: 28 Idx: 0 Loss: 0.00989372784097613
Epoch: 28 Idx: 5000 Loss: 0.02206597356791297
Epoch: 29 Idx: 0 Loss: 0.01683526639495366
Epoch: 29 Idx: 5000 Loss: 0.010866106067857532
Epoch: 30 Idx: 0 Loss: 0.024600593593204614
Epoch: 30 Idx: 5000 Loss: 0.020692700137661613
Epoch: 31 Idx: 0 Loss: 0.023100707355365548
Epoch: 31 Idx: 5000 Loss: 0.007099349626835881
Epoch: 32 Idx: 0 Loss: 0.030938515156646865
Epoch: 32 Idx: 5000 Loss: 0.02172684187162937
Epoch: 33 Idx: 0 Loss: 0.016413480999782792
Epoch: 33 Idx: 5000 Loss: 0.01626040799028865
Epoch: 34 Idx: 0 Loss: 0.00860590092895711
Epoch: 34 Idx: 5000 Loss: 0.012270915762496937
Epoch: 35 Idx: 0 Loss: 0.007830134386977279
Epoch: 35 Idx: 5000 Loss: 0.01115785245744051
Epoch: 36 Idx: 0 Loss: 0.006958021358564488
Epoch: 36 Idx: 5000 Loss: 0.01118228012224299
Epoch: 37 Idx: 0 Loss: 0.011017276963824462
Epoch: 37 Idx: 5000 Loss: 0.029213708114841253
Epoch: 38 Idx: 0 Loss: 0.019915444663951176
Epoch: 38 Idx: 5000 Loss: 0.01572291812278382
Epoch: 39 Idx: 0 Loss: 0.013526286472355382
Epoch: 39 Idx: 5000 Loss: 0.020663298099155604
Epoch: 40 Idx: 0 Loss: 0.008262057365774244
Epoch: 40 Idx: 5000 Loss: 0.011520826242830948
Epoch: 41 Idx: 0 Loss: 0.016003377958681335
Epoch: 41 Idx: 5000 Loss: 0.003919016333722528
Epoch: 42 Idx: 0 Loss: 0.0068364635632395185
Epoch: 42 Idx: 5000 Loss: 0.0058188722254345175
Epoch: 43 Idx: 0 Loss: 0.04429891047891017
Epoch: 43 Idx: 5000 Loss: 0.029418419221791788
Epoch: 44 Idx: 0 Loss: 0.01627865499381443
Epoch: 44 Idx: 5000 Loss: 0.02661979608068825
Epoch: 45 Idx: 0 Loss: 0.008498177417632629
Epoch: 45 Idx: 5000 Loss: 0.03237709977051376
Epoch: 46 Idx: 0 Loss: 0.022839765870605485
Epoch: 46 Idx: 5000 Loss: 0.020886168780358618
Epoch: 47 Idx: 0 Loss: 0.013070581254138593
Epoch: 47 Idx: 5000 Loss: 0.023538334702012588
Epoch: 48 Idx: 0 Loss: 0.01486167977368495
Epoch: 48 Idx: 5000 Loss: 0.008623579366534866
Epoch: 49 Idx: 0 Loss: 0.015249268443267862
Epoch: 49 Idx: 5000 Loss: 0.006083630353143204
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1427405100182671
Epoch: 0 Idx: 5000 Loss: 0.017423577719205854
Epoch: 1 Idx: 0 Loss: 0.010467043457480785
Epoch: 1 Idx: 5000 Loss: 0.023724812450227548
Epoch: 2 Idx: 0 Loss: 0.014351722447610283
Epoch: 2 Idx: 5000 Loss: 0.010725527034250296
Epoch: 3 Idx: 0 Loss: 0.022573909810995045
Epoch: 3 Idx: 5000 Loss: 0.01458048905319839
Epoch: 4 Idx: 0 Loss: 0.008442874828072384
Epoch: 4 Idx: 5000 Loss: 0.01489243399167227
Epoch: 5 Idx: 0 Loss: 0.017794485232591344
Epoch: 5 Idx: 5000 Loss: 0.03161879907165582
Epoch: 6 Idx: 0 Loss: 0.018172155665958974
Epoch: 6 Idx: 5000 Loss: 0.02189250503334572
Epoch: 7 Idx: 0 Loss: 0.016970030388908226
Epoch: 7 Idx: 5000 Loss: 0.008711909317152856
Epoch: 8 Idx: 0 Loss: 0.013825458511443057
Epoch: 8 Idx: 5000 Loss: 0.011704540050764807
Epoch: 9 Idx: 0 Loss: 0.02495369566452421
Epoch: 9 Idx: 5000 Loss: 0.018380731349158092
Epoch: 10 Idx: 0 Loss: 0.01343926042887578
Epoch: 10 Idx: 5000 Loss: 0.02247812676347486
Epoch: 11 Idx: 0 Loss: 0.014479857651806418
Epoch: 11 Idx: 5000 Loss: 0.005175608619468414
Epoch: 12 Idx: 0 Loss: 0.009381874347655762
Epoch: 12 Idx: 5000 Loss: 0.014640906201427316
Epoch: 13 Idx: 0 Loss: 0.012502506425684559
Epoch: 13 Idx: 5000 Loss: 0.017858012072641503
Epoch: 14 Idx: 0 Loss: 0.016553205084904026
Epoch: 14 Idx: 5000 Loss: 0.007276275093914223
Epoch: 15 Idx: 0 Loss: 0.01247543353204445
Epoch: 15 Idx: 5000 Loss: 0.009093752521834362
Epoch: 16 Idx: 0 Loss: 0.012142978245385112
Epoch: 16 Idx: 5000 Loss: 0.0229876093964988
Epoch: 17 Idx: 0 Loss: 0.016740123920738537
Epoch: 17 Idx: 5000 Loss: 0.010565303520016535
Epoch: 18 Idx: 0 Loss: 0.007886359442473675
Epoch: 18 Idx: 5000 Loss: 0.010582511007067922
Epoch: 19 Idx: 0 Loss: 0.022188164243487723
Epoch: 19 Idx: 5000 Loss: 0.010600016801385923
Epoch: 20 Idx: 0 Loss: 0.01931408932347923
Epoch: 20 Idx: 5000 Loss: 0.011303623293121193
Epoch: 21 Idx: 0 Loss: 0.01068054095339525
Epoch: 21 Idx: 5000 Loss: 0.0198008796213913
Epoch: 22 Idx: 0 Loss: 0.011375106747423966
Epoch: 22 Idx: 5000 Loss: 0.00817693463880948
Epoch: 23 Idx: 0 Loss: 0.050606623622095
Epoch: 23 Idx: 5000 Loss: 0.013437793336562521
Epoch: 24 Idx: 0 Loss: 0.008000749074940031
Epoch: 24 Idx: 5000 Loss: 0.01936766065423977
Epoch: 25 Idx: 0 Loss: 0.02672340148913726
Epoch: 25 Idx: 5000 Loss: 0.014938293893490849
Epoch: 26 Idx: 0 Loss: 0.00847202687676123
Epoch: 26 Idx: 5000 Loss: 0.012189214317882675
Epoch: 27 Idx: 0 Loss: 0.04141366766498896
Epoch: 27 Idx: 5000 Loss: 0.008064442159238452
Epoch: 28 Idx: 0 Loss: 0.01685902289608688
Epoch: 28 Idx: 5000 Loss: 0.007281863208705304
Epoch: 29 Idx: 0 Loss: 0.019041692133413567
Epoch: 29 Idx: 5000 Loss: 0.008093392774541176
Epoch: 30 Idx: 0 Loss: 0.024621751372387653
Epoch: 30 Idx: 5000 Loss: 0.024659777940754087
Epoch: 31 Idx: 0 Loss: 0.026326883726950016
Epoch: 31 Idx: 5000 Loss: 0.022736996241563737
Epoch: 32 Idx: 0 Loss: 0.011349375652934453
Epoch: 32 Idx: 5000 Loss: 0.011945776056465067
Epoch: 33 Idx: 0 Loss: 0.007771407597446508
Epoch: 33 Idx: 5000 Loss: 0.014489307266890704
Epoch: 34 Idx: 0 Loss: 0.009359187224792053
Epoch: 34 Idx: 5000 Loss: 0.029115107027734
Epoch: 35 Idx: 0 Loss: 0.015671393733986995
Epoch: 35 Idx: 5000 Loss: 0.019298919244182342
Epoch: 36 Idx: 0 Loss: 0.020117954460642018
Epoch: 36 Idx: 5000 Loss: 0.00841997287514979
Epoch: 37 Idx: 0 Loss: 0.03263643106468937
Epoch: 37 Idx: 5000 Loss: 0.005685554040039292
Epoch: 38 Idx: 0 Loss: 0.017823930193095118
Epoch: 38 Idx: 5000 Loss: 0.010167921056185959
Epoch: 39 Idx: 0 Loss: 0.017111459416589075
Epoch: 39 Idx: 5000 Loss: 0.0070742990621923615
Epoch: 40 Idx: 0 Loss: 0.013630157035171089
Epoch: 40 Idx: 5000 Loss: 0.02299977391676969
Epoch: 41 Idx: 0 Loss: 0.010316097774892202
Epoch: 41 Idx: 5000 Loss: 0.005434008517468201
Epoch: 42 Idx: 0 Loss: 0.009080437936338491
Epoch: 42 Idx: 5000 Loss: 0.008831934142183754
Epoch: 43 Idx: 0 Loss: 0.015049173572220662
Epoch: 43 Idx: 5000 Loss: 0.012857925190461323
Epoch: 44 Idx: 0 Loss: 0.015398297119103094
Epoch: 44 Idx: 5000 Loss: 0.05508651402452072
Epoch: 45 Idx: 0 Loss: 0.010435389657012243
Epoch: 45 Idx: 5000 Loss: 0.014317436718143912
Epoch: 46 Idx: 0 Loss: 0.014007549092006168
Epoch: 46 Idx: 5000 Loss: 0.03446209062269832
Epoch: 47 Idx: 0 Loss: 0.006086879874084662
Epoch: 47 Idx: 5000 Loss: 0.030246853083076484
Epoch: 48 Idx: 0 Loss: 0.009101393578177906
Epoch: 48 Idx: 5000 Loss: 0.010607501870569809
Epoch: 49 Idx: 0 Loss: 0.008041793355217045
Epoch: 49 Idx: 5000 Loss: 0.00472801374255063
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13222118283960183
Epoch: 0 Idx: 5000 Loss: 0.014393795253295701
Epoch: 1 Idx: 0 Loss: 0.020320539997203006
Epoch: 1 Idx: 5000 Loss: 0.0125056320701284
Epoch: 2 Idx: 0 Loss: 0.032744251947848864
Epoch: 2 Idx: 5000 Loss: 0.008336507826319018
Epoch: 3 Idx: 0 Loss: 0.01948675432826941
Epoch: 3 Idx: 5000 Loss: 0.015509820256243137
Epoch: 4 Idx: 0 Loss: 0.013665352509576017
Epoch: 4 Idx: 5000 Loss: 0.02596000248186334
Epoch: 5 Idx: 0 Loss: 0.013698530567593334
Epoch: 5 Idx: 5000 Loss: 0.00812276395156337
Epoch: 6 Idx: 0 Loss: 0.010842183067988547
Epoch: 6 Idx: 5000 Loss: 0.0165421118015431
Epoch: 7 Idx: 0 Loss: 0.013097026660705145
Epoch: 7 Idx: 5000 Loss: 0.016465818540788626
Epoch: 8 Idx: 0 Loss: 0.012408486524398882
Epoch: 8 Idx: 5000 Loss: 0.011763643696292918
Epoch: 9 Idx: 0 Loss: 0.0364037209571396
Epoch: 9 Idx: 5000 Loss: 0.024548854047926578
Epoch: 10 Idx: 0 Loss: 0.02807249546389136
Epoch: 10 Idx: 5000 Loss: 0.006525243624183663
Epoch: 11 Idx: 0 Loss: 0.018708417537585634
Epoch: 11 Idx: 5000 Loss: 0.017006882153132938
Epoch: 12 Idx: 0 Loss: 0.010869251924397917
Epoch: 12 Idx: 5000 Loss: 0.008900408746592136
Epoch: 13 Idx: 0 Loss: 0.02872572401941495
Epoch: 13 Idx: 5000 Loss: 0.012303714494486374
Epoch: 14 Idx: 0 Loss: 0.018412017277225544
Epoch: 14 Idx: 5000 Loss: 0.024115347702384035
Epoch: 15 Idx: 0 Loss: 0.012541335102317912
Epoch: 15 Idx: 5000 Loss: 0.010662338707829604
Epoch: 16 Idx: 0 Loss: 0.036144046992599654
Epoch: 16 Idx: 5000 Loss: 0.041596563554673706
Epoch: 17 Idx: 0 Loss: 0.007708119729315694
Epoch: 17 Idx: 5000 Loss: 0.006936264785999638
Epoch: 18 Idx: 0 Loss: 0.02046668959431023
Epoch: 18 Idx: 5000 Loss: 0.011451955743661292
Epoch: 19 Idx: 0 Loss: 0.010824099655315389
Epoch: 19 Idx: 5000 Loss: 0.04856127733615494
Epoch: 20 Idx: 0 Loss: 0.021101892733258305
Epoch: 20 Idx: 5000 Loss: 0.014177209940615151
Epoch: 21 Idx: 0 Loss: 0.023367924728862545
Epoch: 21 Idx: 5000 Loss: 0.019829973340241485
Epoch: 22 Idx: 0 Loss: 0.012017648399794858
Epoch: 22 Idx: 5000 Loss: 0.016289878671453963
Epoch: 23 Idx: 0 Loss: 0.039984783452339016
Epoch: 23 Idx: 5000 Loss: 0.015619812174957937
Epoch: 24 Idx: 0 Loss: 0.012876855618517605
Epoch: 24 Idx: 5000 Loss: 0.03203583637102499
Epoch: 25 Idx: 0 Loss: 0.019261903861444368
Epoch: 25 Idx: 5000 Loss: 0.009761868944813106
Epoch: 26 Idx: 0 Loss: 0.005855602041700885
Epoch: 26 Idx: 5000 Loss: 0.007542887565848046
Epoch: 27 Idx: 0 Loss: 0.015890226691445318
Epoch: 27 Idx: 5000 Loss: 0.021867630814701233
Epoch: 28 Idx: 0 Loss: 0.014771343496524019
Epoch: 28 Idx: 5000 Loss: 0.008638085228531052
Epoch: 29 Idx: 0 Loss: 0.010658251412246186
Epoch: 29 Idx: 5000 Loss: 0.015352563309202611
Epoch: 30 Idx: 0 Loss: 0.025745373498128762
Epoch: 30 Idx: 5000 Loss: 0.009893108626850989
Epoch: 31 Idx: 0 Loss: 0.019348347005523993
Epoch: 31 Idx: 5000 Loss: 0.013026446603807394
Epoch: 32 Idx: 0 Loss: 0.013224500341787734
Epoch: 32 Idx: 5000 Loss: 0.014434458239153323
Epoch: 33 Idx: 0 Loss: 0.005443068087745064
Epoch: 33 Idx: 5000 Loss: 0.016247640698247946
Epoch: 34 Idx: 0 Loss: 0.04278564115461868
Epoch: 34 Idx: 5000 Loss: 0.010520533774853891
Epoch: 35 Idx: 0 Loss: 0.010654978850567785
Epoch: 35 Idx: 5000 Loss: 0.01456694634885426
Epoch: 36 Idx: 0 Loss: 0.01709004729495459
Epoch: 36 Idx: 5000 Loss: 0.026096550244228994
Epoch: 37 Idx: 0 Loss: 0.020420311927396902
Epoch: 37 Idx: 5000 Loss: 0.007705494979042235
Epoch: 38 Idx: 0 Loss: 0.00813719695234722
Epoch: 38 Idx: 5000 Loss: 0.016974995828739434
Epoch: 39 Idx: 0 Loss: 0.011787813627380574
Epoch: 39 Idx: 5000 Loss: 0.01243642489765175
Epoch: 40 Idx: 0 Loss: 0.029145829718807262
Epoch: 40 Idx: 5000 Loss: 0.026744262205369164
Epoch: 41 Idx: 0 Loss: 0.013246310102446814
Epoch: 41 Idx: 5000 Loss: 0.005214458316143399
Epoch: 42 Idx: 0 Loss: 0.023805495100338952
Epoch: 42 Idx: 5000 Loss: 0.015320328427868013
Epoch: 43 Idx: 0 Loss: 0.011790578191201774
Epoch: 43 Idx: 5000 Loss: 0.0069284071941638995
Epoch: 44 Idx: 0 Loss: 0.02041506046452274
Epoch: 44 Idx: 5000 Loss: 0.012607408138000398
Epoch: 45 Idx: 0 Loss: 0.011949260693067386
Epoch: 45 Idx: 5000 Loss: 0.01221673668420932
Epoch: 46 Idx: 0 Loss: 0.0077432815817738325
Epoch: 46 Idx: 5000 Loss: 0.017973703736691694
Epoch: 47 Idx: 0 Loss: 0.012404166698213008
Epoch: 47 Idx: 5000 Loss: 0.014378534814903284
Epoch: 48 Idx: 0 Loss: 0.01915749670785352
Epoch: 48 Idx: 5000 Loss: 0.007734809757891926
Epoch: 49 Idx: 0 Loss: 0.02137937165758816
Epoch: 49 Idx: 5000 Loss: 0.013305078390762014
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.23643758161835937
Epoch: 0 Idx: 5000 Loss: 0.017280965003487362
Epoch: 1 Idx: 0 Loss: 0.010048389161933478
Epoch: 1 Idx: 5000 Loss: 0.015841174008030458
Epoch: 2 Idx: 0 Loss: 0.014385520128382352
Epoch: 2 Idx: 5000 Loss: 0.021412785035899815
Epoch: 3 Idx: 0 Loss: 0.013204475142649896
Epoch: 3 Idx: 5000 Loss: 0.007969648675404799
Epoch: 4 Idx: 0 Loss: 0.012750409755478344
Epoch: 4 Idx: 5000 Loss: 0.011706637194319065
Epoch: 5 Idx: 0 Loss: 0.01931009554502728
Epoch: 5 Idx: 5000 Loss: 0.011228054584156268
Epoch: 6 Idx: 0 Loss: 0.020524124119147433
Epoch: 6 Idx: 5000 Loss: 0.019612912010529105
Epoch: 7 Idx: 0 Loss: 0.017991122694850682
Epoch: 7 Idx: 5000 Loss: 0.02145658503286909
Epoch: 8 Idx: 0 Loss: 0.009982337258154603
Epoch: 8 Idx: 5000 Loss: 0.026524012100547223
Epoch: 9 Idx: 0 Loss: 0.007810635890871637
Epoch: 9 Idx: 5000 Loss: 0.007731641814880761
Epoch: 10 Idx: 0 Loss: 0.0068163055741421
Epoch: 10 Idx: 5000 Loss: 0.014670829074630465
Epoch: 11 Idx: 0 Loss: 0.006934670795233171
Epoch: 11 Idx: 5000 Loss: 0.012513904208581714
Epoch: 12 Idx: 0 Loss: 0.012144577115686436
Epoch: 12 Idx: 5000 Loss: 0.013978094412226694
Epoch: 13 Idx: 0 Loss: 0.030258316861381997
Epoch: 13 Idx: 5000 Loss: 0.024901690957508403
Epoch: 14 Idx: 0 Loss: 0.044413536557820155
Epoch: 14 Idx: 5000 Loss: 0.012648866397861296
Epoch: 15 Idx: 0 Loss: 0.011308237940821277
Epoch: 15 Idx: 5000 Loss: 0.015342751004452988
Epoch: 16 Idx: 0 Loss: 0.010748725238390692
Epoch: 16 Idx: 5000 Loss: 0.0202924329970547
Epoch: 17 Idx: 0 Loss: 0.021032544567813064
Epoch: 17 Idx: 5000 Loss: 0.007247450815509981
Epoch: 18 Idx: 0 Loss: 0.0062494993439609695
Epoch: 18 Idx: 5000 Loss: 0.008897380002617396
Epoch: 19 Idx: 0 Loss: 0.008696338897758199
Epoch: 19 Idx: 5000 Loss: 0.01412552889649769
Epoch: 20 Idx: 0 Loss: 0.019035820667510778
Epoch: 20 Idx: 5000 Loss: 0.029903521452976475
Epoch: 21 Idx: 0 Loss: 0.005458969998054548
Epoch: 21 Idx: 5000 Loss: 0.03766370442265308
Epoch: 22 Idx: 0 Loss: 0.008023432975806708
Epoch: 22 Idx: 5000 Loss: 0.01855829131756056
Epoch: 23 Idx: 0 Loss: 0.008570205352895778
Epoch: 23 Idx: 5000 Loss: 0.02511498721449874
Epoch: 24 Idx: 0 Loss: 0.012977667521035357
Epoch: 24 Idx: 5000 Loss: 0.010659719917909472
Epoch: 25 Idx: 0 Loss: 0.04794738508022079
Epoch: 25 Idx: 5000 Loss: 0.010576401115325781
Epoch: 26 Idx: 0 Loss: 0.009848314529794193
Epoch: 26 Idx: 5000 Loss: 0.010187974191232987
Epoch: 27 Idx: 0 Loss: 0.0237593696608831
Epoch: 27 Idx: 5000 Loss: 0.042028576087866365
Epoch: 28 Idx: 0 Loss: 0.009219559674731587
Epoch: 28 Idx: 5000 Loss: 0.015350784677811171
Epoch: 29 Idx: 0 Loss: 0.013258683909143185
Epoch: 29 Idx: 5000 Loss: 0.023741228385066006
Epoch: 30 Idx: 0 Loss: 0.014525783486887198
Epoch: 30 Idx: 5000 Loss: 0.011803730078151603
Epoch: 31 Idx: 0 Loss: 0.01915225021786877
Epoch: 31 Idx: 5000 Loss: 0.010004393673917434
Epoch: 32 Idx: 0 Loss: 0.012542251936849647
Epoch: 32 Idx: 5000 Loss: 0.02125956145153644
Epoch: 33 Idx: 0 Loss: 0.016191903043397023
Epoch: 33 Idx: 5000 Loss: 0.020649584857838393
Epoch: 34 Idx: 0 Loss: 0.01641921851281647
Epoch: 34 Idx: 5000 Loss: 0.01940074197757241
Epoch: 35 Idx: 0 Loss: 0.007129105916885857
Epoch: 35 Idx: 5000 Loss: 0.015324286798409957
Epoch: 36 Idx: 0 Loss: 0.016378238246447817
Epoch: 36 Idx: 5000 Loss: 0.00812380447892917
Epoch: 37 Idx: 0 Loss: 0.012904468205133161
Epoch: 37 Idx: 5000 Loss: 0.00939911889649745
Epoch: 38 Idx: 0 Loss: 0.01788472200653818
Epoch: 38 Idx: 5000 Loss: 0.013668782540800353
Epoch: 39 Idx: 0 Loss: 0.009642086172479776
Epoch: 39 Idx: 5000 Loss: 0.029560525536099405
Epoch: 40 Idx: 0 Loss: 0.015048765438482681
Epoch: 40 Idx: 5000 Loss: 0.04150161244506531
Epoch: 41 Idx: 0 Loss: 0.013753984913799037
Epoch: 41 Idx: 5000 Loss: 0.009716800526224374
Epoch: 42 Idx: 0 Loss: 0.01126688778802571
Epoch: 42 Idx: 5000 Loss: 0.022728234579269924
Epoch: 43 Idx: 0 Loss: 0.008436056018376412
Epoch: 43 Idx: 5000 Loss: 0.01575018795591341
Epoch: 44 Idx: 0 Loss: 0.009446989929248154
Epoch: 44 Idx: 5000 Loss: 0.016096562705073682
Epoch: 45 Idx: 0 Loss: 0.023074522467774534
Epoch: 45 Idx: 5000 Loss: 0.013108168310748274
Epoch: 46 Idx: 0 Loss: 0.040850079060139974
Epoch: 46 Idx: 5000 Loss: 0.029615687997367787
Epoch: 47 Idx: 0 Loss: 0.017690887349462267
Epoch: 47 Idx: 5000 Loss: 0.030391792496969848
Epoch: 48 Idx: 0 Loss: 0.040864463315072805
Epoch: 48 Idx: 5000 Loss: 0.04088384580531885
Epoch: 49 Idx: 0 Loss: 0.01395522183425126
Epoch: 49 Idx: 5000 Loss: 0.014947080450378878
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.22638730751899513
Epoch: 0 Idx: 5000 Loss: 0.012311316525465058
Epoch: 1 Idx: 0 Loss: 0.019849282880985586
Epoch: 1 Idx: 5000 Loss: 0.019278014150011166
Epoch: 2 Idx: 0 Loss: 0.03745469493920055
Epoch: 2 Idx: 5000 Loss: 0.012450080064847626
Epoch: 3 Idx: 0 Loss: 0.027295383087803105
Epoch: 3 Idx: 5000 Loss: 0.005989541468846212
Epoch: 4 Idx: 0 Loss: 0.012121235184349094
Epoch: 4 Idx: 5000 Loss: 0.009058904208626706
Epoch: 5 Idx: 0 Loss: 0.01241520411193512
Epoch: 5 Idx: 5000 Loss: 0.011451440765929187
Epoch: 6 Idx: 0 Loss: 0.008738890432061944
Epoch: 6 Idx: 5000 Loss: 0.012868212420250736
Epoch: 7 Idx: 0 Loss: 0.017112415072310934
Epoch: 7 Idx: 5000 Loss: 0.021521865863440473
Epoch: 8 Idx: 0 Loss: 0.010634872767225394
Epoch: 8 Idx: 5000 Loss: 0.017328123112860454
Epoch: 9 Idx: 0 Loss: 0.02365105540177581
Epoch: 9 Idx: 5000 Loss: 0.013490317983991357
Epoch: 10 Idx: 0 Loss: 0.010148300895209118
Epoch: 10 Idx: 5000 Loss: 0.008032183261933229
Epoch: 11 Idx: 0 Loss: 0.01449914244979544
Epoch: 11 Idx: 5000 Loss: 0.0103726594974277
Epoch: 12 Idx: 0 Loss: 0.029934752381692697
Epoch: 12 Idx: 5000 Loss: 0.025501914610224143
Epoch: 13 Idx: 0 Loss: 0.022601988898494903
Epoch: 13 Idx: 5000 Loss: 0.01422381506029834
Epoch: 14 Idx: 0 Loss: 0.016182032800245452
Epoch: 14 Idx: 5000 Loss: 0.01838466205011742
Epoch: 15 Idx: 0 Loss: 0.013004626097099724
Epoch: 15 Idx: 5000 Loss: 0.017258276398283923
Epoch: 16 Idx: 0 Loss: 0.014971879806158174
Epoch: 16 Idx: 5000 Loss: 0.02502652113562385
Epoch: 17 Idx: 0 Loss: 0.01497873104192653
Epoch: 17 Idx: 5000 Loss: 0.007415835019594021
Epoch: 18 Idx: 0 Loss: 0.018056116004853604
Epoch: 18 Idx: 5000 Loss: 0.009469826183969965
Epoch: 19 Idx: 0 Loss: 0.023325403271704143
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 345, in forward
    + self.w_data_neighbours * distance_weighted_path[:,3,:]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc217>
Subject: Job 4066857: <python main.py 5 10 False False> in cluster <dcc> Exited

Job <python main.py 5 10 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc217>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 10 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46126.13 sec.
    Max Memory :                                 2933 MB
    Average Memory :                             2739.25 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40484.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46222 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

