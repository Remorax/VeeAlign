2020-09-15 15:49:39.156658: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.618354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:42.736900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:42.737014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.739252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:42.740901: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:42.741850: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:42.743982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:42.745513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:42.745811: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:42.745834: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:42.746193: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:42.754774: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599845000 Hz
2020-09-15 15:49:42.754981: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ba34fd89f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:42.755004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:42.757100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:42.757144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.17266170931777866
Epoch: 0 Idx: 5000 Loss: 0.008375210371355357
Epoch: 1 Idx: 0 Loss: 0.032352155808193214
Epoch: 1 Idx: 5000 Loss: 0.022371174811165885
Epoch: 2 Idx: 0 Loss: 0.0071527173526232625
Epoch: 2 Idx: 5000 Loss: 0.011567903211935807
Epoch: 3 Idx: 0 Loss: 0.015293128557107832
Epoch: 3 Idx: 5000 Loss: 0.02312387911543851
Epoch: 4 Idx: 0 Loss: 0.010927761226813552
Epoch: 4 Idx: 5000 Loss: 0.008635646824841574
Epoch: 5 Idx: 0 Loss: 0.029423832005593342
Epoch: 5 Idx: 5000 Loss: 0.03148025981952945
Epoch: 6 Idx: 0 Loss: 0.014917051801315934
Epoch: 6 Idx: 5000 Loss: 0.010088375578175449
Epoch: 7 Idx: 0 Loss: 0.017991647831510846
Epoch: 7 Idx: 5000 Loss: 0.021356654715748404
Epoch: 8 Idx: 0 Loss: 0.009048683579896735
Epoch: 8 Idx: 5000 Loss: 0.01100780102884432
Epoch: 9 Idx: 0 Loss: 0.016009484608484253
Epoch: 9 Idx: 5000 Loss: 0.00703771138811202
Epoch: 10 Idx: 0 Loss: 0.007850822705665523
Epoch: 10 Idx: 5000 Loss: 0.015991113478159055
Epoch: 11 Idx: 0 Loss: 0.029626347563326244
Epoch: 11 Idx: 5000 Loss: 0.0254975802291487
Epoch: 12 Idx: 0 Loss: 0.010489287426354528
Epoch: 12 Idx: 5000 Loss: 0.016444736590712127
Epoch: 13 Idx: 0 Loss: 0.012761533776358943
Epoch: 13 Idx: 5000 Loss: 0.012293987897033704
Epoch: 14 Idx: 0 Loss: 0.01840190855646336
Epoch: 14 Idx: 5000 Loss: 0.019379414480747016
Epoch: 15 Idx: 0 Loss: 0.015258743421076231
Epoch: 15 Idx: 5000 Loss: 0.0106147730167479
Epoch: 16 Idx: 0 Loss: 0.010138155570245229
Epoch: 16 Idx: 5000 Loss: 0.00995409260767387
Epoch: 17 Idx: 0 Loss: 0.00925615155959724
Epoch: 17 Idx: 5000 Loss: 0.02358733700531878
Epoch: 18 Idx: 0 Loss: 0.005927936153937241
Epoch: 18 Idx: 5000 Loss: 0.019287634609621115
Epoch: 19 Idx: 0 Loss: 0.014615293739558255
Epoch: 19 Idx: 5000 Loss: 0.011049026844534047
Epoch: 20 Idx: 0 Loss: 0.004621847666255765
Epoch: 20 Idx: 5000 Loss: 0.008525509787172819
Epoch: 21 Idx: 0 Loss: 0.007382179464974957
Epoch: 21 Idx: 5000 Loss: 0.03774488332543022
Epoch: 22 Idx: 0 Loss: 0.014322979022912487
Epoch: 22 Idx: 5000 Loss: 0.017614501730034187
Epoch: 23 Idx: 0 Loss: 0.018680371391064418
Epoch: 23 Idx: 5000 Loss: 0.017420333079571842
Epoch: 24 Idx: 0 Loss: 0.03414174424675865
Epoch: 24 Idx: 5000 Loss: 0.011332516394201412
Epoch: 25 Idx: 0 Loss: 0.016935763965324868
Epoch: 25 Idx: 5000 Loss: 0.014851569590746483
Epoch: 26 Idx: 0 Loss: 0.030263777138704834
Epoch: 26 Idx: 5000 Loss: 0.009879236405788193
Epoch: 27 Idx: 0 Loss: 0.012930283820000714
Epoch: 27 Idx: 5000 Loss: 0.02121543534741684
Epoch: 28 Idx: 0 Loss: 0.009965977729042112
Epoch: 28 Idx: 5000 Loss: 0.03698024694381479
Epoch: 29 Idx: 0 Loss: 0.014018792847660057
Epoch: 29 Idx: 5000 Loss: 0.009837664427663243
Epoch: 30 Idx: 0 Loss: 0.013338900375504132
Epoch: 30 Idx: 5000 Loss: 0.011521223368351834
Epoch: 31 Idx: 0 Loss: 0.03995246266118931
Epoch: 31 Idx: 5000 Loss: 0.02394264005321115
Epoch: 32 Idx: 0 Loss: 0.01965795570920955
Epoch: 32 Idx: 5000 Loss: 0.015177350090697261
Epoch: 33 Idx: 0 Loss: 0.025785781512297785
Epoch: 33 Idx: 5000 Loss: 0.01780985568767103
Epoch: 34 Idx: 0 Loss: 0.018808346801644737
Epoch: 34 Idx: 5000 Loss: 0.027146518567724393
Epoch: 35 Idx: 0 Loss: 0.01096094040687668
Epoch: 35 Idx: 5000 Loss: 0.020809956714529385
Epoch: 36 Idx: 0 Loss: 0.0064838823283424225
Epoch: 36 Idx: 5000 Loss: 0.012644530237501641
Epoch: 37 Idx: 0 Loss: 0.019685194782409245
Epoch: 37 Idx: 5000 Loss: 0.0187409207414156
Epoch: 38 Idx: 0 Loss: 0.013738087081024444
Epoch: 38 Idx: 5000 Loss: 0.05286468855232525
Epoch: 39 Idx: 0 Loss: 0.025570747788059726
Epoch: 39 Idx: 5000 Loss: 0.017937793154869253
Epoch: 40 Idx: 0 Loss: 0.0071947718904584925
Epoch: 40 Idx: 5000 Loss: 0.010950196445848487
Epoch: 41 Idx: 0 Loss: 0.02466565384942632
Epoch: 41 Idx: 5000 Loss: 0.012356382965961477
Epoch: 42 Idx: 0 Loss: 0.005456471065530282
Epoch: 42 Idx: 5000 Loss: 0.012728869223401487
Epoch: 43 Idx: 0 Loss: 0.016500369731469292
Epoch: 43 Idx: 5000 Loss: 0.038825146984617136
Epoch: 44 Idx: 0 Loss: 0.006063444789274418
Epoch: 44 Idx: 5000 Loss: 0.04306660156873229
Epoch: 45 Idx: 0 Loss: 0.005293591330134873
Epoch: 45 Idx: 5000 Loss: 0.031415396865523186
Epoch: 46 Idx: 0 Loss: 0.018391605877474602
Epoch: 46 Idx: 5000 Loss: 0.008713195148595672
Epoch: 47 Idx: 0 Loss: 0.015072289827921775
Epoch: 47 Idx: 5000 Loss: 0.026357247558804472
Epoch: 48 Idx: 0 Loss: 0.011138158890253207
Epoch: 48 Idx: 5000 Loss: 0.018974653551516986
Epoch: 49 Idx: 0 Loss: 0.00978729363468188
Epoch: 49 Idx: 5000 Loss: 0.01400397651511512
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14361439725109643
Epoch: 0 Idx: 5000 Loss: 0.027924059206423057
Epoch: 1 Idx: 0 Loss: 0.01097929303846707
Epoch: 1 Idx: 5000 Loss: 0.01867976761114682
Epoch: 2 Idx: 0 Loss: 0.025709928371381887
Epoch: 2 Idx: 5000 Loss: 0.02137742220797009
Epoch: 3 Idx: 0 Loss: 0.013637917699232215
Epoch: 3 Idx: 5000 Loss: 0.012904948221104637
Epoch: 4 Idx: 0 Loss: 0.00953738645849093
Epoch: 4 Idx: 5000 Loss: 0.013359847112528663
Epoch: 5 Idx: 0 Loss: 0.017965814067253952
Epoch: 5 Idx: 5000 Loss: 0.006065802734077247
Epoch: 6 Idx: 0 Loss: 0.01455693611302617
Epoch: 6 Idx: 5000 Loss: 0.00937441367713254
Epoch: 7 Idx: 0 Loss: 0.010866081037330855
Epoch: 7 Idx: 5000 Loss: 0.009446886104337408
Epoch: 8 Idx: 0 Loss: 0.008810731642474952
Epoch: 8 Idx: 5000 Loss: 0.014661343806034666
Epoch: 9 Idx: 0 Loss: 0.016919172605999833
Epoch: 9 Idx: 5000 Loss: 0.02089283180377484
Epoch: 10 Idx: 0 Loss: 0.01071520788753133
Epoch: 10 Idx: 5000 Loss: 0.025969437562674932
Epoch: 11 Idx: 0 Loss: 0.02010906511592349
Epoch: 11 Idx: 5000 Loss: 0.011165966877395463
Epoch: 12 Idx: 0 Loss: 0.010599715479052411
Epoch: 12 Idx: 5000 Loss: 0.02768827722875763
Epoch: 13 Idx: 0 Loss: 0.032199664684896726
Epoch: 13 Idx: 5000 Loss: 0.007868511788484914
Epoch: 14 Idx: 0 Loss: 0.02124913237152149
Epoch: 14 Idx: 5000 Loss: 0.02001315664151865
Epoch: 15 Idx: 0 Loss: 0.0214933033840039
Epoch: 15 Idx: 5000 Loss: 0.02169579914198102
Epoch: 16 Idx: 0 Loss: 0.01451286827291522
Epoch: 16 Idx: 5000 Loss: 0.04012127482421219
Epoch: 17 Idx: 0 Loss: 0.00892472996291023
Epoch: 17 Idx: 5000 Loss: 0.01038939241296125
Epoch: 18 Idx: 0 Loss: 0.01483241419139176
Epoch: 18 Idx: 5000 Loss: 0.007583295973967696
Epoch: 19 Idx: 0 Loss: 0.010255706966700848
Epoch: 19 Idx: 5000 Loss: 0.011192003529291263
Epoch: 20 Idx: 0 Loss: 0.010155725439255386
Epoch: 20 Idx: 5000 Loss: 0.011364053493840806
Epoch: 21 Idx: 0 Loss: 0.006052026008235987
Epoch: 21 Idx: 5000 Loss: 0.00703391133285638
Epoch: 22 Idx: 0 Loss: 0.009892627780942655
Epoch: 22 Idx: 5000 Loss: 0.02109165915220084
Epoch: 23 Idx: 0 Loss: 0.01396016438418576
Epoch: 23 Idx: 5000 Loss: 0.013754021480543086
Epoch: 24 Idx: 0 Loss: 0.02289685150967228
Epoch: 24 Idx: 5000 Loss: 0.016757246249981015
Epoch: 25 Idx: 0 Loss: 0.010755559001471227
Epoch: 25 Idx: 5000 Loss: 0.021984116305281208
Epoch: 26 Idx: 0 Loss: 0.007757134838009998
Epoch: 26 Idx: 5000 Loss: 0.005178863083124438
Epoch: 27 Idx: 0 Loss: 0.029118301352325772
Epoch: 27 Idx: 5000 Loss: 0.02839497780691359
Epoch: 28 Idx: 0 Loss: 0.013040616026148522
Epoch: 28 Idx: 5000 Loss: 0.007690171891202134
Epoch: 29 Idx: 0 Loss: 0.01023714518786329
Epoch: 29 Idx: 5000 Loss: 0.03577551911178433
Epoch: 30 Idx: 0 Loss: 0.015591048702118464
Epoch: 30 Idx: 5000 Loss: 0.020347746388276557
Epoch: 31 Idx: 0 Loss: 0.01736796419936945
Epoch: 31 Idx: 5000 Loss: 0.03050974223604193
Epoch: 32 Idx: 0 Loss: 0.023803760089772863
Epoch: 32 Idx: 5000 Loss: 0.03299021298643442
Epoch: 33 Idx: 0 Loss: 0.026687477142400964
Epoch: 33 Idx: 5000 Loss: 0.0060085803344542416
Epoch: 34 Idx: 0 Loss: 0.05378208634800255
Epoch: 34 Idx: 5000 Loss: 0.011746570662451447
Epoch: 35 Idx: 0 Loss: 0.019022073360632774
Epoch: 35 Idx: 5000 Loss: 0.007800989924906956
Epoch: 36 Idx: 0 Loss: 0.014300452091702758
Epoch: 36 Idx: 5000 Loss: 0.008494003414879416
Epoch: 37 Idx: 0 Loss: 0.01197101393801021
Epoch: 37 Idx: 5000 Loss: 0.017479068254992854
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 312, in forward
    feature_emb = self.name_embedding(features[i]) #  dim: (2, batch_size, max_types, max_paths, max_pathlen, 512)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1814, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc219>
Subject: Job 4066890: <python main.py 6 20 False True> in cluster <dcc> Exited

Job <python main.py 6 20 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc219>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 20 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46143.31 sec.
    Max Memory :                                 2995 MB
    Average Memory :                             2757.37 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40422.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46142 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

