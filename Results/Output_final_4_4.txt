2020-09-15 15:48:45.259442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:56.011443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:56.131358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:56.131447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:56.133781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:56.135450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:56.136345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:56.138434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:56.140057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:56.140375: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:56.140397: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:56.140818: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:56.185375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600065000 Hz
2020-09-15 15:48:56.185668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a1e2401d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:56.185690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:56.188865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:56.188916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.21474424983686455
Epoch: 0 Idx: 5000 Loss: 0.005118430035203616
Epoch: 1 Idx: 0 Loss: 0.01321448346160552
Epoch: 1 Idx: 5000 Loss: 0.027138605792695912
Epoch: 2 Idx: 0 Loss: 0.01000603070753281
Epoch: 2 Idx: 5000 Loss: 0.014357175358012092
Epoch: 3 Idx: 0 Loss: 0.023548514169109955
Epoch: 3 Idx: 5000 Loss: 0.012268911501304899
Epoch: 4 Idx: 0 Loss: 0.03908309439857065
Epoch: 4 Idx: 5000 Loss: 0.012244298181940692
Epoch: 5 Idx: 0 Loss: 0.014219647454089062
Epoch: 5 Idx: 5000 Loss: 0.025347376401303967
Epoch: 6 Idx: 0 Loss: 0.009354615108333294
Epoch: 6 Idx: 5000 Loss: 0.023623005686417335
Epoch: 7 Idx: 0 Loss: 0.010183147301133687
Epoch: 7 Idx: 5000 Loss: 0.014263813879504933
Epoch: 8 Idx: 0 Loss: 0.014344537027317536
Epoch: 8 Idx: 5000 Loss: 0.007187157105335578
Epoch: 9 Idx: 0 Loss: 0.011172855026158666
Epoch: 9 Idx: 5000 Loss: 0.013634676931403843
Epoch: 10 Idx: 0 Loss: 0.017213976506994216
Epoch: 10 Idx: 5000 Loss: 0.02636915497992908
Epoch: 11 Idx: 0 Loss: 0.027797497391097846
Epoch: 11 Idx: 5000 Loss: 0.021057331619039495
Epoch: 12 Idx: 0 Loss: 0.006854578450298921
Epoch: 12 Idx: 5000 Loss: 0.0106853850684832
Epoch: 13 Idx: 0 Loss: 0.02686800669596389
Epoch: 13 Idx: 5000 Loss: 0.013343344212862039
Epoch: 14 Idx: 0 Loss: 0.013560528581835336
Epoch: 14 Idx: 5000 Loss: 0.01718744907621922
Epoch: 15 Idx: 0 Loss: 0.012049292293786384
Epoch: 15 Idx: 5000 Loss: 0.013200544147397244
Epoch: 16 Idx: 0 Loss: 0.017657947923680854
Epoch: 16 Idx: 5000 Loss: 0.007565272142600758
Epoch: 17 Idx: 0 Loss: 0.02331346572524656
Epoch: 17 Idx: 5000 Loss: 0.024245626035591144
Epoch: 18 Idx: 0 Loss: 0.019779289256108154
Epoch: 18 Idx: 5000 Loss: 0.03782202776885143
Epoch: 19 Idx: 0 Loss: 0.0092293698580124
Epoch: 19 Idx: 5000 Loss: 0.05045951818774877
Epoch: 20 Idx: 0 Loss: 0.0146315836051785
Epoch: 20 Idx: 5000 Loss: 0.005491262330960536
Epoch: 21 Idx: 0 Loss: 0.0244238397589769
Epoch: 21 Idx: 5000 Loss: 0.013283404607280464
Epoch: 22 Idx: 0 Loss: 0.007121489904482935
Epoch: 22 Idx: 5000 Loss: 0.018019927310528316
Epoch: 23 Idx: 0 Loss: 0.011957000855754305
Epoch: 23 Idx: 5000 Loss: 0.017851958065357047
Epoch: 24 Idx: 0 Loss: 0.015060088215599399
Epoch: 24 Idx: 5000 Loss: 0.004408285910730787
Epoch: 25 Idx: 0 Loss: 0.011015862717783396
Epoch: 25 Idx: 5000 Loss: 0.011377159726757562
Epoch: 26 Idx: 0 Loss: 0.02039306096981397
Epoch: 26 Idx: 5000 Loss: 0.012017989543297549
Epoch: 27 Idx: 0 Loss: 0.012962206919973912
Epoch: 27 Idx: 5000 Loss: 0.016146419388404214
Epoch: 28 Idx: 0 Loss: 0.025830285159366195
Epoch: 28 Idx: 5000 Loss: 0.023873801116735954
Epoch: 29 Idx: 0 Loss: 0.02981345237424518
Epoch: 29 Idx: 5000 Loss: 0.00868670969064381
Epoch: 30 Idx: 0 Loss: 0.009775753859745101
Epoch: 30 Idx: 5000 Loss: 0.003682838555452871
Epoch: 31 Idx: 0 Loss: 0.024245806872764362
Epoch: 31 Idx: 5000 Loss: 0.017127443368072506
Epoch: 32 Idx: 0 Loss: 0.012635114439297067
Epoch: 32 Idx: 5000 Loss: 0.007983941188739845
Epoch: 33 Idx: 0 Loss: 0.012651502968662846
Epoch: 33 Idx: 5000 Loss: 0.008436314617233893
Epoch: 34 Idx: 0 Loss: 0.00816285624242069
Epoch: 34 Idx: 5000 Loss: 0.01022812460657594
Epoch: 35 Idx: 0 Loss: 0.021432790658543477
Epoch: 35 Idx: 5000 Loss: 0.006646885767693304
Epoch: 36 Idx: 0 Loss: 0.020924686058376104
Epoch: 36 Idx: 5000 Loss: 0.017507617992562403
Epoch: 37 Idx: 0 Loss: 0.014240754635594138
Epoch: 37 Idx: 5000 Loss: 0.017170312417929268
Epoch: 38 Idx: 0 Loss: 0.01633325240695946
Epoch: 38 Idx: 5000 Loss: 0.022684675585076745
Epoch: 39 Idx: 0 Loss: 0.0141864891939263
Epoch: 39 Idx: 5000 Loss: 0.04120064559042423
Epoch: 40 Idx: 0 Loss: 0.010725263917955927
Epoch: 40 Idx: 5000 Loss: 0.01281412485251259
Epoch: 41 Idx: 0 Loss: 0.023190394708942755
Epoch: 41 Idx: 5000 Loss: 0.015387791941091807
Epoch: 42 Idx: 0 Loss: 0.011442707022199258
Epoch: 42 Idx: 5000 Loss: 0.010258937426928627
Epoch: 43 Idx: 0 Loss: 0.019197175537326666
Epoch: 43 Idx: 5000 Loss: 0.007188925547127763
Epoch: 44 Idx: 0 Loss: 0.012050432057973308
Epoch: 44 Idx: 5000 Loss: 0.02461552819060918
Epoch: 45 Idx: 0 Loss: 0.01147179093404879
Epoch: 45 Idx: 5000 Loss: 0.015512380673771595
Epoch: 46 Idx: 0 Loss: 0.006446305112733307
Epoch: 46 Idx: 5000 Loss: 0.012292112098602963
Epoch: 47 Idx: 0 Loss: 0.022100557947010182
Epoch: 47 Idx: 5000 Loss: 0.01348644200464115
Epoch: 48 Idx: 0 Loss: 0.012746919259557803
Epoch: 48 Idx: 5000 Loss: 0.015417851346187334
Epoch: 49 Idx: 0 Loss: 0.022282689493858324
Epoch: 49 Idx: 5000 Loss: 0.017925594615233603
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1400222437393715
Epoch: 0 Idx: 5000 Loss: 0.012332034999788497
Epoch: 1 Idx: 0 Loss: 0.020810243531264674
Epoch: 1 Idx: 5000 Loss: 0.01831203256836029
Epoch: 2 Idx: 0 Loss: 0.025401618298817152
Epoch: 2 Idx: 5000 Loss: 0.011462315357252584
Epoch: 3 Idx: 0 Loss: 0.01833037167406806
Epoch: 3 Idx: 5000 Loss: 0.018869309340040608
Epoch: 4 Idx: 0 Loss: 0.010070530095502853
Epoch: 4 Idx: 5000 Loss: 0.01346024899218069
Epoch: 5 Idx: 0 Loss: 0.018373484060675523
Epoch: 5 Idx: 5000 Loss: 0.022155179458769964
Epoch: 6 Idx: 0 Loss: 0.016710323312934275
Epoch: 6 Idx: 5000 Loss: 0.0054522993915152975
Epoch: 7 Idx: 0 Loss: 0.014404499591697033
Epoch: 7 Idx: 5000 Loss: 0.028803997346281113
Epoch: 8 Idx: 0 Loss: 0.021112180175219552
Epoch: 8 Idx: 5000 Loss: 0.009574055510882895
Epoch: 9 Idx: 0 Loss: 0.03887212583530121
Epoch: 9 Idx: 5000 Loss: 0.013289991654060373
Epoch: 10 Idx: 0 Loss: 0.016655660553674578
Epoch: 10 Idx: 5000 Loss: 0.01889822047788449
Epoch: 11 Idx: 0 Loss: 0.010034498122817098
Epoch: 11 Idx: 5000 Loss: 0.005739640069271426
Epoch: 12 Idx: 0 Loss: 0.01657069962222929
Epoch: 12 Idx: 5000 Loss: 0.014445166227984932
Epoch: 13 Idx: 0 Loss: 0.01510829054198265
Epoch: 13 Idx: 5000 Loss: 0.03560458422782994
Epoch: 14 Idx: 0 Loss: 0.00601364038375858
Epoch: 14 Idx: 5000 Loss: 0.032228694126061525
Epoch: 15 Idx: 0 Loss: 0.011042363077109379
Epoch: 15 Idx: 5000 Loss: 0.0216114259829425
Epoch: 16 Idx: 0 Loss: 0.025741692175664972
Epoch: 16 Idx: 5000 Loss: 0.010166038365634724
Epoch: 17 Idx: 0 Loss: 0.009804790383506299
Epoch: 17 Idx: 5000 Loss: 0.042586905273917085
Epoch: 18 Idx: 0 Loss: 0.00845350280919574
Epoch: 18 Idx: 5000 Loss: 0.014083539290212421
Epoch: 19 Idx: 0 Loss: 0.027233144125203494
Epoch: 19 Idx: 5000 Loss: 0.01527386051565194
Epoch: 20 Idx: 0 Loss: 0.021236811364287164
Epoch: 20 Idx: 5000 Loss: 0.013423285810037083
Epoch: 21 Idx: 0 Loss: 0.011136007471159882
Epoch: 21 Idx: 5000 Loss: 0.01505218125625672
Epoch: 22 Idx: 0 Loss: 0.008112798789545385
Epoch: 22 Idx: 5000 Loss: 0.026940767131458643
Epoch: 23 Idx: 0 Loss: 0.009311686939835577
Epoch: 23 Idx: 5000 Loss: 0.014310032018380884
Epoch: 24 Idx: 0 Loss: 0.017010225237315994
Epoch: 24 Idx: 5000 Loss: 0.00847389075511332
Epoch: 25 Idx: 0 Loss: 0.019056189808733078
Epoch: 25 Idx: 5000 Loss: 0.045322478406196055
Epoch: 26 Idx: 0 Loss: 0.024036305862264556
Epoch: 26 Idx: 5000 Loss: 0.008096444371448991
Epoch: 27 Idx: 0 Loss: 0.015969310787712167
Epoch: 27 Idx: 5000 Loss: 0.011810483863132852
Epoch: 28 Idx: 0 Loss: 0.009506668086069486
Epoch: 28 Idx: 5000 Loss: 0.026092376462674934
Epoch: 29 Idx: 0 Loss: 0.010204932554043276
Epoch: 29 Idx: 5000 Loss: 0.027310914716937234
Epoch: 30 Idx: 0 Loss: 0.01972395172020561
Epoch: 30 Idx: 5000 Loss: 0.02205027812969062
Epoch: 31 Idx: 0 Loss: 0.01787846550112076
Epoch: 31 Idx: 5000 Loss: 0.019551810954883488
Epoch: 32 Idx: 0 Loss: 0.03338328671895403
Epoch: 32 Idx: 5000 Loss: 0.012193012878059264
Epoch: 33 Idx: 0 Loss: 0.021918230756819194
Epoch: 33 Idx: 5000 Loss: 0.020925450604881185
Epoch: 34 Idx: 0 Loss: 0.010703180676380448
Epoch: 34 Idx: 5000 Loss: 0.02148701720281056
Epoch: 35 Idx: 0 Loss: 0.020520347665137793
Epoch: 35 Idx: 5000 Loss: 0.013071351030816981
Epoch: 36 Idx: 0 Loss: 0.009835457389838733
Epoch: 36 Idx: 5000 Loss: 0.015415163184501915
Epoch: 37 Idx: 0 Loss: 0.010464897269677033
Epoch: 37 Idx: 5000 Loss: 0.015047501187464798
Epoch: 38 Idx: 0 Loss: 0.010399589630722728
Epoch: 38 Idx: 5000 Loss: 0.015075960258457822
Epoch: 39 Idx: 0 Loss: 0.018676640561239938
Epoch: 39 Idx: 5000 Loss: 0.027341280310349624
Epoch: 40 Idx: 0 Loss: 0.021806391706493494
Epoch: 40 Idx: 5000 Loss: 0.0257414338555108
Epoch: 41 Idx: 0 Loss: 0.009683735061918672
Epoch: 41 Idx: 5000 Loss: 0.014839504009254035
Epoch: 42 Idx: 0 Loss: 0.009414425003055005
Epoch: 42 Idx: 5000 Loss: 0.08355933440198522
Epoch: 43 Idx: 0 Loss: 0.015744952639725928
Epoch: 43 Idx: 5000 Loss: 0.008458914875429602
Epoch: 44 Idx: 0 Loss: 0.021729839612633042
Epoch: 44 Idx: 5000 Loss: 0.01364118591043833
Epoch: 45 Idx: 0 Loss: 0.014430966293955043
Epoch: 45 Idx: 5000 Loss: 0.017350786601833677
Epoch: 46 Idx: 0 Loss: 0.02808033221980144
Epoch: 46 Idx: 5000 Loss: 0.008371752082208608
Epoch: 47 Idx: 0 Loss: 0.009521610458865414
Epoch: 47 Idx: 5000 Loss: 0.033178136404230764
Epoch: 48 Idx: 0 Loss: 0.011843727920073335
Epoch: 48 Idx: 5000 Loss: 0.012468337336461785
Epoch: 49 Idx: 0 Loss: 0.013299190628094867
Epoch: 49 Idx: 5000 Loss: 0.01182333980462984
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14492698645575133
Epoch: 0 Idx: 5000 Loss: 0.025970908465560556
Epoch: 1 Idx: 0 Loss: 0.018619261639451753
Epoch: 1 Idx: 5000 Loss: 0.01824762939688141
Epoch: 2 Idx: 0 Loss: 0.011029720510362079
Epoch: 2 Idx: 5000 Loss: 0.011240615497884613
Epoch: 3 Idx: 0 Loss: 0.018400126612338266
Epoch: 3 Idx: 5000 Loss: 0.0196337209419184
Epoch: 4 Idx: 0 Loss: 0.02870973965853001
Epoch: 4 Idx: 5000 Loss: 0.016424777834924346
Epoch: 5 Idx: 0 Loss: 0.01257746301977554
Epoch: 5 Idx: 5000 Loss: 0.03979216618394238
Epoch: 6 Idx: 0 Loss: 0.007967500506567578
Epoch: 6 Idx: 5000 Loss: 0.026134550404776753
Epoch: 7 Idx: 0 Loss: 0.008391620957111025
Epoch: 7 Idx: 5000 Loss: 0.018292135161257918
Epoch: 8 Idx: 0 Loss: 0.029357435824967925
Epoch: 8 Idx: 5000 Loss: 0.013327101571220233
Epoch: 9 Idx: 0 Loss: 0.02507879558301217
Epoch: 9 Idx: 5000 Loss: 0.013552402486752824
Epoch: 10 Idx: 0 Loss: 0.009615831158326668
Epoch: 10 Idx: 5000 Loss: 0.011001878862046418
Epoch: 11 Idx: 0 Loss: 0.033240753323656336
Epoch: 11 Idx: 5000 Loss: 0.006659173823571363
Epoch: 12 Idx: 0 Loss: 0.02581740534514946
Epoch: 12 Idx: 5000 Loss: 0.006729707171558414
Epoch: 13 Idx: 0 Loss: 0.02547921694723969
Epoch: 13 Idx: 5000 Loss: 0.014122681812514158
Epoch: 14 Idx: 0 Loss: 0.031099595818784704
Epoch: 14 Idx: 5000 Loss: 0.014044130655774593
Epoch: 15 Idx: 0 Loss: 0.007364514697176137
Epoch: 15 Idx: 5000 Loss: 0.005683537975006517
Epoch: 16 Idx: 0 Loss: 0.02100540334712107
Epoch: 16 Idx: 5000 Loss: 0.03299749625027927
Epoch: 17 Idx: 0 Loss: 0.005646570663023057
Epoch: 17 Idx: 5000 Loss: 0.01733554423167416
Epoch: 18 Idx: 0 Loss: 0.014405214193025748
Epoch: 18 Idx: 5000 Loss: 0.017410232375642567
Epoch: 19 Idx: 0 Loss: 0.010111417439738129
Epoch: 19 Idx: 5000 Loss: 0.04080934781655312
Epoch: 20 Idx: 0 Loss: 0.015511173085889875
Epoch: 20 Idx: 5000 Loss: 0.028158724539788436
Epoch: 21 Idx: 0 Loss: 0.021834261771706998
Epoch: 21 Idx: 5000 Loss: 0.01587035816074358
Epoch: 22 Idx: 0 Loss: 0.010737892868507732
Epoch: 22 Idx: 5000 Loss: 0.013937082359164105
Epoch: 23 Idx: 0 Loss: 0.011750907601803025
Epoch: 23 Idx: 5000 Loss: 0.015488280528457764
Epoch: 24 Idx: 0 Loss: 0.022007798887525448
Epoch: 24 Idx: 5000 Loss: 0.015832967949839398
Epoch: 25 Idx: 0 Loss: 0.010254623314111021
Epoch: 25 Idx: 5000 Loss: 0.03794389880042804
Epoch: 26 Idx: 0 Loss: 0.013376929780852444
Epoch: 26 Idx: 5000 Loss: 0.02402110035593623
Epoch: 27 Idx: 0 Loss: 0.01215963708431924
Epoch: 27 Idx: 5000 Loss: 0.011610314094716407
Epoch: 28 Idx: 0 Loss: 0.010605232474440222
Epoch: 28 Idx: 5000 Loss: 0.008076419406780076
Epoch: 29 Idx: 0 Loss: 0.008525666776481908
Epoch: 29 Idx: 5000 Loss: 0.022296027639919766
Epoch: 30 Idx: 0 Loss: 0.009777598380842363
Epoch: 30 Idx: 5000 Loss: 0.014203163276960038
Epoch: 31 Idx: 0 Loss: 0.04030316922113674
Epoch: 31 Idx: 5000 Loss: 0.00891025677395458
Epoch: 32 Idx: 0 Loss: 0.014837765409541886
Epoch: 32 Idx: 5000 Loss: 0.020034328133468744
Epoch: 33 Idx: 0 Loss: 0.005262187575882616
Epoch: 33 Idx: 5000 Loss: 0.008123574880979091
Epoch: 34 Idx: 0 Loss: 0.021565096699440005
Epoch: 34 Idx: 5000 Loss: 0.013051421793360773
Epoch: 35 Idx: 0 Loss: 0.00944153498506598
Epoch: 35 Idx: 5000 Loss: 0.051113252939012685
Epoch: 36 Idx: 0 Loss: 0.005722702530147576
Epoch: 36 Idx: 5000 Loss: 0.028470973097777103
Epoch: 37 Idx: 0 Loss: 0.016497721464549378
Epoch: 37 Idx: 5000 Loss: 0.008319199595620465
Epoch: 38 Idx: 0 Loss: 0.009496037027338767
Epoch: 38 Idx: 5000 Loss: 0.02255384395543426
Epoch: 39 Idx: 0 Loss: 0.028158825163253375
Epoch: 39 Idx: 5000 Loss: 0.00968193387647848
Epoch: 40 Idx: 0 Loss: 0.027193903672718525
Epoch: 40 Idx: 5000 Loss: 0.013026515826217163
Epoch: 41 Idx: 0 Loss: 0.009881421949106893
Epoch: 41 Idx: 5000 Loss: 0.015503809345641202
Epoch: 42 Idx: 0 Loss: 0.006664140323989489
Epoch: 42 Idx: 5000 Loss: 0.0069989256914038435
Epoch: 43 Idx: 0 Loss: 0.008789075261759666
Epoch: 43 Idx: 5000 Loss: 0.011643445920877456
Epoch: 44 Idx: 0 Loss: 0.015638200227896776
Epoch: 44 Idx: 5000 Loss: 0.023288748162980284
Epoch: 45 Idx: 0 Loss: 0.023403718393693155
Epoch: 45 Idx: 5000 Loss: 0.012377468716230154
Epoch: 46 Idx: 0 Loss: 0.03401665814602058
Epoch: 46 Idx: 5000 Loss: 0.01630427979311635
Epoch: 47 Idx: 0 Loss: 0.00946886701605416
Epoch: 47 Idx: 5000 Loss: 0.016543608293440946
Epoch: 48 Idx: 0 Loss: 0.023351487923302158
Epoch: 48 Idx: 5000 Loss: 0.016085805878527575
Epoch: 49 Idx: 0 Loss: 0.025065596129869576
Epoch: 49 Idx: 5000 Loss: 0.024950499907604097
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.225615016146976
Epoch: 0 Idx: 5000 Loss: 0.045033596475598806
Epoch: 1 Idx: 0 Loss: 0.009718260971742974
Epoch: 1 Idx: 5000 Loss: 0.012314422091411844
Epoch: 2 Idx: 0 Loss: 0.01637538112877985
Epoch: 2 Idx: 5000 Loss: 0.018956334520484293
Epoch: 3 Idx: 0 Loss: 0.026882384277685537
Epoch: 3 Idx: 5000 Loss: 0.005858203818863496
Epoch: 4 Idx: 0 Loss: 0.014295752344856156
Epoch: 4 Idx: 5000 Loss: 0.006846255078349672
Epoch: 5 Idx: 0 Loss: 0.01346550804139059
Epoch: 5 Idx: 5000 Loss: 0.00929314145498179
Epoch: 6 Idx: 0 Loss: 0.012978175048401014
Epoch: 6 Idx: 5000 Loss: 0.018306663754375056
Epoch: 7 Idx: 0 Loss: 0.028356095042898592
Epoch: 7 Idx: 5000 Loss: 0.013296042999171075
Epoch: 8 Idx: 0 Loss: 0.017479518762279534
Epoch: 8 Idx: 5000 Loss: 0.018220274363272112
Epoch: 9 Idx: 0 Loss: 0.024696911187536058
Epoch: 9 Idx: 5000 Loss: 0.01700554667938094
Epoch: 10 Idx: 0 Loss: 0.008824491281262734
Epoch: 10 Idx: 5000 Loss: 0.011629959945966878
Epoch: 11 Idx: 0 Loss: 0.009005930876443547
Epoch: 11 Idx: 5000 Loss: 0.05743805913445376
Epoch: 12 Idx: 0 Loss: 0.032116578767906044
Epoch: 12 Idx: 5000 Loss: 0.0329179074421996
Epoch: 13 Idx: 0 Loss: 0.008035977124167506
Epoch: 13 Idx: 5000 Loss: 0.014717952031563088
Epoch: 14 Idx: 0 Loss: 0.01569423486953927
Epoch: 14 Idx: 5000 Loss: 0.022202823258682867
Epoch: 15 Idx: 0 Loss: 0.011817160215416893
Epoch: 15 Idx: 5000 Loss: 0.009099271424720806
Epoch: 16 Idx: 0 Loss: 0.01401533744672279
Epoch: 16 Idx: 5000 Loss: 0.02193281938716929
Epoch: 17 Idx: 0 Loss: 0.0072966588326785365
Epoch: 17 Idx: 5000 Loss: 0.02611410562368755
Epoch: 18 Idx: 0 Loss: 0.026120959235649166
Epoch: 18 Idx: 5000 Loss: 0.0425543009133222
Epoch: 19 Idx: 0 Loss: 0.007123176533725232
Epoch: 19 Idx: 5000 Loss: 0.00975446100437804
Epoch: 20 Idx: 0 Loss: 0.011200895271643672
Epoch: 20 Idx: 5000 Loss: 0.005803062741049391
Epoch: 21 Idx: 0 Loss: 0.018267907448562177
Epoch: 21 Idx: 5000 Loss: 0.014359547875880535
Epoch: 22 Idx: 0 Loss: 0.010509611735032757
Epoch: 22 Idx: 5000 Loss: 0.02061166480214369
Epoch: 23 Idx: 0 Loss: 0.017268346450691533
Epoch: 23 Idx: 5000 Loss: 0.021340190048071042
Epoch: 24 Idx: 0 Loss: 0.01769081238600526
Epoch: 24 Idx: 5000 Loss: 0.029676878558935083
Epoch: 25 Idx: 0 Loss: 0.011640137504657628
Epoch: 25 Idx: 5000 Loss: 0.028871532115595247
Epoch: 26 Idx: 0 Loss: 0.01160686249420005
Epoch: 26 Idx: 5000 Loss: 0.009792444853486976
Epoch: 27 Idx: 0 Loss: 0.02319337080087997
Epoch: 27 Idx: 5000 Loss: 0.012866056217960595
Epoch: 28 Idx: 0 Loss: 0.014285090062094285
Epoch: 28 Idx: 5000 Loss: 0.010740335183535801
Epoch: 29 Idx: 0 Loss: 0.007868893108329533
Epoch: 29 Idx: 5000 Loss: 0.02664379388404182
Epoch: 30 Idx: 0 Loss: 0.019786141049343793
Epoch: 30 Idx: 5000 Loss: 0.0166575382574617
Epoch: 31 Idx: 0 Loss: 0.014046188799351846
Epoch: 31 Idx: 5000 Loss: 0.011551868282610598
Epoch: 32 Idx: 0 Loss: 0.01407461676020533
Epoch: 32 Idx: 5000 Loss: 0.012145591124600537
Epoch: 33 Idx: 0 Loss: 0.01732653367477348
Epoch: 33 Idx: 5000 Loss: 0.01670742163337475
Epoch: 34 Idx: 0 Loss: 0.018219296838687532
Epoch: 34 Idx: 5000 Loss: 0.03678343960489981
Epoch: 35 Idx: 0 Loss: 0.00659116538487635
Epoch: 35 Idx: 5000 Loss: 0.013311008326881795
Epoch: 36 Idx: 0 Loss: 0.009490997001972127
Epoch: 36 Idx: 5000 Loss: 0.011877766630207273
Epoch: 37 Idx: 0 Loss: 0.010938870642587408
Epoch: 37 Idx: 5000 Loss: 0.00662608310885807
Epoch: 38 Idx: 0 Loss: 0.012377555045160103
Epoch: 38 Idx: 5000 Loss: 0.02193596786398919
Epoch: 39 Idx: 0 Loss: 0.03248645136383631
Epoch: 39 Idx: 5000 Loss: 0.01965858996923809
Epoch: 40 Idx: 0 Loss: 0.02111714936333783
Epoch: 40 Idx: 5000 Loss: 0.020297724669308334
Epoch: 41 Idx: 0 Loss: 0.013131697579204984
Epoch: 41 Idx: 5000 Loss: 0.012401048149060026
Epoch: 42 Idx: 0 Loss: 0.013220731233012033
Epoch: 42 Idx: 5000 Loss: 0.014345985220268195
Epoch: 43 Idx: 0 Loss: 0.03108823684828703
Epoch: 43 Idx: 5000 Loss: 0.014050368793162814
Epoch: 44 Idx: 0 Loss: 0.010854483823579557
Epoch: 44 Idx: 5000 Loss: 0.0361633380317193
Epoch: 45 Idx: 0 Loss: 0.008642502000270676
Epoch: 45 Idx: 5000 Loss: 0.010050953231123648
Epoch: 46 Idx: 0 Loss: 0.009375087953898638
Epoch: 46 Idx: 5000 Loss: 0.027614160857878087
Epoch: 47 Idx: 0 Loss: 0.01550901881118472
Epoch: 47 Idx: 5000 Loss: 0.006471513367691939
Epoch: 48 Idx: 0 Loss: 0.014567742391235242
Epoch: 48 Idx: 5000 Loss: 0.011444207112702935
Epoch: 49 Idx: 0 Loss: 0.008823883745448556
Epoch: 49 Idx: 5000 Loss: 0.04600298370063259
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.19985954205402198
Epoch: 0 Idx: 5000 Loss: 0.0120788837269152
Epoch: 1 Idx: 0 Loss: 0.010511375463125423
Epoch: 1 Idx: 5000 Loss: 0.01419785442663244
Epoch: 2 Idx: 0 Loss: 0.010847008559369275
Epoch: 2 Idx: 5000 Loss: 0.00909655416965651
Epoch: 3 Idx: 0 Loss: 0.010250217382483086
Epoch: 3 Idx: 5000 Loss: 0.010627225263002842
Epoch: 4 Idx: 0 Loss: 0.023071334346077048
Epoch: 4 Idx: 5000 Loss: 0.01417686035593267
Epoch: 5 Idx: 0 Loss: 0.016235425921825745
Epoch: 5 Idx: 5000 Loss: 0.010437273383163897
Epoch: 6 Idx: 0 Loss: 0.03868108025477684
Epoch: 6 Idx: 5000 Loss: 0.031504120923891224
Epoch: 7 Idx: 0 Loss: 0.007958398814122532
Epoch: 7 Idx: 5000 Loss: 0.005796931849770247
Epoch: 8 Idx: 0 Loss: 0.03433322436711644
Epoch: 8 Idx: 5000 Loss: 0.014115849836203257
Epoch: 9 Idx: 0 Loss: 0.009035817359780995
Epoch: 9 Idx: 5000 Loss: 0.012543368683381028
Epoch: 10 Idx: 0 Loss: 0.025884155878498103
Epoch: 10 Idx: 5000 Loss: 0.01196126423165862
Epoch: 11 Idx: 0 Loss: 0.0217511625387838
Epoch: 11 Idx: 5000 Loss: 0.015195811217805815
Epoch: 12 Idx: 0 Loss: 0.007946928404709359
Epoch: 12 Idx: 5000 Loss: 0.012888709590315869
Epoch: 13 Idx: 0 Loss: 0.015375528032317653
Epoch: 13 Idx: 5000 Loss: 0.01546616552577661
Epoch: 14 Idx: 0 Loss: 0.009162461564596498
Epoch: 14 Idx: 5000 Loss: 0.0093518218869281
Epoch: 15 Idx: 0 Loss: 0.02602790290291232
Epoch: 15 Idx: 5000 Loss: 0.009864547267061888
Epoch: 16 Idx: 0 Loss: 0.01982695407823199
Epoch: 16 Idx: 5000 Loss: 0.010208549884422446
Epoch: 17 Idx: 0 Loss: 0.013231330463757313
Epoch: 17 Idx: 5000 Loss: 0.019364362312138055
Epoch: 18 Idx: 0 Loss: 0.017578052660279963
Epoch: 18 Idx: 5000 Loss: 0.02284200435116402
Epoch: 19 Idx: 0 Loss: 0.028337814241239552
Epoch: 19 Idx: 5000 Loss: 0.015523779082213904
Epoch: 20 Idx: 0 Loss: 0.025873456227880474
Epoch: 20 Idx: 5000 Loss: 0.01588678061464749
Epoch: 21 Idx: 0 Loss: 0.012639536523011426
Epoch: 21 Idx: 5000 Loss: 0.01003869744904558
Epoch: 22 Idx: 0 Loss: 0.028044150029513045
Epoch: 22 Idx: 5000 Loss: 0.023229806836088947
Epoch: 23 Idx: 0 Loss: 0.007017063006721619
Epoch: 23 Idx: 5000 Loss: 0.01832056198761466
Epoch: 24 Idx: 0 Loss: 0.02503152054797962
Epoch: 24 Idx: 5000 Loss: 0.00872988116678286
Epoch: 25 Idx: 0 Loss: 0.025585326242648577
Epoch: 25 Idx: 5000 Loss: 0.024384375194535728
Epoch: 26 Idx: 0 Loss: 0.021011106574665737
Epoch: 26 Idx: 5000 Loss: 0.013192069410915202
Epoch: 27 Idx: 0 Loss: 0.008517915244141088
Epoch: 27 Idx: 5000 Loss: 0.016838485339357914
Epoch: 28 Idx: 0 Loss: 0.014523347316373083
Epoch: 28 Idx: 5000 Loss: 0.014091946636036056
Epoch: 29 Idx: 0 Loss: 0.014612015450338533
Epoch: 29 Idx: 5000 Loss: 0.018245408808747383
Epoch: 30 Idx: 0 Loss: 0.011772813014623764
Epoch: 30 Idx: 5000 Loss: 0.01091976101596407
Epoch: 31 Idx: 0 Loss: 0.013919585923530682
Epoch: 31 Idx: 5000 Loss: 0.023886105140729343
Epoch: 32 Idx: 0 Loss: 0.012851758787007003
Epoch: 32 Idx: 5000 Loss: 0.010596193324745134
Epoch: 33 Idx: 0 Loss: 0.008692548013522903
Epoch: 33 Idx: 5000 Loss: 0.030927167404885395
Epoch: 34 Idx: 0 Loss: 0.01844301184545692
Epoch: 34 Idx: 5000 Loss: 0.017135018210234665
Epoch: 35 Idx: 0 Loss: 0.014057966843978142
Epoch: 35 Idx: 5000 Loss: 0.02664406048515562
Epoch: 36 Idx: 0 Loss: 0.018598322640742775
Epoch: 36 Idx: 5000 Loss: 0.010442785984510341
Epoch: 37 Idx: 0 Loss: 0.011880638713818788
Epoch: 37 Idx: 5000 Loss: 0.010381827859756559
Epoch: 38 Idx: 0 Loss: 0.012881821233029889
Epoch: 38 Idx: 5000 Loss: 0.015397163197551623
Epoch: 39 Idx: 0 Loss: 0.012958863088947524
Epoch: 39 Idx: 5000 Loss: 0.021496144661490336
Epoch: 40 Idx: 0 Loss: 0.030309050314770058
Epoch: 40 Idx: 5000 Loss: 0.025412092077446866
Epoch: 41 Idx: 0 Loss: 0.011521647110184316
Epoch: 41 Idx: 5000 Loss: 0.01149985370917029
Epoch: 42 Idx: 0 Loss: 0.014705705433134554
Epoch: 42 Idx: 5000 Loss: 0.010608989351337226
Epoch: 43 Idx: 0 Loss: 0.012993190767141212
Epoch: 43 Idx: 5000 Loss: 0.010514949696707174
Epoch: 44 Idx: 0 Loss: 0.01008213619711118
Epoch: 44 Idx: 5000 Loss: 0.01865860696169197
Epoch: 45 Idx: 0 Loss: 0.016270069287672412
Epoch: 45 Idx: 5000 Loss: 0.01252280699974824
Epoch: 46 Idx: 0 Loss: 0.026143417233371886
Epoch: 46 Idx: 5000 Loss: 0.02713845616249628
Epoch: 47 Idx: 0 Loss: 0.029876440935730234
Epoch: 47 Idx: 5000 Loss: 0.013017236862300396
Epoch: 48 Idx: 0 Loss: 0.020843071072746917
Epoch: 48 Idx: 5000 Loss: 0.02008040912375201
Epoch: 49 Idx: 0 Loss: 0.02174326980484674
Epoch: 49 Idx: 5000 Loss: 0.01782286365003355
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.2229710196075032
Epoch: 0 Idx: 5000 Loss: 0.012031801473130009
Epoch: 1 Idx: 0 Loss: 0.011289736338294706
Epoch: 1 Idx: 5000 Loss: 0.01612644198762776
Epoch: 2 Idx: 0 Loss: 0.011090123173888812
Epoch: 2 Idx: 5000 Loss: 0.015929696532837885
Epoch: 3 Idx: 0 Loss: 0.012036581328379982
Epoch: 3 Idx: 5000 Loss: 0.02108584763316131
Epoch: 4 Idx: 0 Loss: 0.04083670326731416
Epoch: 4 Idx: 5000 Loss: 0.011902359659714593
Epoch: 5 Idx: 0 Loss: 0.018121280097707203
Epoch: 5 Idx: 5000 Loss: 0.009113077475126944
Epoch: 6 Idx: 0 Loss: 0.011139698099700484
Epoch: 6 Idx: 5000 Loss: 0.021802143194477153
Epoch: 7 Idx: 0 Loss: 0.0076850882690902905
Epoch: 7 Idx: 5000 Loss: 0.04552972850079682
Epoch: 8 Idx: 0 Loss: 0.005150876317492706
Epoch: 8 Idx: 5000 Loss: 0.011214123174912473
Epoch: 9 Idx: 0 Loss: 0.0076294314279104405
Epoch: 9 Idx: 5000 Loss: 0.017072249430182297
Epoch: 10 Idx: 0 Loss: 0.004756103632895486
Epoch: 10 Idx: 5000 Loss: 0.026772937525493777
Epoch: 11 Idx: 0 Loss: 0.007119767122702495
Epoch: 11 Idx: 5000 Loss: 0.016359462697647806
Epoch: 12 Idx: 0 Loss: 0.01750704322266729
Epoch: 12 Idx: 5000 Loss: 0.007662058367769127
Epoch: 13 Idx: 0 Loss: 0.010682210114169605
Epoch: 13 Idx: 5000 Loss: 0.02018857352013377
Epoch: 14 Idx: 0 Loss: 0.010953377047058599
Epoch: 14 Idx: 5000 Loss: 0.020745008388260874
Epoch: 15 Idx: 0 Loss: 0.009396974600058599
Epoch: 15 Idx: 5000 Loss: 0.01933750080223145
Epoch: 16 Idx: 0 Loss: 0.024044807513663016
Epoch: 16 Idx: 5000 Loss: 0.015153730259258329
Epoch: 17 Idx: 0 Loss: 0.01284321488954115
Epoch: 17 Idx: 5000 Loss: 0.014041495748324015
Epoch: 18 Idx: 0 Loss: 0.013199798322113106
Epoch: 18 Idx: 5000 Loss: 0.00541882390437824
Epoch: 19 Idx: 0 Loss: 0.013848004153209014
Epoch: 19 Idx: 5000 Loss: 0.016538684016548462
Epoch: 20 Idx: 0 Loss: 0.02228935014346374
Epoch: 20 Idx: 5000 Loss: 0.009710712417471885
Epoch: 21 Idx: 0 Loss: 0.010510544859003079
Epoch: 21 Idx: 5000 Loss: 0.012773283115122122
Epoch: 22 Idx: 0 Loss: 0.017884165703389854
Epoch: 22 Idx: 5000 Loss: 0.0062095491257535
Epoch: 23 Idx: 0 Loss: 0.021532328964719852
Epoch: 23 Idx: 5000 Loss: 0.015594744192716292
Epoch: 24 Idx: 0 Loss: 0.026430416687456302
Epoch: 24 Idx: 5000 Loss: 0.009035701235737496
Epoch: 25 Idx: 0 Loss: 0.031666702833716656
Epoch: 25 Idx: 5000 Loss: 0.019432220015733248
Epoch: 26 Idx: 0 Loss: 0.012068448164526993
Epoch: 26 Idx: 5000 Loss: 0.024431964923889528
Epoch: 27 Idx: 0 Loss: 0.016653142733358068
Epoch: 27 Idx: 5000 Loss: 0.013202772467636396
Epoch: 28 Idx: 0 Loss: 0.017594983467911607
Epoch: 28 Idx: 5000 Loss: 0.013889362787664717
Epoch: 29 Idx: 0 Loss: 0.006192231260210894
Epoch: 29 Idx: 5000 Loss: 0.023268746032590472
Epoch: 30 Idx: 0 Loss: 0.013977545734251333
Epoch: 30 Idx: 5000 Loss: 0.0329472253546705
Epoch: 31 Idx: 0 Loss: 0.008796085268685805
Epoch: 31 Idx: 5000 Loss: 0.023141904871565477
Epoch: 32 Idx: 0 Loss: 0.012180788711904873
Epoch: 32 Idx: 5000 Loss: 0.009847476912476685
Epoch: 33 Idx: 0 Loss: 0.008284667339330972
Epoch: 33 Idx: 5000 Loss: 0.018569313858205032
Epoch: 34 Idx: 0 Loss: 0.03142342569282767
Epoch: 34 Idx: 5000 Loss: 0.005574474235553645
Epoch: 35 Idx: 0 Loss: 0.008768428284994821
Epoch: 35 Idx: 5000 Loss: 0.03471121143381685
Epoch: 36 Idx: 0 Loss: 0.008792721815590984
Epoch: 36 Idx: 5000 Loss: 0.02144853357016383
Epoch: 37 Idx: 0 Loss: 0.0053344067984956705
Epoch: 37 Idx: 5000 Loss: 0.022135762665597976
Epoch: 38 Idx: 0 Loss: 0.015246419442151375
Epoch: 38 Idx: 5000 Loss: 0.011427270283890924
Epoch: 39 Idx: 0 Loss: 0.008544906810966386
Epoch: 39 Idx: 5000 Loss: 0.013857968290716113
Epoch: 40 Idx: 0 Loss: 0.010632064763245932
Epoch: 40 Idx: 5000 Loss: 0.028647731897991593
Epoch: 41 Idx: 0 Loss: 0.008373000337473216
Epoch: 41 Idx: 5000 Loss: 0.01556659142793411
Epoch: 42 Idx: 0 Loss: 0.013393413193575683
Epoch: 42 Idx: 5000 Loss: 0.013821613345772178
Epoch: 43 Idx: 0 Loss: 0.01283028917783326
Epoch: 43 Idx: 5000 Loss: 0.006016464738062315
Epoch: 44 Idx: 0 Loss: 0.007792055245072492
Epoch: 44 Idx: 5000 Loss: 0.030677303297139344
Epoch: 45 Idx: 0 Loss: 0.018924939195139205
Epoch: 45 Idx: 5000 Loss: 0.034578834911800145
Epoch: 46 Idx: 0 Loss: 0.015851173764868345
Epoch: 46 Idx: 5000 Loss: 0.013005171054107648
Epoch: 47 Idx: 0 Loss: 0.011210802027962726
Epoch: 47 Idx: 5000 Loss: 0.01193705597248069
Epoch: 48 Idx: 0 Loss: 0.007070074738470143
Epoch: 48 Idx: 5000 Loss: 0.008609103552406051
Epoch: 49 Idx: 0 Loss: 0.008609038389181716
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 383, in to_feature
    for elem in inputs]
  File "main.py", line 383, in <listcomp>
    for elem in inputs]
  File "main.py", line 382, in <listcomp>
    for ent in elem]
  File "main.py", line 381, in <listcomp>
    for nbr_type in ent[:max_types]]
  File "main.py", line 380, in <listcomp>
    for path in nbr_type[:max_paths]]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc264>
Subject: Job 4066814: <python main.py 4 4 False False> in cluster <dcc> Exited

Job <python main.py 4 4 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
Job was executed on host(s) <dccxc264>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:38 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 4 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46079.78 sec.
    Max Memory :                                 2900 MB
    Average Memory :                             2740.46 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40517.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46225 sec.
    Turnaround time :                            46204 sec.

The output (if any) is above this job summary.

