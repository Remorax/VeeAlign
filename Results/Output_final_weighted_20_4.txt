2020-09-15 15:48:43.657300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.797399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:50.912322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:50.912408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.914662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.916366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.916810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.918940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.920501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.920772: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.920793: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.921216: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.955885: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599955000 Hz
2020-09-15 15:48:50.956244: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fab1e71220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.956273: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.959239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.959279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20049827681735766
Epoch: 0 Idx: 5000 Loss: 0.011924530725953168
Epoch: 1 Idx: 0 Loss: 0.015076838307219237
Epoch: 1 Idx: 5000 Loss: 0.023723964494955403
Epoch: 2 Idx: 0 Loss: 0.014814592662271623
Epoch: 2 Idx: 5000 Loss: 0.0233720034458552
Epoch: 3 Idx: 0 Loss: 0.00782932730822345
Epoch: 3 Idx: 5000 Loss: 0.011523291706536883
Epoch: 4 Idx: 0 Loss: 0.02437415275856388
Epoch: 4 Idx: 5000 Loss: 0.050485051025156304
Epoch: 5 Idx: 0 Loss: 0.016260160081100043
Epoch: 5 Idx: 5000 Loss: 0.026183252582413462
Epoch: 6 Idx: 0 Loss: 0.020499045722202257
Epoch: 6 Idx: 5000 Loss: 0.01690289891570993
Epoch: 7 Idx: 0 Loss: 0.010835127028920848
Epoch: 7 Idx: 5000 Loss: 0.02387390342049457
Epoch: 8 Idx: 0 Loss: 0.012274668182364534
Epoch: 8 Idx: 5000 Loss: 0.005885278443906751
Epoch: 9 Idx: 0 Loss: 0.01848359437730434
Epoch: 9 Idx: 5000 Loss: 0.013176194513604448
Epoch: 10 Idx: 0 Loss: 0.016224383715961292
Epoch: 10 Idx: 5000 Loss: 0.016902996310601732
Epoch: 11 Idx: 0 Loss: 0.014851625471805685
Epoch: 11 Idx: 5000 Loss: 0.04557477773588531
Epoch: 12 Idx: 0 Loss: 0.009736694825398174
Epoch: 12 Idx: 5000 Loss: 0.015301734782871454
Epoch: 13 Idx: 0 Loss: 0.010562313694894992
Epoch: 13 Idx: 5000 Loss: 0.007136226308927974
Epoch: 14 Idx: 0 Loss: 0.034175646535608124
Epoch: 14 Idx: 5000 Loss: 0.013080010640956423
Epoch: 15 Idx: 0 Loss: 0.011608459727485696
Epoch: 15 Idx: 5000 Loss: 0.026920589544389265
Epoch: 16 Idx: 0 Loss: 0.00621856193845556
Epoch: 16 Idx: 5000 Loss: 0.009602038474038108
Epoch: 17 Idx: 0 Loss: 0.013591924584001696
Epoch: 17 Idx: 5000 Loss: 0.01858637754413743
Epoch: 18 Idx: 0 Loss: 0.013154518155507403
Epoch: 18 Idx: 5000 Loss: 0.021392144255623455
Epoch: 19 Idx: 0 Loss: 0.011253888575129071
Epoch: 19 Idx: 5000 Loss: 0.0057407981823199734
Epoch: 20 Idx: 0 Loss: 0.010461935799419496
Epoch: 20 Idx: 5000 Loss: 0.010554353251446184
Epoch: 21 Idx: 0 Loss: 0.01774822682831718
Epoch: 21 Idx: 5000 Loss: 0.0242480580878632
Epoch: 22 Idx: 0 Loss: 0.010848960524659714
Epoch: 22 Idx: 5000 Loss: 0.03288838800485874
Epoch: 23 Idx: 0 Loss: 0.01825036831746378
Epoch: 23 Idx: 5000 Loss: 0.015112506518483764
Epoch: 24 Idx: 0 Loss: 0.01962881409116931
Epoch: 24 Idx: 5000 Loss: 0.015028370185819217
Epoch: 25 Idx: 0 Loss: 0.010878688231314635
Epoch: 25 Idx: 5000 Loss: 0.02223545288659
Epoch: 26 Idx: 0 Loss: 0.013137919167604047
Epoch: 26 Idx: 5000 Loss: 0.01568242634740706
Epoch: 27 Idx: 0 Loss: 0.005957160006217519
Epoch: 27 Idx: 5000 Loss: 0.016087533447856284
Epoch: 28 Idx: 0 Loss: 0.029310769153036112
Epoch: 28 Idx: 5000 Loss: 0.01274771141830663
Epoch: 29 Idx: 0 Loss: 0.021889899284215454
Epoch: 29 Idx: 5000 Loss: 0.011149879922431657
Epoch: 30 Idx: 0 Loss: 0.020323657368476595
Epoch: 30 Idx: 5000 Loss: 0.007930229309791977
Epoch: 31 Idx: 0 Loss: 0.01402225389138776
Epoch: 31 Idx: 5000 Loss: 0.010603636490545524
Epoch: 32 Idx: 0 Loss: 0.014600031634346849
Epoch: 32 Idx: 5000 Loss: 0.013327154255621795
Epoch: 33 Idx: 0 Loss: 0.04406857824807562
Epoch: 33 Idx: 5000 Loss: 0.004321087422673555
Epoch: 34 Idx: 0 Loss: 0.017266127701886687
Epoch: 34 Idx: 5000 Loss: 0.020129926143970904
Epoch: 35 Idx: 0 Loss: 0.01506289084521658
Epoch: 35 Idx: 5000 Loss: 0.011402667335098057
Epoch: 36 Idx: 0 Loss: 0.013868250968280921
Epoch: 36 Idx: 5000 Loss: 0.008544234533525081
Epoch: 37 Idx: 0 Loss: 0.012282174745997257
Epoch: 37 Idx: 5000 Loss: 0.009853150922290449
Epoch: 38 Idx: 0 Loss: 0.008880661170987077
Epoch: 38 Idx: 5000 Loss: 0.0374316273397061
Epoch: 39 Idx: 0 Loss: 0.012921817658557985
Epoch: 39 Idx: 5000 Loss: 0.006914872999983328
Epoch: 40 Idx: 0 Loss: 0.013155653558821714
Epoch: 40 Idx: 5000 Loss: 0.03499619347364232
Epoch: 41 Idx: 0 Loss: 0.010806592420940848
Epoch: 41 Idx: 5000 Loss: 0.006149131657952703
Epoch: 42 Idx: 0 Loss: 0.014343713157790304
Epoch: 42 Idx: 5000 Loss: 0.011067672310451583
Epoch: 43 Idx: 0 Loss: 0.009564793470456015
Epoch: 43 Idx: 5000 Loss: 0.03945409000673358
Epoch: 44 Idx: 0 Loss: 0.009374945691771193
Epoch: 44 Idx: 5000 Loss: 0.012855560981609941
Epoch: 45 Idx: 0 Loss: 0.005927219602406201
Epoch: 45 Idx: 5000 Loss: 0.019612770548708667
Epoch: 46 Idx: 0 Loss: 0.025268188595833765
Epoch: 46 Idx: 5000 Loss: 0.04104846673120981
Epoch: 47 Idx: 0 Loss: 0.009928894156736858
Epoch: 47 Idx: 5000 Loss: 0.027631508669709124
Epoch: 48 Idx: 0 Loss: 0.007540285370673841
Epoch: 48 Idx: 5000 Loss: 0.018685005054858605
Epoch: 49 Idx: 0 Loss: 0.014442622559270457
Epoch: 49 Idx: 5000 Loss: 0.019618636022418548
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1503222071915681
Epoch: 0 Idx: 5000 Loss: 0.02233735417116314
Epoch: 1 Idx: 0 Loss: 0.014965419259095634
Epoch: 1 Idx: 5000 Loss: 0.029719535365008466
Epoch: 2 Idx: 0 Loss: 0.014529843278700407
Epoch: 2 Idx: 5000 Loss: 0.01502087501117623
Epoch: 3 Idx: 0 Loss: 0.01615006290975636
Epoch: 3 Idx: 5000 Loss: 0.011413195650636162
Epoch: 4 Idx: 0 Loss: 0.032189099943366446
Epoch: 4 Idx: 5000 Loss: 0.014778914516013777
Epoch: 5 Idx: 0 Loss: 0.017562484863384447
Epoch: 5 Idx: 5000 Loss: 0.024041819235253753
Epoch: 6 Idx: 0 Loss: 0.013321763692657886
Epoch: 6 Idx: 5000 Loss: 0.02178406996083142
Epoch: 7 Idx: 0 Loss: 0.028469753620790537
Epoch: 7 Idx: 5000 Loss: 0.009604895145925928
Epoch: 8 Idx: 0 Loss: 0.007606457499514795
Epoch: 8 Idx: 5000 Loss: 0.024145632236866693
Epoch: 9 Idx: 0 Loss: 0.01056455859964764
Epoch: 9 Idx: 5000 Loss: 0.02503007258028406
Epoch: 10 Idx: 0 Loss: 0.00808065509277739
Epoch: 10 Idx: 5000 Loss: 0.020477300978443847
Epoch: 11 Idx: 0 Loss: 0.014698558599328258
Epoch: 11 Idx: 5000 Loss: 0.005568751721867986
Epoch: 12 Idx: 0 Loss: 0.007461839871690497
Epoch: 12 Idx: 5000 Loss: 0.02674015401985015
Epoch: 13 Idx: 0 Loss: 0.011881148868458053
Epoch: 13 Idx: 5000 Loss: 0.0178121642179685
Epoch: 14 Idx: 0 Loss: 0.009281622328409081
Epoch: 14 Idx: 5000 Loss: 0.024031183157142498
Epoch: 15 Idx: 0 Loss: 0.030558818974747142
Epoch: 15 Idx: 5000 Loss: 0.0066460352580581285
Epoch: 16 Idx: 0 Loss: 0.021233852032436495
Epoch: 16 Idx: 5000 Loss: 0.01227977321588454
Epoch: 17 Idx: 0 Loss: 0.03889540733935251
Epoch: 17 Idx: 5000 Loss: 0.007980276657405172
Epoch: 18 Idx: 0 Loss: 0.008598174744503579
Epoch: 18 Idx: 5000 Loss: 0.01120914687975345
Epoch: 19 Idx: 0 Loss: 0.01604352724168205
Epoch: 19 Idx: 5000 Loss: 0.03581514997860613
Epoch: 20 Idx: 0 Loss: 0.018692714428101758
Epoch: 20 Idx: 5000 Loss: 0.018662546353454133
Epoch: 21 Idx: 0 Loss: 0.022318345197540557
Epoch: 21 Idx: 5000 Loss: 0.01308340082237814
Epoch: 22 Idx: 0 Loss: 0.02064923568462351
Epoch: 22 Idx: 5000 Loss: 0.012050830328980393
Epoch: 23 Idx: 0 Loss: 0.04685601070529408
Epoch: 23 Idx: 5000 Loss: 0.0088524234070064
Epoch: 24 Idx: 0 Loss: 0.016689495835737075
Epoch: 24 Idx: 5000 Loss: 0.017638618862156702
Epoch: 25 Idx: 0 Loss: 0.009404067644343784
Epoch: 25 Idx: 5000 Loss: 0.01815042491253433
Epoch: 26 Idx: 0 Loss: 0.03125126577255423
Epoch: 26 Idx: 5000 Loss: 0.0070237728296263565
Epoch: 27 Idx: 0 Loss: 0.013563389963932334
Epoch: 27 Idx: 5000 Loss: 0.013899648154371128
Epoch: 28 Idx: 0 Loss: 0.023701406706424323
Epoch: 28 Idx: 5000 Loss: 0.01815745084001598
Epoch: 29 Idx: 0 Loss: 0.017092498612613968
Epoch: 29 Idx: 5000 Loss: 0.015511946478261636
Epoch: 30 Idx: 0 Loss: 0.022115799569324076
Epoch: 30 Idx: 5000 Loss: 0.008689338640225471
Epoch: 31 Idx: 0 Loss: 0.0116034673869836
Epoch: 31 Idx: 5000 Loss: 0.01426830268573848
Epoch: 32 Idx: 0 Loss: 0.010492397812024878
Epoch: 32 Idx: 5000 Loss: 0.008975804198077803
Epoch: 33 Idx: 0 Loss: 0.008058739917433775
Epoch: 33 Idx: 5000 Loss: 0.030866333333524763
Epoch: 34 Idx: 0 Loss: 0.01030036223954347
Epoch: 34 Idx: 5000 Loss: 0.009484761271780166
Epoch: 35 Idx: 0 Loss: 0.029742701173177392
Epoch: 35 Idx: 5000 Loss: 0.010318969801079863
Epoch: 36 Idx: 0 Loss: 0.007770935751661132
Epoch: 36 Idx: 5000 Loss: 0.009720891531273037
Epoch: 37 Idx: 0 Loss: 0.009832400715033503
Epoch: 37 Idx: 5000 Loss: 0.01962626427363144
Epoch: 38 Idx: 0 Loss: 0.01640395013269509
Epoch: 38 Idx: 5000 Loss: 0.0066487524997711055
Epoch: 39 Idx: 0 Loss: 0.010354559152295858
Epoch: 39 Idx: 5000 Loss: 0.006067423047971346
Epoch: 40 Idx: 0 Loss: 0.013500847054036008
Epoch: 40 Idx: 5000 Loss: 0.014298138574106832
Epoch: 41 Idx: 0 Loss: 0.01854050299974644
Epoch: 41 Idx: 5000 Loss: 0.05425690759536267
Epoch: 42 Idx: 0 Loss: 0.012405394776539236
Epoch: 42 Idx: 5000 Loss: 0.040478820440965076
Epoch: 43 Idx: 0 Loss: 0.01911884955153894
Epoch: 43 Idx: 5000 Loss: 0.007036938777735402
Epoch: 44 Idx: 0 Loss: 0.009978497551987545
Epoch: 44 Idx: 5000 Loss: 0.02393305408321783
Epoch: 45 Idx: 0 Loss: 0.02243139115191116
Epoch: 45 Idx: 5000 Loss: 0.004482438709508746
Epoch: 46 Idx: 0 Loss: 0.01253386909638416
Epoch: 46 Idx: 5000 Loss: 0.012232014366237158
Epoch: 47 Idx: 0 Loss: 0.008555511075926513
Epoch: 47 Idx: 5000 Loss: 0.011044324742315117
Epoch: 48 Idx: 0 Loss: 0.016621955644035614
Epoch: 48 Idx: 5000 Loss: 0.019406915160634867
Epoch: 49 Idx: 0 Loss: 0.014302835743339454
Epoch: 49 Idx: 5000 Loss: 0.01166774908161616
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13370501671087
Epoch: 0 Idx: 5000 Loss: 0.012639838216522408
Epoch: 1 Idx: 0 Loss: 0.015721165775402737
Epoch: 1 Idx: 5000 Loss: 0.010753700835890258
Epoch: 2 Idx: 0 Loss: 0.012123817434524129
Epoch: 2 Idx: 5000 Loss: 0.02008966460006227
Epoch: 3 Idx: 0 Loss: 0.015324637382494271
Epoch: 3 Idx: 5000 Loss: 0.019071426384731523
Epoch: 4 Idx: 0 Loss: 0.006090877104101285
Epoch: 4 Idx: 5000 Loss: 0.014536964281134742
Epoch: 5 Idx: 0 Loss: 0.033142449616545305
Epoch: 5 Idx: 5000 Loss: 0.0180627302083647
Epoch: 6 Idx: 0 Loss: 0.019488592909004863
Epoch: 6 Idx: 5000 Loss: 0.04145833001473473
Epoch: 7 Idx: 0 Loss: 0.01629601369057484
Epoch: 7 Idx: 5000 Loss: 0.012760191710425101
Epoch: 8 Idx: 0 Loss: 0.010121990605819293
Epoch: 8 Idx: 5000 Loss: 0.010119299207603532
Epoch: 9 Idx: 0 Loss: 0.017417577431642624
Epoch: 9 Idx: 5000 Loss: 0.02454534491461768
Epoch: 10 Idx: 0 Loss: 0.018545696303591836
Epoch: 10 Idx: 5000 Loss: 0.005962363899156903
Epoch: 11 Idx: 0 Loss: 0.014551608734446709
Epoch: 11 Idx: 5000 Loss: 0.010972505036854246
Epoch: 12 Idx: 0 Loss: 0.00976603925972535
Epoch: 12 Idx: 5000 Loss: 0.012227589105333177
Epoch: 13 Idx: 0 Loss: 0.006374629391770749
Epoch: 13 Idx: 5000 Loss: 0.039654172818471035
Epoch: 14 Idx: 0 Loss: 0.010585651936451538
Epoch: 14 Idx: 5000 Loss: 0.014085903777729596
Epoch: 15 Idx: 0 Loss: 0.03180230100728373
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 323, in forward
    best_path = torch.bmm(path_weights.reshape(-1, 1, self.max_paths), feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc229>
Subject: Job 4066838: <python main.py 4 20 False True> in cluster <dcc> Exited

Job <python main.py 4 20 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
Job was executed on host(s) <dccxc229>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:38 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 20 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   85976.61 sec.
    Max Memory :                                 2870 MB
    Average Memory :                             2645.37 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40547.00 MB
    Max Swap :                                   4 MB
    Max Processes :                              3
    Max Threads :                                17
    Run time :                                   46201 sec.
    Turnaround time :                            46202 sec.

The output (if any) is above this job summary.

