2020-09-15 15:49:37.272688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.504426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:40.625844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:40.625940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.628000: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:40.629451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:40.629811: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:40.631672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:40.633018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:40.633238: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:40.633260: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:40.633581: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:40.641254: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600185000 Hz
2020-09-15 15:49:40.641443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5640a58366a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:40.641463: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:40.643474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:40.643518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1997612742909609
Epoch: 0 Idx: 5000 Loss: 0.011732162622857435
Epoch: 1 Idx: 0 Loss: 0.015164921563915459
Epoch: 1 Idx: 5000 Loss: 0.006852205529527048
Epoch: 2 Idx: 0 Loss: 0.011265093152832889
Epoch: 2 Idx: 5000 Loss: 0.023415987409315223
Epoch: 3 Idx: 0 Loss: 0.02164556395723573
Epoch: 3 Idx: 5000 Loss: 0.04030777991881304
Epoch: 4 Idx: 0 Loss: 0.02114631374497222
Epoch: 4 Idx: 5000 Loss: 0.025348310960461265
Epoch: 5 Idx: 0 Loss: 0.010621212390597122
Epoch: 5 Idx: 5000 Loss: 0.011023525353943912
Epoch: 6 Idx: 0 Loss: 0.019899699539931183
Epoch: 6 Idx: 5000 Loss: 0.010051287116396506
Epoch: 7 Idx: 0 Loss: 0.0160869049632298
Epoch: 7 Idx: 5000 Loss: 0.019118729661063268
Epoch: 8 Idx: 0 Loss: 0.012856846154660082
Epoch: 8 Idx: 5000 Loss: 0.007972162648642327
Epoch: 9 Idx: 0 Loss: 0.010347018493194627
Epoch: 9 Idx: 5000 Loss: 0.006423769078817464
Epoch: 10 Idx: 0 Loss: 0.018803367546784796
Epoch: 10 Idx: 5000 Loss: 0.019710061142355163
Epoch: 11 Idx: 0 Loss: 0.02091323665390632
Epoch: 11 Idx: 5000 Loss: 0.020555750762224566
Epoch: 12 Idx: 0 Loss: 0.009403562256487698
Epoch: 12 Idx: 5000 Loss: 0.018418806029106765
Epoch: 13 Idx: 0 Loss: 0.01645635250561038
Epoch: 13 Idx: 5000 Loss: 0.008947537410150289
Epoch: 14 Idx: 0 Loss: 0.012198233545047418
Epoch: 14 Idx: 5000 Loss: 0.009011492171640557
Epoch: 15 Idx: 0 Loss: 0.018057768831180255
Epoch: 15 Idx: 5000 Loss: 0.025964130295890748
Epoch: 16 Idx: 0 Loss: 0.010834851971010539
Epoch: 16 Idx: 5000 Loss: 0.014281223261936595
Epoch: 17 Idx: 0 Loss: 0.01036193521800638
Epoch: 17 Idx: 5000 Loss: 0.005929752027928288
Epoch: 18 Idx: 0 Loss: 0.01886010395662544
Epoch: 18 Idx: 5000 Loss: 0.03463421365258414
Epoch: 19 Idx: 0 Loss: 0.011969575462574635
Epoch: 19 Idx: 5000 Loss: 0.03720645874213422
Epoch: 20 Idx: 0 Loss: 0.006999548917916279
Epoch: 20 Idx: 5000 Loss: 0.01458580172317498
Epoch: 21 Idx: 0 Loss: 0.015396310254686683
Epoch: 21 Idx: 5000 Loss: 0.03660188757063372
Epoch: 22 Idx: 0 Loss: 0.022344833064893637
Epoch: 22 Idx: 5000 Loss: 0.019653568645557708
Epoch: 23 Idx: 0 Loss: 0.011207162541375382
Epoch: 23 Idx: 5000 Loss: 0.027819801266342876
Epoch: 24 Idx: 0 Loss: 0.017888225660244
Epoch: 24 Idx: 5000 Loss: 0.017074124976242337
Epoch: 25 Idx: 0 Loss: 0.013309117698715157
Epoch: 25 Idx: 5000 Loss: 0.013990280847867922
Epoch: 26 Idx: 0 Loss: 0.011115855961081752
Epoch: 26 Idx: 5000 Loss: 0.0386937791417222
Epoch: 27 Idx: 0 Loss: 0.020545709904095856
Epoch: 27 Idx: 5000 Loss: 0.011957437492165258
Epoch: 28 Idx: 0 Loss: 0.04513724929323233
Epoch: 28 Idx: 5000 Loss: 0.021051820983075422
Epoch: 29 Idx: 0 Loss: 0.02151493635944525
Epoch: 29 Idx: 5000 Loss: 0.007667919968894763
Epoch: 30 Idx: 0 Loss: 0.010467921346495018
Epoch: 30 Idx: 5000 Loss: 0.00615104732866401
Epoch: 31 Idx: 0 Loss: 0.01375255291952552
Epoch: 31 Idx: 5000 Loss: 0.027273858742856375
Epoch: 32 Idx: 0 Loss: 0.030737142505908546
Epoch: 32 Idx: 5000 Loss: 0.017397693522060054
Epoch: 33 Idx: 0 Loss: 0.029200515275002423
Epoch: 33 Idx: 5000 Loss: 0.01666039283383807
Epoch: 34 Idx: 0 Loss: 0.01256838097234213
Epoch: 34 Idx: 5000 Loss: 0.009935296938659974
Epoch: 35 Idx: 0 Loss: 0.012587905882767241
Epoch: 35 Idx: 5000 Loss: 0.011736002328378028
Epoch: 36 Idx: 0 Loss: 0.03757866152920859
Epoch: 36 Idx: 5000 Loss: 0.02667280221460583
Epoch: 37 Idx: 0 Loss: 0.026378254001985825
Epoch: 37 Idx: 5000 Loss: 0.026978796415035006
Epoch: 38 Idx: 0 Loss: 0.008814325299526884
Epoch: 38 Idx: 5000 Loss: 0.01912596908246305
Epoch: 39 Idx: 0 Loss: 0.02262883508976447
Epoch: 39 Idx: 5000 Loss: 0.01493383204630178
Epoch: 40 Idx: 0 Loss: 0.006116630504444822
Epoch: 40 Idx: 5000 Loss: 0.011269209771703466
Epoch: 41 Idx: 0 Loss: 0.016110318729021467
Epoch: 41 Idx: 5000 Loss: 0.028134249784384044
Epoch: 42 Idx: 0 Loss: 0.01777038958291869
Epoch: 42 Idx: 5000 Loss: 0.020934269878685206
Epoch: 43 Idx: 0 Loss: 0.013118863435221784
Epoch: 43 Idx: 5000 Loss: 0.015940979048342747
Epoch: 44 Idx: 0 Loss: 0.013884589946354584
Epoch: 44 Idx: 5000 Loss: 0.02241424002575061
Epoch: 45 Idx: 0 Loss: 0.013977762445113825
Epoch: 45 Idx: 5000 Loss: 0.019986211718397522
Epoch: 46 Idx: 0 Loss: 0.01530865171767881
Epoch: 46 Idx: 5000 Loss: 0.010272798068374542
Epoch: 47 Idx: 0 Loss: 0.014995884019364828
Epoch: 47 Idx: 5000 Loss: 0.007649074786896568
Epoch: 48 Idx: 0 Loss: 0.013346934708008337
Epoch: 48 Idx: 5000 Loss: 0.013341867825420798
Epoch: 49 Idx: 0 Loss: 0.021360223266700465
Epoch: 49 Idx: 5000 Loss: 0.014694580493452276
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1602672576645324
Epoch: 0 Idx: 5000 Loss: 0.023336530053506457
Epoch: 1 Idx: 0 Loss: 0.005479454418773093
Epoch: 1 Idx: 5000 Loss: 0.01718663234093078
Epoch: 2 Idx: 0 Loss: 0.01605561635546202
Epoch: 2 Idx: 5000 Loss: 0.020119656870670972
Epoch: 3 Idx: 0 Loss: 0.018682432799066447
Epoch: 3 Idx: 5000 Loss: 0.013110549819992063
Epoch: 4 Idx: 0 Loss: 0.009652340284420195
Epoch: 4 Idx: 5000 Loss: 0.00724708743724712
Epoch: 5 Idx: 0 Loss: 0.012474803506313989
Epoch: 5 Idx: 5000 Loss: 0.009285345661795313
Epoch: 6 Idx: 0 Loss: 0.01127816063988705
Epoch: 6 Idx: 5000 Loss: 0.05790710036458621
Epoch: 7 Idx: 0 Loss: 0.010835068757760673
Epoch: 7 Idx: 5000 Loss: 0.016060247823853863
Epoch: 8 Idx: 0 Loss: 0.005596914983503862
Epoch: 8 Idx: 5000 Loss: 0.02066858932289669
Epoch: 9 Idx: 0 Loss: 0.011982702608857752
Epoch: 9 Idx: 5000 Loss: 0.010901899518780723
Epoch: 10 Idx: 0 Loss: 0.0060547754438464675
Epoch: 10 Idx: 5000 Loss: 0.006106335430858422
Epoch: 11 Idx: 0 Loss: 0.005757052381425466
Epoch: 11 Idx: 5000 Loss: 0.00870741138121555
Epoch: 12 Idx: 0 Loss: 0.01967849587288858
Epoch: 12 Idx: 5000 Loss: 0.03631227489222094
Epoch: 13 Idx: 0 Loss: 0.008768548260407322
Epoch: 13 Idx: 5000 Loss: 0.01463660236496892
Epoch: 14 Idx: 0 Loss: 0.012239765176083594
Epoch: 14 Idx: 5000 Loss: 0.01584937855684661
Epoch: 15 Idx: 0 Loss: 0.014097880220904541
Epoch: 15 Idx: 5000 Loss: 0.020046723436221867
Epoch: 16 Idx: 0 Loss: 0.01911843014726406
Epoch: 16 Idx: 5000 Loss: 0.020702605737100352
Epoch: 17 Idx: 0 Loss: 0.01335681378867871
Epoch: 17 Idx: 5000 Loss: 0.01701762662229406
Epoch: 18 Idx: 0 Loss: 0.010558956387603038
Epoch: 18 Idx: 5000 Loss: 0.01394257753659045
Epoch: 19 Idx: 0 Loss: 0.037662361375269196
Epoch: 19 Idx: 5000 Loss: 0.009620630327839075
Epoch: 20 Idx: 0 Loss: 0.03829794387038717
Epoch: 20 Idx: 5000 Loss: 0.02956489210019387
Epoch: 21 Idx: 0 Loss: 0.026189693347155638
Epoch: 21 Idx: 5000 Loss: 0.008590749156981476
Epoch: 22 Idx: 0 Loss: 0.014982345583987422
Epoch: 22 Idx: 5000 Loss: 0.02666122040314595
Epoch: 23 Idx: 0 Loss: 0.015473878229569384
Epoch: 23 Idx: 5000 Loss: 0.010746737506661809
Epoch: 24 Idx: 0 Loss: 0.01848699359319514
Epoch: 24 Idx: 5000 Loss: 0.019913871800364726
Epoch: 25 Idx: 0 Loss: 0.021041821003286262
Epoch: 25 Idx: 5000 Loss: 0.012235876040418195
Epoch: 26 Idx: 0 Loss: 0.020883960515245607
Epoch: 26 Idx: 5000 Loss: 0.0198863364427962
Epoch: 27 Idx: 0 Loss: 0.013807910412970113
Epoch: 27 Idx: 5000 Loss: 0.020821176096007424
Epoch: 28 Idx: 0 Loss: 0.009334420773630066
Epoch: 28 Idx: 5000 Loss: 0.009273897318751986
Epoch: 29 Idx: 0 Loss: 0.0037185963818998653
Epoch: 29 Idx: 5000 Loss: 0.032473861822201446
Epoch: 30 Idx: 0 Loss: 0.03301616159005376
Epoch: 30 Idx: 5000 Loss: 0.020060105391729914
Epoch: 31 Idx: 0 Loss: 0.012243134143197462
Epoch: 31 Idx: 5000 Loss: 0.024954206961232434
Epoch: 32 Idx: 0 Loss: 0.011679643313609891
Epoch: 32 Idx: 5000 Loss: 0.011895271494974326
Epoch: 33 Idx: 0 Loss: 0.02046030167821557
Epoch: 33 Idx: 5000 Loss: 0.023066940757375767
Epoch: 34 Idx: 0 Loss: 0.007937398180155996
Epoch: 34 Idx: 5000 Loss: 0.015980293023582972
Epoch: 35 Idx: 0 Loss: 0.010346674009138
Epoch: 35 Idx: 5000 Loss: 0.010640048112498513
Epoch: 36 Idx: 0 Loss: 0.027904203972203858
Epoch: 36 Idx: 5000 Loss: 0.01392629158924931
Epoch: 37 Idx: 0 Loss: 0.010802910427542601
Epoch: 37 Idx: 5000 Loss: 0.013349718603002889
Epoch: 38 Idx: 0 Loss: 0.017717930039670798
Epoch: 38 Idx: 5000 Loss: 0.010536075169125789
Epoch: 39 Idx: 0 Loss: 0.007885119260947919
Epoch: 39 Idx: 5000 Loss: 0.012711518538243132
Epoch: 40 Idx: 0 Loss: 0.013042694490409332
Epoch: 40 Idx: 5000 Loss: 0.030747178673771386
Epoch: 41 Idx: 0 Loss: 0.012474501613563293
Epoch: 41 Idx: 5000 Loss: 0.02157949858502864
Epoch: 42 Idx: 0 Loss: 0.0168762922000012
Epoch: 42 Idx: 5000 Loss: 0.014919840560425009
Epoch: 43 Idx: 0 Loss: 0.02201977817949572
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 315, in forward
    path_weights = torch.bmm(node_emb[:, None, :], feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc236>
Subject: Job 4066866: <python main.py 5 21 False True> in cluster <dcc> Exited

Job <python main.py 5 21 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc236>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:35 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 21 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46133.69 sec.
    Max Memory :                                 2972 MB
    Average Memory :                             2759.83 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40445.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46145 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

