2020-09-15 15:48:45.302955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.698986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:52.812838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:52.812923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.815247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:53.129592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:53.352453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:53.401651: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:53.423324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:53.423861: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:53.423885: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:53.424414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:53.470691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600035000 Hz
2020-09-15 15:48:53.470943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568b5352bd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:53.470964: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:53.474357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:53.474413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19559439045338262
Epoch: 0 Idx: 5000 Loss: 0.006207339240901859
Epoch: 1 Idx: 0 Loss: 0.020643655753164455
Epoch: 1 Idx: 5000 Loss: 0.012201060266102006
Epoch: 2 Idx: 0 Loss: 0.01145787807889782
Epoch: 2 Idx: 5000 Loss: 0.0165724356624459
Epoch: 3 Idx: 0 Loss: 0.030385258983412117
Epoch: 3 Idx: 5000 Loss: 0.021381261427364677
Epoch: 4 Idx: 0 Loss: 0.016910936558916116
Epoch: 4 Idx: 5000 Loss: 0.012701114287629652
Epoch: 5 Idx: 0 Loss: 0.017665447299458646
Epoch: 5 Idx: 5000 Loss: 0.01119241158278954
Epoch: 6 Idx: 0 Loss: 0.011407007050405638
Epoch: 6 Idx: 5000 Loss: 0.015276588792422816
Epoch: 7 Idx: 0 Loss: 0.009115989105270523
Epoch: 7 Idx: 5000 Loss: 0.010052042139250462
Epoch: 8 Idx: 0 Loss: 0.012948878132946465
Epoch: 8 Idx: 5000 Loss: 0.010621002590961558
Epoch: 9 Idx: 0 Loss: 0.014141797359108641
Epoch: 9 Idx: 5000 Loss: 0.01631613103123247
Epoch: 10 Idx: 0 Loss: 0.014967383395347578
Epoch: 10 Idx: 5000 Loss: 0.02067520207553912
Epoch: 11 Idx: 0 Loss: 0.009455979164516638
Epoch: 11 Idx: 5000 Loss: 0.014819422163864393
Epoch: 12 Idx: 0 Loss: 0.0131711779981976
Epoch: 12 Idx: 5000 Loss: 0.012946322480574103
Epoch: 13 Idx: 0 Loss: 0.007931199411187612
Epoch: 13 Idx: 5000 Loss: 0.009072384612695003
Epoch: 14 Idx: 0 Loss: 0.012781666745452485
Epoch: 14 Idx: 5000 Loss: 0.013260594498884776
Epoch: 15 Idx: 0 Loss: 0.01657913990178613
Epoch: 15 Idx: 5000 Loss: 0.014297267193512006
Epoch: 16 Idx: 0 Loss: 0.01817802526749198
Epoch: 16 Idx: 5000 Loss: 0.013100139940497562
Epoch: 17 Idx: 0 Loss: 0.010999762617245494
Epoch: 17 Idx: 5000 Loss: 0.01088948853180058
Epoch: 18 Idx: 0 Loss: 0.014621252673634243
Epoch: 18 Idx: 5000 Loss: 0.005977423898312968
Epoch: 19 Idx: 0 Loss: 0.02145208987545665
Epoch: 19 Idx: 5000 Loss: 0.02773265878775616
Epoch: 20 Idx: 0 Loss: 0.009750408993348076
Epoch: 20 Idx: 5000 Loss: 0.017809034060123994
Epoch: 21 Idx: 0 Loss: 0.006866822039227291
Epoch: 21 Idx: 5000 Loss: 0.013691700428971651
Epoch: 22 Idx: 0 Loss: 0.01686422823564928
Epoch: 22 Idx: 5000 Loss: 0.011343992102898466
Epoch: 23 Idx: 0 Loss: 0.025987206597171218
Epoch: 23 Idx: 5000 Loss: 0.020589995143431898
Epoch: 24 Idx: 0 Loss: 0.010330860190568674
Epoch: 24 Idx: 5000 Loss: 0.022404054303250792
Epoch: 25 Idx: 0 Loss: 0.027045261575755028
Epoch: 25 Idx: 5000 Loss: 0.011653051197097069
Epoch: 26 Idx: 0 Loss: 0.003449412246806889
Epoch: 26 Idx: 5000 Loss: 0.026555961060453263
Epoch: 27 Idx: 0 Loss: 0.012355045100055157
Epoch: 27 Idx: 5000 Loss: 0.014184129440527282
Epoch: 28 Idx: 0 Loss: 0.017029929656718037
Epoch: 28 Idx: 5000 Loss: 0.02761048675670624
Epoch: 29 Idx: 0 Loss: 0.015444158453831347
Epoch: 29 Idx: 5000 Loss: 0.035509776504808875
Epoch: 30 Idx: 0 Loss: 0.02210401593140414
Epoch: 30 Idx: 5000 Loss: 0.01032564062683664
Epoch: 31 Idx: 0 Loss: 0.015185456923366427
Epoch: 31 Idx: 5000 Loss: 0.020762541508113366
Epoch: 32 Idx: 0 Loss: 0.048993048465458384
Epoch: 32 Idx: 5000 Loss: 0.010885171584826426
Epoch: 33 Idx: 0 Loss: 0.012218086216838394
Epoch: 33 Idx: 5000 Loss: 0.007959492651579197
Epoch: 34 Idx: 0 Loss: 0.010567096168071189
Epoch: 34 Idx: 5000 Loss: 0.008979085091907826
Epoch: 35 Idx: 0 Loss: 0.011421132536520459
Epoch: 35 Idx: 5000 Loss: 0.011248126165434198
Epoch: 36 Idx: 0 Loss: 0.008285343467652976
Epoch: 36 Idx: 5000 Loss: 0.014033420341037772
Epoch: 37 Idx: 0 Loss: 0.016977871183127425
Epoch: 37 Idx: 5000 Loss: 0.009809142325451032
Epoch: 38 Idx: 0 Loss: 0.026122598893841623
Epoch: 38 Idx: 5000 Loss: 0.021290478731703654
Epoch: 39 Idx: 0 Loss: 0.010703274212531427
Epoch: 39 Idx: 5000 Loss: 0.022105047682332575
Epoch: 40 Idx: 0 Loss: 0.007547277288629414
Epoch: 40 Idx: 5000 Loss: 0.011813639598856925
Epoch: 41 Idx: 0 Loss: 0.015564491659104727
Epoch: 41 Idx: 5000 Loss: 0.015647511426135303
Epoch: 42 Idx: 0 Loss: 0.030010790000041237
Epoch: 42 Idx: 5000 Loss: 0.018651529601615775
Epoch: 43 Idx: 0 Loss: 0.012158085152207052
Epoch: 43 Idx: 5000 Loss: 0.021831183368880604
Epoch: 44 Idx: 0 Loss: 0.030551056029065243
Epoch: 44 Idx: 5000 Loss: 0.0073172422565739095
Epoch: 45 Idx: 0 Loss: 0.011615935400889479
Epoch: 45 Idx: 5000 Loss: 0.012864305346268468
Epoch: 46 Idx: 0 Loss: 0.015807807377402634
Epoch: 46 Idx: 5000 Loss: 0.011158417734945884
Epoch: 47 Idx: 0 Loss: 0.01619047272783025
Epoch: 47 Idx: 5000 Loss: 0.010014784725454848
Epoch: 48 Idx: 0 Loss: 0.019160130317007903
Epoch: 48 Idx: 5000 Loss: 0.02856426876918673
Epoch: 49 Idx: 0 Loss: 0.008690856457749068
Epoch: 49 Idx: 5000 Loss: 0.026507236968017347
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.16651174930027862
Epoch: 0 Idx: 5000 Loss: 0.011727272392980399
Epoch: 1 Idx: 0 Loss: 0.03923178427659339
Epoch: 1 Idx: 5000 Loss: 0.01654400998280383
Epoch: 2 Idx: 0 Loss: 0.029104603247964798
Epoch: 2 Idx: 5000 Loss: 0.028296440266437878
Epoch: 3 Idx: 0 Loss: 0.013079757293902596
Epoch: 3 Idx: 5000 Loss: 0.012664936194708794
Epoch: 4 Idx: 0 Loss: 0.00867448680366955
Epoch: 4 Idx: 5000 Loss: 0.01852197565913227
Epoch: 5 Idx: 0 Loss: 0.009797368457988457
Epoch: 5 Idx: 5000 Loss: 0.011701420780001207
Epoch: 6 Idx: 0 Loss: 0.013024664809704288
Epoch: 6 Idx: 5000 Loss: 0.011349720774759858
Epoch: 7 Idx: 0 Loss: 0.007564105446779468
Epoch: 7 Idx: 5000 Loss: 0.03012541652746616
Epoch: 8 Idx: 0 Loss: 0.007838731594589317
Epoch: 8 Idx: 5000 Loss: 0.009352185021722154
Epoch: 9 Idx: 0 Loss: 0.011238032294186661
Epoch: 9 Idx: 5000 Loss: 0.00683222313244066
Epoch: 10 Idx: 0 Loss: 0.004267726844331833
Epoch: 10 Idx: 5000 Loss: 0.012470009270956988
Epoch: 11 Idx: 0 Loss: 0.0142860909905252
Epoch: 11 Idx: 5000 Loss: 0.007972981767240006
Epoch: 12 Idx: 0 Loss: 0.008157287116795368
Epoch: 12 Idx: 5000 Loss: 0.026311644093632985
Epoch: 13 Idx: 0 Loss: 0.008640672559782644
Epoch: 13 Idx: 5000 Loss: 0.01216523963701134
Epoch: 14 Idx: 0 Loss: 0.005904249084606727
Epoch: 14 Idx: 5000 Loss: 0.02873520635193428
Epoch: 15 Idx: 0 Loss: 0.0149226926645502
Epoch: 15 Idx: 5000 Loss: 0.01955155718254157
Epoch: 16 Idx: 0 Loss: 0.021450232007599084
Epoch: 16 Idx: 5000 Loss: 0.01664568669365581
Epoch: 17 Idx: 0 Loss: 0.014300515633825247
Epoch: 17 Idx: 5000 Loss: 0.030205460272556935
Epoch: 18 Idx: 0 Loss: 0.012636137117202814
Epoch: 18 Idx: 5000 Loss: 0.013441020509968617
Epoch: 19 Idx: 0 Loss: 0.01621034702202193
Epoch: 19 Idx: 5000 Loss: 0.013166682702611331
Epoch: 20 Idx: 0 Loss: 0.022019346867925477
Epoch: 20 Idx: 5000 Loss: 0.01392260522740372
Epoch: 21 Idx: 0 Loss: 0.009603808152706738
Epoch: 21 Idx: 5000 Loss: 0.025462287668691033
Epoch: 22 Idx: 0 Loss: 0.017462610224652956
Epoch: 22 Idx: 5000 Loss: 0.01359535741522922
Epoch: 23 Idx: 0 Loss: 0.013619791792870057
Epoch: 23 Idx: 5000 Loss: 0.019423806801833046
Epoch: 24 Idx: 0 Loss: 0.009291033680436782
Epoch: 24 Idx: 5000 Loss: 0.008795065887056672
Epoch: 25 Idx: 0 Loss: 0.015627362443656007
Epoch: 25 Idx: 5000 Loss: 0.0102840188255384
Epoch: 26 Idx: 0 Loss: 0.015055006121595863
Epoch: 26 Idx: 5000 Loss: 0.016205396906749707
Epoch: 27 Idx: 0 Loss: 0.030763058319198306
Epoch: 27 Idx: 5000 Loss: 0.016479851047846567
Epoch: 28 Idx: 0 Loss: 0.014478064695132237
Epoch: 28 Idx: 5000 Loss: 0.02442719732430745
Epoch: 29 Idx: 0 Loss: 0.014428846265298565
Epoch: 29 Idx: 5000 Loss: 0.01926771044319239
Epoch: 30 Idx: 0 Loss: 0.01508309876361768
Epoch: 30 Idx: 5000 Loss: 0.031013953444213996
Epoch: 31 Idx: 0 Loss: 0.007883699111281565
Epoch: 31 Idx: 5000 Loss: 0.005332306724235311
Epoch: 32 Idx: 0 Loss: 0.026238356938435053
Epoch: 32 Idx: 5000 Loss: 0.010032329667694483
Epoch: 33 Idx: 0 Loss: 0.022411897050860066
Epoch: 33 Idx: 5000 Loss: 0.0116684540225791
Epoch: 34 Idx: 0 Loss: 0.01301259997081908
Epoch: 34 Idx: 5000 Loss: 0.009770828815419184
Epoch: 35 Idx: 0 Loss: 0.005808424900827058
Epoch: 35 Idx: 5000 Loss: 0.008738765726636412
Epoch: 36 Idx: 0 Loss: 0.01799126889366669
Epoch: 36 Idx: 5000 Loss: 0.005562455553627317
Epoch: 37 Idx: 0 Loss: 0.007873764876405585
Epoch: 37 Idx: 5000 Loss: 0.014512465579201541
Epoch: 38 Idx: 0 Loss: 0.015646123019133155
Epoch: 38 Idx: 5000 Loss: 0.010060801775206227
Epoch: 39 Idx: 0 Loss: 0.027384908096008954
Epoch: 39 Idx: 5000 Loss: 0.01773175183096568
Epoch: 40 Idx: 0 Loss: 0.021814298457389164
Epoch: 40 Idx: 5000 Loss: 0.02246487152256714
Epoch: 41 Idx: 0 Loss: 0.009433979830277434
Epoch: 41 Idx: 5000 Loss: 0.00933153244399534
Epoch: 42 Idx: 0 Loss: 0.047070201957815416
Epoch: 42 Idx: 5000 Loss: 0.014032028535891704
Epoch: 43 Idx: 0 Loss: 0.009990005219653752
Epoch: 43 Idx: 5000 Loss: 0.010074180624231405
Epoch: 44 Idx: 0 Loss: 0.030638050085051934
Epoch: 44 Idx: 5000 Loss: 0.016766348470651726
Epoch: 45 Idx: 0 Loss: 0.030791459221321368
Epoch: 45 Idx: 5000 Loss: 0.008936696820262739
Epoch: 46 Idx: 0 Loss: 0.023840862302926095
Epoch: 46 Idx: 5000 Loss: 0.01219756918686765
Epoch: 47 Idx: 0 Loss: 0.005488906799894496
Epoch: 47 Idx: 5000 Loss: 0.028467990706694115
Epoch: 48 Idx: 0 Loss: 0.011097907184966383
Epoch: 48 Idx: 5000 Loss: 0.02343820064581108
Epoch: 49 Idx: 0 Loss: 0.019395530152048788
Epoch: 49 Idx: 5000 Loss: 0.016080718010657524
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.12360264579879099
Epoch: 0 Idx: 5000 Loss: 0.0613666866995441
Epoch: 1 Idx: 0 Loss: 0.019042348852272135
Epoch: 1 Idx: 5000 Loss: 0.009358474900808446
Epoch: 2 Idx: 0 Loss: 0.012005843025987003
Epoch: 2 Idx: 5000 Loss: 0.008381166548325238
Epoch: 3 Idx: 0 Loss: 0.011784933071051423
Epoch: 3 Idx: 5000 Loss: 0.018402065733503756
Epoch: 4 Idx: 0 Loss: 0.009453677425854174
Epoch: 4 Idx: 5000 Loss: 0.012486109086618328
Epoch: 5 Idx: 0 Loss: 0.012165845848440975
Epoch: 5 Idx: 5000 Loss: 0.005787354153933361
Epoch: 6 Idx: 0 Loss: 0.014823192968622747
Epoch: 6 Idx: 5000 Loss: 0.020702215272162778
Epoch: 7 Idx: 0 Loss: 0.010574323406990556
Epoch: 7 Idx: 5000 Loss: 0.015535743967139559
Epoch: 8 Idx: 0 Loss: 0.0080894724735129
Epoch: 8 Idx: 5000 Loss: 0.012210421482624759
Epoch: 9 Idx: 0 Loss: 0.009868133707750956
Epoch: 9 Idx: 5000 Loss: 0.028543944122797094
Epoch: 10 Idx: 0 Loss: 0.020484687465203523
Epoch: 10 Idx: 5000 Loss: 0.013406376976276915
Epoch: 11 Idx: 0 Loss: 0.010855909643872752
Epoch: 11 Idx: 5000 Loss: 0.027501842126484273
Epoch: 12 Idx: 0 Loss: 0.008677424579819504
Epoch: 12 Idx: 5000 Loss: 0.010546324704719874
Epoch: 13 Idx: 0 Loss: 0.008724227702725885
Epoch: 13 Idx: 5000 Loss: 0.006811866550471206
Epoch: 14 Idx: 0 Loss: 0.014092430912703274
Epoch: 14 Idx: 5000 Loss: 0.019112288869444015
Epoch: 15 Idx: 0 Loss: 0.009409345023053812
Epoch: 15 Idx: 5000 Loss: 0.02887808072064134
Epoch: 16 Idx: 0 Loss: 0.020030501388458348
Epoch: 16 Idx: 5000 Loss: 0.014983792834255938
Epoch: 17 Idx: 0 Loss: 0.02022699735346012
Epoch: 17 Idx: 5000 Loss: 0.020410409848960455
Epoch: 18 Idx: 0 Loss: 0.01754147581591973
Epoch: 18 Idx: 5000 Loss: 0.03088401803257291
Epoch: 19 Idx: 0 Loss: 0.021408084587162566
Epoch: 19 Idx: 5000 Loss: 0.012175950433286164
Epoch: 20 Idx: 0 Loss: 0.014757356959411081
Epoch: 20 Idx: 5000 Loss: 0.021556115227699072
Epoch: 21 Idx: 0 Loss: 0.006551626437379359
Epoch: 21 Idx: 5000 Loss: 0.011341982125187076
Epoch: 22 Idx: 0 Loss: 0.017490489743087825
Epoch: 22 Idx: 5000 Loss: 0.022337982411357052
Epoch: 23 Idx: 0 Loss: 0.017444107717661302
Epoch: 23 Idx: 5000 Loss: 0.01119404909113313
Epoch: 24 Idx: 0 Loss: 0.008332756717644085
Epoch: 24 Idx: 5000 Loss: 0.01258722049267884
Epoch: 25 Idx: 0 Loss: 0.010453895823572399
Epoch: 25 Idx: 5000 Loss: 0.013291871682066803
Epoch: 26 Idx: 0 Loss: 0.014144039251944653
Epoch: 26 Idx: 5000 Loss: 0.01154727007504433
Epoch: 27 Idx: 0 Loss: 0.011667588259386314
Epoch: 27 Idx: 5000 Loss: 0.01990776082145372
Epoch: 28 Idx: 0 Loss: 0.00717550608135625
Epoch: 28 Idx: 5000 Loss: 0.008449233922353952
Epoch: 29 Idx: 0 Loss: 0.012445123855602196
Epoch: 29 Idx: 5000 Loss: 0.016845467433021257
Epoch: 30 Idx: 0 Loss: 0.008638955800303992
Epoch: 30 Idx: 5000 Loss: 0.014560328003158624
Epoch: 31 Idx: 0 Loss: 0.022142573116279297
Epoch: 31 Idx: 5000 Loss: 0.00881652540900808
Epoch: 32 Idx: 0 Loss: 0.017795090110132743
Epoch: 32 Idx: 5000 Loss: 0.023150223112925528
Epoch: 33 Idx: 0 Loss: 0.011902447009417713
Epoch: 33 Idx: 5000 Loss: 0.019593559735040185
Epoch: 34 Idx: 0 Loss: 0.02100441060012804
Epoch: 34 Idx: 5000 Loss: 0.009618389107029116
Epoch: 35 Idx: 0 Loss: 0.009957353849866936
Epoch: 35 Idx: 5000 Loss: 0.016628222479285013
Epoch: 36 Idx: 0 Loss: 0.02783410911927285
Epoch: 36 Idx: 5000 Loss: 0.022791403583019225
Epoch: 37 Idx: 0 Loss: 0.011981691386699037
Epoch: 37 Idx: 5000 Loss: 0.018220575164757623
Epoch: 38 Idx: 0 Loss: 0.019244310204213588
Epoch: 38 Idx: 5000 Loss: 0.011536263906456434
Epoch: 39 Idx: 0 Loss: 0.017583207635096337
Epoch: 39 Idx: 5000 Loss: 0.01812273387004571
Epoch: 40 Idx: 0 Loss: 0.030516458067615538
Epoch: 40 Idx: 5000 Loss: 0.02659247908938527
Epoch: 41 Idx: 0 Loss: 0.005120682484222358
Epoch: 41 Idx: 5000 Loss: 0.01373119498363141
Epoch: 42 Idx: 0 Loss: 0.009653692580029306
Epoch: 42 Idx: 5000 Loss: 0.013646608116521864
Epoch: 43 Idx: 0 Loss: 0.011968170255148014
Epoch: 43 Idx: 5000 Loss: 0.009832552860123921
Epoch: 44 Idx: 0 Loss: 0.01883208364934043
Epoch: 44 Idx: 5000 Loss: 0.014821022184053338
Epoch: 45 Idx: 0 Loss: 0.02160021058982596
Epoch: 45 Idx: 5000 Loss: 0.0222691452066187
Epoch: 46 Idx: 0 Loss: 0.024735373065673694
Epoch: 46 Idx: 5000 Loss: 0.005712922135064085
Epoch: 47 Idx: 0 Loss: 0.01768116053088094
Epoch: 47 Idx: 5000 Loss: 0.026856395751470127
Epoch: 48 Idx: 0 Loss: 0.0329869522392713
Epoch: 48 Idx: 5000 Loss: 0.011229112318512745
Epoch: 49 Idx: 0 Loss: 0.026438224197453564
Epoch: 49 Idx: 5000 Loss: 0.004549643899276756
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.2583074434134874
Epoch: 0 Idx: 5000 Loss: 0.015641638754087018
Epoch: 1 Idx: 0 Loss: 0.018761986911937985
Epoch: 1 Idx: 5000 Loss: 0.032314278303953725
Epoch: 2 Idx: 0 Loss: 0.008169478367231055
Epoch: 2 Idx: 5000 Loss: 0.016470847784261684
Epoch: 3 Idx: 0 Loss: 0.01881183692056984
Epoch: 3 Idx: 5000 Loss: 0.03377881553697546
Epoch: 4 Idx: 0 Loss: 0.022971337622287785
Epoch: 4 Idx: 5000 Loss: 0.00891780964720963
Epoch: 5 Idx: 0 Loss: 0.01591037670889745
Epoch: 5 Idx: 5000 Loss: 0.01105403720199933
Epoch: 6 Idx: 0 Loss: 0.008292652921768206
Epoch: 6 Idx: 5000 Loss: 0.009443943946606264
Epoch: 7 Idx: 0 Loss: 0.008608375808799829
Epoch: 7 Idx: 5000 Loss: 0.009877681590040937
Epoch: 8 Idx: 0 Loss: 0.014898441114233371
Epoch: 8 Idx: 5000 Loss: 0.018955250800132176
Epoch: 9 Idx: 0 Loss: 0.03941730815646985
Epoch: 9 Idx: 5000 Loss: 0.0093903744102205
Epoch: 10 Idx: 0 Loss: 0.03440979221095934
Epoch: 10 Idx: 5000 Loss: 0.020438934861160017
Epoch: 11 Idx: 0 Loss: 0.005227130462807741
Epoch: 11 Idx: 5000 Loss: 0.01038541488639183
Epoch: 12 Idx: 0 Loss: 0.0050528401815292424
Epoch: 12 Idx: 5000 Loss: 0.0238028269911095
Epoch: 13 Idx: 0 Loss: 0.015477366080198592
Epoch: 13 Idx: 5000 Loss: 0.02022769669865524
Epoch: 14 Idx: 0 Loss: 0.004624356160426904
Epoch: 14 Idx: 5000 Loss: 0.009945399695098563
Epoch: 15 Idx: 0 Loss: 0.008816785119629378
Epoch: 15 Idx: 5000 Loss: 0.016178402524989817
Epoch: 16 Idx: 0 Loss: 0.01249764588005584
Epoch: 16 Idx: 5000 Loss: 0.01612461756172497
Epoch: 17 Idx: 0 Loss: 0.008369603090715685
Epoch: 17 Idx: 5000 Loss: 0.009642386363627083
Epoch: 18 Idx: 0 Loss: 0.00773232545479055
Epoch: 18 Idx: 5000 Loss: 0.006380564693769939
Epoch: 19 Idx: 0 Loss: 0.011402836108414437
Epoch: 19 Idx: 5000 Loss: 0.012143549371167578
Epoch: 20 Idx: 0 Loss: 0.009710382380045398
Epoch: 20 Idx: 5000 Loss: 0.019879464922192537
Epoch: 21 Idx: 0 Loss: 0.006306335544047472
Epoch: 21 Idx: 5000 Loss: 0.014464118136058524
Epoch: 22 Idx: 0 Loss: 0.015392675675471897
Epoch: 22 Idx: 5000 Loss: 0.01036783871799685
Epoch: 23 Idx: 0 Loss: 0.008255433974916742
Epoch: 23 Idx: 5000 Loss: 0.025300085794912393
Epoch: 24 Idx: 0 Loss: 0.021534343042486522
Epoch: 24 Idx: 5000 Loss: 0.02571711134342515
Epoch: 25 Idx: 0 Loss: 0.015058042568120326
Epoch: 25 Idx: 5000 Loss: 0.023920127317079327
Epoch: 26 Idx: 0 Loss: 0.012658714785993539
Epoch: 26 Idx: 5000 Loss: 0.012249993239418694
Epoch: 27 Idx: 0 Loss: 0.02052562692473419
Epoch: 27 Idx: 5000 Loss: 0.012644274382497305
Epoch: 28 Idx: 0 Loss: 0.0048215030416983405
Epoch: 28 Idx: 5000 Loss: 0.014492759179019587
Epoch: 29 Idx: 0 Loss: 0.04289893653562365
Epoch: 29 Idx: 5000 Loss: 0.013561743761313128
Epoch: 30 Idx: 0 Loss: 0.011705449475518003
Epoch: 30 Idx: 5000 Loss: 0.02015078278542497
Epoch: 31 Idx: 0 Loss: 0.008698956546197735
Epoch: 31 Idx: 5000 Loss: 0.014499016999311498
Epoch: 32 Idx: 0 Loss: 0.01432051811513543
Epoch: 32 Idx: 5000 Loss: 0.02017592528005534
Epoch: 33 Idx: 0 Loss: 0.008945128517477755
Epoch: 33 Idx: 5000 Loss: 0.0056277984934412365
Epoch: 34 Idx: 0 Loss: 0.01169465076016028
Epoch: 34 Idx: 5000 Loss: 0.0177792512494936
Epoch: 35 Idx: 0 Loss: 0.015949040683350818
Epoch: 35 Idx: 5000 Loss: 0.014550466088325213
Epoch: 36 Idx: 0 Loss: 0.017995257801902018
Epoch: 36 Idx: 5000 Loss: 0.007675892548830833
Epoch: 37 Idx: 0 Loss: 0.01763847608281739
Epoch: 37 Idx: 5000 Loss: 0.0216223227164952
Epoch: 38 Idx: 0 Loss: 0.047082911922616474
Epoch: 38 Idx: 5000 Loss: 0.018514296550686947
Epoch: 39 Idx: 0 Loss: 0.02213047833342066
Epoch: 39 Idx: 5000 Loss: 0.02112571030626597
Epoch: 40 Idx: 0 Loss: 0.010697101901289124
Epoch: 40 Idx: 5000 Loss: 0.02236520213891388
Epoch: 41 Idx: 0 Loss: 0.0096956325777348
Epoch: 41 Idx: 5000 Loss: 0.015467638901296599
Epoch: 42 Idx: 0 Loss: 0.00848645780070498
Epoch: 42 Idx: 5000 Loss: 0.01381592559711191
Epoch: 43 Idx: 0 Loss: 0.01839938886597477
Epoch: 43 Idx: 5000 Loss: 0.015574469371064359
Epoch: 44 Idx: 0 Loss: 0.011843060541927365
Epoch: 44 Idx: 5000 Loss: 0.017930081985004228
Epoch: 45 Idx: 0 Loss: 0.010655200651644733
Epoch: 45 Idx: 5000 Loss: 0.018633975738286263
Epoch: 46 Idx: 0 Loss: 0.00605954801212513
Epoch: 46 Idx: 5000 Loss: 0.005985918854832951
Epoch: 47 Idx: 0 Loss: 0.005478145182813047
Epoch: 47 Idx: 5000 Loss: 0.009692200400947162
Epoch: 48 Idx: 0 Loss: 0.020702393532261925
Epoch: 48 Idx: 5000 Loss: 0.011188428001275258
Epoch: 49 Idx: 0 Loss: 0.004956996201483345
Epoch: 49 Idx: 5000 Loss: 0.01300669350504505
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.19901907575150984
Epoch: 0 Idx: 5000 Loss: 0.011562459544182358
Epoch: 1 Idx: 0 Loss: 0.03290964151792416
Epoch: 1 Idx: 5000 Loss: 0.008839102882452772
Epoch: 2 Idx: 0 Loss: 0.01537664032737477
Epoch: 2 Idx: 5000 Loss: 0.0099798800485556
Epoch: 3 Idx: 0 Loss: 0.025432574514923197
Epoch: 3 Idx: 5000 Loss: 0.004471629469732441
Epoch: 4 Idx: 0 Loss: 0.017870911777200724
Epoch: 4 Idx: 5000 Loss: 0.02324967005008699
Epoch: 5 Idx: 0 Loss: 0.03115659702000433
Epoch: 5 Idx: 5000 Loss: 0.04008256337077179
Epoch: 6 Idx: 0 Loss: 0.01509324615863439
Epoch: 6 Idx: 5000 Loss: 0.021796133934792346
Epoch: 7 Idx: 0 Loss: 0.013001146482612719
Epoch: 7 Idx: 5000 Loss: 0.009506582803994638
Epoch: 8 Idx: 0 Loss: 0.028024722873828303
Epoch: 8 Idx: 5000 Loss: 0.009941807698709072
Epoch: 9 Idx: 0 Loss: 0.023944405041208355
Epoch: 9 Idx: 5000 Loss: 0.02216697947713975
Epoch: 10 Idx: 0 Loss: 0.00930826632692646
Epoch: 10 Idx: 5000 Loss: 0.018621634718388947
Epoch: 11 Idx: 0 Loss: 0.009695541283656156
Epoch: 11 Idx: 5000 Loss: 0.006819754781993784
Epoch: 12 Idx: 0 Loss: 0.017065600646563574
Epoch: 12 Idx: 5000 Loss: 0.010489417354234667
Epoch: 13 Idx: 0 Loss: 0.025761562751043524
Epoch: 13 Idx: 5000 Loss: 0.013997438724228806
Epoch: 14 Idx: 0 Loss: 0.01943337996742803
Epoch: 14 Idx: 5000 Loss: 0.017183924473404454
Epoch: 15 Idx: 0 Loss: 0.020455007497461156
Epoch: 15 Idx: 5000 Loss: 0.009874528531792565
Epoch: 16 Idx: 0 Loss: 0.013124449611048639
Epoch: 16 Idx: 5000 Loss: 0.00845660240937119
Epoch: 17 Idx: 0 Loss: 0.007749193949461378
Epoch: 17 Idx: 5000 Loss: 0.01767337110657318
Epoch: 18 Idx: 0 Loss: 0.009960579421461113
Epoch: 18 Idx: 5000 Loss: 0.01005131821206813
Epoch: 19 Idx: 0 Loss: 0.011188588701077851
Epoch: 19 Idx: 5000 Loss: 0.017350603412844938
Epoch: 20 Idx: 0 Loss: 0.019892184856375932
Epoch: 20 Idx: 5000 Loss: 0.017150066496427176
Epoch: 21 Idx: 0 Loss: 0.03165078125135188
Epoch: 21 Idx: 5000 Loss: 0.01709696987836477
Epoch: 22 Idx: 0 Loss: 0.012892514893957974
Epoch: 22 Idx: 5000 Loss: 0.019268158920172924
Epoch: 23 Idx: 0 Loss: 0.006231952186372149
Epoch: 23 Idx: 5000 Loss: 0.0160724098700353
Epoch: 24 Idx: 0 Loss: 0.023733643984318376
Epoch: 24 Idx: 5000 Loss: 0.019196846937647484
Epoch: 25 Idx: 0 Loss: 0.012518465598133667
Epoch: 25 Idx: 5000 Loss: 0.010779801033444631
Epoch: 26 Idx: 0 Loss: 0.01063365212088639
Epoch: 26 Idx: 5000 Loss: 0.0085809512586732
Epoch: 27 Idx: 0 Loss: 0.009955025307069862
Epoch: 27 Idx: 5000 Loss: 0.017272483445126472
Epoch: 28 Idx: 0 Loss: 0.02044428925988204
Epoch: 28 Idx: 5000 Loss: 0.008360209966130409
Epoch: 29 Idx: 0 Loss: 0.018234627699157773
Epoch: 29 Idx: 5000 Loss: 0.030150059120365787
Epoch: 30 Idx: 0 Loss: 0.025154095770120937
Epoch: 30 Idx: 5000 Loss: 0.013936174163578549
Epoch: 31 Idx: 0 Loss: 0.006729999937085616
Epoch: 31 Idx: 5000 Loss: 0.013065720708568356
Epoch: 32 Idx: 0 Loss: 0.028870870079949297
Epoch: 32 Idx: 5000 Loss: 0.013810977715573321
Epoch: 33 Idx: 0 Loss: 0.011775156779347961
Epoch: 33 Idx: 5000 Loss: 0.01698742926927393
Epoch: 34 Idx: 0 Loss: 0.022835203377376267
Epoch: 34 Idx: 5000 Loss: 0.01810024696295893
Epoch: 35 Idx: 0 Loss: 0.011824231467918457
Epoch: 35 Idx: 5000 Loss: 0.01835198592741173
Epoch: 36 Idx: 0 Loss: 0.013678322333372643
Epoch: 36 Idx: 5000 Loss: 0.010320529799940045
Epoch: 37 Idx: 0 Loss: 0.006669911348124334
Epoch: 37 Idx: 5000 Loss: 0.006096343816578361
Epoch: 38 Idx: 0 Loss: 0.035695507021918635
Epoch: 38 Idx: 5000 Loss: 0.015060485014206865
Epoch: 39 Idx: 0 Loss: 0.011116535162152465
Epoch: 39 Idx: 5000 Loss: 0.008488120346188937
Epoch: 40 Idx: 0 Loss: 0.02068232471285343
Epoch: 40 Idx: 5000 Loss: 0.011461931229446436
Epoch: 41 Idx: 0 Loss: 0.012729616925103793
Epoch: 41 Idx: 5000 Loss: 0.013461621408303572
Epoch: 42 Idx: 0 Loss: 0.017995853615444396
Epoch: 42 Idx: 5000 Loss: 0.014549445022948766
Epoch: 43 Idx: 0 Loss: 0.018663856264721005
Epoch: 43 Idx: 5000 Loss: 0.008162012815917472
Epoch: 44 Idx: 0 Loss: 0.02830232445791302
Epoch: 44 Idx: 5000 Loss: 0.01359267337153922
Epoch: 45 Idx: 0 Loss: 0.01447102231676333
Epoch: 45 Idx: 5000 Loss: 0.0052884178729631914
Epoch: 46 Idx: 0 Loss: 0.025758825185296545
Epoch: 46 Idx: 5000 Loss: 0.015552094281016494
Epoch: 47 Idx: 0 Loss: 0.02199383483970038
Epoch: 47 Idx: 5000 Loss: 0.00629215134330538
Epoch: 48 Idx: 0 Loss: 0.031675598193311956
Epoch: 48 Idx: 5000 Loss: 0.013752872491859965
Epoch: 49 Idx: 0 Loss: 0.026847111635533563
Epoch: 49 Idx: 5000 Loss: 0.010800836141983584
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.20804351163208512
Epoch: 0 Idx: 5000 Loss: 0.028629010014610295
Epoch: 1 Idx: 0 Loss: 0.006496890055843333
Epoch: 1 Idx: 5000 Loss: 0.018702115208622784
Epoch: 2 Idx: 0 Loss: 0.011044382795176177
Epoch: 2 Idx: 5000 Loss: 0.011671071042256675
Epoch: 3 Idx: 0 Loss: 0.016775416265602455
Epoch: 3 Idx: 5000 Loss: 0.011047813898445776
Epoch: 4 Idx: 0 Loss: 0.005850583133848709
Epoch: 4 Idx: 5000 Loss: 0.031415167436864996
Epoch: 5 Idx: 0 Loss: 0.010408623440668351
Epoch: 5 Idx: 5000 Loss: 0.026148697398904634
Epoch: 6 Idx: 0 Loss: 0.032442916453608764
Epoch: 6 Idx: 5000 Loss: 0.018090254390072613
Epoch: 7 Idx: 0 Loss: 0.006113095619580746
Epoch: 7 Idx: 5000 Loss: 0.010165562510220326
Epoch: 8 Idx: 0 Loss: 0.006321916117568747
Epoch: 8 Idx: 5000 Loss: 0.022201106891750404
Epoch: 9 Idx: 0 Loss: 0.007594422596216611
Epoch: 9 Idx: 5000 Loss: 0.00915438979378562
Epoch: 10 Idx: 0 Loss: 0.005311280656618568
Epoch: 10 Idx: 5000 Loss: 0.00720587802224511
Epoch: 11 Idx: 0 Loss: 0.0099649338740319
Epoch: 11 Idx: 5000 Loss: 0.018711477853733404
Epoch: 12 Idx: 0 Loss: 0.019336336200600972
Epoch: 12 Idx: 5000 Loss: 0.012744004571645474
Epoch: 13 Idx: 0 Loss: 0.00764605571683339
Epoch: 13 Idx: 5000 Loss: 0.01779367146444026
Epoch: 14 Idx: 0 Loss: 0.009611869668804203
Epoch: 14 Idx: 5000 Loss: 0.01590615569384242
Epoch: 15 Idx: 0 Loss: 0.025833397704981817
Epoch: 15 Idx: 5000 Loss: 0.03453184855404244
Epoch: 16 Idx: 0 Loss: 0.038623441910695146
Epoch: 16 Idx: 5000 Loss: 0.016540533103887325
Epoch: 17 Idx: 0 Loss: 0.023317512131707935
Epoch: 17 Idx: 5000 Loss: 0.030585158260287564
Epoch: 18 Idx: 0 Loss: 0.01428314123778783
Epoch: 18 Idx: 5000 Loss: 0.018017449606487226
Epoch: 19 Idx: 0 Loss: 0.01715951439977927
Epoch: 19 Idx: 5000 Loss: 0.016290787693753715
Epoch: 20 Idx: 0 Loss: 0.02601225542601991
Epoch: 20 Idx: 5000 Loss: 0.013759219446406767
Epoch: 21 Idx: 0 Loss: 0.019049694131845776
Epoch: 21 Idx: 5000 Loss: 0.01786488231710505
Epoch: 22 Idx: 0 Loss: 0.00788397465324267
Epoch: 22 Idx: 5000 Loss: 0.008582653469000424
Epoch: 23 Idx: 0 Loss: 0.01569811518399096
Epoch: 23 Idx: 5000 Loss: 0.009699189468592386
Epoch: 24 Idx: 0 Loss: 0.03604965030302251
Epoch: 24 Idx: 5000 Loss: 0.030402028625409337
Epoch: 25 Idx: 0 Loss: 0.012919735478939666
Epoch: 25 Idx: 5000 Loss: 0.023709825115901216
Epoch: 26 Idx: 0 Loss: 0.028004304415118714
Epoch: 26 Idx: 5000 Loss: 0.03094683786374021
Epoch: 27 Idx: 0 Loss: 0.0213186763505206
Epoch: 27 Idx: 5000 Loss: 0.007596335636063153
Epoch: 28 Idx: 0 Loss: 0.018736691798411455
Epoch: 28 Idx: 5000 Loss: 0.01382810504603239
Epoch: 29 Idx: 0 Loss: 0.012992411558605236
Epoch: 29 Idx: 5000 Loss: 0.009364448068204747
Epoch: 30 Idx: 0 Loss: 0.0124946123293296
Epoch: 30 Idx: 5000 Loss: 0.009926267284834516
Epoch: 31 Idx: 0 Loss: 0.0067130500470525736
Epoch: 31 Idx: 5000 Loss: 0.005278541270764605
Epoch: 32 Idx: 0 Loss: 0.015074249862758134
Epoch: 32 Idx: 5000 Loss: 0.014311307735740906
Epoch: 33 Idx: 0 Loss: 0.007415389801091441
Epoch: 33 Idx: 5000 Loss: 0.00845272653886732
Epoch: 34 Idx: 0 Loss: 0.01047344662392819
Epoch: 34 Idx: 5000 Loss: 0.00804561833434141
Epoch: 35 Idx: 0 Loss: 0.005601920124726347
Epoch: 35 Idx: 5000 Loss: 0.01866682418123229
Epoch: 36 Idx: 0 Loss: 0.022488327413576523
Epoch: 36 Idx: 5000 Loss: 0.008861720585684412
Epoch: 37 Idx: 0 Loss: 0.008136108039458067
Epoch: 37 Idx: 5000 Loss: 0.0037357521463076723
Epoch: 38 Idx: 0 Loss: 0.012440917176617461
Epoch: 38 Idx: 5000 Loss: 0.01991221332043952
Epoch: 39 Idx: 0 Loss: 0.007718161205738438
Epoch: 39 Idx: 5000 Loss: 0.023186141661123073
Epoch: 40 Idx: 0 Loss: 0.009341238809558472
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 387, in to_feature
    for elem in inputs_lenpadded]
  File "main.py", line 387, in <listcomp>
    for elem in inputs_lenpadded]
  File "main.py", line 386, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "main.py", line 386, in <listcomp>
    for nbr_type in ent] for ent in elem]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc214>
Subject: Job 4066851: <python main.py 5 5 False False> in cluster <dcc> Exited

Job <python main.py 5 5 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc214>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 5 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46131.58 sec.
    Max Memory :                                 2904 MB
    Average Memory :                             2752.25 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40513.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46229 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

