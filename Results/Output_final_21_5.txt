2020-09-15 15:49:37.200275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.515555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:40.638427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:40.638538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:40.640571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:40.642203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:40.642575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:40.644523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:40.645996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:40.646224: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:40.646245: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:40.646555: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:40.654089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600075000 Hz
2020-09-15 15:49:40.654278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55decd7bb920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:40.654297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:40.656238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:40.656270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1792803319770792
Epoch: 0 Idx: 5000 Loss: 0.03048818474733906
Epoch: 1 Idx: 0 Loss: 0.019594332112650173
Epoch: 1 Idx: 5000 Loss: 0.042989177960718314
Epoch: 2 Idx: 0 Loss: 0.008618085541384945
Epoch: 2 Idx: 5000 Loss: 0.029337043291510965
Epoch: 3 Idx: 0 Loss: 0.014236630221011442
Epoch: 3 Idx: 5000 Loss: 0.010936169943024626
Epoch: 4 Idx: 0 Loss: 0.025859576771262716
Epoch: 4 Idx: 5000 Loss: 0.024434138227577902
Epoch: 5 Idx: 0 Loss: 0.014935006199145347
Epoch: 5 Idx: 5000 Loss: 0.012118903792419197
Epoch: 6 Idx: 0 Loss: 0.03130891160646706
Epoch: 6 Idx: 5000 Loss: 0.0426231923711987
Epoch: 7 Idx: 0 Loss: 0.010791686778437993
Epoch: 7 Idx: 5000 Loss: 0.023427816075606463
Epoch: 8 Idx: 0 Loss: 0.009220603626463078
Epoch: 8 Idx: 5000 Loss: 0.010650792714935884
Epoch: 9 Idx: 0 Loss: 0.011327580536820175
Epoch: 9 Idx: 5000 Loss: 0.0076013171138326376
Epoch: 10 Idx: 0 Loss: 0.023768302413750907
Epoch: 10 Idx: 5000 Loss: 0.01370236433302376
Epoch: 11 Idx: 0 Loss: 0.0188548574600184
Epoch: 11 Idx: 5000 Loss: 0.014546698878712409
Epoch: 12 Idx: 0 Loss: 0.006859653256403797
Epoch: 12 Idx: 5000 Loss: 0.013714076911735314
Epoch: 13 Idx: 0 Loss: 0.010973539608229044
Epoch: 13 Idx: 5000 Loss: 0.008229809221617045
Epoch: 14 Idx: 0 Loss: 0.015209324287030573
Epoch: 14 Idx: 5000 Loss: 0.013671149348649166
Epoch: 15 Idx: 0 Loss: 0.02867883765438402
Epoch: 15 Idx: 5000 Loss: 0.03636159908257533
Epoch: 16 Idx: 0 Loss: 0.019393657851275933
Epoch: 16 Idx: 5000 Loss: 0.016231973406302388
Epoch: 17 Idx: 0 Loss: 0.026328442169686595
Epoch: 17 Idx: 5000 Loss: 0.036711644503605555
Epoch: 18 Idx: 0 Loss: 0.021920734979225358
Epoch: 18 Idx: 5000 Loss: 0.008474842224095705
Epoch: 19 Idx: 0 Loss: 0.02513913251837694
Epoch: 19 Idx: 5000 Loss: 0.02125091973283815
Epoch: 20 Idx: 0 Loss: 0.008315143837869451
Epoch: 20 Idx: 5000 Loss: 0.015440476641888171
Epoch: 21 Idx: 0 Loss: 0.017078654212948585
Epoch: 21 Idx: 5000 Loss: 0.03416234667532284
Epoch: 22 Idx: 0 Loss: 0.005816480951589308
Epoch: 22 Idx: 5000 Loss: 0.019521640048163664
Epoch: 23 Idx: 0 Loss: 0.012123009865639182
Epoch: 23 Idx: 5000 Loss: 0.023339279364047477
Epoch: 24 Idx: 0 Loss: 0.013133980154431141
Epoch: 24 Idx: 5000 Loss: 0.01178929132647999
Epoch: 25 Idx: 0 Loss: 0.057477167758824804
Epoch: 25 Idx: 5000 Loss: 0.011819375994831297
Epoch: 26 Idx: 0 Loss: 0.013038291304990922
Epoch: 26 Idx: 5000 Loss: 0.02657231051271033
Epoch: 27 Idx: 0 Loss: 0.01682982884882223
Epoch: 27 Idx: 5000 Loss: 0.015593761375617583
Epoch: 28 Idx: 0 Loss: 0.02422271095796105
Epoch: 28 Idx: 5000 Loss: 0.039246119007939353
Epoch: 29 Idx: 0 Loss: 0.016340185401039417
Epoch: 29 Idx: 5000 Loss: 0.023008515507263426
Epoch: 30 Idx: 0 Loss: 0.011321484190855527
Epoch: 30 Idx: 5000 Loss: 0.0071124884262427565
Epoch: 31 Idx: 0 Loss: 0.01938543445413433
Epoch: 31 Idx: 5000 Loss: 0.02324614469992758
Epoch: 32 Idx: 0 Loss: 0.009372904254626287
Epoch: 32 Idx: 5000 Loss: 0.041107243470002594
Epoch: 33 Idx: 0 Loss: 0.010130021279214155
Epoch: 33 Idx: 5000 Loss: 0.010586438958600208
Epoch: 34 Idx: 0 Loss: 0.015357644396762335
Epoch: 34 Idx: 5000 Loss: 0.04050025644579221
Epoch: 35 Idx: 0 Loss: 0.007463699129239119
Epoch: 35 Idx: 5000 Loss: 0.013430478966626094
Epoch: 36 Idx: 0 Loss: 0.021008488452135907
Epoch: 36 Idx: 5000 Loss: 0.01938282897830105
Epoch: 37 Idx: 0 Loss: 0.028227694025802885
Epoch: 37 Idx: 5000 Loss: 0.013044489090303025
Epoch: 38 Idx: 0 Loss: 0.02875495296689651
Epoch: 38 Idx: 5000 Loss: 0.010370141613381003
Epoch: 39 Idx: 0 Loss: 0.02037837810450798
Epoch: 39 Idx: 5000 Loss: 0.018104777856193622
Epoch: 40 Idx: 0 Loss: 0.010248733435249461
Epoch: 40 Idx: 5000 Loss: 0.011177781726664459
Epoch: 41 Idx: 0 Loss: 0.011129537295527325
Epoch: 41 Idx: 5000 Loss: 0.011663536691035866
Epoch: 42 Idx: 0 Loss: 0.010153311282276652
Epoch: 42 Idx: 5000 Loss: 0.012667966291484372
Epoch: 43 Idx: 0 Loss: 0.0422634055239292
Epoch: 43 Idx: 5000 Loss: 0.032543090566123006
Epoch: 44 Idx: 0 Loss: 0.03346233992133225
Epoch: 44 Idx: 5000 Loss: 0.01352821636309959
Epoch: 45 Idx: 0 Loss: 0.011969423373669255
Epoch: 45 Idx: 5000 Loss: 0.01606951377905403
Epoch: 46 Idx: 0 Loss: 0.0226153707683971
Epoch: 46 Idx: 5000 Loss: 0.03961289074447128
Epoch: 47 Idx: 0 Loss: 0.01987157631454402
Epoch: 47 Idx: 5000 Loss: 0.015501456748126034
Epoch: 48 Idx: 0 Loss: 0.01083519872032601
Epoch: 48 Idx: 5000 Loss: 0.018814582676093823
Epoch: 49 Idx: 0 Loss: 0.013595036304337421
Epoch: 49 Idx: 5000 Loss: 0.03064382471702484
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1380599400858366
Epoch: 0 Idx: 5000 Loss: 0.008082548227361618
Epoch: 1 Idx: 0 Loss: 0.01240400920791632
Epoch: 1 Idx: 5000 Loss: 0.014502792986875861
Epoch: 2 Idx: 0 Loss: 0.02976374859153826
Epoch: 2 Idx: 5000 Loss: 0.019895936642035157
Epoch: 3 Idx: 0 Loss: 0.015040374339269155
Epoch: 3 Idx: 5000 Loss: 0.04809532750142355
Epoch: 4 Idx: 0 Loss: 0.017515880270105068
Epoch: 4 Idx: 5000 Loss: 0.019154218726919567
Epoch: 5 Idx: 0 Loss: 0.013093710844761863
Epoch: 5 Idx: 5000 Loss: 0.011702165665692604
Epoch: 6 Idx: 0 Loss: 0.027287474062719266
Epoch: 6 Idx: 5000 Loss: 0.03971467444868972
Epoch: 7 Idx: 0 Loss: 0.008803432785601311
Epoch: 7 Idx: 5000 Loss: 0.015980113748694486
Epoch: 8 Idx: 0 Loss: 0.01616441551861741
Epoch: 8 Idx: 5000 Loss: 0.00772147151023583
Epoch: 9 Idx: 0 Loss: 0.011577255901438434
Epoch: 9 Idx: 5000 Loss: 0.009359514919276531
Epoch: 10 Idx: 0 Loss: 0.007908851546159038
Epoch: 10 Idx: 5000 Loss: 0.037193201879860756
Epoch: 11 Idx: 0 Loss: 0.029360510023539454
Epoch: 11 Idx: 5000 Loss: 0.005187500264392736
Epoch: 12 Idx: 0 Loss: 0.013486622331694873
Epoch: 12 Idx: 5000 Loss: 0.016308151320535355
Epoch: 13 Idx: 0 Loss: 0.013524269558306889
Epoch: 13 Idx: 5000 Loss: 0.017988233297681285
Epoch: 14 Idx: 0 Loss: 0.006550601805266899
Epoch: 14 Idx: 5000 Loss: 0.015221053188236303
Epoch: 15 Idx: 0 Loss: 0.011833780590184908
Epoch: 15 Idx: 5000 Loss: 0.0313825597759781
Epoch: 16 Idx: 0 Loss: 0.02096223599098007
Epoch: 16 Idx: 5000 Loss: 0.02718391043967275
Epoch: 17 Idx: 0 Loss: 0.010858341214898315
Epoch: 17 Idx: 5000 Loss: 0.020896753420361965
Epoch: 18 Idx: 0 Loss: 0.013885450849755506
Epoch: 18 Idx: 5000 Loss: 0.010824646720062758
Epoch: 19 Idx: 0 Loss: 0.013039400675193241
Epoch: 19 Idx: 5000 Loss: 0.015611854597525536
Epoch: 20 Idx: 0 Loss: 0.015514986041773555
Epoch: 20 Idx: 5000 Loss: 0.019258848716960535
Epoch: 21 Idx: 0 Loss: 0.006466679924536998
Epoch: 21 Idx: 5000 Loss: 0.03208471507703349
Epoch: 22 Idx: 0 Loss: 0.016400630494717485
Epoch: 22 Idx: 5000 Loss: 0.007848623715255711
Epoch: 23 Idx: 0 Loss: 0.01468482521940688
Epoch: 23 Idx: 5000 Loss: 0.014624079722869832
Epoch: 24 Idx: 0 Loss: 0.024208985826316073
Epoch: 24 Idx: 5000 Loss: 0.014460837035525767
Epoch: 25 Idx: 0 Loss: 0.02057027237417121
Epoch: 25 Idx: 5000 Loss: 0.014061390740264567
Epoch: 26 Idx: 0 Loss: 0.011335232903932329
Epoch: 26 Idx: 5000 Loss: 0.0074968041867786266
Epoch: 27 Idx: 0 Loss: 0.01856935837988252
Epoch: 27 Idx: 5000 Loss: 0.012578197541875951
Epoch: 28 Idx: 0 Loss: 0.017596169404999768
Epoch: 28 Idx: 5000 Loss: 0.02293632980577231
Epoch: 29 Idx: 0 Loss: 0.019662117705108798
Epoch: 29 Idx: 5000 Loss: 0.020184288696498937
Epoch: 30 Idx: 0 Loss: 0.0354570527360933
Epoch: 30 Idx: 5000 Loss: 0.007075341553979533
Epoch: 31 Idx: 0 Loss: 0.021711456278985602
Epoch: 31 Idx: 5000 Loss: 0.006799519570531674
Epoch: 32 Idx: 0 Loss: 0.01451641948152519
Epoch: 32 Idx: 5000 Loss: 0.016490420494208326
Epoch: 33 Idx: 0 Loss: 0.018458254527980743
Epoch: 33 Idx: 5000 Loss: 0.005872913738407047
Epoch: 34 Idx: 0 Loss: 0.014401512249439332
Epoch: 34 Idx: 5000 Loss: 0.011581825419742989
Epoch: 35 Idx: 0 Loss: 0.01075380564871446
Epoch: 35 Idx: 5000 Loss: 0.011791875476379431
Epoch: 36 Idx: 0 Loss: 0.01111374148082043
Epoch: 36 Idx: 5000 Loss: 0.02328466809249575
Epoch: 37 Idx: 0 Loss: 0.015582275988842636
Epoch: 37 Idx: 5000 Loss: 0.012446219242353413
Epoch: 38 Idx: 0 Loss: 0.010537534709194944
Epoch: 38 Idx: 5000 Loss: 0.015581107301470512
Epoch: 39 Idx: 0 Loss: 0.014598325734533566
Epoch: 39 Idx: 5000 Loss: 0.02460179772157371
Epoch: 40 Idx: 0 Loss: 0.009408492099267118
Epoch: 40 Idx: 5000 Loss: 0.015463064672922796
Epoch: 41 Idx: 0 Loss: 0.025645883752474674
Epoch: 41 Idx: 5000 Loss: 0.009349263113918314
Epoch: 42 Idx: 0 Loss: 0.02279986965963776
Epoch: 42 Idx: 5000 Loss: 0.02068031824979888
Epoch: 43 Idx: 0 Loss: 0.03037046502535237
Epoch: 43 Idx: 5000 Loss: 0.013318087161436037
Epoch: 44 Idx: 0 Loss: 0.025851184623078276
Epoch: 44 Idx: 5000 Loss: 0.01642395490163614
Epoch: 45 Idx: 0 Loss: 0.025946112507649787
Epoch: 45 Idx: 5000 Loss: 0.014195570074181131
Epoch: 46 Idx: 0 Loss: 0.016103845529745937
Epoch: 46 Idx: 5000 Loss: 0.022084390120220728
Epoch: 47 Idx: 0 Loss: 0.008393693799428701
Epoch: 47 Idx: 5000 Loss: 0.03114784414639448
Epoch: 48 Idx: 0 Loss: 0.019140211876957094
Epoch: 48 Idx: 5000 Loss: 0.01597910988523396
Epoch: 49 Idx: 0 Loss: 0.02244039887790706
Epoch: 49 Idx: 5000 Loss: 0.018591505820891883
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1308087104796605
Epoch: 0 Idx: 5000 Loss: 0.0087692933952829
Epoch: 1 Idx: 0 Loss: 0.015441076222277585
Epoch: 1 Idx: 5000 Loss: 0.008108859123539928
Epoch: 2 Idx: 0 Loss: 0.015973703296791562
Epoch: 2 Idx: 5000 Loss: 0.01029570462614899
Epoch: 3 Idx: 0 Loss: 0.023817933895236277
Epoch: 3 Idx: 5000 Loss: 0.028633284052303393
Epoch: 4 Idx: 0 Loss: 0.02425154410244008
Epoch: 4 Idx: 5000 Loss: 0.009054009765326942
Epoch: 5 Idx: 0 Loss: 0.012663543832196207
Epoch: 5 Idx: 5000 Loss: 0.008010869021870162
Epoch: 6 Idx: 0 Loss: 0.012139222268062378
Epoch: 6 Idx: 5000 Loss: 0.011941687518186514
Epoch: 7 Idx: 0 Loss: 0.014332495539099302
Epoch: 7 Idx: 5000 Loss: 0.015966461889672247
Epoch: 8 Idx: 0 Loss: 0.007287028944449093
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 315, in forward
    path_weights = torch.bmm(node_emb[:, None, :], feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc265>
Subject: Job 4066865: <python main.py 5 21 False False> in cluster <dcc> Exited

Job <python main.py 5 21 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc265>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:35 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 21 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46074.04 sec.
    Max Memory :                                 2987 MB
    Average Memory :                             2758.49 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40430.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46143 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

