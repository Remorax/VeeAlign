2020-09-15 15:48:42.626822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:53.182568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:53.298301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:53.298367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:53.300590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:53.320455: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:53.358559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:53.401063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:53.427725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:53.428263: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:53.428286: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:53.428724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:53.477110: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599830000 Hz
2020-09-15 15:48:53.477389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5612243832f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:53.477410: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:53.480447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:53.480471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18502540539869478
Epoch: 0 Idx: 5000 Loss: 0.029967065938769816
Epoch: 1 Idx: 0 Loss: 0.013891867824364811
Epoch: 1 Idx: 5000 Loss: 0.01769917600932326
Epoch: 2 Idx: 0 Loss: 0.010584609684477794
Epoch: 2 Idx: 5000 Loss: 0.013034511827042513
Epoch: 3 Idx: 0 Loss: 0.029088951775966005
Epoch: 3 Idx: 5000 Loss: 0.008176467835625837
Epoch: 4 Idx: 0 Loss: 0.024450886621141713
Epoch: 4 Idx: 5000 Loss: 0.019712719887917653
Epoch: 5 Idx: 0 Loss: 0.008590695680210063
Epoch: 5 Idx: 5000 Loss: 0.005979231721621934
Epoch: 6 Idx: 0 Loss: 0.018396407825106546
Epoch: 6 Idx: 5000 Loss: 0.011110939749178492
Epoch: 7 Idx: 0 Loss: 0.010978544830249872
Epoch: 7 Idx: 5000 Loss: 0.009903361648894903
Epoch: 8 Idx: 0 Loss: 0.02641534507132374
Epoch: 8 Idx: 5000 Loss: 0.017857676514423028
Epoch: 9 Idx: 0 Loss: 0.009131432417303728
Epoch: 9 Idx: 5000 Loss: 0.008323111963860014
Epoch: 10 Idx: 0 Loss: 0.013827253752045902
Epoch: 10 Idx: 5000 Loss: 0.017857696243974628
Epoch: 11 Idx: 0 Loss: 0.02288456489254428
Epoch: 11 Idx: 5000 Loss: 0.0326383178933839
Epoch: 12 Idx: 0 Loss: 0.011523054488317391
Epoch: 12 Idx: 5000 Loss: 0.02572959672889297
Epoch: 13 Idx: 0 Loss: 0.021408066498350274
Epoch: 13 Idx: 5000 Loss: 0.004358122056016626
Epoch: 14 Idx: 0 Loss: 0.028304974174294634
Epoch: 14 Idx: 5000 Loss: 0.020608864059857693
Epoch: 15 Idx: 0 Loss: 0.011775126420051433
Epoch: 15 Idx: 5000 Loss: 0.019238197913940058
Epoch: 16 Idx: 0 Loss: 0.013532155598833341
Epoch: 16 Idx: 5000 Loss: 0.011070133889508088
Epoch: 17 Idx: 0 Loss: 0.00836488016712328
Epoch: 17 Idx: 5000 Loss: 0.012513248759326898
Epoch: 18 Idx: 0 Loss: 0.011050760666611814
Epoch: 18 Idx: 5000 Loss: 0.015736556483523633
Epoch: 19 Idx: 0 Loss: 0.011091718273697595
Epoch: 19 Idx: 5000 Loss: 0.012048853633494975
Epoch: 20 Idx: 0 Loss: 0.013541789541765303
Epoch: 20 Idx: 5000 Loss: 0.014954007860064133
Epoch: 21 Idx: 0 Loss: 0.029513927099300532
Epoch: 21 Idx: 5000 Loss: 0.019694159112834134
Epoch: 22 Idx: 0 Loss: 0.010342106982706796
Epoch: 22 Idx: 5000 Loss: 0.01596044226327802
Epoch: 23 Idx: 0 Loss: 0.008344763565393858
Epoch: 23 Idx: 5000 Loss: 0.029137989703007135
Epoch: 24 Idx: 0 Loss: 0.025630044961448082
Epoch: 24 Idx: 5000 Loss: 0.010280468482175323
Epoch: 25 Idx: 0 Loss: 0.02391709765125925
Epoch: 25 Idx: 5000 Loss: 0.008671872618207491
Epoch: 26 Idx: 0 Loss: 0.005504158110368971
Epoch: 26 Idx: 5000 Loss: 0.01391015043322254
Epoch: 27 Idx: 0 Loss: 0.008124504679893096
Epoch: 27 Idx: 5000 Loss: 0.023076935800457103
Epoch: 28 Idx: 0 Loss: 0.022883833513676358
Epoch: 28 Idx: 5000 Loss: 0.02351638479746635
Epoch: 29 Idx: 0 Loss: 0.017583447369097224
Epoch: 29 Idx: 5000 Loss: 0.010876581121335091
Epoch: 30 Idx: 0 Loss: 0.02242011516471067
Epoch: 30 Idx: 5000 Loss: 0.007173953654682532
Epoch: 31 Idx: 0 Loss: 0.012134947855905538
Epoch: 31 Idx: 5000 Loss: 0.006601528284679867
Epoch: 32 Idx: 0 Loss: 0.029729086806826364
Epoch: 32 Idx: 5000 Loss: 0.015331518489574219
Epoch: 33 Idx: 0 Loss: 0.007823889806791098
Epoch: 33 Idx: 5000 Loss: 0.027405401089536003
Epoch: 34 Idx: 0 Loss: 0.014042900088896765
Epoch: 34 Idx: 5000 Loss: 0.010186349359934923
Epoch: 35 Idx: 0 Loss: 0.014619806732264587
Epoch: 35 Idx: 5000 Loss: 0.01242247478419527
Epoch: 36 Idx: 0 Loss: 0.009254959495113606
Epoch: 36 Idx: 5000 Loss: 0.006354054895662568
Epoch: 37 Idx: 0 Loss: 0.014145158174328161
Epoch: 37 Idx: 5000 Loss: 0.009502685300890108
Epoch: 38 Idx: 0 Loss: 0.027003827850950245
Epoch: 38 Idx: 5000 Loss: 0.021751505011299313
Epoch: 39 Idx: 0 Loss: 0.01363567098899342
Epoch: 39 Idx: 5000 Loss: 0.012339677530218439
Epoch: 40 Idx: 0 Loss: 0.008683766830464873
Epoch: 40 Idx: 5000 Loss: 0.011532831187662528
Epoch: 41 Idx: 0 Loss: 0.016900204755928114
Epoch: 41 Idx: 5000 Loss: 0.004130337067679884
Epoch: 42 Idx: 0 Loss: 0.025164542789785388
Epoch: 42 Idx: 5000 Loss: 0.017319745169606524
Epoch: 43 Idx: 0 Loss: 0.01140421835052263
Epoch: 43 Idx: 5000 Loss: 0.01078138090832638
Epoch: 44 Idx: 0 Loss: 0.01698695180881723
Epoch: 44 Idx: 5000 Loss: 0.016507575561274128
Epoch: 45 Idx: 0 Loss: 0.010624600477453115
Epoch: 45 Idx: 5000 Loss: 0.011203914443881052
Epoch: 46 Idx: 0 Loss: 0.01047911335360893
Epoch: 46 Idx: 5000 Loss: 0.029991726486799895
Epoch: 47 Idx: 0 Loss: 0.025008249282859423
Epoch: 47 Idx: 5000 Loss: 0.018005366478679445
Epoch: 48 Idx: 0 Loss: 0.011987205005384239
Epoch: 48 Idx: 5000 Loss: 0.014530167251390426
Epoch: 49 Idx: 0 Loss: 0.017619973731577962
Epoch: 49 Idx: 5000 Loss: 0.01785402129638616
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14620697770399166
Epoch: 0 Idx: 5000 Loss: 0.011760406573340893
Epoch: 1 Idx: 0 Loss: 0.01981119258238009
Epoch: 1 Idx: 5000 Loss: 0.008422120816476987
Epoch: 2 Idx: 0 Loss: 0.012252490782081743
Epoch: 2 Idx: 5000 Loss: 0.021466735858624245
Epoch: 3 Idx: 0 Loss: 0.015429873514940504
Epoch: 3 Idx: 5000 Loss: 0.006915731079240355
Epoch: 4 Idx: 0 Loss: 0.019344820690180998
Epoch: 4 Idx: 5000 Loss: 0.01918472470563852
Epoch: 5 Idx: 0 Loss: 0.007604427347737287
Epoch: 5 Idx: 5000 Loss: 0.010037942484451078
Epoch: 6 Idx: 0 Loss: 0.015605285132177835
Epoch: 6 Idx: 5000 Loss: 0.01903699787995931
Epoch: 7 Idx: 0 Loss: 0.013680512704220386
Epoch: 7 Idx: 5000 Loss: 0.010637484383332426
Epoch: 8 Idx: 0 Loss: 0.005703719434628754
Epoch: 8 Idx: 5000 Loss: 0.008804584487401502
Epoch: 9 Idx: 0 Loss: 0.013993286893174889
Epoch: 9 Idx: 5000 Loss: 0.012145902076043257
Epoch: 10 Idx: 0 Loss: 0.013938330603103611
Epoch: 10 Idx: 5000 Loss: 0.016581623532013496
Epoch: 11 Idx: 0 Loss: 0.0352165500393905
Epoch: 11 Idx: 5000 Loss: 0.008070972296806062
Epoch: 12 Idx: 0 Loss: 0.010121859574744816
Epoch: 12 Idx: 5000 Loss: 0.022295865962656966
Epoch: 13 Idx: 0 Loss: 0.006475282525896061
Epoch: 13 Idx: 5000 Loss: 0.014824714242412647
Epoch: 14 Idx: 0 Loss: 0.012802888413190652
Epoch: 14 Idx: 5000 Loss: 0.029797439881930933
Epoch: 15 Idx: 0 Loss: 0.009074614115490393
Epoch: 15 Idx: 5000 Loss: 0.013287514174913492
Epoch: 16 Idx: 0 Loss: 0.01534725273219547
Epoch: 16 Idx: 5000 Loss: 0.051974958368926835
Epoch: 17 Idx: 0 Loss: 0.014143468968329654
Epoch: 17 Idx: 5000 Loss: 0.01411584876026565
Epoch: 18 Idx: 0 Loss: 0.013978588231036353
Epoch: 18 Idx: 5000 Loss: 0.011864550912969927
Epoch: 19 Idx: 0 Loss: 0.013944322769890065
Epoch: 19 Idx: 5000 Loss: 0.006445577877220489
Epoch: 20 Idx: 0 Loss: 0.014325995500414159
Epoch: 20 Idx: 5000 Loss: 0.010623541322734152
Epoch: 21 Idx: 0 Loss: 0.011497094849566836
Epoch: 21 Idx: 5000 Loss: 0.023429603095661212
Epoch: 22 Idx: 0 Loss: 0.015269303879736013
Epoch: 22 Idx: 5000 Loss: 0.013573273802806892
Epoch: 23 Idx: 0 Loss: 0.015197937557177998
Epoch: 23 Idx: 5000 Loss: 0.0127283582263394
Epoch: 24 Idx: 0 Loss: 0.026970475864895413
Epoch: 24 Idx: 5000 Loss: 0.009940171530835826
Epoch: 25 Idx: 0 Loss: 0.02350060866889661
Epoch: 25 Idx: 5000 Loss: 0.016906752547463884
Epoch: 26 Idx: 0 Loss: 0.00476166914592362
Epoch: 26 Idx: 5000 Loss: 0.03609719420249847
Epoch: 27 Idx: 0 Loss: 0.008441001368947607
Epoch: 27 Idx: 5000 Loss: 0.012155069608158625
Epoch: 28 Idx: 0 Loss: 0.009350235630822525
Epoch: 28 Idx: 5000 Loss: 0.006871884068705169
Epoch: 29 Idx: 0 Loss: 0.006558671811155306
Epoch: 29 Idx: 5000 Loss: 0.021877966096476784
Epoch: 30 Idx: 0 Loss: 0.03796312651101865
Epoch: 30 Idx: 5000 Loss: 0.025433697289732857
Epoch: 31 Idx: 0 Loss: 0.01152612425711265
Epoch: 31 Idx: 5000 Loss: 0.015112357070442088
Epoch: 32 Idx: 0 Loss: 0.00909311396914268
Epoch: 32 Idx: 5000 Loss: 0.01126248358198259
Epoch: 33 Idx: 0 Loss: 0.014983462369819319
Epoch: 33 Idx: 5000 Loss: 0.013322985230306329
Epoch: 34 Idx: 0 Loss: 0.02889505371180479
Epoch: 34 Idx: 5000 Loss: 0.013802138365187747
Epoch: 35 Idx: 0 Loss: 0.02044795998147856
Epoch: 35 Idx: 5000 Loss: 0.018954843649696705
Epoch: 36 Idx: 0 Loss: 0.015918662337917062
Epoch: 36 Idx: 5000 Loss: 0.01857544675760881
Epoch: 37 Idx: 0 Loss: 0.019639267173077773
Epoch: 37 Idx: 5000 Loss: 0.011040472212884525
Epoch: 38 Idx: 0 Loss: 0.03177587570078613
Epoch: 38 Idx: 5000 Loss: 0.007695170792618095
Epoch: 39 Idx: 0 Loss: 0.007464303826223555
Epoch: 39 Idx: 5000 Loss: 0.01250443927691004
Epoch: 40 Idx: 0 Loss: 0.007716295406553516
Epoch: 40 Idx: 5000 Loss: 0.007518015251601548
Epoch: 41 Idx: 0 Loss: 0.0184594331415934
Epoch: 41 Idx: 5000 Loss: 0.007604054144865495
Epoch: 42 Idx: 0 Loss: 0.015581715440147498
Epoch: 42 Idx: 5000 Loss: 0.01826642597159083
Epoch: 43 Idx: 0 Loss: 0.012692714241446976
Epoch: 43 Idx: 5000 Loss: 0.007932204125212061
Epoch: 44 Idx: 0 Loss: 0.029749952492043118
Epoch: 44 Idx: 5000 Loss: 0.012875713875801607
Epoch: 45 Idx: 0 Loss: 0.01718944589731531
Epoch: 45 Idx: 5000 Loss: 0.005682374920196678
Epoch: 46 Idx: 0 Loss: 0.01907113443466579
Epoch: 46 Idx: 5000 Loss: 0.0073007897394902705
Epoch: 47 Idx: 0 Loss: 0.008492501524642058
Epoch: 47 Idx: 5000 Loss: 0.005395419326586474
Epoch: 48 Idx: 0 Loss: 0.016633474147698613
Epoch: 48 Idx: 5000 Loss: 0.00927762163722815
Epoch: 49 Idx: 0 Loss: 0.03224355851479524
Epoch: 49 Idx: 5000 Loss: 0.017419376603732453
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.12643189730890125
Epoch: 0 Idx: 5000 Loss: 0.022679918329698786
Epoch: 1 Idx: 0 Loss: 0.024818020606955878
Epoch: 1 Idx: 5000 Loss: 0.009802057293583289
Epoch: 2 Idx: 0 Loss: 0.04075257031742513
Epoch: 2 Idx: 5000 Loss: 0.014977652076686901
Epoch: 3 Idx: 0 Loss: 0.0172408724883858
Epoch: 3 Idx: 5000 Loss: 0.016726440916029872
Epoch: 4 Idx: 0 Loss: 0.02138120849848459
Epoch: 4 Idx: 5000 Loss: 0.015193666191435862
Epoch: 5 Idx: 0 Loss: 0.01543650219798069
Epoch: 5 Idx: 5000 Loss: 0.009966428365921407
Epoch: 6 Idx: 0 Loss: 0.007272716404630035
Epoch: 6 Idx: 5000 Loss: 0.01786923513340724
Epoch: 7 Idx: 0 Loss: 0.019747755572242637
Epoch: 7 Idx: 5000 Loss: 0.018861006972182917
Epoch: 8 Idx: 0 Loss: 0.011318452650064374
Epoch: 8 Idx: 5000 Loss: 0.010527914741064036
Epoch: 9 Idx: 0 Loss: 0.013354008786779073
Epoch: 9 Idx: 5000 Loss: 0.00924027637202294
Epoch: 10 Idx: 0 Loss: 0.014702265065870843
Epoch: 10 Idx: 5000 Loss: 0.007546027818185924
Epoch: 11 Idx: 0 Loss: 0.010133430633072524
Epoch: 11 Idx: 5000 Loss: 0.01324201357027534
Epoch: 12 Idx: 0 Loss: 0.023275752642863058
Epoch: 12 Idx: 5000 Loss: 0.014369226983811366
Epoch: 13 Idx: 0 Loss: 0.008728866286118816
Epoch: 13 Idx: 5000 Loss: 0.013656751383995098
Epoch: 14 Idx: 0 Loss: 0.022669570668449008
Epoch: 14 Idx: 5000 Loss: 0.010271596157621554
Epoch: 15 Idx: 0 Loss: 0.010374541469285042
Epoch: 15 Idx: 5000 Loss: 0.02121463688648397
Epoch: 16 Idx: 0 Loss: 0.010672959022829328
Epoch: 16 Idx: 5000 Loss: 0.020224290512270593
Epoch: 17 Idx: 0 Loss: 0.010489899408800959
Epoch: 17 Idx: 5000 Loss: 0.022455810243735802
Epoch: 18 Idx: 0 Loss: 0.005877814021705426
Epoch: 18 Idx: 5000 Loss: 0.019158391900865275
Epoch: 19 Idx: 0 Loss: 0.039710160712923076
Epoch: 19 Idx: 5000 Loss: 0.015377174242318756
Epoch: 20 Idx: 0 Loss: 0.015781250622719758
Epoch: 20 Idx: 5000 Loss: 0.011938596072426524
Epoch: 21 Idx: 0 Loss: 0.011073301076087456
Epoch: 21 Idx: 5000 Loss: 0.007868109733823792
Epoch: 22 Idx: 0 Loss: 0.018805229908168984
Epoch: 22 Idx: 5000 Loss: 0.015798187351282515
Epoch: 23 Idx: 0 Loss: 0.010062209317106994
Epoch: 23 Idx: 5000 Loss: 0.009977238579722146
Epoch: 24 Idx: 0 Loss: 0.011501630507933626
Epoch: 24 Idx: 5000 Loss: 0.01149584481532363
Epoch: 25 Idx: 0 Loss: 0.016672593521379862
Epoch: 25 Idx: 5000 Loss: 0.01175533664763279
Epoch: 26 Idx: 0 Loss: 0.01534985152923124
Epoch: 26 Idx: 5000 Loss: 0.006904110567386525
Epoch: 27 Idx: 0 Loss: 0.018432818982798697
Epoch: 27 Idx: 5000 Loss: 0.017708239564646296
Epoch: 28 Idx: 0 Loss: 0.037264792542929456
Epoch: 28 Idx: 5000 Loss: 0.012533060735986198
Epoch: 29 Idx: 0 Loss: 0.015736131239884276
Epoch: 29 Idx: 5000 Loss: 0.01925928269720286
Epoch: 30 Idx: 0 Loss: 0.008446011200036388
Epoch: 30 Idx: 5000 Loss: 0.03259971677768939
Epoch: 31 Idx: 0 Loss: 0.01520787275275207
Epoch: 31 Idx: 5000 Loss: 0.03740719401766312
Epoch: 32 Idx: 0 Loss: 0.00756673031727751
Epoch: 32 Idx: 5000 Loss: 0.009392846194161936
Epoch: 33 Idx: 0 Loss: 0.009753893050066171
Epoch: 33 Idx: 5000 Loss: 0.04119685388689495
Epoch: 34 Idx: 0 Loss: 0.007891953114613614
Epoch: 34 Idx: 5000 Loss: 0.015481261385393748
Epoch: 35 Idx: 0 Loss: 0.01912036211230552
Epoch: 35 Idx: 5000 Loss: 0.004969423700426114
Epoch: 36 Idx: 0 Loss: 0.008379980118767266
Epoch: 36 Idx: 5000 Loss: 0.009627837870142257
Epoch: 37 Idx: 0 Loss: 0.008077245497539727
Epoch: 37 Idx: 5000 Loss: 0.0057948690003776625
Epoch: 38 Idx: 0 Loss: 0.011144554813706069
Epoch: 38 Idx: 5000 Loss: 0.010152652902293932
Epoch: 39 Idx: 0 Loss: 0.033752099270905424
Epoch: 39 Idx: 5000 Loss: 0.005798773917800565
Epoch: 40 Idx: 0 Loss: 0.015467230990726012
Epoch: 40 Idx: 5000 Loss: 0.009252872027616477
Epoch: 41 Idx: 0 Loss: 0.008790334020207558
Epoch: 41 Idx: 5000 Loss: 0.014605241729465127
Epoch: 42 Idx: 0 Loss: 0.00984648500433344
Epoch: 42 Idx: 5000 Loss: 0.008133389811481524
Epoch: 43 Idx: 0 Loss: 0.015227738765515097
Epoch: 43 Idx: 5000 Loss: 0.008551439436362405
Epoch: 44 Idx: 0 Loss: 0.010328523091081057
Epoch: 44 Idx: 5000 Loss: 0.006849310604025636
Epoch: 45 Idx: 0 Loss: 0.010355277203375186
Epoch: 45 Idx: 5000 Loss: 0.01242033396675998
Epoch: 46 Idx: 0 Loss: 0.015427652484571636
Epoch: 46 Idx: 5000 Loss: 0.0132719397832534
Epoch: 47 Idx: 0 Loss: 0.00840780861364827
Epoch: 47 Idx: 5000 Loss: 0.014587388376016624
Epoch: 48 Idx: 0 Loss: 0.01123126814173627
Epoch: 48 Idx: 5000 Loss: 0.021078851074665603
Epoch: 49 Idx: 0 Loss: 0.015668819031440653
Epoch: 49 Idx: 5000 Loss: 0.006576969331186902
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.23600477313486934
Epoch: 0 Idx: 5000 Loss: 0.023593756182346978
Epoch: 1 Idx: 0 Loss: 0.006420601816823513
Epoch: 1 Idx: 5000 Loss: 0.01312670034865245
Epoch: 2 Idx: 0 Loss: 0.016533089555317466
Epoch: 2 Idx: 5000 Loss: 0.01355891205499352
Epoch: 3 Idx: 0 Loss: 0.026845901163102634
Epoch: 3 Idx: 5000 Loss: 0.01365702466502888
Epoch: 4 Idx: 0 Loss: 0.023477628983136472
Epoch: 4 Idx: 5000 Loss: 0.008212391896237554
Epoch: 5 Idx: 0 Loss: 0.027033350237325438
Epoch: 5 Idx: 5000 Loss: 0.006229919652010663
Epoch: 6 Idx: 0 Loss: 0.008440864640512672
Epoch: 6 Idx: 5000 Loss: 0.009224850473018171
Epoch: 7 Idx: 0 Loss: 0.019711700491962705
Epoch: 7 Idx: 5000 Loss: 0.01102417991676234
Epoch: 8 Idx: 0 Loss: 0.04005128057901341
Epoch: 8 Idx: 5000 Loss: 0.020284331607930924
Epoch: 9 Idx: 0 Loss: 0.015215202920414148
Epoch: 9 Idx: 5000 Loss: 0.014583335409426783
Epoch: 10 Idx: 0 Loss: 0.022181175321968075
Epoch: 10 Idx: 5000 Loss: 0.011792919071126621
Epoch: 11 Idx: 0 Loss: 0.006261635519858881
Epoch: 11 Idx: 5000 Loss: 0.04494683602572093
Epoch: 12 Idx: 0 Loss: 0.012793239507355524
Epoch: 12 Idx: 5000 Loss: 0.03703404273857982
Epoch: 13 Idx: 0 Loss: 0.015180341986635967
Epoch: 13 Idx: 5000 Loss: 0.019845787211328812
Epoch: 14 Idx: 0 Loss: 0.009495830827777408
Epoch: 14 Idx: 5000 Loss: 0.009905874073421216
Epoch: 15 Idx: 0 Loss: 0.010764173957208738
Epoch: 15 Idx: 5000 Loss: 0.018533897457367377
Epoch: 16 Idx: 0 Loss: 0.014637734911171098
Epoch: 16 Idx: 5000 Loss: 0.021533758607697337
Epoch: 17 Idx: 0 Loss: 0.011188003844563034
Epoch: 17 Idx: 5000 Loss: 0.027614432460768053
Epoch: 18 Idx: 0 Loss: 0.02508634642746292
Epoch: 18 Idx: 5000 Loss: 0.0355099762028763
Epoch: 19 Idx: 0 Loss: 0.007982611489935013
Epoch: 19 Idx: 5000 Loss: 0.03568308141205443
Epoch: 20 Idx: 0 Loss: 0.008697790639390727
Epoch: 20 Idx: 5000 Loss: 0.020394548948155775
Epoch: 21 Idx: 0 Loss: 0.00838588532128759
Epoch: 21 Idx: 5000 Loss: 0.03356635115865658
Epoch: 22 Idx: 0 Loss: 0.013572625799907485
Epoch: 22 Idx: 5000 Loss: 0.02453981065742822
Epoch: 23 Idx: 0 Loss: 0.03313440904405323
Epoch: 23 Idx: 5000 Loss: 0.03581166989815541
Epoch: 24 Idx: 0 Loss: 0.009384783553725132
Epoch: 24 Idx: 5000 Loss: 0.007112185887187184
Epoch: 25 Idx: 0 Loss: 0.022056653284452367
Epoch: 25 Idx: 5000 Loss: 0.03292103459716628
Epoch: 26 Idx: 0 Loss: 0.01031885575827916
Epoch: 26 Idx: 5000 Loss: 0.009597494471062474
Epoch: 27 Idx: 0 Loss: 0.011099996979760541
Epoch: 27 Idx: 5000 Loss: 0.02750885075644204
Epoch: 28 Idx: 0 Loss: 0.009268744752492824
Epoch: 28 Idx: 5000 Loss: 0.01226174469575354
Epoch: 29 Idx: 0 Loss: 0.013971795963476934
Epoch: 29 Idx: 5000 Loss: 0.021413948698253343
Epoch: 30 Idx: 0 Loss: 0.009344192616362537
Epoch: 30 Idx: 5000 Loss: 0.01139301345524095
Epoch: 31 Idx: 0 Loss: 0.017953151908527146
Epoch: 31 Idx: 5000 Loss: 0.012952792399663963
Epoch: 32 Idx: 0 Loss: 0.036486038003204435
Epoch: 32 Idx: 5000 Loss: 0.01894586064397413
Epoch: 33 Idx: 0 Loss: 0.008998337386333353
Epoch: 33 Idx: 5000 Loss: 0.029417438804581073
Epoch: 34 Idx: 0 Loss: 0.009446715344280982
Epoch: 34 Idx: 5000 Loss: 0.015408715599911266
Epoch: 35 Idx: 0 Loss: 0.02973129124092197
Epoch: 35 Idx: 5000 Loss: 0.007912271589571689
Epoch: 36 Idx: 0 Loss: 0.012933371113987815
Epoch: 36 Idx: 5000 Loss: 0.022134382455510474
Epoch: 37 Idx: 0 Loss: 0.011037660604359283
Epoch: 37 Idx: 5000 Loss: 0.022462494581962568
Epoch: 38 Idx: 0 Loss: 0.026029321731108487
Epoch: 38 Idx: 5000 Loss: 0.011137885194064783
Epoch: 39 Idx: 0 Loss: 0.0088170505828124
Epoch: 39 Idx: 5000 Loss: 0.01298282014295556
Epoch: 40 Idx: 0 Loss: 0.01391232069049052
Epoch: 40 Idx: 5000 Loss: 0.016680144908265426
Epoch: 41 Idx: 0 Loss: 0.010610199021601026
Epoch: 41 Idx: 5000 Loss: 0.01643060512686094
Epoch: 42 Idx: 0 Loss: 0.013995240807900804
Epoch: 42 Idx: 5000 Loss: 0.014502523864260273
Epoch: 43 Idx: 0 Loss: 0.005758717134186495
Epoch: 43 Idx: 5000 Loss: 0.017797513587362975
Epoch: 44 Idx: 0 Loss: 0.021495574231206203
Epoch: 44 Idx: 5000 Loss: 0.014642486825367163
Epoch: 45 Idx: 0 Loss: 0.008823739768698392
Epoch: 45 Idx: 5000 Loss: 0.0062012836901619095
Epoch: 46 Idx: 0 Loss: 0.027642943641784046
Epoch: 46 Idx: 5000 Loss: 0.014799868723241892
Epoch: 47 Idx: 0 Loss: 0.014363375972596132
Epoch: 47 Idx: 5000 Loss: 0.01956138848286805
Epoch: 48 Idx: 0 Loss: 0.016179343704199683
Epoch: 48 Idx: 5000 Loss: 0.020332352281934314
Epoch: 49 Idx: 0 Loss: 0.012188934996078126
Epoch: 49 Idx: 5000 Loss: 0.010227038624881946
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.21080024242722017
Epoch: 0 Idx: 5000 Loss: 0.01452066720784687
Epoch: 1 Idx: 0 Loss: 0.011319547036960005
Epoch: 1 Idx: 5000 Loss: 0.007075579052386266
Epoch: 2 Idx: 0 Loss: 0.009556474636890825
Epoch: 2 Idx: 5000 Loss: 0.01408072430572341
Epoch: 3 Idx: 0 Loss: 0.027817814297058607
Epoch: 3 Idx: 5000 Loss: 0.01830233747248604
Epoch: 4 Idx: 0 Loss: 0.012431773539727664
Epoch: 4 Idx: 5000 Loss: 0.015076596450929835
Epoch: 5 Idx: 0 Loss: 0.012208137074743422
Epoch: 5 Idx: 5000 Loss: 0.03198164311338913
Epoch: 6 Idx: 0 Loss: 0.013067012759005313
Epoch: 6 Idx: 5000 Loss: 0.013640300062246362
Epoch: 7 Idx: 0 Loss: 0.03973562679123602
Epoch: 7 Idx: 5000 Loss: 0.008679767162874106
Epoch: 8 Idx: 0 Loss: 0.015298949599533068
Epoch: 8 Idx: 5000 Loss: 0.018918498792539103
Epoch: 9 Idx: 0 Loss: 0.012424332753740563
Epoch: 9 Idx: 5000 Loss: 0.00817352524800597
Epoch: 10 Idx: 0 Loss: 0.011910352465295012
Epoch: 10 Idx: 5000 Loss: 0.007143187902520299
Epoch: 11 Idx: 0 Loss: 0.014068294506876997
Epoch: 11 Idx: 5000 Loss: 0.03137347175000633
Epoch: 12 Idx: 0 Loss: 0.016173509144963
Epoch: 12 Idx: 5000 Loss: 0.02429904328500733
Epoch: 13 Idx: 0 Loss: 0.02263919641143457
Epoch: 13 Idx: 5000 Loss: 0.016400891156488052
Epoch: 14 Idx: 0 Loss: 0.02166617641726361
Epoch: 14 Idx: 5000 Loss: 0.013490986124424795
Epoch: 15 Idx: 0 Loss: 0.018117608597221432
Epoch: 15 Idx: 5000 Loss: 0.01751792542861958
Epoch: 16 Idx: 0 Loss: 0.010886896125679123
Epoch: 16 Idx: 5000 Loss: 0.012106358866823473
Epoch: 17 Idx: 0 Loss: 0.016425085393132133
Epoch: 17 Idx: 5000 Loss: 0.0063061539848923605
Epoch: 18 Idx: 0 Loss: 0.013585605102771422
Epoch: 18 Idx: 5000 Loss: 0.008784117345658062
Epoch: 19 Idx: 0 Loss: 0.010177753780910893
Epoch: 19 Idx: 5000 Loss: 0.012312866959371607
Epoch: 20 Idx: 0 Loss: 0.010623455669905413
Epoch: 20 Idx: 5000 Loss: 0.0075527871697473855
Epoch: 21 Idx: 0 Loss: 0.020140054428449947
Epoch: 21 Idx: 5000 Loss: 0.016106175855490946
Epoch: 22 Idx: 0 Loss: 0.04111741988883589
Epoch: 22 Idx: 5000 Loss: 0.013094902857936026
Epoch: 23 Idx: 0 Loss: 0.010474992010255058
Epoch: 23 Idx: 5000 Loss: 0.010436755382857946
Epoch: 24 Idx: 0 Loss: 0.015340342345591718
Epoch: 24 Idx: 5000 Loss: 0.054425558028678295
Epoch: 25 Idx: 0 Loss: 0.00967918074548383
Epoch: 25 Idx: 5000 Loss: 0.01968938031104997
Epoch: 26 Idx: 0 Loss: 0.015034489642510484
Epoch: 26 Idx: 5000 Loss: 0.02524967675084759
Epoch: 27 Idx: 0 Loss: 0.006495467177567368
Epoch: 27 Idx: 5000 Loss: 0.017111470049834807
Epoch: 28 Idx: 0 Loss: 0.008874715757745493
Epoch: 28 Idx: 5000 Loss: 0.008321000736512338
Epoch: 29 Idx: 0 Loss: 0.014608624398717258
Epoch: 29 Idx: 5000 Loss: 0.011548132455193304
Epoch: 30 Idx: 0 Loss: 0.008680676143535267
Epoch: 30 Idx: 5000 Loss: 0.01627176841976579
Epoch: 31 Idx: 0 Loss: 0.010474247032114364
Epoch: 31 Idx: 5000 Loss: 0.011264531996199874
Epoch: 32 Idx: 0 Loss: 0.010709298795541469
Epoch: 32 Idx: 5000 Loss: 0.007338421328068398
Epoch: 33 Idx: 0 Loss: 0.012481713740969739
Epoch: 33 Idx: 5000 Loss: 0.01078400255834716
Epoch: 34 Idx: 0 Loss: 0.022114189119870006
Epoch: 34 Idx: 5000 Loss: 0.009934188178880704
Epoch: 35 Idx: 0 Loss: 0.010394928709768082
Epoch: 35 Idx: 5000 Loss: 0.03562318150195523
Epoch: 36 Idx: 0 Loss: 0.017806776410691637
Epoch: 36 Idx: 5000 Loss: 0.017227840440295735
Epoch: 37 Idx: 0 Loss: 0.020996461162648947
Epoch: 37 Idx: 5000 Loss: 0.008640132320291857
Epoch: 38 Idx: 0 Loss: 0.0261677470831388
Epoch: 38 Idx: 5000 Loss: 0.02719510370856465
Epoch: 39 Idx: 0 Loss: 0.008282446437030744
Epoch: 39 Idx: 5000 Loss: 0.022723926304400243
Epoch: 40 Idx: 0 Loss: 0.019497616062952684
Epoch: 40 Idx: 5000 Loss: 0.019031343389472783
Epoch: 41 Idx: 0 Loss: 0.009567198976848918
Epoch: 41 Idx: 5000 Loss: 0.013811466187468835
Epoch: 42 Idx: 0 Loss: 0.01610092116063957
Epoch: 42 Idx: 5000 Loss: 0.025144625820933148
Epoch: 43 Idx: 0 Loss: 0.022032339482863775
Epoch: 43 Idx: 5000 Loss: 0.009018870299811813
Epoch: 44 Idx: 0 Loss: 0.005406220587986529
Epoch: 44 Idx: 5000 Loss: 0.01376234450697559
Epoch: 45 Idx: 0 Loss: 0.010372238215580594
Epoch: 45 Idx: 5000 Loss: 0.025243979917960346
Epoch: 46 Idx: 0 Loss: 0.005264145028590255
Epoch: 46 Idx: 5000 Loss: 0.01102583981957922
Epoch: 47 Idx: 0 Loss: 0.016650546940460413
Epoch: 47 Idx: 5000 Loss: 0.005758180437943302
Epoch: 48 Idx: 0 Loss: 0.034322098805978266
Epoch: 48 Idx: 5000 Loss: 0.015789655724798856
Epoch: 49 Idx: 0 Loss: 0.027562670261473035
Epoch: 49 Idx: 5000 Loss: 0.028781049114143704
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.18829081524968003
Epoch: 0 Idx: 5000 Loss: 0.024837128388230274
Epoch: 1 Idx: 0 Loss: 0.01363838061804042
Epoch: 1 Idx: 5000 Loss: 0.014779105316537096
Epoch: 2 Idx: 0 Loss: 0.010060240449080472
Epoch: 2 Idx: 5000 Loss: 0.03125179162960054
Epoch: 3 Idx: 0 Loss: 0.008313994441345427
Epoch: 3 Idx: 5000 Loss: 0.02607114525209911
Epoch: 4 Idx: 0 Loss: 0.01383596822870439
Epoch: 4 Idx: 5000 Loss: 0.005353393345433618
Epoch: 5 Idx: 0 Loss: 0.012806714473288239
Epoch: 5 Idx: 5000 Loss: 0.014845738921115952
Epoch: 6 Idx: 0 Loss: 0.011056994630609565
Epoch: 6 Idx: 5000 Loss: 0.022987448764948123
Epoch: 7 Idx: 0 Loss: 0.006992532807788342
Epoch: 7 Idx: 5000 Loss: 0.011580421304093043
Epoch: 8 Idx: 0 Loss: 0.004011736214675391
Epoch: 8 Idx: 5000 Loss: 0.020974962421616134
Epoch: 9 Idx: 0 Loss: 0.02456859307313799
Epoch: 9 Idx: 5000 Loss: 0.009822787902892916
Epoch: 10 Idx: 0 Loss: 0.011067915764502969
Epoch: 10 Idx: 5000 Loss: 0.010833631570501497
Epoch: 11 Idx: 0 Loss: 0.022318222492322255
Epoch: 11 Idx: 5000 Loss: 0.013497933237148653
Epoch: 12 Idx: 0 Loss: 0.013337029107080263
Epoch: 12 Idx: 5000 Loss: 0.007537280095579434
Epoch: 13 Idx: 0 Loss: 0.0121996577603171
Epoch: 13 Idx: 5000 Loss: 0.010668930543782491
Epoch: 14 Idx: 0 Loss: 0.012246423867640382
Epoch: 14 Idx: 5000 Loss: 0.010576064329588646
Epoch: 15 Idx: 0 Loss: 0.015453603497339513
Epoch: 15 Idx: 5000 Loss: 0.029534645810005734
Epoch: 16 Idx: 0 Loss: 0.01786397426718883
Epoch: 16 Idx: 5000 Loss: 0.014441245848020609
Epoch: 17 Idx: 0 Loss: 0.014107616451879978
Epoch: 17 Idx: 5000 Loss: 0.01553216973383916
Epoch: 18 Idx: 0 Loss: 0.007563573559654517
Epoch: 18 Idx: 5000 Loss: 0.024553201471345897
Epoch: 19 Idx: 0 Loss: 0.01618092556680544
Epoch: 19 Idx: 5000 Loss: 0.017241486877219256
Epoch: 20 Idx: 0 Loss: 0.015383832501944748
Epoch: 20 Idx: 5000 Loss: 0.012091144411598366
Epoch: 21 Idx: 0 Loss: 0.014196083293216368
Epoch: 21 Idx: 5000 Loss: 0.016001603472202322
Epoch: 22 Idx: 0 Loss: 0.016363592536588638
Epoch: 22 Idx: 5000 Loss: 0.00473928230317724
Epoch: 23 Idx: 0 Loss: 0.010099272457562694
Epoch: 23 Idx: 5000 Loss: 0.03213479947805395
Epoch: 24 Idx: 0 Loss: 0.016516349137960896
Epoch: 24 Idx: 5000 Loss: 0.01640260389228421
Epoch: 25 Idx: 0 Loss: 0.018498540127888458
Epoch: 25 Idx: 5000 Loss: 0.02327417844568656
Epoch: 26 Idx: 0 Loss: 0.012858330944205213
Epoch: 26 Idx: 5000 Loss: 0.009439214194691951
Epoch: 27 Idx: 0 Loss: 0.012665130511375907
Epoch: 27 Idx: 5000 Loss: 0.008616285845252081
Epoch: 28 Idx: 0 Loss: 0.03755998708036293
Epoch: 28 Idx: 5000 Loss: 0.019454548470023845
Epoch: 29 Idx: 0 Loss: 0.01735897645155848
Epoch: 29 Idx: 5000 Loss: 0.030212936099239036
Epoch: 30 Idx: 0 Loss: 0.012497038267359106
Epoch: 30 Idx: 5000 Loss: 0.014786691305125355
Epoch: 31 Idx: 0 Loss: 0.027582583247342363
Epoch: 31 Idx: 5000 Loss: 0.011446171991373207
Epoch: 32 Idx: 0 Loss: 0.006351477425914522
Epoch: 32 Idx: 5000 Loss: 0.0071346023645482304
Epoch: 33 Idx: 0 Loss: 0.017730054127133868
Epoch: 33 Idx: 5000 Loss: 0.013719828858119072
Epoch: 34 Idx: 0 Loss: 0.015957496810831053
Epoch: 34 Idx: 5000 Loss: 0.01944458880770484
Epoch: 35 Idx: 0 Loss: 0.021779995185293288
Epoch: 35 Idx: 5000 Loss: 0.006004579415096568
Epoch: 36 Idx: 0 Loss: 0.02600699730443209
Epoch: 36 Idx: 5000 Loss: 0.010074525037308836
Epoch: 37 Idx: 0 Loss: 0.007020122299602205
Epoch: 37 Idx: 5000 Loss: 0.008237359172020352
Epoch: 38 Idx: 0 Loss: 0.025433811539243043
Epoch: 38 Idx: 5000 Loss: 0.011604439380306973
Epoch: 39 Idx: 0 Loss: 0.010986953725170338
Epoch: 39 Idx: 5000 Loss: 0.003705685033363282
Epoch: 40 Idx: 0 Loss: 0.03818908071539916
Epoch: 40 Idx: 5000 Loss: 0.008565094170284816
Epoch: 41 Idx: 0 Loss: 0.012696413547703086
Epoch: 41 Idx: 5000 Loss: 0.01599004259877437
Epoch: 42 Idx: 0 Loss: 0.044342812237455904
Epoch: 42 Idx: 5000 Loss: 0.00825187973330225
Epoch: 43 Idx: 0 Loss: 0.02227893324690646
Epoch: 43 Idx: 5000 Loss: 0.0128409633296418
Epoch: 44 Idx: 0 Loss: 0.010883738605088426
Epoch: 44 Idx: 5000 Loss: 0.019727476265009324
Epoch: 45 Idx: 0 Loss: 0.0310307253599494
Epoch: 45 Idx: 5000 Loss: 0.008846711859422467
Epoch: 46 Idx: 0 Loss: 0.015949252614327336
Epoch: 46 Idx: 5000 Loss: 0.024353551414866004
Epoch: 47 Idx: 0 Loss: 0.014899311006813725
Epoch: 47 Idx: 5000 Loss: 0.01384937889594573
Epoch: 48 Idx: 0 Loss: 0.012014985537559107
Epoch: 48 Idx: 5000 Loss: 0.023825371674396967
Epoch: 49 Idx: 0 Loss: 0.008535643235881326
Epoch: 49 Idx: 5000 Loss: 0.01585658074384832
Len (direct inputs):  1690
Inputs len 10074 10 11464
Len (direct inputs):  1400
Starting sliding window evaluation...
Step 12/7
Val onto:  [('conference', 'iasted')] test_onto:  [('confof', 'edas')]
Training size: 104813 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.1877442229358397
Epoch: 0 Idx: 5000 Loss: 0.02378005540566543
Epoch: 1 Idx: 0 Loss: 0.011855485452591446
Epoch: 1 Idx: 5000 Loss: 0.00973856981434432
Epoch: 2 Idx: 0 Loss: 0.010585317071419423
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc243>
Subject: Job 4066792: <python main.py 3 6 False False> in cluster <dcc> Exited

Job <python main.py 3 6 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc243>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:35 2020
Terminated at Wed Sep 16 04:38:38 2020
Results reported at Wed Sep 16 04:38:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 6 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46121.10 sec.
    Max Memory :                                 2835 MB
    Average Memory :                             2674.24 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40582.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46224 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

