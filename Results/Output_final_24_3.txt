2020-09-15 15:48:42.519701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.629802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.744674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.744758: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.747044: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.766464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.801261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.844142: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.866854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.867395: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.867418: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.867836: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.906800: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600120000 Hz
2020-09-15 15:48:49.907068: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562510f082f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.907089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.909976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.910010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1886531907111733
Epoch: 0 Idx: 5000 Loss: 0.008618341449571902
Epoch: 1 Idx: 0 Loss: 0.005679199774397813
Epoch: 1 Idx: 5000 Loss: 0.016828660001500163
Epoch: 2 Idx: 0 Loss: 0.02261022059116328
Epoch: 2 Idx: 5000 Loss: 0.01371027603727889
Epoch: 3 Idx: 0 Loss: 0.029371107208874394
Epoch: 3 Idx: 5000 Loss: 0.012114858196421628
Epoch: 4 Idx: 0 Loss: 0.021225511055376935
Epoch: 4 Idx: 5000 Loss: 0.012390695110692008
Epoch: 5 Idx: 0 Loss: 0.014571731846940827
Epoch: 5 Idx: 5000 Loss: 0.016478694874866712
Epoch: 6 Idx: 0 Loss: 0.007841316433620333
Epoch: 6 Idx: 5000 Loss: 0.010444220677710236
Epoch: 7 Idx: 0 Loss: 0.009002744477093061
Epoch: 7 Idx: 5000 Loss: 0.03244068105300566
Epoch: 8 Idx: 0 Loss: 0.01190768767587137
Epoch: 8 Idx: 5000 Loss: 0.022773639789569936
Epoch: 9 Idx: 0 Loss: 0.014059176244017662
Epoch: 9 Idx: 5000 Loss: 0.006301497015727453
Epoch: 10 Idx: 0 Loss: 0.02393272457282939
Epoch: 10 Idx: 5000 Loss: 0.025387157173430333
Epoch: 11 Idx: 0 Loss: 0.010200020648020149
Epoch: 11 Idx: 5000 Loss: 0.01266928813973173
Epoch: 12 Idx: 0 Loss: 0.011677708539757223
Epoch: 12 Idx: 5000 Loss: 0.01645681669820207
Epoch: 13 Idx: 0 Loss: 0.01746259713045073
Epoch: 13 Idx: 5000 Loss: 0.005123624062042772
Epoch: 14 Idx: 0 Loss: 0.023901663927960292
Epoch: 14 Idx: 5000 Loss: 0.021688418762352425
Epoch: 15 Idx: 0 Loss: 0.017419296579169834
Epoch: 15 Idx: 5000 Loss: 0.040633491192190556
Epoch: 16 Idx: 0 Loss: 0.010680393110001941
Epoch: 16 Idx: 5000 Loss: 0.03434737436473968
Epoch: 17 Idx: 0 Loss: 0.03592083809588752
Epoch: 17 Idx: 5000 Loss: 0.00767762103993691
Epoch: 18 Idx: 0 Loss: 0.010216560987190756
Epoch: 18 Idx: 5000 Loss: 0.023362542528103825
Epoch: 19 Idx: 0 Loss: 0.033760692158509006
Epoch: 19 Idx: 5000 Loss: 0.011758364703337106
Epoch: 20 Idx: 0 Loss: 0.015509165601715
Epoch: 20 Idx: 5000 Loss: 0.020688857724470395
Epoch: 21 Idx: 0 Loss: 0.037301572679955375
Epoch: 21 Idx: 5000 Loss: 0.016962074240508898
Epoch: 22 Idx: 0 Loss: 0.0207445794207453
Epoch: 22 Idx: 5000 Loss: 0.03807312334087848
Epoch: 23 Idx: 0 Loss: 0.025976951832008065
Epoch: 23 Idx: 5000 Loss: 0.021765909854914913
Epoch: 24 Idx: 0 Loss: 0.015097220020537337
Epoch: 24 Idx: 5000 Loss: 0.013169528387709059
Epoch: 25 Idx: 0 Loss: 0.013731710638172441
Epoch: 25 Idx: 5000 Loss: 0.019094639055345277
Epoch: 26 Idx: 0 Loss: 0.007050732298516559
Epoch: 26 Idx: 5000 Loss: 0.007877823836341002
Epoch: 27 Idx: 0 Loss: 0.008166668740008617
Epoch: 27 Idx: 5000 Loss: 0.016515780138841134
Epoch: 28 Idx: 0 Loss: 0.01465878336958549
Epoch: 28 Idx: 5000 Loss: 0.033995312886693635
Epoch: 29 Idx: 0 Loss: 0.011371328780543527
Epoch: 29 Idx: 5000 Loss: 0.011727185025887899
Epoch: 30 Idx: 0 Loss: 0.04830271269795684
Epoch: 30 Idx: 5000 Loss: 0.009595548027018633
Epoch: 31 Idx: 0 Loss: 0.009835091610053678
Epoch: 31 Idx: 5000 Loss: 0.014546999169181283
Epoch: 32 Idx: 0 Loss: 0.0167172450270669
Epoch: 32 Idx: 5000 Loss: 0.006702872067596651
Epoch: 33 Idx: 0 Loss: 0.009693093982516941
Epoch: 33 Idx: 5000 Loss: 0.013707859321469357
Epoch: 34 Idx: 0 Loss: 0.041256520116994086
Epoch: 34 Idx: 5000 Loss: 0.011352834641555096
Epoch: 35 Idx: 0 Loss: 0.01537781812674402
Epoch: 35 Idx: 5000 Loss: 0.013048575440511079
Epoch: 36 Idx: 0 Loss: 0.014021318212771344
Epoch: 36 Idx: 5000 Loss: 0.01691750457021483
Epoch: 37 Idx: 0 Loss: 0.020358674896906903
Epoch: 37 Idx: 5000 Loss: 0.02403268959000232
Epoch: 38 Idx: 0 Loss: 0.01879546226375951
Epoch: 38 Idx: 5000 Loss: 0.021206972777451823
Epoch: 39 Idx: 0 Loss: 0.015537310714179435
Epoch: 39 Idx: 5000 Loss: 0.024673633600862575
Epoch: 40 Idx: 0 Loss: 0.03041419409838009
Epoch: 40 Idx: 5000 Loss: 0.012030559456865092
Epoch: 41 Idx: 0 Loss: 0.02155589993852501
Epoch: 41 Idx: 5000 Loss: 0.007417559021564152
Epoch: 42 Idx: 0 Loss: 0.010158805199161252
Epoch: 42 Idx: 5000 Loss: 0.005513526288325151
Epoch: 43 Idx: 0 Loss: 0.013251102782045733
Epoch: 43 Idx: 5000 Loss: 0.012698805886881773
Epoch: 44 Idx: 0 Loss: 0.010026119013028884
Epoch: 44 Idx: 5000 Loss: 0.013743577972455758
Epoch: 45 Idx: 0 Loss: 0.004224105255949176
Epoch: 45 Idx: 5000 Loss: 0.020506585122101302
Epoch: 46 Idx: 0 Loss: 0.008923875446899501
Epoch: 46 Idx: 5000 Loss: 0.014158007779888347
Epoch: 47 Idx: 0 Loss: 0.009157587640085434
Epoch: 47 Idx: 5000 Loss: 0.018247565633887537
Epoch: 48 Idx: 0 Loss: 0.011169539658844636
Epoch: 48 Idx: 5000 Loss: 0.0236641632157151
Epoch: 49 Idx: 0 Loss: 0.02268400936340284
Epoch: 49 Idx: 5000 Loss: 0.039044943150069976
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1376406582769538
Epoch: 0 Idx: 5000 Loss: 0.022754363958834636
Epoch: 1 Idx: 0 Loss: 0.01659401132101999
Epoch: 1 Idx: 5000 Loss: 0.028494674297909684
Epoch: 2 Idx: 0 Loss: 0.01389872564897047
Epoch: 2 Idx: 5000 Loss: 0.018530510863601635
Epoch: 3 Idx: 0 Loss: 0.0073496701722828295
Epoch: 3 Idx: 5000 Loss: 0.008040329012775972
Epoch: 4 Idx: 0 Loss: 0.009811918416350974
Epoch: 4 Idx: 5000 Loss: 0.02808664648274784
Epoch: 5 Idx: 0 Loss: 0.0234835014013545
Epoch: 5 Idx: 5000 Loss: 0.019803942266610607
Epoch: 6 Idx: 0 Loss: 0.01255649272883062
Epoch: 6 Idx: 5000 Loss: 0.013069747464373555
Epoch: 7 Idx: 0 Loss: 0.014814721081012956
Epoch: 7 Idx: 5000 Loss: 0.027910704464432848
Epoch: 8 Idx: 0 Loss: 0.025462236526177337
Epoch: 8 Idx: 5000 Loss: 0.010747664194966432
Epoch: 9 Idx: 0 Loss: 0.010898522712266698
Epoch: 9 Idx: 5000 Loss: 0.011657177439543835
Epoch: 10 Idx: 0 Loss: 0.022571107238977327
Epoch: 10 Idx: 5000 Loss: 0.017239216539923715
Epoch: 11 Idx: 0 Loss: 0.024385624644899406
Epoch: 11 Idx: 5000 Loss: 0.008006392188372461
Epoch: 12 Idx: 0 Loss: 0.020450502473370852
Epoch: 12 Idx: 5000 Loss: 0.02514136600786215
Epoch: 13 Idx: 0 Loss: 0.007577905042133347
Epoch: 13 Idx: 5000 Loss: 0.03349057671819183
Epoch: 14 Idx: 0 Loss: 0.01135256297493555
Epoch: 14 Idx: 5000 Loss: 0.03497800494245166
Epoch: 15 Idx: 0 Loss: 0.008478833510030983
Epoch: 15 Idx: 5000 Loss: 0.013797689416232516
Epoch: 16 Idx: 0 Loss: 0.020856950260733254
Epoch: 16 Idx: 5000 Loss: 0.018162402145592848
Epoch: 17 Idx: 0 Loss: 0.017240556279181946
Epoch: 17 Idx: 5000 Loss: 0.00922743400968697
Epoch: 18 Idx: 0 Loss: 0.01270927676672753
Epoch: 18 Idx: 5000 Loss: 0.02777286957648275
Epoch: 19 Idx: 0 Loss: 0.012543698769685259
Epoch: 19 Idx: 5000 Loss: 0.008278572184100323
Epoch: 20 Idx: 0 Loss: 0.011834076879195932
Epoch: 20 Idx: 5000 Loss: 0.043494367421359356
Epoch: 21 Idx: 0 Loss: 0.029104926419834247
Epoch: 21 Idx: 5000 Loss: 0.012267879036735983
Epoch: 22 Idx: 0 Loss: 0.012484213199651366
Epoch: 22 Idx: 5000 Loss: 0.009949381627730677
Epoch: 23 Idx: 0 Loss: 0.008538844722728
Epoch: 23 Idx: 5000 Loss: 0.009536530750852893
Epoch: 24 Idx: 0 Loss: 0.009953352135607068
Epoch: 24 Idx: 5000 Loss: 0.012207587950970093
Epoch: 25 Idx: 0 Loss: 0.011282526376664548
Epoch: 25 Idx: 5000 Loss: 0.02460739205524826
Epoch: 26 Idx: 0 Loss: 0.02826249013698914
Epoch: 26 Idx: 5000 Loss: 0.01225735296158741
Epoch: 27 Idx: 0 Loss: 0.006544201696827759
Epoch: 27 Idx: 5000 Loss: 0.007911400159129878
Epoch: 28 Idx: 0 Loss: 0.011815218731405754
Epoch: 28 Idx: 5000 Loss: 0.010432709698078479
Epoch: 29 Idx: 0 Loss: 0.018248977888949084
Epoch: 29 Idx: 5000 Loss: 0.027291167404836492
Epoch: 30 Idx: 0 Loss: 0.019419802606993185
Epoch: 30 Idx: 5000 Loss: 0.01177784409109747
Epoch: 31 Idx: 0 Loss: 0.014391878812626782
Epoch: 31 Idx: 5000 Loss: 0.018055297286094247
Epoch: 32 Idx: 0 Loss: 0.041377512488572916
Epoch: 32 Idx: 5000 Loss: 0.02769630162350406
Epoch: 33 Idx: 0 Loss: 0.017124946478823448
Epoch: 33 Idx: 5000 Loss: 0.016305423807005337
Epoch: 34 Idx: 0 Loss: 0.00685940309625945
Epoch: 34 Idx: 5000 Loss: 0.024117221527837292
Epoch: 35 Idx: 0 Loss: 0.006790067779055771
Epoch: 35 Idx: 5000 Loss: 0.014720764848888467
Epoch: 36 Idx: 0 Loss: 0.018982410017338653
Epoch: 36 Idx: 5000 Loss: 0.014209531053881005
Epoch: 37 Idx: 0 Loss: 0.008526926313116303
Epoch: 37 Idx: 5000 Loss: 0.02378536934319888
Epoch: 38 Idx: 0 Loss: 0.012302787756964749
Epoch: 38 Idx: 5000 Loss: 0.013141688750207874
Epoch: 39 Idx: 0 Loss: 0.0230451912715159
Epoch: 39 Idx: 5000 Loss: 0.02571831256882844
Epoch: 40 Idx: 0 Loss: 0.010571833502040724
Epoch: 40 Idx: 5000 Loss: 0.03245300865017305
Epoch: 41 Idx: 0 Loss: 0.03336726445814581
Epoch: 41 Idx: 5000 Loss: 0.006692555834483143
Epoch: 42 Idx: 0 Loss: 0.0080479643903443
Epoch: 42 Idx: 5000 Loss: 0.02689437505162547
Epoch: 43 Idx: 0 Loss: 0.016353049176381203
Epoch: 43 Idx: 5000 Loss: 0.011498374436809315
Epoch: 44 Idx: 0 Loss: 0.02693762958882822
Epoch: 44 Idx: 5000 Loss: 0.016136618609180874
Epoch: 45 Idx: 0 Loss: 0.007839340848071957
Epoch: 45 Idx: 5000 Loss: 0.009774327903788776
Epoch: 46 Idx: 0 Loss: 0.01117450195858272
Epoch: 46 Idx: 5000 Loss: 0.030549900891781896
Epoch: 47 Idx: 0 Loss: 0.027422693472318193
Epoch: 47 Idx: 5000 Loss: 0.010866118994524191
Epoch: 48 Idx: 0 Loss: 0.023346058184668603
Epoch: 48 Idx: 5000 Loss: 0.01818198984096588
Epoch: 49 Idx: 0 Loss: 0.007071724715194116
Epoch: 49 Idx: 5000 Loss: 0.006631685974373065
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13422479688460726
Epoch: 0 Idx: 5000 Loss: 0.02522842608231788
Epoch: 1 Idx: 0 Loss: 0.010131555037070358
Epoch: 1 Idx: 5000 Loss: 0.007808945873571439
Epoch: 2 Idx: 0 Loss: 0.02105193065450487
Epoch: 2 Idx: 5000 Loss: 0.013648453393849238
Epoch: 3 Idx: 0 Loss: 0.013274371300766696
Epoch: 3 Idx: 5000 Loss: 0.011259027547532652
Epoch: 4 Idx: 0 Loss: 0.009298515062125413
Epoch: 4 Idx: 5000 Loss: 0.019978915063879023
Epoch: 5 Idx: 0 Loss: 0.01834910251384485
Epoch: 5 Idx: 5000 Loss: 0.020942014926569948
Epoch: 6 Idx: 0 Loss: 0.00817224180478813
Epoch: 6 Idx: 5000 Loss: 0.013305028505046371
Epoch: 7 Idx: 0 Loss: 0.014264875305254261
Epoch: 7 Idx: 5000 Loss: 0.013675205164737162
Epoch: 8 Idx: 0 Loss: 0.020396046305489027
Epoch: 8 Idx: 5000 Loss: 0.01503673856725404
Epoch: 9 Idx: 0 Loss: 0.012180442410238022
Epoch: 9 Idx: 5000 Loss: 0.01376174269026921
Epoch: 10 Idx: 0 Loss: 0.030256215131124583
Epoch: 10 Idx: 5000 Loss: 0.029398318350592353
Epoch: 11 Idx: 0 Loss: 0.016679883875877127
Epoch: 11 Idx: 5000 Loss: 0.011457908832984335
Epoch: 12 Idx: 0 Loss: 0.013500109991884186
Epoch: 12 Idx: 5000 Loss: 0.008704818117929811
Epoch: 13 Idx: 0 Loss: 0.024548575018192655
Epoch: 13 Idx: 5000 Loss: 0.027803589323353004
Epoch: 14 Idx: 0 Loss: 0.04129671293364481
Epoch: 14 Idx: 5000 Loss: 0.013132456439907902
Epoch: 15 Idx: 0 Loss: 0.039814537165960895
Epoch: 15 Idx: 5000 Loss: 0.006720403903894789
Epoch: 16 Idx: 0 Loss: 0.01653803374693497
Epoch: 16 Idx: 5000 Loss: 0.010654356000585487
Epoch: 17 Idx: 0 Loss: 0.015569254673185118
Epoch: 17 Idx: 5000 Loss: 0.011610314387935212
Epoch: 18 Idx: 0 Loss: 0.01134696293266817
Epoch: 18 Idx: 5000 Loss: 0.012704755661003053
Epoch: 19 Idx: 0 Loss: 0.04467188558445764
Epoch: 19 Idx: 5000 Loss: 0.02225868543267883
Epoch: 20 Idx: 0 Loss: 0.01332951766868696
Epoch: 20 Idx: 5000 Loss: 0.0333325213015982
Epoch: 21 Idx: 0 Loss: 0.008369670376254789
Epoch: 21 Idx: 5000 Loss: 0.015062259274173099
Epoch: 22 Idx: 0 Loss: 0.018693365948143637
Epoch: 22 Idx: 5000 Loss: 0.026835283869761965
Epoch: 23 Idx: 0 Loss: 0.02158745682569525
Epoch: 23 Idx: 5000 Loss: 0.009074099780560682
Epoch: 24 Idx: 0 Loss: 0.01971984628120643
Epoch: 24 Idx: 5000 Loss: 0.020708858383251767
Epoch: 25 Idx: 0 Loss: 0.02177758809541415
Epoch: 25 Idx: 5000 Loss: 0.031180906571873685
Epoch: 26 Idx: 0 Loss: 0.020313847073891084
Epoch: 26 Idx: 5000 Loss: 0.01202441306162639
Epoch: 27 Idx: 0 Loss: 0.023328531999158734
Epoch: 27 Idx: 5000 Loss: 0.025958853359546143
Epoch: 28 Idx: 0 Loss: 0.014258640810663206
Epoch: 28 Idx: 5000 Loss: 0.007091673389017799
Epoch: 29 Idx: 0 Loss: 0.013161808058998744
Epoch: 29 Idx: 5000 Loss: 0.00853149845307883
Epoch: 30 Idx: 0 Loss: 0.009346654490306652
Epoch: 30 Idx: 5000 Loss: 0.06180577141655968
Epoch: 31 Idx: 0 Loss: 0.010949574242747652
Epoch: 31 Idx: 5000 Loss: 0.008594586319396184
Epoch: 32 Idx: 0 Loss: 0.006482791992833261
Epoch: 32 Idx: 5000 Loss: 0.0054397198333654175
Epoch: 33 Idx: 0 Loss: 0.03531607020243283
Epoch: 33 Idx: 5000 Loss: 0.03488356851375425
Epoch: 34 Idx: 0 Loss: 0.01811172771497226
Epoch: 34 Idx: 5000 Loss: 0.03168583361425815
Epoch: 35 Idx: 0 Loss: 0.012503964860962703
Epoch: 35 Idx: 5000 Loss: 0.017143338980982723
Epoch: 36 Idx: 0 Loss: 0.010738373563372705
Epoch: 36 Idx: 5000 Loss: 0.010429785508444565
Epoch: 37 Idx: 0 Loss: 0.0052143408504299665
Epoch: 37 Idx: 5000 Loss: 0.03008299772650974
Epoch: 38 Idx: 0 Loss: 0.013155280904142214
Epoch: 38 Idx: 5000 Loss: 0.012698577878305776
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc251>
Subject: Job 4066806: <python main.py 3 24 False False> in cluster <dcc> Exited

Job <python main.py 3 24 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
Job was executed on host(s) <dccxc251>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 24 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46189.00 sec.
    Max Memory :                                 2969 MB
    Average Memory :                             2745.19 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40448.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46229 sec.
    Turnaround time :                            46204 sec.

The output (if any) is above this job summary.

