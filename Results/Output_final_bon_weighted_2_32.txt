2020-09-15 15:49:42.277917: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.621332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.750558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.750655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.752759: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.754268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.755073: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.757005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.758426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.758652: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.758680: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.758993: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.765949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600005000 Hz
2020-09-15 15:49:45.766124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ccba2b4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.766145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.767932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.767956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19374059659010373
Epoch: 0 Idx: 5000 Loss: 0.007340971578067831
Epoch: 1 Idx: 0 Loss: 0.024804010831444716
Epoch: 1 Idx: 5000 Loss: 0.00975196677721395
Epoch: 2 Idx: 0 Loss: 0.01386868073969183
Epoch: 2 Idx: 5000 Loss: 0.011439207806539974
Epoch: 3 Idx: 0 Loss: 0.017322813828181446
Epoch: 3 Idx: 5000 Loss: 0.014096070238029685
Epoch: 4 Idx: 0 Loss: 0.006729223425909952
Epoch: 4 Idx: 5000 Loss: 0.021693977706371388
Epoch: 5 Idx: 0 Loss: 0.013449386372110583
Epoch: 5 Idx: 5000 Loss: 0.015051906350783956
Epoch: 6 Idx: 0 Loss: 0.011577586607762558
Epoch: 6 Idx: 5000 Loss: 0.025424646625474088
Epoch: 7 Idx: 0 Loss: 0.011783045408734902
Epoch: 7 Idx: 5000 Loss: 0.03324953877862357
Epoch: 8 Idx: 0 Loss: 0.0297309676258442
Epoch: 8 Idx: 5000 Loss: 0.017330023165115886
Epoch: 9 Idx: 0 Loss: 0.01757088728257588
Epoch: 9 Idx: 5000 Loss: 0.01623187951220468
Epoch: 10 Idx: 0 Loss: 0.014474378147384693
Epoch: 10 Idx: 5000 Loss: 0.016455406049569004
Epoch: 11 Idx: 0 Loss: 0.0198049006428583
Epoch: 11 Idx: 5000 Loss: 0.01589697663261061
Epoch: 12 Idx: 0 Loss: 0.006285680179415795
Epoch: 12 Idx: 5000 Loss: 0.01848636610570674
Epoch: 13 Idx: 0 Loss: 0.010259572387976468
Epoch: 13 Idx: 5000 Loss: 0.011912753854692763
Epoch: 14 Idx: 0 Loss: 0.04821669919186966
Epoch: 14 Idx: 5000 Loss: 0.014966394284952448
Epoch: 15 Idx: 0 Loss: 0.021563581254019717
Epoch: 15 Idx: 5000 Loss: 0.03289686715324323
Epoch: 16 Idx: 0 Loss: 0.019290399576881605
Epoch: 16 Idx: 5000 Loss: 0.024520811916182654
Epoch: 17 Idx: 0 Loss: 0.042322078487170636
Epoch: 17 Idx: 5000 Loss: 0.0142731105672375
Epoch: 18 Idx: 0 Loss: 0.01615453049288693
Epoch: 18 Idx: 5000 Loss: 0.02592701770839241
Epoch: 19 Idx: 0 Loss: 0.012670445403736554
Epoch: 19 Idx: 5000 Loss: 0.016983234975836717
Epoch: 20 Idx: 0 Loss: 0.004281388793934385
Epoch: 20 Idx: 5000 Loss: 0.017263875752057362
Epoch: 21 Idx: 0 Loss: 0.012517033717800517
Epoch: 21 Idx: 5000 Loss: 0.028701733846013436
Epoch: 22 Idx: 0 Loss: 0.01532640500618684
Epoch: 22 Idx: 5000 Loss: 0.014043905620990603
Epoch: 23 Idx: 0 Loss: 0.011998391280545837
Epoch: 23 Idx: 5000 Loss: 0.016620967244049788
Epoch: 24 Idx: 0 Loss: 0.01819188487456499
Epoch: 24 Idx: 5000 Loss: 0.016053514604628706
Epoch: 25 Idx: 0 Loss: 0.01086053511083214
Epoch: 25 Idx: 5000 Loss: 0.016050747871856515
Epoch: 26 Idx: 0 Loss: 0.025613922524425937
Epoch: 26 Idx: 5000 Loss: 0.01470090348904338
Epoch: 27 Idx: 0 Loss: 0.012163885864583703
Epoch: 27 Idx: 5000 Loss: 0.01572181215861386
Epoch: 28 Idx: 0 Loss: 0.03401183057388135
Epoch: 28 Idx: 5000 Loss: 0.043052462496446994
Epoch: 29 Idx: 0 Loss: 0.016069095588605743
Epoch: 29 Idx: 5000 Loss: 0.012777017114164652
Epoch: 30 Idx: 0 Loss: 0.038804403076259195
Epoch: 30 Idx: 5000 Loss: 0.009675272577185232
Epoch: 31 Idx: 0 Loss: 0.01072783336787452
Epoch: 31 Idx: 5000 Loss: 0.02121343372349134
Epoch: 32 Idx: 0 Loss: 0.015600337291174934
Epoch: 32 Idx: 5000 Loss: 0.015789281282751266
Epoch: 33 Idx: 0 Loss: 0.014486504952593036
Epoch: 33 Idx: 5000 Loss: 0.009266188388314205
Epoch: 34 Idx: 0 Loss: 0.045996382599773886
Epoch: 34 Idx: 5000 Loss: 0.020985989769506882
Epoch: 35 Idx: 0 Loss: 0.018047291831540684
Epoch: 35 Idx: 5000 Loss: 0.015845034214379793
Epoch: 36 Idx: 0 Loss: 0.018188642496477943
Epoch: 36 Idx: 5000 Loss: 0.027662563801071047
Epoch: 37 Idx: 0 Loss: 0.014244158945820727
Epoch: 37 Idx: 5000 Loss: 0.009639357348934393
Epoch: 38 Idx: 0 Loss: 0.011897137266604641
Epoch: 38 Idx: 5000 Loss: 0.01634874492647179
Epoch: 39 Idx: 0 Loss: 0.01710448775645476
Epoch: 39 Idx: 5000 Loss: 0.020827204440709967
Epoch: 40 Idx: 0 Loss: 0.013313342132760182
Epoch: 40 Idx: 5000 Loss: 0.013326894444396605
Epoch: 41 Idx: 0 Loss: 0.013235720984135555
Epoch: 41 Idx: 5000 Loss: 0.008728117420110912
Epoch: 42 Idx: 0 Loss: 0.00949368284143894
Epoch: 42 Idx: 5000 Loss: 0.011571558407800843
Epoch: 43 Idx: 0 Loss: 0.016461904427781365
Epoch: 43 Idx: 5000 Loss: 0.020069472790020255
Epoch: 44 Idx: 0 Loss: 0.013497242776286188
Epoch: 44 Idx: 5000 Loss: 0.02067823109422559
Epoch: 45 Idx: 0 Loss: 0.014450663776132104
Epoch: 45 Idx: 5000 Loss: 0.021486444351715255
Epoch: 46 Idx: 0 Loss: 0.008498802889345253
Epoch: 46 Idx: 5000 Loss: 0.019735996436764856
Epoch: 47 Idx: 0 Loss: 0.010147888987621326
Epoch: 47 Idx: 5000 Loss: 0.027240641300970043
Epoch: 48 Idx: 0 Loss: 0.013285674100653096
Epoch: 48 Idx: 5000 Loss: 0.021416179474663448
Epoch: 49 Idx: 0 Loss: 0.009410413791872466
Epoch: 49 Idx: 5000 Loss: 0.00960681879533955
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15720404199279028
Epoch: 0 Idx: 5000 Loss: 0.01797308288692515
Epoch: 1 Idx: 0 Loss: 0.032509073305337595
Epoch: 1 Idx: 5000 Loss: 0.021821040033922906
Epoch: 2 Idx: 0 Loss: 0.025431720874312804
Epoch: 2 Idx: 5000 Loss: 0.017038046149223898
Epoch: 3 Idx: 0 Loss: 0.006848090677364373
Epoch: 3 Idx: 5000 Loss: 0.009712441599761817
Epoch: 4 Idx: 0 Loss: 0.010073821887236553
Epoch: 4 Idx: 5000 Loss: 0.020564807735063157
Epoch: 5 Idx: 0 Loss: 0.012580225238251202
Epoch: 5 Idx: 5000 Loss: 0.006557451967646771
Epoch: 6 Idx: 0 Loss: 0.028467204288616373
Epoch: 6 Idx: 5000 Loss: 0.03681277458984471
Epoch: 7 Idx: 0 Loss: 0.011007588532540247
Epoch: 7 Idx: 5000 Loss: 0.011961504825697246
Epoch: 8 Idx: 0 Loss: 0.01638345638486665
Epoch: 8 Idx: 5000 Loss: 0.009726371273132008
Epoch: 9 Idx: 0 Loss: 0.014352021093131034
Epoch: 9 Idx: 5000 Loss: 0.015235694858228526
Epoch: 10 Idx: 0 Loss: 0.012848082898507493
Epoch: 10 Idx: 5000 Loss: 0.01886133373555979
Epoch: 11 Idx: 0 Loss: 0.015470360739339786
Epoch: 11 Idx: 5000 Loss: 0.014604340814716923
Epoch: 12 Idx: 0 Loss: 0.00754100383317052
Epoch: 12 Idx: 5000 Loss: 0.012261957406806776
Epoch: 13 Idx: 0 Loss: 0.011412673915365266
Epoch: 13 Idx: 5000 Loss: 0.017104146273683472
Epoch: 14 Idx: 0 Loss: 0.02866622924716674
Epoch: 14 Idx: 5000 Loss: 0.012192884941737182
Epoch: 15 Idx: 0 Loss: 0.0100065010990286
Epoch: 15 Idx: 5000 Loss: 0.019183553333667815
Epoch: 16 Idx: 0 Loss: 0.012639403488360757
Epoch: 16 Idx: 5000 Loss: 0.013993537189848138
Epoch: 17 Idx: 0 Loss: 0.018206542023866953
Epoch: 17 Idx: 5000 Loss: 0.011291215900775323
Epoch: 18 Idx: 0 Loss: 0.03347089128008455
Epoch: 18 Idx: 5000 Loss: 0.021133583558231313
Epoch: 19 Idx: 0 Loss: 0.026303095102346484
Epoch: 19 Idx: 5000 Loss: 0.014481278442077595
Epoch: 20 Idx: 0 Loss: 0.019134364321516772
Epoch: 20 Idx: 5000 Loss: 0.0163484832547841
Epoch: 21 Idx: 0 Loss: 0.03501809783465676
Epoch: 21 Idx: 5000 Loss: 0.013128251477901969
Epoch: 22 Idx: 0 Loss: 0.01683949579034011
Epoch: 22 Idx: 5000 Loss: 0.014414665775789915
Epoch: 23 Idx: 0 Loss: 0.008299421937063754
Epoch: 23 Idx: 5000 Loss: 0.01663006952679828
Epoch: 24 Idx: 0 Loss: 0.011336564615561864
Epoch: 24 Idx: 5000 Loss: 0.02529291789049344
Epoch: 25 Idx: 0 Loss: 0.010590823368768786
Epoch: 25 Idx: 5000 Loss: 0.03697672309499683
Epoch: 26 Idx: 0 Loss: 0.006461296147086603
Epoch: 26 Idx: 5000 Loss: 0.011114130837713787
Epoch: 27 Idx: 0 Loss: 0.00924869349344904
Epoch: 27 Idx: 5000 Loss: 0.01756391525772688
Epoch: 28 Idx: 0 Loss: 0.020626833652985534
Epoch: 28 Idx: 5000 Loss: 0.00875679231526537
Epoch: 29 Idx: 0 Loss: 0.00771311688799751
Epoch: 29 Idx: 5000 Loss: 0.03769984769119818
Epoch: 30 Idx: 0 Loss: 0.019202811228317903
Epoch: 30 Idx: 5000 Loss: 0.03125921140475585
Epoch: 31 Idx: 0 Loss: 0.010994391106945313
Epoch: 31 Idx: 5000 Loss: 0.019254069984616543
Epoch: 32 Idx: 0 Loss: 0.013254067643119198
Epoch: 32 Idx: 5000 Loss: 0.01598965735917719
Epoch: 33 Idx: 0 Loss: 0.009385280875268322
Epoch: 33 Idx: 5000 Loss: 0.0072422665549519635
Epoch: 34 Idx: 0 Loss: 0.007330227381559641
Epoch: 34 Idx: 5000 Loss: 0.013227551957193577
Epoch: 35 Idx: 0 Loss: 0.012772934522753573
Epoch: 35 Idx: 5000 Loss: 0.028160412612148085
Epoch: 36 Idx: 0 Loss: 0.01078039367533918
Epoch: 36 Idx: 5000 Loss: 0.03299446161254886
Epoch: 37 Idx: 0 Loss: 0.01690204590993027
Epoch: 37 Idx: 5000 Loss: 0.009425688823023248
Epoch: 38 Idx: 0 Loss: 0.015604743875112905
Epoch: 38 Idx: 5000 Loss: 0.009782262141067831
Epoch: 39 Idx: 0 Loss: 0.009436963773364044
Epoch: 39 Idx: 5000 Loss: 0.019714070511387537
Epoch: 40 Idx: 0 Loss: 0.006606522994596814
Epoch: 40 Idx: 5000 Loss: 0.023151664939078997
Epoch: 41 Idx: 0 Loss: 0.013606391581797736
Epoch: 41 Idx: 5000 Loss: 0.011686834162292764
Epoch: 42 Idx: 0 Loss: 0.012115087629734352
Epoch: 42 Idx: 5000 Loss: 0.008691207784762194
Epoch: 43 Idx: 0 Loss: 0.03300521305923156
Epoch: 43 Idx: 5000 Loss: 0.006275417369755677
Epoch: 44 Idx: 0 Loss: 0.009275724704980374
Epoch: 44 Idx: 5000 Loss: 0.018180190826432272
Epoch: 45 Idx: 0 Loss: 0.012104299410248815
Epoch: 45 Idx: 5000 Loss: 0.006294197054998079
Epoch: 46 Idx: 0 Loss: 0.01504862011205303
Epoch: 46 Idx: 5000 Loss: 0.014858134442781652
Epoch: 47 Idx: 0 Loss: 0.014430177892763824
Epoch: 47 Idx: 5000 Loss: 0.016509885115837557
Epoch: 48 Idx: 0 Loss: 0.04017343337854055
Epoch: 48 Idx: 5000 Loss: 0.029902745326626762
Epoch: 49 Idx: 0 Loss: 0.009758499737295402
Epoch: 49 Idx: 5000 Loss: 0.023332657899710854
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1613842070363328
Epoch: 0 Idx: 5000 Loss: 0.04577789340031699
Epoch: 1 Idx: 0 Loss: 0.027406654327500564
Epoch: 1 Idx: 5000 Loss: 0.01239318497022188
Epoch: 2 Idx: 0 Loss: 0.030597377905900197
Epoch: 2 Idx: 5000 Loss: 0.019474444396172335
Epoch: 3 Idx: 0 Loss: 0.040010847766198565
Epoch: 3 Idx: 5000 Loss: 0.017285975460411544
Epoch: 4 Idx: 0 Loss: 0.029602292118001923
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 323, in forward
    best_path = torch.bmm(path_weights.reshape(-1, 1, self.max_paths), feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc206>
Subject: Job 4066916: <python main.py 32 2 True True> in cluster <dcc> Exited

Job <python main.py 32 2 True True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:42 2020
Job was executed on host(s) <dccxc206>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:37 2020
Results reported at Wed Sep 16 04:38:37 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 32 2 True True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46135.08 sec.
    Max Memory :                                 2946 MB
    Average Memory :                             2719.68 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40471.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46137 sec.
    Turnaround time :                            46195 sec.

The output (if any) is above this job summary.

