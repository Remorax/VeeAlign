2020-09-15 15:48:42.496294: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.536010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.659612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.659685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.662082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.684787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.728695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.777122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.800692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.801244: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.801278: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.801703: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.834243: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600100000 Hz
2020-09-15 15:48:49.834534: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55631f715830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.834557: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.837506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.837531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20521467359647866
Epoch: 0 Idx: 5000 Loss: 0.008412404805983029
Epoch: 1 Idx: 0 Loss: 0.01614635817753582
Epoch: 1 Idx: 5000 Loss: 0.03406735710139623
Epoch: 2 Idx: 0 Loss: 0.015272722298554609
Epoch: 2 Idx: 5000 Loss: 0.007187325161694365
Epoch: 3 Idx: 0 Loss: 0.016507631850749615
Epoch: 3 Idx: 5000 Loss: 0.010037246721316825
Epoch: 4 Idx: 0 Loss: 0.008179192818197826
Epoch: 4 Idx: 5000 Loss: 0.016634946667517247
Epoch: 5 Idx: 0 Loss: 0.008989013166429879
Epoch: 5 Idx: 5000 Loss: 0.013490269636746934
Epoch: 6 Idx: 0 Loss: 0.014078820047638508
Epoch: 6 Idx: 5000 Loss: 0.00967561030755807
Epoch: 7 Idx: 0 Loss: 0.008607174755518069
Epoch: 7 Idx: 5000 Loss: 0.02008872051757061
Epoch: 8 Idx: 0 Loss: 0.01614639157115561
Epoch: 8 Idx: 5000 Loss: 0.00707257691739674
Epoch: 9 Idx: 0 Loss: 0.013711294130635775
Epoch: 9 Idx: 5000 Loss: 0.00441837366777884
Epoch: 10 Idx: 0 Loss: 0.01330025687013832
Epoch: 10 Idx: 5000 Loss: 0.025811646215643566
Epoch: 11 Idx: 0 Loss: 0.00924693681680366
Epoch: 11 Idx: 5000 Loss: 0.010444158537777073
Epoch: 12 Idx: 0 Loss: 0.0073897212638932095
Epoch: 12 Idx: 5000 Loss: 0.01940130761598593
Epoch: 13 Idx: 0 Loss: 0.009661488193247643
Epoch: 13 Idx: 5000 Loss: 0.01049449238788951
Epoch: 14 Idx: 0 Loss: 0.012721543712554788
Epoch: 14 Idx: 5000 Loss: 0.016280652277220444
Epoch: 15 Idx: 0 Loss: 0.019913692710714602
Epoch: 15 Idx: 5000 Loss: 0.01644016376030924
Epoch: 16 Idx: 0 Loss: 0.02972227954342783
Epoch: 16 Idx: 5000 Loss: 0.013917023370180253
Epoch: 17 Idx: 0 Loss: 0.032045843275458764
Epoch: 17 Idx: 5000 Loss: 0.012951371449842283
Epoch: 18 Idx: 0 Loss: 0.017123015667205668
Epoch: 18 Idx: 5000 Loss: 0.008708446367654514
Epoch: 19 Idx: 0 Loss: 0.01725965474680889
Epoch: 19 Idx: 5000 Loss: 0.011355344249060068
Epoch: 20 Idx: 0 Loss: 0.004564018108962882
Epoch: 20 Idx: 5000 Loss: 0.020138977834610383
Epoch: 21 Idx: 0 Loss: 0.017543109897923712
Epoch: 21 Idx: 5000 Loss: 0.016256493993963367
Epoch: 22 Idx: 0 Loss: 0.018398619049030892
Epoch: 22 Idx: 5000 Loss: 0.012946335086367215
Epoch: 23 Idx: 0 Loss: 0.018166246759382863
Epoch: 23 Idx: 5000 Loss: 0.021611689302804216
Epoch: 24 Idx: 0 Loss: 0.017783332247808342
Epoch: 24 Idx: 5000 Loss: 0.006868230437391059
Epoch: 25 Idx: 0 Loss: 0.023799891374843472
Epoch: 25 Idx: 5000 Loss: 0.020367418569843917
Epoch: 26 Idx: 0 Loss: 0.015872726191387312
Epoch: 26 Idx: 5000 Loss: 0.021639035948338416
Epoch: 27 Idx: 0 Loss: 0.008900399626887975
Epoch: 27 Idx: 5000 Loss: 0.01349011319901722
Epoch: 28 Idx: 0 Loss: 0.012722816660753318
Epoch: 28 Idx: 5000 Loss: 0.02045702828277446
Epoch: 29 Idx: 0 Loss: 0.00966243490972324
Epoch: 29 Idx: 5000 Loss: 0.009821111046982106
Epoch: 30 Idx: 0 Loss: 0.007596802967466232
Epoch: 30 Idx: 5000 Loss: 0.004160854437055375
Epoch: 31 Idx: 0 Loss: 0.009862909549436446
Epoch: 31 Idx: 5000 Loss: 0.026103367551267666
Epoch: 32 Idx: 0 Loss: 0.013354087711120793
Epoch: 32 Idx: 5000 Loss: 0.014758563861496227
Epoch: 33 Idx: 0 Loss: 0.03845372706770192
Epoch: 33 Idx: 5000 Loss: 0.01767942050756244
Epoch: 34 Idx: 0 Loss: 0.00834770282623709
Epoch: 34 Idx: 5000 Loss: 0.01939522090670836
Epoch: 35 Idx: 0 Loss: 0.010087943337258388
Epoch: 35 Idx: 5000 Loss: 0.011962234588230931
Epoch: 36 Idx: 0 Loss: 0.015912587984703276
Epoch: 36 Idx: 5000 Loss: 0.02406898460950413
Epoch: 37 Idx: 0 Loss: 0.02653328864791579
Epoch: 37 Idx: 5000 Loss: 0.011469516869605676
Epoch: 38 Idx: 0 Loss: 0.006864580157219166
Epoch: 38 Idx: 5000 Loss: 0.01736733715390817
Epoch: 39 Idx: 0 Loss: 0.017673139157000785
Epoch: 39 Idx: 5000 Loss: 0.0112920900126479
Epoch: 40 Idx: 0 Loss: 0.012802755231894333
Epoch: 40 Idx: 5000 Loss: 0.01704487924340049
Epoch: 41 Idx: 0 Loss: 0.019103595653656085
Epoch: 41 Idx: 5000 Loss: 0.005791251499582325
Epoch: 42 Idx: 0 Loss: 0.011285265542115508
Epoch: 42 Idx: 5000 Loss: 0.006578091259047153
Epoch: 43 Idx: 0 Loss: 0.021127073307343158
Epoch: 43 Idx: 5000 Loss: 0.015085843978891463
Epoch: 44 Idx: 0 Loss: 0.011696045663572486
Epoch: 44 Idx: 5000 Loss: 0.0158500473209404
Epoch: 45 Idx: 0 Loss: 0.00891218535993181
Epoch: 45 Idx: 5000 Loss: 0.02139536558291537
Epoch: 46 Idx: 0 Loss: 0.024877301928513982
Epoch: 46 Idx: 5000 Loss: 0.013297865897892622
Epoch: 47 Idx: 0 Loss: 0.01611176912125018
Epoch: 47 Idx: 5000 Loss: 0.007709393166070775
Epoch: 48 Idx: 0 Loss: 0.04170285183170386
Epoch: 48 Idx: 5000 Loss: 0.018640854659016718
Epoch: 49 Idx: 0 Loss: 0.008774536910349021
Epoch: 49 Idx: 5000 Loss: 0.014154426207213517
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14181722062073407
Epoch: 0 Idx: 5000 Loss: 0.023508981886309226
Epoch: 1 Idx: 0 Loss: 0.008147409998494682
Epoch: 1 Idx: 5000 Loss: 0.01585037471343601
Epoch: 2 Idx: 0 Loss: 0.009403884292092183
Epoch: 2 Idx: 5000 Loss: 0.019467600730762015
Epoch: 3 Idx: 0 Loss: 0.008109082828383267
Epoch: 3 Idx: 5000 Loss: 0.017204016942721286
Epoch: 4 Idx: 0 Loss: 0.019414221946293123
Epoch: 4 Idx: 5000 Loss: 0.01267530847195562
Epoch: 5 Idx: 0 Loss: 0.013690436599260518
Epoch: 5 Idx: 5000 Loss: 0.030909580487830487
Epoch: 6 Idx: 0 Loss: 0.01141424838876566
Epoch: 6 Idx: 5000 Loss: 0.02795288746555933
Epoch: 7 Idx: 0 Loss: 0.010052550576236156
Epoch: 7 Idx: 5000 Loss: 0.01275669800175409
Epoch: 8 Idx: 0 Loss: 0.016453213880948968
Epoch: 8 Idx: 5000 Loss: 0.018286262909393836
Epoch: 9 Idx: 0 Loss: 0.010333790788278169
Epoch: 9 Idx: 5000 Loss: 0.012056385815178924
Epoch: 10 Idx: 0 Loss: 0.008265611181876114
Epoch: 10 Idx: 5000 Loss: 0.011123033568401788
Epoch: 11 Idx: 0 Loss: 0.021087774797384853
Epoch: 11 Idx: 5000 Loss: 0.012012713561112932
Epoch: 12 Idx: 0 Loss: 0.005122909016577819
Epoch: 12 Idx: 5000 Loss: 0.032953431191071095
Epoch: 13 Idx: 0 Loss: 0.01603495683882594
Epoch: 13 Idx: 5000 Loss: 0.01545199360459477
Epoch: 14 Idx: 0 Loss: 0.007641666361323735
Epoch: 14 Idx: 5000 Loss: 0.01358588316312365
Epoch: 15 Idx: 0 Loss: 0.010743766987177703
Epoch: 15 Idx: 5000 Loss: 0.027686416360661645
Epoch: 16 Idx: 0 Loss: 0.012559731496315021
Epoch: 16 Idx: 5000 Loss: 0.01580293095641984
Epoch: 17 Idx: 0 Loss: 0.018493090952915774
Epoch: 17 Idx: 5000 Loss: 0.0082585792900675
Epoch: 18 Idx: 0 Loss: 0.031230611733621842
Epoch: 18 Idx: 5000 Loss: 0.016685932594112635
Epoch: 19 Idx: 0 Loss: 0.018191112725938503
Epoch: 19 Idx: 5000 Loss: 0.006950168478332926
Epoch: 20 Idx: 0 Loss: 0.018696311280734994
Epoch: 20 Idx: 5000 Loss: 0.03234034144700535
Epoch: 21 Idx: 0 Loss: 0.020372529739633383
Epoch: 21 Idx: 5000 Loss: 0.016412684813801297
Epoch: 22 Idx: 0 Loss: 0.017698637642570198
Epoch: 22 Idx: 5000 Loss: 0.011056908052777968
Epoch: 23 Idx: 0 Loss: 0.007765837864918301
Epoch: 23 Idx: 5000 Loss: 0.010936278638411543
Epoch: 24 Idx: 0 Loss: 0.02209726140243711
Epoch: 24 Idx: 5000 Loss: 0.03414808182411866
Epoch: 25 Idx: 0 Loss: 0.007588529346789847
Epoch: 25 Idx: 5000 Loss: 0.033049737488191504
Epoch: 26 Idx: 0 Loss: 0.00885397173025444
Epoch: 26 Idx: 5000 Loss: 0.010740061598431364
Epoch: 27 Idx: 0 Loss: 0.01643796429401915
Epoch: 27 Idx: 5000 Loss: 0.0077796019368521095
Epoch: 28 Idx: 0 Loss: 0.028828904671900146
Epoch: 28 Idx: 5000 Loss: 0.012686051417654316
Epoch: 29 Idx: 0 Loss: 0.01977026695721382
Epoch: 29 Idx: 5000 Loss: 0.01720839563703396
Epoch: 30 Idx: 0 Loss: 0.0357354743108262
Epoch: 30 Idx: 5000 Loss: 0.020683117614165657
Epoch: 31 Idx: 0 Loss: 0.011426585028828078
Epoch: 31 Idx: 5000 Loss: 0.011053457035216901
Epoch: 32 Idx: 0 Loss: 0.008734484040704203
Epoch: 32 Idx: 5000 Loss: 0.018011242119451744
Epoch: 33 Idx: 0 Loss: 0.016093371802347253
Epoch: 33 Idx: 5000 Loss: 0.019148342617023393
Epoch: 34 Idx: 0 Loss: 0.008188854357506964
Epoch: 34 Idx: 5000 Loss: 0.017744457927198067
Epoch: 35 Idx: 0 Loss: 0.01342442756978475
Epoch: 35 Idx: 5000 Loss: 0.01978152162525787
Epoch: 36 Idx: 0 Loss: 0.011458728087667413
Epoch: 36 Idx: 5000 Loss: 0.018941151149449716
Epoch: 37 Idx: 0 Loss: 0.01595644385073996
Epoch: 37 Idx: 5000 Loss: 0.03782992711056842
Epoch: 38 Idx: 0 Loss: 0.01629045815405258
Epoch: 38 Idx: 5000 Loss: 0.012481432672165846
Epoch: 39 Idx: 0 Loss: 0.008984975508561964
Epoch: 39 Idx: 5000 Loss: 0.009197776561196242
Epoch: 40 Idx: 0 Loss: 0.02190364061768481
Epoch: 40 Idx: 5000 Loss: 0.014925236574907965
Epoch: 41 Idx: 0 Loss: 0.0332766795524715
Epoch: 41 Idx: 5000 Loss: 0.016006156849499503
Epoch: 42 Idx: 0 Loss: 0.012879917462452687
Epoch: 42 Idx: 5000 Loss: 0.00647635960452377
Epoch: 43 Idx: 0 Loss: 0.008722791907176411
Epoch: 43 Idx: 5000 Loss: 0.006203985380695054
Epoch: 44 Idx: 0 Loss: 0.022882957363117497
Epoch: 44 Idx: 5000 Loss: 0.0210075102385971
Epoch: 45 Idx: 0 Loss: 0.014339189809257673
Epoch: 45 Idx: 5000 Loss: 0.030342217234909596
Epoch: 46 Idx: 0 Loss: 0.011079107781880706
Epoch: 46 Idx: 5000 Loss: 0.02303922901113125
Epoch: 47 Idx: 0 Loss: 0.01680584628237981
Epoch: 47 Idx: 5000 Loss: 0.009701424683368607
Epoch: 48 Idx: 0 Loss: 0.011949242181677523
Epoch: 48 Idx: 5000 Loss: 0.018228374624998153
Epoch: 49 Idx: 0 Loss: 0.01663461627216714
Epoch: 49 Idx: 5000 Loss: 0.0073629939729685035
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14627432498422016
Epoch: 0 Idx: 5000 Loss: 0.0240490892675581
Epoch: 1 Idx: 0 Loss: 0.02275186613193924
Epoch: 1 Idx: 5000 Loss: 0.0197381774192405
Epoch: 2 Idx: 0 Loss: 0.027405949348640754
Epoch: 2 Idx: 5000 Loss: 0.015317042363923642
Epoch: 3 Idx: 0 Loss: 0.01851844634096996
Epoch: 3 Idx: 5000 Loss: 0.016002778149843213
Epoch: 4 Idx: 0 Loss: 0.010908726907121217
Epoch: 4 Idx: 5000 Loss: 0.0155035086534988
Epoch: 5 Idx: 0 Loss: 0.012962241618756722
Epoch: 5 Idx: 5000 Loss: 0.010745860985188916
Epoch: 6 Idx: 0 Loss: 0.007900115665819732
Epoch: 6 Idx: 5000 Loss: 0.025641264202079753
Epoch: 7 Idx: 0 Loss: 0.020504606776647227
Epoch: 7 Idx: 5000 Loss: 0.010968404088133592
Epoch: 8 Idx: 0 Loss: 0.00782294156167946
Epoch: 8 Idx: 5000 Loss: 0.013388590164080331
Epoch: 9 Idx: 0 Loss: 0.012664368040522768
Epoch: 9 Idx: 5000 Loss: 0.011610511173961176
Epoch: 10 Idx: 0 Loss: 0.019696805926316452
Epoch: 10 Idx: 5000 Loss: 0.019926130928217503
Epoch: 11 Idx: 0 Loss: 0.01564419538056036
Epoch: 11 Idx: 5000 Loss: 0.00919605057945719
Epoch: 12 Idx: 0 Loss: 0.01508101648531283
Epoch: 12 Idx: 5000 Loss: 0.008114483875377922
Epoch: 13 Idx: 0 Loss: 0.008770805701494942
Epoch: 13 Idx: 5000 Loss: 0.005353868040530268
Epoch: 14 Idx: 0 Loss: 0.014814935058283813
Epoch: 14 Idx: 5000 Loss: 0.02207096324133577
Epoch: 15 Idx: 0 Loss: 0.011809685718899265
Epoch: 15 Idx: 5000 Loss: 0.01408080608865764
Epoch: 16 Idx: 0 Loss: 0.01737993478399452
Epoch: 16 Idx: 5000 Loss: 0.017515882361748544
Epoch: 17 Idx: 0 Loss: 0.009150646908621453
Epoch: 17 Idx: 5000 Loss: 0.049760669574652056
Epoch: 18 Idx: 0 Loss: 0.03937930348684538
Epoch: 18 Idx: 5000 Loss: 0.008049977441298716
Epoch: 19 Idx: 0 Loss: 0.016527485846341592
Epoch: 19 Idx: 5000 Loss: 0.027064079465118393
Epoch: 20 Idx: 0 Loss: 0.009819208716910534
Epoch: 20 Idx: 5000 Loss: 0.02164502944052417
Epoch: 21 Idx: 0 Loss: 0.0165220981121127
Epoch: 21 Idx: 5000 Loss: 0.011237940358591065
Epoch: 22 Idx: 0 Loss: 0.021295463907498893
Epoch: 22 Idx: 5000 Loss: 0.020067494844747145
Epoch: 23 Idx: 0 Loss: 0.00868424640352269
Epoch: 23 Idx: 5000 Loss: 0.010905461118179484
Epoch: 24 Idx: 0 Loss: 0.017603945350408486
Epoch: 24 Idx: 5000 Loss: 0.014837540279088852
Epoch: 25 Idx: 0 Loss: 0.029379720246970775
Epoch: 25 Idx: 5000 Loss: 0.010145523882577997
Epoch: 26 Idx: 0 Loss: 0.009355933587728012
Epoch: 26 Idx: 5000 Loss: 0.016521961804327585
Epoch: 27 Idx: 0 Loss: 0.009474721395743376
Epoch: 27 Idx: 5000 Loss: 0.017623240880793107
Epoch: 28 Idx: 0 Loss: 0.03194692968733769
Epoch: 28 Idx: 5000 Loss: 0.039283076823708254
Epoch: 29 Idx: 0 Loss: 0.014522334419263715
Epoch: 29 Idx: 5000 Loss: 0.011798247234413122
Epoch: 30 Idx: 0 Loss: 0.014728231916541622
Epoch: 30 Idx: 5000 Loss: 0.011995077368138684
Epoch: 31 Idx: 0 Loss: 0.007330921421105267
Epoch: 31 Idx: 5000 Loss: 0.020554245522892048
Epoch: 32 Idx: 0 Loss: 0.023501952644549934
Epoch: 32 Idx: 5000 Loss: 0.006637831880616042
Epoch: 33 Idx: 0 Loss: 0.011991183136291755
Epoch: 33 Idx: 5000 Loss: 0.00912995873828588
Epoch: 34 Idx: 0 Loss: 0.028100313927279706
Epoch: 34 Idx: 5000 Loss: 0.006768425939712191
Epoch: 35 Idx: 0 Loss: 0.00901533982946323
Epoch: 35 Idx: 5000 Loss: 0.028063249920078963
Epoch: 36 Idx: 0 Loss: 0.009341012918183214
Epoch: 36 Idx: 5000 Loss: 0.007127214317260464
Epoch: 37 Idx: 0 Loss: 0.012374402002436183
Epoch: 37 Idx: 5000 Loss: 0.01640136112470125
Epoch: 38 Idx: 0 Loss: 0.011754262780708652
Epoch: 38 Idx: 5000 Loss: 0.010832179485796796
Epoch: 39 Idx: 0 Loss: 0.00812276843988344
Epoch: 39 Idx: 5000 Loss: 0.008559482647552392
Epoch: 40 Idx: 0 Loss: 0.023398080191523136
Epoch: 40 Idx: 5000 Loss: 0.010651688640806107
Epoch: 41 Idx: 0 Loss: 0.005820140283193477
Epoch: 41 Idx: 5000 Loss: 0.008165693857575328
Epoch: 42 Idx: 0 Loss: 0.010219678902271333
Epoch: 42 Idx: 5000 Loss: 0.014094421576181716
Epoch: 43 Idx: 0 Loss: 0.008955990511099804
Epoch: 43 Idx: 5000 Loss: 0.010843037732490499
Epoch: 44 Idx: 0 Loss: 0.02748560167142693
Epoch: 44 Idx: 5000 Loss: 0.012392708242874691
Epoch: 45 Idx: 0 Loss: 0.032084168302195085
Epoch: 45 Idx: 5000 Loss: 0.023042173419435288
Epoch: 46 Idx: 0 Loss: 0.030834413357988626
Epoch: 46 Idx: 5000 Loss: 0.008542563216490898
Epoch: 47 Idx: 0 Loss: 0.014388750829699561
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 315, in forward
    path_weights = torch.bmm(node_emb[:, None, :], feature_emb_reshaped)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc259>
Subject: Job 4066804: <python main.py 3 21 False False> in cluster <dcc> Exited

Job <python main.py 3 21 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
Job was executed on host(s) <dccxc259>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:37 2020
Terminated at Wed Sep 16 04:38:42 2020
Results reported at Wed Sep 16 04:38:42 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 21 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46074.83 sec.
    Max Memory :                                 2935 MB
    Average Memory :                             2727.48 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40482.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46225 sec.
    Turnaround time :                            46206 sec.

The output (if any) is above this job summary.

