2020-09-15 15:49:39.324593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.672268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:57.691110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:57.691195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:57.693406: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:57.694902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:57.695791: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:57.697823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:57.699378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:57.699611: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:57.699632: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:57.699938: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:57.707185: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600000000 Hz
2020-09-15 15:49:57.707391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56269a7c8360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:57.707410: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:57.709272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:57.709297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18384606851023175
Epoch: 0 Idx: 5000 Loss: 0.007992026635935616
Epoch: 1 Idx: 0 Loss: 0.01360842435671513
Epoch: 1 Idx: 5000 Loss: 0.017947326898454588
Epoch: 2 Idx: 0 Loss: 0.009912305173157495
Epoch: 2 Idx: 5000 Loss: 0.01960106697276904
Epoch: 3 Idx: 0 Loss: 0.012707769581237894
Epoch: 3 Idx: 5000 Loss: 0.01756143530089694
Epoch: 4 Idx: 0 Loss: 0.006731509429394837
Epoch: 4 Idx: 5000 Loss: 0.013305839524411887
Epoch: 5 Idx: 0 Loss: 0.006728884790129731
Epoch: 5 Idx: 5000 Loss: 0.01286176539426679
Epoch: 6 Idx: 0 Loss: 0.02734127508502821
Epoch: 6 Idx: 5000 Loss: 0.008618299211279741
Epoch: 7 Idx: 0 Loss: 0.016329530367337756
Epoch: 7 Idx: 5000 Loss: 0.029513714737790145
Epoch: 8 Idx: 0 Loss: 0.020852402023272473
Epoch: 8 Idx: 5000 Loss: 0.008163706972405958
Epoch: 9 Idx: 0 Loss: 0.017779218144447342
Epoch: 9 Idx: 5000 Loss: 0.007488314709126787
Epoch: 10 Idx: 0 Loss: 0.009428727729957096
Epoch: 10 Idx: 5000 Loss: 0.024894423813214907
Epoch: 11 Idx: 0 Loss: 0.012660929269339968
Epoch: 11 Idx: 5000 Loss: 0.037776737135791154
Epoch: 12 Idx: 0 Loss: 0.008655566863964407
Epoch: 12 Idx: 5000 Loss: 0.0382557275483366
Epoch: 13 Idx: 0 Loss: 0.011351418064768276
Epoch: 13 Idx: 5000 Loss: 0.04593931156096759
Epoch: 14 Idx: 0 Loss: 0.013201021494576365
Epoch: 14 Idx: 5000 Loss: 0.012390090014044064
Epoch: 15 Idx: 0 Loss: 0.02031757432186823
Epoch: 15 Idx: 5000 Loss: 0.033734775154515284
Epoch: 16 Idx: 0 Loss: 0.008373215236007914
Epoch: 16 Idx: 5000 Loss: 0.02656751453773842
Epoch: 17 Idx: 0 Loss: 0.009309308669464281
Epoch: 17 Idx: 5000 Loss: 0.04714174347996599
Epoch: 18 Idx: 0 Loss: 0.012686021366016879
Epoch: 18 Idx: 5000 Loss: 0.022626969379162993
Epoch: 19 Idx: 0 Loss: 0.012909147630488347
Epoch: 19 Idx: 5000 Loss: 0.03309377728150288
Epoch: 20 Idx: 0 Loss: 0.008020641448172666
Epoch: 20 Idx: 5000 Loss: 0.01608014043228971
Epoch: 21 Idx: 0 Loss: 0.022714005212640102
Epoch: 21 Idx: 5000 Loss: 0.036223975237360526
Epoch: 22 Idx: 0 Loss: 0.01886923047751452
Epoch: 22 Idx: 5000 Loss: 0.019520380676825082
Epoch: 23 Idx: 0 Loss: 0.02089775501509081
Epoch: 23 Idx: 5000 Loss: 0.006400369109358338
Epoch: 24 Idx: 0 Loss: 0.014862115549956562
Epoch: 24 Idx: 5000 Loss: 0.014441309916102102
Epoch: 25 Idx: 0 Loss: 0.010047167173975184
Epoch: 25 Idx: 5000 Loss: 0.01350100543073483
Epoch: 26 Idx: 0 Loss: 0.017947838114444326
Epoch: 26 Idx: 5000 Loss: 0.029180762421144882
Epoch: 27 Idx: 0 Loss: 0.01200781181380747
Epoch: 27 Idx: 5000 Loss: 0.026212954952089404
Epoch: 28 Idx: 0 Loss: 0.013192051159953437
Epoch: 28 Idx: 5000 Loss: 0.013628950274263026
Epoch: 29 Idx: 0 Loss: 0.011377465383439771
Epoch: 29 Idx: 5000 Loss: 0.018276659241430248
Epoch: 30 Idx: 0 Loss: 0.017298259455804287
Epoch: 30 Idx: 5000 Loss: 0.008247144057146376
Epoch: 31 Idx: 0 Loss: 0.010042720348888139
Epoch: 31 Idx: 5000 Loss: 0.036673936728084035
Epoch: 32 Idx: 0 Loss: 0.011036380372602853
Epoch: 32 Idx: 5000 Loss: 0.017359055539451634
Epoch: 33 Idx: 0 Loss: 0.01723551594786639
Epoch: 33 Idx: 5000 Loss: 0.0298894869947801
Epoch: 34 Idx: 0 Loss: 0.0063014919401933435
Epoch: 34 Idx: 5000 Loss: 0.012757350294997985
Epoch: 35 Idx: 0 Loss: 0.012671441038840974
Epoch: 35 Idx: 5000 Loss: 0.008245185843462483
Epoch: 36 Idx: 0 Loss: 0.03223818048866308
Epoch: 36 Idx: 5000 Loss: 0.014613064513179315
Epoch: 37 Idx: 0 Loss: 0.028056656301987108
Epoch: 37 Idx: 5000 Loss: 0.017305772600850637
Epoch: 38 Idx: 0 Loss: 0.03812531431309168
Epoch: 38 Idx: 5000 Loss: 0.0242259124479714
Epoch: 39 Idx: 0 Loss: 0.012023770605628372
Epoch: 39 Idx: 5000 Loss: 0.01928373595942364
Epoch: 40 Idx: 0 Loss: 0.010766536283845014
Epoch: 40 Idx: 5000 Loss: 0.023283035977542502
Epoch: 41 Idx: 0 Loss: 0.03551927120373826
Epoch: 41 Idx: 5000 Loss: 0.009086378110403599
Epoch: 42 Idx: 0 Loss: 0.021164134159222348
Epoch: 42 Idx: 5000 Loss: 0.022743801765883583
Epoch: 43 Idx: 0 Loss: 0.023724952400115185
Epoch: 43 Idx: 5000 Loss: 0.023908278867216266
Epoch: 44 Idx: 0 Loss: 0.0069370898382689694
Epoch: 44 Idx: 5000 Loss: 0.011777375405417206
Epoch: 45 Idx: 0 Loss: 0.0062626096087867456
Epoch: 45 Idx: 5000 Loss: 0.012317103829427727
Epoch: 46 Idx: 0 Loss: 0.01076072286643552
Epoch: 46 Idx: 5000 Loss: 0.016723532530306135
Epoch: 47 Idx: 0 Loss: 0.01058639748718401
Epoch: 47 Idx: 5000 Loss: 0.011313848793731755
Epoch: 48 Idx: 0 Loss: 0.023360849241195074
Epoch: 48 Idx: 5000 Loss: 0.015126617737402814
Epoch: 49 Idx: 0 Loss: 0.010130737478075243
Epoch: 49 Idx: 5000 Loss: 0.02263969739300088
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14136229911818682
Epoch: 0 Idx: 5000 Loss: 0.0425348146465432
Epoch: 1 Idx: 0 Loss: 0.015175590320144596
Epoch: 1 Idx: 5000 Loss: 0.044468008492467175
Epoch: 2 Idx: 0 Loss: 0.017451459222141627
Epoch: 2 Idx: 5000 Loss: 0.0038982156905480736
Epoch: 3 Idx: 0 Loss: 0.013655317923530074
Epoch: 3 Idx: 5000 Loss: 0.020978407786540268
Epoch: 4 Idx: 0 Loss: 0.015515348953329185
Epoch: 4 Idx: 5000 Loss: 0.012424511651557672
Epoch: 5 Idx: 0 Loss: 0.02602368578053306
Epoch: 5 Idx: 5000 Loss: 0.013380397056726043
Epoch: 6 Idx: 0 Loss: 0.015778780090178895
Epoch: 6 Idx: 5000 Loss: 0.028079324801754693
Epoch: 7 Idx: 0 Loss: 0.009859351315552285
Epoch: 7 Idx: 5000 Loss: 0.011824556998203256
Epoch: 8 Idx: 0 Loss: 0.007187579431072859
Epoch: 8 Idx: 5000 Loss: 0.025964485056284202
Epoch: 9 Idx: 0 Loss: 0.005033648830506051
Epoch: 9 Idx: 5000 Loss: 0.014085839654592118
Epoch: 10 Idx: 0 Loss: 0.009359338182244067
Epoch: 10 Idx: 5000 Loss: 0.009282647467296052
Epoch: 11 Idx: 0 Loss: 0.010691668491740025
Epoch: 11 Idx: 5000 Loss: 0.013447304854995956
Epoch: 12 Idx: 0 Loss: 0.010109149102907396
Epoch: 12 Idx: 5000 Loss: 0.015215722213145528
Epoch: 13 Idx: 0 Loss: 0.01733102009777231
Epoch: 13 Idx: 5000 Loss: 0.010251955565869754
Epoch: 14 Idx: 0 Loss: 0.0071607124652145
Epoch: 14 Idx: 5000 Loss: 0.03132663495783259
Epoch: 15 Idx: 0 Loss: 0.011643936398688385
Epoch: 15 Idx: 5000 Loss: 0.020875236407354225
Epoch: 16 Idx: 0 Loss: 0.03223152275217318
Epoch: 16 Idx: 5000 Loss: 0.012662855563783191
Epoch: 17 Idx: 0 Loss: 0.00973185636881696
Epoch: 17 Idx: 5000 Loss: 0.018119147853289434
Epoch: 18 Idx: 0 Loss: 0.015164418495960431
Epoch: 18 Idx: 5000 Loss: 0.01211581662350587
Epoch: 19 Idx: 0 Loss: 0.015178189829493049
Epoch: 19 Idx: 5000 Loss: 0.010494992151195677
Epoch: 20 Idx: 0 Loss: 0.01995942383089872
Epoch: 20 Idx: 5000 Loss: 0.015680235997211234
Epoch: 21 Idx: 0 Loss: 0.00971377275608297
Epoch: 21 Idx: 5000 Loss: 0.02010297712497594
Epoch: 22 Idx: 0 Loss: 0.017851256281007567
Epoch: 22 Idx: 5000 Loss: 0.005314178620782664
Epoch: 23 Idx: 0 Loss: 0.01619757132772725
Epoch: 23 Idx: 5000 Loss: 0.009276336856542947
Epoch: 24 Idx: 0 Loss: 0.010721100769697022
Epoch: 24 Idx: 5000 Loss: 0.008066220774955744
Epoch: 25 Idx: 0 Loss: 0.005800674203510175
Epoch: 25 Idx: 5000 Loss: 0.0309448320132404
Epoch: 26 Idx: 0 Loss: 0.012899346109539253
Epoch: 26 Idx: 5000 Loss: 0.01799450070520634
Epoch: 27 Idx: 0 Loss: 0.02168326370794965
Epoch: 27 Idx: 5000 Loss: 0.014524253966448793
Epoch: 28 Idx: 0 Loss: 0.006949874614032869
Epoch: 28 Idx: 5000 Loss: 0.004684900170756543
Epoch: 29 Idx: 0 Loss: 0.022148277183095207
Epoch: 29 Idx: 5000 Loss: 0.026058205519321025
Epoch: 30 Idx: 0 Loss: 0.013200790882107898
Epoch: 30 Idx: 5000 Loss: 0.008522159153268968
Epoch: 31 Idx: 0 Loss: 0.011078192724855279
Epoch: 31 Idx: 5000 Loss: 0.02243380622883929
Epoch: 32 Idx: 0 Loss: 0.008350765367788834
Epoch: 32 Idx: 5000 Loss: 0.009942242146611656
Epoch: 33 Idx: 0 Loss: 0.011555574270708933
Epoch: 33 Idx: 5000 Loss: 0.01262151188918555
Epoch: 34 Idx: 0 Loss: 0.02292368645287882
Epoch: 34 Idx: 5000 Loss: 0.013600400013205253
Epoch: 35 Idx: 0 Loss: 0.014314138717313813
Epoch: 35 Idx: 5000 Loss: 0.007407673424530639
Epoch: 36 Idx: 0 Loss: 0.015208710048180103
Epoch: 36 Idx: 5000 Loss: 0.011790379287271212
Epoch: 37 Idx: 0 Loss: 0.006093239524071104
Epoch: 37 Idx: 5000 Loss: 0.01567901025920571
Epoch: 38 Idx: 0 Loss: 0.011031203808666049
Epoch: 38 Idx: 5000 Loss: 0.009076329362818544
Epoch: 39 Idx: 0 Loss: 0.008938968557511149
Epoch: 39 Idx: 5000 Loss: 0.014358016124365353
Epoch: 40 Idx: 0 Loss: 0.013645559247285166
Epoch: 40 Idx: 5000 Loss: 0.00962884621793576
Epoch: 41 Idx: 0 Loss: 0.012204950169321348
Epoch: 41 Idx: 5000 Loss: 0.010087299945154764
Epoch: 42 Idx: 0 Loss: 0.005684954700637931
Epoch: 42 Idx: 5000 Loss: 0.011013831313879337
Epoch: 43 Idx: 0 Loss: 0.015575907341252124
Epoch: 43 Idx: 5000 Loss: 0.004224541017073858
Epoch: 44 Idx: 0 Loss: 0.029968538598364583
Epoch: 44 Idx: 5000 Loss: 0.016203267617051542
Epoch: 45 Idx: 0 Loss: 0.00816453517313941
Epoch: 45 Idx: 5000 Loss: 0.02513250336289053
Epoch: 46 Idx: 0 Loss: 0.010708065779990143
Epoch: 46 Idx: 5000 Loss: 0.041461865438071246
Epoch: 47 Idx: 0 Loss: 0.016415298584625926
Epoch: 47 Idx: 5000 Loss: 0.011927646002123968
Epoch: 48 Idx: 0 Loss: 0.02075445428718816
Epoch: 48 Idx: 5000 Loss: 0.015459171735054296
Epoch: 49 Idx: 0 Loss: 0.013487436057771838
Epoch: 49 Idx: 5000 Loss: 0.026761413252500033
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13939205788621398
Epoch: 0 Idx: 5000 Loss: 0.007161309572274444
Epoch: 1 Idx: 0 Loss: 0.01260670018320577
Epoch: 1 Idx: 5000 Loss: 0.01225484931805182
Epoch: 2 Idx: 0 Loss: 0.014804423426985408
Epoch: 2 Idx: 5000 Loss: 0.00845169611143368
Epoch: 3 Idx: 0 Loss: 0.04015936236598412
Epoch: 3 Idx: 5000 Loss: 0.01429135277107244
Epoch: 4 Idx: 0 Loss: 0.03245164302965605
Epoch: 4 Idx: 5000 Loss: 0.008147350393424508
Epoch: 5 Idx: 0 Loss: 0.024771262287735366
Epoch: 5 Idx: 5000 Loss: 0.026989804283789182
Epoch: 6 Idx: 0 Loss: 0.019668144510109276
Epoch: 6 Idx: 5000 Loss: 0.03403622192386764
Epoch: 7 Idx: 0 Loss: 0.030110690265124994
Epoch: 7 Idx: 5000 Loss: 0.020328930936327434
Epoch: 8 Idx: 0 Loss: 0.009900871118375655
Epoch: 8 Idx: 5000 Loss: 0.01081803452878631
Epoch: 9 Idx: 0 Loss: 0.015370777965912451
Epoch: 9 Idx: 5000 Loss: 0.018143241321551738
Epoch: 10 Idx: 0 Loss: 0.0207170407253639
Epoch: 10 Idx: 5000 Loss: 0.014109942432189071
Epoch: 11 Idx: 0 Loss: 0.010165102529614207
Epoch: 11 Idx: 5000 Loss: 0.02631669710808501
Epoch: 12 Idx: 0 Loss: 0.02024489456333205
Epoch: 12 Idx: 5000 Loss: 0.010275232395046312
Epoch: 13 Idx: 0 Loss: 0.009480725481417707
Epoch: 13 Idx: 5000 Loss: 0.012694109323536996
Epoch: 14 Idx: 0 Loss: 0.029800230496291026
Epoch: 14 Idx: 5000 Loss: 0.018468711553942405
Epoch: 15 Idx: 0 Loss: 0.007799284437429199
Epoch: 15 Idx: 5000 Loss: 0.008615985843915815
Epoch: 16 Idx: 0 Loss: 0.02202268235711989
Epoch: 16 Idx: 5000 Loss: 0.017515668982114423
Epoch: 17 Idx: 0 Loss: 0.014431116788113344
Epoch: 17 Idx: 5000 Loss: 0.01547938781556783
Epoch: 18 Idx: 0 Loss: 0.010111244485234943
Epoch: 18 Idx: 5000 Loss: 0.03220443176186994
Epoch: 19 Idx: 0 Loss: 0.021847302174633015
Epoch: 19 Idx: 5000 Loss: 0.0163588638910407
Epoch: 20 Idx: 0 Loss: 0.0050606950840215255
Epoch: 20 Idx: 5000 Loss: 0.020065797635679773
Epoch: 21 Idx: 0 Loss: 0.0167882509268985
Epoch: 21 Idx: 5000 Loss: 0.011438829748975591
Epoch: 22 Idx: 0 Loss: 0.010954000256223138
Epoch: 22 Idx: 5000 Loss: 0.006171416459906524
Epoch: 23 Idx: 0 Loss: 0.021758919863301612
Epoch: 23 Idx: 5000 Loss: 0.012530025149434475
Epoch: 24 Idx: 0 Loss: 0.015570358185077886
Epoch: 24 Idx: 5000 Loss: 0.011216104866743107
Epoch: 25 Idx: 0 Loss: 0.008904818280355322
Epoch: 25 Idx: 5000 Loss: 0.012040433152265587
Epoch: 26 Idx: 0 Loss: 0.007764126756325855
Epoch: 26 Idx: 5000 Loss: 0.012565048187045291
Epoch: 27 Idx: 0 Loss: 0.04288345112624591
Epoch: 27 Idx: 5000 Loss: 0.02488390882403641
Epoch: 28 Idx: 0 Loss: 0.01599890989840666
Epoch: 28 Idx: 5000 Loss: 0.0335192920197668
Epoch: 29 Idx: 0 Loss: 0.024103252847066672
Epoch: 29 Idx: 5000 Loss: 0.017079428217866743
Epoch: 30 Idx: 0 Loss: 0.0070958132114709105
Epoch: 30 Idx: 5000 Loss: 0.01184746945128403
Epoch: 31 Idx: 0 Loss: 0.01654986951579958
Epoch: 31 Idx: 5000 Loss: 0.01468522511214523
Epoch: 32 Idx: 0 Loss: 0.009648067523047515
Epoch: 32 Idx: 5000 Loss: 0.009543684026598904
Epoch: 33 Idx: 0 Loss: 0.008523100576336208
Epoch: 33 Idx: 5000 Loss: 0.013070741786991975
Epoch: 34 Idx: 0 Loss: 0.019734467781459954
Epoch: 34 Idx: 5000 Loss: 0.020208112910230887
Epoch: 35 Idx: 0 Loss: 0.012989171727497178
Epoch: 35 Idx: 5000 Loss: 0.023840055884678954
Epoch: 36 Idx: 0 Loss: 0.006841232497741723
Epoch: 36 Idx: 5000 Loss: 0.008199965919113959
Epoch: 37 Idx: 0 Loss: 0.00787296198538726
Epoch: 37 Idx: 5000 Loss: 0.02144248569928982
Epoch: 38 Idx: 0 Loss: 0.029952530513705992
Epoch: 38 Idx: 5000 Loss: 0.017098613408256958
Epoch: 39 Idx: 0 Loss: 0.013501453682554251
Epoch: 39 Idx: 5000 Loss: 0.017614906744626038
Epoch: 40 Idx: 0 Loss: 0.01897672835477016
Epoch: 40 Idx: 5000 Loss: 0.01319345192530501
Epoch: 41 Idx: 0 Loss: 0.012770374910766378
Epoch: 41 Idx: 5000 Loss: 0.02924636016856896
Epoch: 42 Idx: 0 Loss: 0.040076130271556695
Epoch: 42 Idx: 5000 Loss: 0.017481351216755467
Epoch: 43 Idx: 0 Loss: 0.007312006324335745
Epoch: 43 Idx: 5000 Loss: 0.00897357556439911
Epoch: 44 Idx: 0 Loss: 0.02205019094266488
Epoch: 44 Idx: 5000 Loss: 0.01714026143762669
Epoch: 45 Idx: 0 Loss: 0.013674396851833782
Epoch: 45 Idx: 5000 Loss: 0.009212187029872334
Epoch: 46 Idx: 0 Loss: 0.012105044984036924
Epoch: 46 Idx: 5000 Loss: 0.01224377656150325
Epoch: 47 Idx: 0 Loss: 0.021546275900645957
Epoch: 47 Idx: 5000 Loss: 0.01674363420205693
Epoch: 48 Idx: 0 Loss: 0.017901238939005984
Epoch: 48 Idx: 5000 Loss: 0.009785234853814323
Epoch: 49 Idx: 0 Loss: 0.011998512831623105
Epoch: 49 Idx: 5000 Loss: 0.0073411665084710705
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.2539532695424248
Epoch: 0 Idx: 5000 Loss: 0.018653244525884988
Epoch: 1 Idx: 0 Loss: 0.012612739901845443
Epoch: 1 Idx: 5000 Loss: 0.013286679029227548
Epoch: 2 Idx: 0 Loss: 0.013306846251881416
Epoch: 2 Idx: 5000 Loss: 0.013762589342837797
Epoch: 3 Idx: 0 Loss: 0.015374401420353193
Epoch: 3 Idx: 5000 Loss: 0.012371951607841318
Epoch: 4 Idx: 0 Loss: 0.03491588961286452
Epoch: 4 Idx: 5000 Loss: 0.009435584916163968
Epoch: 5 Idx: 0 Loss: 0.0163073514793809
Epoch: 5 Idx: 5000 Loss: 0.014428441844648417
Epoch: 6 Idx: 0 Loss: 0.011629932184116494
Epoch: 6 Idx: 5000 Loss: 0.011364744679382201
Epoch: 7 Idx: 0 Loss: 0.008172050830913455
Epoch: 7 Idx: 5000 Loss: 0.01666878036200007
Epoch: 8 Idx: 0 Loss: 0.009718878344298973
Epoch: 8 Idx: 5000 Loss: 0.016557103117834652
Epoch: 9 Idx: 0 Loss: 0.023595132621603815
Epoch: 9 Idx: 5000 Loss: 0.007411106833538289
Epoch: 10 Idx: 0 Loss: 0.01262434382662152
Epoch: 10 Idx: 5000 Loss: 0.02244484026440354
Epoch: 11 Idx: 0 Loss: 0.02127526547519928
Epoch: 11 Idx: 5000 Loss: 0.005798783886600586
Epoch: 12 Idx: 0 Loss: 0.014504416671817514
Epoch: 12 Idx: 5000 Loss: 0.015298566890823604
Epoch: 13 Idx: 0 Loss: 0.016311233046095237
Epoch: 13 Idx: 5000 Loss: 0.033273927147006374
Epoch: 14 Idx: 0 Loss: 0.007739048352619315
Epoch: 14 Idx: 5000 Loss: 0.007423517948751798
Epoch: 15 Idx: 0 Loss: 0.018568606510209314
Epoch: 15 Idx: 5000 Loss: 0.011946446731227087
Epoch: 16 Idx: 0 Loss: 0.010929088110433156
Epoch: 16 Idx: 5000 Loss: 0.009091300233529274
Epoch: 17 Idx: 0 Loss: 0.01389281418345227
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc262>
Subject: Job 4066881: <python main.py 6 9 False False> in cluster <dcc> Exited

Job <python main.py 6 9 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc262>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 9 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46116.48 sec.
    Max Memory :                                 2940 MB
    Average Memory :                             2731.33 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40477.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46142 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

