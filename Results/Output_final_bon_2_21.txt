2020-09-15 15:49:41.962610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.041033: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.165618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.165724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.167744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.169216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.169678: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.171529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.172952: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.173213: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.173234: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.173552: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.180814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599940000 Hz
2020-09-15 15:49:45.181021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56236a6f40e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.181041: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.182937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.182967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1838250057400973
Epoch: 0 Idx: 5000 Loss: 0.014902417889477795
Epoch: 1 Idx: 0 Loss: 0.019697919415221556
Epoch: 1 Idx: 5000 Loss: 0.02740215811566203
Epoch: 2 Idx: 0 Loss: 0.022759320270563384
Epoch: 2 Idx: 5000 Loss: 0.06603907308453136
Epoch: 3 Idx: 0 Loss: 0.028419051177355104
Epoch: 3 Idx: 5000 Loss: 0.009631121564321957
Epoch: 4 Idx: 0 Loss: 0.015596044886166744
Epoch: 4 Idx: 5000 Loss: 0.007148966327879979
Epoch: 5 Idx: 0 Loss: 0.014604955889368151
Epoch: 5 Idx: 5000 Loss: 0.02755284279373781
Epoch: 6 Idx: 0 Loss: 0.011726441859555018
Epoch: 6 Idx: 5000 Loss: 0.01635231520846731
Epoch: 7 Idx: 0 Loss: 0.014765029415955127
Epoch: 7 Idx: 5000 Loss: 0.02385289108758573
Epoch: 8 Idx: 0 Loss: 0.019650587924335352
Epoch: 8 Idx: 5000 Loss: 0.021355562152653617
Epoch: 9 Idx: 0 Loss: 0.01150865190453574
Epoch: 9 Idx: 5000 Loss: 0.012800309003083186
Epoch: 10 Idx: 0 Loss: 0.0041305958195780425
Epoch: 10 Idx: 5000 Loss: 0.014261409370874605
Epoch: 11 Idx: 0 Loss: 0.014016068059322897
Epoch: 11 Idx: 5000 Loss: 0.02409154774717341
Epoch: 12 Idx: 0 Loss: 0.01077620872177348
Epoch: 12 Idx: 5000 Loss: 0.010394357502295738
Epoch: 13 Idx: 0 Loss: 0.021406693114229866
Epoch: 13 Idx: 5000 Loss: 0.004745408154041724
Epoch: 14 Idx: 0 Loss: 0.005996292873553765
Epoch: 14 Idx: 5000 Loss: 0.01529404623435994
Epoch: 15 Idx: 0 Loss: 0.0158010528520528
Epoch: 15 Idx: 5000 Loss: 0.014477536495646199
Epoch: 16 Idx: 0 Loss: 0.016953849201598814
Epoch: 16 Idx: 5000 Loss: 0.021879474553431283
Epoch: 17 Idx: 0 Loss: 0.018607756564912897
Epoch: 17 Idx: 5000 Loss: 0.012760469892073766
Epoch: 18 Idx: 0 Loss: 0.011967774983074629
Epoch: 18 Idx: 5000 Loss: 0.011656239912445755
Epoch: 19 Idx: 0 Loss: 0.006466704454577716
Epoch: 19 Idx: 5000 Loss: 0.06087036173394303
Epoch: 20 Idx: 0 Loss: 0.007093480467130281
Epoch: 20 Idx: 5000 Loss: 0.017290353563899935
Epoch: 21 Idx: 0 Loss: 0.012878949556039614
Epoch: 21 Idx: 5000 Loss: 0.020879836746632283
Epoch: 22 Idx: 0 Loss: 0.025265548706962494
Epoch: 22 Idx: 5000 Loss: 0.010056025001263397
Epoch: 23 Idx: 0 Loss: 0.02107580548821757
Epoch: 23 Idx: 5000 Loss: 0.009525877251925913
Epoch: 24 Idx: 0 Loss: 0.010247113136475257
Epoch: 24 Idx: 5000 Loss: 0.011043775680361616
Epoch: 25 Idx: 0 Loss: 0.012863117163556571
Epoch: 25 Idx: 5000 Loss: 0.009447716811823471
Epoch: 26 Idx: 0 Loss: 0.011696164752183089
Epoch: 26 Idx: 5000 Loss: 0.0052969936960073054
Epoch: 27 Idx: 0 Loss: 0.006985544853858558
Epoch: 27 Idx: 5000 Loss: 0.005624217278215002
Epoch: 28 Idx: 0 Loss: 0.01168252183395471
Epoch: 28 Idx: 5000 Loss: 0.01373521782691912
Epoch: 29 Idx: 0 Loss: 0.022971425372770114
Epoch: 29 Idx: 5000 Loss: 0.013869514243952445
Epoch: 30 Idx: 0 Loss: 0.017943762483327626
Epoch: 30 Idx: 5000 Loss: 0.023384766845937113
Epoch: 31 Idx: 0 Loss: 0.006976558055499727
Epoch: 31 Idx: 5000 Loss: 0.014541591471831103
Epoch: 32 Idx: 0 Loss: 0.011971890908231834
Epoch: 32 Idx: 5000 Loss: 0.006634064435818234
Epoch: 33 Idx: 0 Loss: 0.008851104148999093
Epoch: 33 Idx: 5000 Loss: 0.009652700302495026
Epoch: 34 Idx: 0 Loss: 0.022714334208456
Epoch: 34 Idx: 5000 Loss: 0.016866469983259993
Epoch: 35 Idx: 0 Loss: 0.01436668023988089
Epoch: 35 Idx: 5000 Loss: 0.02962487723242569
Epoch: 36 Idx: 0 Loss: 0.024488139177571443
Epoch: 36 Idx: 5000 Loss: 0.014486696012500912
Epoch: 37 Idx: 0 Loss: 0.019048157078164728
Epoch: 37 Idx: 5000 Loss: 0.020783790484628913
Epoch: 38 Idx: 0 Loss: 0.0076771688438776785
Epoch: 38 Idx: 5000 Loss: 0.02001666398804256
Epoch: 39 Idx: 0 Loss: 0.014224212131840363
Epoch: 39 Idx: 5000 Loss: 0.01895335514164869
Epoch: 40 Idx: 0 Loss: 0.0195547947613003
Epoch: 40 Idx: 5000 Loss: 0.02294420200709368
Epoch: 41 Idx: 0 Loss: 0.018233254590604764
Epoch: 41 Idx: 5000 Loss: 0.00784435547564274
Epoch: 42 Idx: 0 Loss: 0.025647220262224168
Epoch: 42 Idx: 5000 Loss: 0.013826243081874289
Epoch: 43 Idx: 0 Loss: 0.00987804621397613
Epoch: 43 Idx: 5000 Loss: 0.019247984889347695
Epoch: 44 Idx: 0 Loss: 0.01025851305428261
Epoch: 44 Idx: 5000 Loss: 0.007485751010954045
Epoch: 45 Idx: 0 Loss: 0.010828452722985287
Epoch: 45 Idx: 5000 Loss: 0.018909583560475805
Epoch: 46 Idx: 0 Loss: 0.016390804138226286
Epoch: 46 Idx: 5000 Loss: 0.02023655837224052
Epoch: 47 Idx: 0 Loss: 0.018918874432998792
Epoch: 47 Idx: 5000 Loss: 0.011381409631374802
Epoch: 48 Idx: 0 Loss: 0.012260434035906357
Epoch: 48 Idx: 5000 Loss: 0.014766022654640207
Epoch: 49 Idx: 0 Loss: 0.02060653395628268
Epoch: 49 Idx: 5000 Loss: 0.021189956280063517
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1487520712455142
Epoch: 0 Idx: 5000 Loss: 0.032163536064550954
Epoch: 1 Idx: 0 Loss: 0.007701117498207934
Epoch: 1 Idx: 5000 Loss: 0.006664867732056921
Epoch: 2 Idx: 0 Loss: 0.011575394879505773
Epoch: 2 Idx: 5000 Loss: 0.013479860745982383
Epoch: 3 Idx: 0 Loss: 0.02345573785612996
Epoch: 3 Idx: 5000 Loss: 0.016437055131038873
Epoch: 4 Idx: 0 Loss: 0.01775769770985912
Epoch: 4 Idx: 5000 Loss: 0.011311465238849674
Epoch: 5 Idx: 0 Loss: 0.017645899084261993
Epoch: 5 Idx: 5000 Loss: 0.005306528632485
Epoch: 6 Idx: 0 Loss: 0.01571213859549192
Epoch: 6 Idx: 5000 Loss: 0.02543991673249215
Epoch: 7 Idx: 0 Loss: 0.03370619780737702
Epoch: 7 Idx: 5000 Loss: 0.011560637785117012
Epoch: 8 Idx: 0 Loss: 0.012271155317008408
Epoch: 8 Idx: 5000 Loss: 0.025700529474546794
Epoch: 9 Idx: 0 Loss: 0.02328421784992521
Epoch: 9 Idx: 5000 Loss: 0.020149178060321498
Epoch: 10 Idx: 0 Loss: 0.013178995956344492
Epoch: 10 Idx: 5000 Loss: 0.005894195017961557
Epoch: 11 Idx: 0 Loss: 0.021890429424403616
Epoch: 11 Idx: 5000 Loss: 0.0037083374822984897
Epoch: 12 Idx: 0 Loss: 0.01167955585953618
Epoch: 12 Idx: 5000 Loss: 0.02781343206410045
Epoch: 13 Idx: 0 Loss: 0.008377653358678046
Epoch: 13 Idx: 5000 Loss: 0.004008221384816925
Epoch: 14 Idx: 0 Loss: 0.010881355157028235
Epoch: 14 Idx: 5000 Loss: 0.020184204569430323
Epoch: 15 Idx: 0 Loss: 0.022671680819859468
Epoch: 15 Idx: 5000 Loss: 0.014391605420425394
Epoch: 16 Idx: 0 Loss: 0.018888385520393975
Epoch: 16 Idx: 5000 Loss: 0.019029673152716635
Epoch: 17 Idx: 0 Loss: 0.025064979792869257
Epoch: 17 Idx: 5000 Loss: 0.024046758984288596
Epoch: 18 Idx: 0 Loss: 0.01074732449982413
Epoch: 18 Idx: 5000 Loss: 0.020101601404283853
Epoch: 19 Idx: 0 Loss: 0.022781461189569065
Epoch: 19 Idx: 5000 Loss: 0.008388273010799682
Epoch: 20 Idx: 0 Loss: 0.015137299859519077
Epoch: 20 Idx: 5000 Loss: 0.011249730478290663
Epoch: 21 Idx: 0 Loss: 0.022311431835035783
Epoch: 21 Idx: 5000 Loss: 0.024821220122076795
Epoch: 22 Idx: 0 Loss: 0.007318224480293642
Epoch: 22 Idx: 5000 Loss: 0.007496610154177954
Epoch: 23 Idx: 0 Loss: 0.010872920546205811
Epoch: 23 Idx: 5000 Loss: 0.01281560818580689
Epoch: 24 Idx: 0 Loss: 0.011483762972876267
Epoch: 24 Idx: 5000 Loss: 0.015852093051979058
Epoch: 25 Idx: 0 Loss: 0.01775666991734745
Epoch: 25 Idx: 5000 Loss: 0.025631879215543746
Epoch: 26 Idx: 0 Loss: 0.026008961037601537
Epoch: 26 Idx: 5000 Loss: 0.011780761337916586
Epoch: 27 Idx: 0 Loss: 0.005803196492059371
Epoch: 27 Idx: 5000 Loss: 0.027691919988703566
Epoch: 28 Idx: 0 Loss: 0.017514049128182003
Epoch: 28 Idx: 5000 Loss: 0.012519656302312578
Epoch: 29 Idx: 0 Loss: 0.00922935649918838
Epoch: 29 Idx: 5000 Loss: 0.012687718948293306
Epoch: 30 Idx: 0 Loss: 0.025400449416008598
Epoch: 30 Idx: 5000 Loss: 0.022896418868968756
Epoch: 31 Idx: 0 Loss: 0.016889594328791148
Epoch: 31 Idx: 5000 Loss: 0.04521557981888117
Epoch: 32 Idx: 0 Loss: 0.030622485474090584
Epoch: 32 Idx: 5000 Loss: 0.03496161005735196
Epoch: 33 Idx: 0 Loss: 0.027050451922105444
Epoch: 33 Idx: 5000 Loss: 0.02062278543552383
Epoch: 34 Idx: 0 Loss: 0.03055355774590473
Epoch: 34 Idx: 5000 Loss: 0.022398131672280365
Epoch: 35 Idx: 0 Loss: 0.008475522269664002
Epoch: 35 Idx: 5000 Loss: 0.004557689129389975
Epoch: 36 Idx: 0 Loss: 0.018186343111784624
Epoch: 36 Idx: 5000 Loss: 0.025351433523272248
Epoch: 37 Idx: 0 Loss: 0.008994170819729133
Epoch: 37 Idx: 5000 Loss: 0.014117458771289403
Epoch: 38 Idx: 0 Loss: 0.02541003316248821
Epoch: 38 Idx: 5000 Loss: 0.011767791081359615
Epoch: 39 Idx: 0 Loss: 0.01067701711774201
Epoch: 39 Idx: 5000 Loss: 0.010776858622049933
Epoch: 40 Idx: 0 Loss: 0.009120932921498388
Epoch: 40 Idx: 5000 Loss: 0.017498436986007598
Epoch: 41 Idx: 0 Loss: 0.027514134188259994
Epoch: 41 Idx: 5000 Loss: 0.007445989937194695
Epoch: 42 Idx: 0 Loss: 0.023533381255259604
Epoch: 42 Idx: 5000 Loss: 0.014067623348379523
Epoch: 43 Idx: 0 Loss: 0.013613087205062779
Epoch: 43 Idx: 5000 Loss: 0.009357466620864749
Epoch: 44 Idx: 0 Loss: 0.0173845183453651
Epoch: 44 Idx: 5000 Loss: 0.04663676649134289
Epoch: 45 Idx: 0 Loss: 0.022537263226850623
Epoch: 45 Idx: 5000 Loss: 0.010758995884661542
Epoch: 46 Idx: 0 Loss: 0.01436936805937655
Epoch: 46 Idx: 5000 Loss: 0.027763698087780977
Epoch: 47 Idx: 0 Loss: 0.013635066217426208
Epoch: 47 Idx: 5000 Loss: 0.017510085408847523
Epoch: 48 Idx: 0 Loss: 0.011652483864985082
Epoch: 48 Idx: 5000 Loss: 0.014090016880986139
Epoch: 49 Idx: 0 Loss: 0.008532739173725198
Epoch: 49 Idx: 5000 Loss: 0.011497698274905923
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.12898479399721283
Epoch: 0 Idx: 5000 Loss: 0.013509687708326178
Epoch: 1 Idx: 0 Loss: 0.010009109512896793
Epoch: 1 Idx: 5000 Loss: 0.006354348668226017
Epoch: 2 Idx: 0 Loss: 0.028504129203123334
Epoch: 2 Idx: 5000 Loss: 0.012553509628823636
Epoch: 3 Idx: 0 Loss: 0.045767868435947816
Epoch: 3 Idx: 5000 Loss: 0.02968063773137468
Epoch: 4 Idx: 0 Loss: 0.013474241661099888
Epoch: 4 Idx: 5000 Loss: 0.023782135356924358
Epoch: 5 Idx: 0 Loss: 0.018002671623708905
Epoch: 5 Idx: 5000 Loss: 0.013392269266956849
Epoch: 6 Idx: 0 Loss: 0.026513538816572615
Epoch: 6 Idx: 5000 Loss: 0.011668758670329914
Epoch: 7 Idx: 0 Loss: 0.003354164756724336
Epoch: 7 Idx: 5000 Loss: 0.011990501074608
Epoch: 8 Idx: 0 Loss: 0.005859806522952136
Epoch: 8 Idx: 5000 Loss: 0.017903161767152356
Epoch: 9 Idx: 0 Loss: 0.029945139508039984
Epoch: 9 Idx: 5000 Loss: 0.009827401880556245
Epoch: 10 Idx: 0 Loss: 0.008579631051094272
Epoch: 10 Idx: 5000 Loss: 0.011389030775671745
Epoch: 11 Idx: 0 Loss: 0.02282358023568509
Epoch: 11 Idx: 5000 Loss: 0.03235140078376817
Epoch: 12 Idx: 0 Loss: 0.009142135938521947
Epoch: 12 Idx: 5000 Loss: 0.011770263597782389
Epoch: 13 Idx: 0 Loss: 0.00949772198161487
Epoch: 13 Idx: 5000 Loss: 0.010340124081255054
Epoch: 14 Idx: 0 Loss: 0.02184218692784914
Epoch: 14 Idx: 5000 Loss: 0.025887558154284222
Epoch: 15 Idx: 0 Loss: 0.016371498549624133
Epoch: 15 Idx: 5000 Loss: 0.010878885411907761
Epoch: 16 Idx: 0 Loss: 0.011756110178424753
Epoch: 16 Idx: 5000 Loss: 0.039958341332792885
Epoch: 17 Idx: 0 Loss: 0.017469265957408813
Epoch: 17 Idx: 5000 Loss: 0.01358596323586624
Epoch: 18 Idx: 0 Loss: 0.008013668231476732
Epoch: 18 Idx: 5000 Loss: 0.045963966821713775
Epoch: 19 Idx: 0 Loss: 0.01740714602448499
Epoch: 19 Idx: 5000 Loss: 0.012618725501823613
Epoch: 20 Idx: 0 Loss: 0.018166466434948847
Epoch: 20 Idx: 5000 Loss: 0.011521480589422605
Epoch: 21 Idx: 0 Loss: 0.008429751791839203
Epoch: 21 Idx: 5000 Loss: 0.017247894985052584
Epoch: 22 Idx: 0 Loss: 0.02452371028772008
Epoch: 22 Idx: 5000 Loss: 0.020682796394991612
Epoch: 23 Idx: 0 Loss: 0.0141682431160614
Epoch: 23 Idx: 5000 Loss: 0.014397291620423268
Epoch: 24 Idx: 0 Loss: 0.015895523373270926
Epoch: 24 Idx: 5000 Loss: 0.014560008906794228
Epoch: 25 Idx: 0 Loss: 0.0136027262704606
Epoch: 25 Idx: 5000 Loss: 0.011694031936492906
Epoch: 26 Idx: 0 Loss: 0.012091612519288303
Epoch: 26 Idx: 5000 Loss: 0.017353398817636354
Epoch: 27 Idx: 0 Loss: 0.015180337279695815
Epoch: 27 Idx: 5000 Loss: 0.013846807267567643
Epoch: 28 Idx: 0 Loss: 0.007866519321957338
Epoch: 28 Idx: 5000 Loss: 0.007893265554740281
Epoch: 29 Idx: 0 Loss: 0.01544654970696313
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc274>
Subject: Job 4066905: <python main.py 21 2 True False> in cluster <dcc> Exited

Job <python main.py 21 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc274>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 21 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46051.81 sec.
    Max Memory :                                 2882 MB
    Average Memory :                             2671.10 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40535.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46168 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

