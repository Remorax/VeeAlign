2020-09-16 07:28:01.213988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:28:10.029982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:28:10.156130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1f:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:28:10.156225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:28:10.158108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:28:10.159567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:28:10.159947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:28:10.161826: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:28:10.163246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:28:10.163413: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib
2020-09-16 07:28:10.163434: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:28:10.163852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:28:10.197836: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599940000 Hz
2020-09-16 07:28:10.198116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56474cb730c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:28:10.198137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:28:10.201238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:28:10.201300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/naveen9/arvind/VeeAlign/
Ontologies being aligned are:  [('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.17570508671689344
Epoch: 0 Idx: 5000 Loss: 0.015547956962837402
Epoch: 1 Idx: 0 Loss: 0.01288450109077217
Epoch: 1 Idx: 5000 Loss: 0.03607438111839598
Epoch: 2 Idx: 0 Loss: 0.005938299403911187
Epoch: 2 Idx: 5000 Loss: 0.007394322682328631
Epoch: 3 Idx: 0 Loss: 0.014826158844096141
Epoch: 3 Idx: 5000 Loss: 0.011979556917834951
Epoch: 4 Idx: 0 Loss: 0.010278234030889783
Epoch: 4 Idx: 5000 Loss: 0.011038185345921379
Epoch: 5 Idx: 0 Loss: 0.010502477785236598
Epoch: 5 Idx: 5000 Loss: 0.01690654626727366
Epoch: 6 Idx: 0 Loss: 0.025268490463360653
Epoch: 6 Idx: 5000 Loss: 0.012445674543678436
Epoch: 7 Idx: 0 Loss: 0.04122727926302228
Epoch: 7 Idx: 5000 Loss: 0.010500697963148491
Epoch: 8 Idx: 0 Loss: 0.023358789355067126
Epoch: 8 Idx: 5000 Loss: 0.006629409456520886
Epoch: 9 Idx: 0 Loss: 0.013790709832237326
Epoch: 9 Idx: 5000 Loss: 0.013838365261332525
Epoch: 10 Idx: 0 Loss: 0.009278206209282342
Epoch: 10 Idx: 5000 Loss: 0.008624536295307425
Epoch: 11 Idx: 0 Loss: 0.011130416550548632
Epoch: 11 Idx: 5000 Loss: 0.011545282958682948
Epoch: 12 Idx: 0 Loss: 0.006334871005182068
Epoch: 12 Idx: 5000 Loss: 0.00927724449808659
Epoch: 13 Idx: 0 Loss: 0.008684553705412481
Epoch: 13 Idx: 5000 Loss: 0.01778963877707134
Epoch: 14 Idx: 0 Loss: 0.01817884966839447
Epoch: 14 Idx: 5000 Loss: 0.014105900179647668
Epoch: 15 Idx: 0 Loss: 0.012371052844821574
Epoch: 15 Idx: 5000 Loss: 0.014008021514086531
Epoch: 16 Idx: 0 Loss: 0.019406744967713704
Epoch: 16 Idx: 5000 Loss: 0.012416466019056964
Epoch: 17 Idx: 0 Loss: 0.018394979654587792
Epoch: 17 Idx: 5000 Loss: 0.01006978332887054
Epoch: 18 Idx: 0 Loss: 0.034686325624634945
Epoch: 18 Idx: 5000 Loss: 0.02481199941932054
Epoch: 19 Idx: 0 Loss: 0.011756693706050283
Epoch: 19 Idx: 5000 Loss: 0.01155434030974421
Epoch: 20 Idx: 0 Loss: 0.015566361699500118
Epoch: 20 Idx: 5000 Loss: 0.01597824027399243
Epoch: 21 Idx: 0 Loss: 0.015066402849494162
Epoch: 21 Idx: 5000 Loss: 0.013863380597784481
Epoch: 22 Idx: 0 Loss: 0.02491667683238057
Epoch: 22 Idx: 5000 Loss: 0.008212884390301187
Epoch: 23 Idx: 0 Loss: 0.019090816574911306
Epoch: 23 Idx: 5000 Loss: 0.032608872759119216
Epoch: 24 Idx: 0 Loss: 0.023458156330799507
Epoch: 24 Idx: 5000 Loss: 0.01872243734439694
Epoch: 25 Idx: 0 Loss: 0.007012080426353437
Epoch: 25 Idx: 5000 Loss: 0.01638248574701049
Epoch: 26 Idx: 0 Loss: 0.008653610528188081
Epoch: 26 Idx: 5000 Loss: 0.015784697726634024
Epoch: 27 Idx: 0 Loss: 0.003971255769256622
Epoch: 27 Idx: 5000 Loss: 0.019967986666474802
Epoch: 28 Idx: 0 Loss: 0.007484202344786023
Epoch: 28 Idx: 5000 Loss: 0.02386212873903569
Epoch: 29 Idx: 0 Loss: 0.007038967289208127
Epoch: 29 Idx: 5000 Loss: 0.009019826766915037
Epoch: 30 Idx: 0 Loss: 0.012452906662822841
Epoch: 30 Idx: 5000 Loss: 0.007471185625165447
Epoch: 31 Idx: 0 Loss: 0.022412482229114197
Epoch: 31 Idx: 5000 Loss: 0.009186275198506648
Epoch: 32 Idx: 0 Loss: 0.04628119806780974
Epoch: 32 Idx: 5000 Loss: 0.010851812365438066
Epoch: 33 Idx: 0 Loss: 0.005014527867473065
Epoch: 33 Idx: 5000 Loss: 0.023010452431442896
Epoch: 34 Idx: 0 Loss: 0.007294671576101572
Epoch: 34 Idx: 5000 Loss: 0.027765839467460845
Epoch: 35 Idx: 0 Loss: 0.008992066116726496
Epoch: 35 Idx: 5000 Loss: 0.014445138589135776
Epoch: 36 Idx: 0 Loss: 0.0069867164903376165
Epoch: 36 Idx: 5000 Loss: 0.01677511682805625
Epoch: 37 Idx: 0 Loss: 0.04288865376181727
Epoch: 37 Idx: 5000 Loss: 0.00907405804049238
Epoch: 38 Idx: 0 Loss: 0.008975506169651593
Epoch: 38 Idx: 5000 Loss: 0.04150909111187213
Epoch: 39 Idx: 0 Loss: 0.012892155425371903
Epoch: 39 Idx: 5000 Loss: 0.010183343869643657
Epoch: 40 Idx: 0 Loss: 0.016931099801560563
Epoch: 40 Idx: 5000 Loss: 0.006278226568304407
Epoch: 41 Idx: 0 Loss: 0.03004625871201458
Epoch: 41 Idx: 5000 Loss: 0.013884114105747481
Epoch: 42 Idx: 0 Loss: 0.01218816807239316
Epoch: 42 Idx: 5000 Loss: 0.005367015448732694
Epoch: 43 Idx: 0 Loss: 0.023185258947055636
Epoch: 43 Idx: 5000 Loss: 0.01826158659025449
Epoch: 44 Idx: 0 Loss: 0.011757856819435641
Epoch: 44 Idx: 5000 Loss: 0.03068432462337413
Epoch: 45 Idx: 0 Loss: 0.017753801144016756
Epoch: 45 Idx: 5000 Loss: 0.02111814683190056
Epoch: 46 Idx: 0 Loss: 0.02168952199665082
Epoch: 46 Idx: 5000 Loss: 0.015251142661771015
Epoch: 47 Idx: 0 Loss: 0.04015675821886046
Epoch: 47 Idx: 5000 Loss: 0.013853241386689715
Epoch: 48 Idx: 0 Loss: 0.025385197611221325
Epoch: 48 Idx: 5000 Loss: 0.019697521513205824
Epoch: 49 Idx: 0 Loss: 0.008710522502420676
Epoch: 49 Idx: 5000 Loss: 0.023328450367873975
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.22029557026444327
Epoch: 0 Idx: 5000 Loss: 0.010752879989412482
Epoch: 1 Idx: 0 Loss: 0.023404959945276763
Epoch: 1 Idx: 5000 Loss: 0.03268699266469338
Epoch: 2 Idx: 0 Loss: 0.0229255575394171
Epoch: 2 Idx: 5000 Loss: 0.007038666214638903
Epoch: 3 Idx: 0 Loss: 0.006785634637498065
Epoch: 3 Idx: 5000 Loss: 0.016968315830857665
Epoch: 4 Idx: 0 Loss: 0.012055460408552317
Epoch: 4 Idx: 5000 Loss: 0.004964732967018024
Epoch: 5 Idx: 0 Loss: 0.013363780845979759
Epoch: 5 Idx: 5000 Loss: 0.01001418081626259
Epoch: 6 Idx: 0 Loss: 0.0058201018836911665
Epoch: 6 Idx: 5000 Loss: 0.01564484145079845
Epoch: 7 Idx: 0 Loss: 0.019990109711308917
Epoch: 7 Idx: 5000 Loss: 0.011437988571317946
Epoch: 8 Idx: 0 Loss: 0.013469612125761553
Epoch: 8 Idx: 5000 Loss: 0.011792567242071077
Epoch: 9 Idx: 0 Loss: 0.011233438761435045
Epoch: 9 Idx: 5000 Loss: 0.018443938198585492
Epoch: 10 Idx: 0 Loss: 0.020251715417630413
Epoch: 10 Idx: 5000 Loss: 0.00709915204901374
Epoch: 11 Idx: 0 Loss: 0.015046860409280147
Epoch: 11 Idx: 5000 Loss: 0.0238224132069675
Epoch: 12 Idx: 0 Loss: 0.04492206501179419
Epoch: 12 Idx: 5000 Loss: 0.012897654843797155
Epoch: 13 Idx: 0 Loss: 0.008187621337158259
Epoch: 13 Idx: 5000 Loss: 0.01538578457139182
Epoch: 14 Idx: 0 Loss: 0.016632487250846168
Epoch: 14 Idx: 5000 Loss: 0.01585536445707551
Epoch: 15 Idx: 0 Loss: 0.01819190986742097
Epoch: 15 Idx: 5000 Loss: 0.010768908863012336
Epoch: 16 Idx: 0 Loss: 0.015691527934923406
Epoch: 16 Idx: 5000 Loss: 0.009034238491331545
Epoch: 17 Idx: 0 Loss: 0.010854005248482346
Epoch: 17 Idx: 5000 Loss: 0.006234062055385993
Epoch: 18 Idx: 0 Loss: 0.013834482750613773
Epoch: 18 Idx: 5000 Loss: 0.01173008054826788
Epoch: 19 Idx: 0 Loss: 0.03439330085983745
Epoch: 19 Idx: 5000 Loss: 0.0074716628401579254
Epoch: 20 Idx: 0 Loss: 0.028494068730697313
Epoch: 20 Idx: 5000 Loss: 0.014589096221165396
Epoch: 21 Idx: 0 Loss: 0.023987396177783848
Epoch: 21 Idx: 5000 Loss: 0.011364772171089072
Epoch: 22 Idx: 0 Loss: 0.0074851564943422795
Epoch: 22 Idx: 5000 Loss: 0.027160525484636534
Epoch: 23 Idx: 0 Loss: 0.01179150120912442
Epoch: 23 Idx: 5000 Loss: 0.007608369288802753
Epoch: 24 Idx: 0 Loss: 0.022357111779345663
Epoch: 24 Idx: 5000 Loss: 0.00951067979057535
Epoch: 25 Idx: 0 Loss: 0.014544757183554989
Epoch: 25 Idx: 5000 Loss: 0.007721974201292024
Epoch: 26 Idx: 0 Loss: 0.009810638691586842
Epoch: 26 Idx: 5000 Loss: 0.01343243849035198
Epoch: 27 Idx: 0 Loss: 0.012154163811912415
Epoch: 27 Idx: 5000 Loss: 0.011870165904986013
Epoch: 28 Idx: 0 Loss: 0.011856492212965954
Epoch: 28 Idx: 5000 Loss: 0.013787663476512108
Epoch: 29 Idx: 0 Loss: 0.010819804901372866
Epoch: 29 Idx: 5000 Loss: 0.010949313472357204
Epoch: 30 Idx: 0 Loss: 0.009232637759773952
Epoch: 30 Idx: 5000 Loss: 0.012115781357208654
Epoch: 31 Idx: 0 Loss: 0.01280403336515818
Epoch: 31 Idx: 5000 Loss: 0.018339190525939512
Epoch: 32 Idx: 0 Loss: 0.010118057677885333
Epoch: 32 Idx: 5000 Loss: 0.021808776048931746
Epoch: 33 Idx: 0 Loss: 0.016297030272140273
Epoch: 33 Idx: 5000 Loss: 0.027497116109087952
Epoch: 34 Idx: 0 Loss: 0.016641263414217226
Epoch: 34 Idx: 5000 Loss: 0.015377001964091063
Epoch: 35 Idx: 0 Loss: 0.00896405975319777
Epoch: 35 Idx: 5000 Loss: 0.0092711679194528
Epoch: 36 Idx: 0 Loss: 0.011542123631654149
Epoch: 36 Idx: 5000 Loss: 0.017191756634758085
Epoch: 37 Idx: 0 Loss: 0.005781900536025299
Epoch: 37 Idx: 5000 Loss: 0.011783217056792002
Epoch: 38 Idx: 0 Loss: 0.009244992971268509
Epoch: 38 Idx: 5000 Loss: 0.017707143561575753
Epoch: 39 Idx: 0 Loss: 0.008314208819194556
Epoch: 39 Idx: 5000 Loss: 0.0081628870043782
Epoch: 40 Idx: 0 Loss: 0.010773240966414367
Epoch: 40 Idx: 5000 Loss: 0.017785931056690282
Epoch: 41 Idx: 0 Loss: 0.01831118866015764
Epoch: 41 Idx: 5000 Loss: 0.038014383949360374
Epoch: 42 Idx: 0 Loss: 0.021041006061756927
Epoch: 42 Idx: 5000 Loss: 0.006315535632153424
Epoch: 43 Idx: 0 Loss: 0.012094202303901288
Epoch: 43 Idx: 5000 Loss: 0.03264811299955189
Epoch: 44 Idx: 0 Loss: 0.007736775538403169
Epoch: 44 Idx: 5000 Loss: 0.014225372189512635
Epoch: 45 Idx: 0 Loss: 0.014147298590934922
Epoch: 45 Idx: 5000 Loss: 0.011701990359122522
Epoch: 46 Idx: 0 Loss: 0.01802128860134357
Epoch: 46 Idx: 5000 Loss: 0.021589876717484767
Epoch: 47 Idx: 0 Loss: 0.005635714097433419
Epoch: 47 Idx: 5000 Loss: 0.014463735673207098
Epoch: 48 Idx: 0 Loss: 0.02483898825845668
Epoch: 48 Idx: 5000 Loss: 0.011451112403924069
Epoch: 49 Idx: 0 Loss: 0.008571412076741319
Epoch: 49 Idx: 5000 Loss: 0.044596116217994426
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.17313128781063436
Epoch: 0 Idx: 5000 Loss: 0.015478084186350285
Epoch: 1 Idx: 0 Loss: 0.03360441392637053
Epoch: 1 Idx: 5000 Loss: 0.020332182896721687
Epoch: 2 Idx: 0 Loss: 0.012890692678470877
Epoch: 2 Idx: 5000 Loss: 0.02024248382874788
Epoch: 3 Idx: 0 Loss: 0.032994795287569684
Epoch: 3 Idx: 5000 Loss: 0.0158498855279505
Epoch: 4 Idx: 0 Loss: 0.024980706846005264
Epoch: 4 Idx: 5000 Loss: 0.018280125063822608
Epoch: 5 Idx: 0 Loss: 0.013013803519635062
Epoch: 5 Idx: 5000 Loss: 0.03624549177985531
Epoch: 6 Idx: 0 Loss: 0.01063101019533597
Epoch: 6 Idx: 5000 Loss: 0.036609553344125925
Epoch: 7 Idx: 0 Loss: 0.028135372755616818
Epoch: 7 Idx: 5000 Loss: 0.015311289922432171
Epoch: 8 Idx: 0 Loss: 0.011664281628985432
Epoch: 8 Idx: 5000 Loss: 0.01427371230098349
Epoch: 9 Idx: 0 Loss: 0.009815863886033737
Epoch: 9 Idx: 5000 Loss: 0.016287893127913955
Epoch: 10 Idx: 0 Loss: 0.020616049462548545
Epoch: 10 Idx: 5000 Loss: 0.013254665039482867
Epoch: 11 Idx: 0 Loss: 0.024780310799359495
Epoch: 11 Idx: 5000 Loss: 0.03815377336151525
Epoch: 12 Idx: 0 Loss: 0.020745115488421752
Epoch: 12 Idx: 5000 Loss: 0.012796217110976747
Epoch: 13 Idx: 0 Loss: 0.014122795556773173
Epoch: 13 Idx: 5000 Loss: 0.01424966473745596
Epoch: 14 Idx: 0 Loss: 0.030997553673292853
Epoch: 14 Idx: 5000 Loss: 0.014195259910570362
Epoch: 15 Idx: 0 Loss: 0.01225719662374107
Epoch: 15 Idx: 5000 Loss: 0.007642029335078511
Epoch: 16 Idx: 0 Loss: 0.01669612623790575
Epoch: 16 Idx: 5000 Loss: 0.017965242500670737
Epoch: 17 Idx: 0 Loss: 0.00453266374548848
Epoch: 17 Idx: 5000 Loss: 0.011045592115175229
Epoch: 18 Idx: 0 Loss: 0.018438585734474846
Epoch: 18 Idx: 5000 Loss: 0.016458055603228553
Epoch: 19 Idx: 0 Loss: 0.008336421379669346
Epoch: 19 Idx: 5000 Loss: 0.03471262236672003
Epoch: 20 Idx: 0 Loss: 0.024517133640655612
Epoch: 20 Idx: 5000 Loss: 0.010629399539000805
Epoch: 21 Idx: 0 Loss: 0.019394845434246705
Epoch: 21 Idx: 5000 Loss: 0.028376140718535045
Epoch: 22 Idx: 0 Loss: 0.01606996342052728
Epoch: 22 Idx: 5000 Loss: 0.012885279212965629
Epoch: 23 Idx: 0 Loss: 0.0184158596937008
Epoch: 23 Idx: 5000 Loss: 0.007675802546322035
Epoch: 24 Idx: 0 Loss: 0.008976689736766326
Epoch: 24 Idx: 5000 Loss: 0.01674793192414424
Epoch: 25 Idx: 0 Loss: 0.008062402719728416
Epoch: 25 Idx: 5000 Loss: 0.01691350834234515
Epoch: 26 Idx: 0 Loss: 0.017417094740844144
Epoch: 26 Idx: 5000 Loss: 0.01980456298258939
Epoch: 27 Idx: 0 Loss: 0.020786331564125245
Epoch: 27 Idx: 5000 Loss: 0.009691670900394304
Epoch: 28 Idx: 0 Loss: 0.023051067406664866
Epoch: 28 Idx: 5000 Loss: 0.005055255472455565
Epoch: 29 Idx: 0 Loss: 0.027191065242867168
Epoch: 29 Idx: 5000 Loss: 0.013844667583500732
Epoch: 30 Idx: 0 Loss: 0.014756034738779532
Epoch: 30 Idx: 5000 Loss: 0.009918081031966914
Epoch: 31 Idx: 0 Loss: 0.011518904635618736
Epoch: 31 Idx: 5000 Loss: 0.017540469115846495
Epoch: 32 Idx: 0 Loss: 0.007556790733737013
Epoch: 32 Idx: 5000 Loss: 0.020693671504670275
Epoch: 33 Idx: 0 Loss: 0.007709918091104068
Epoch: 33 Idx: 5000 Loss: 0.041342288880223774
Epoch: 34 Idx: 0 Loss: 0.009472649275787757
Epoch: 34 Idx: 5000 Loss: 0.007370418660643025
Epoch: 35 Idx: 0 Loss: 0.00783125669595311
Epoch: 35 Idx: 5000 Loss: 0.015130829404032065
Epoch: 36 Idx: 0 Loss: 0.012277109787971849
Epoch: 36 Idx: 5000 Loss: 0.014660509904055626
Epoch: 37 Idx: 0 Loss: 0.008310439407648293
Epoch: 37 Idx: 5000 Loss: 0.007868774901239075
Epoch: 38 Idx: 0 Loss: 0.008182643007182275
Epoch: 38 Idx: 5000 Loss: 0.013365180067903631
Epoch: 39 Idx: 0 Loss: 0.006078474101780615
Epoch: 39 Idx: 5000 Loss: 0.01205040930865734
Epoch: 40 Idx: 0 Loss: 0.004823080772059143
Epoch: 40 Idx: 5000 Loss: 0.01794873116519741
Epoch: 41 Idx: 0 Loss: 0.01043605532225059
Epoch: 41 Idx: 5000 Loss: 0.030329715404838857
Epoch: 42 Idx: 0 Loss: 0.02420034719975492
Epoch: 42 Idx: 5000 Loss: 0.021153097286236277
Epoch: 43 Idx: 0 Loss: 0.011887198064856394
Epoch: 43 Idx: 5000 Loss: 0.016569795851551897
Epoch: 44 Idx: 0 Loss: 0.004555648689771619
Epoch: 44 Idx: 5000 Loss: 0.01653187844026536
Epoch: 45 Idx: 0 Loss: 0.01846668721047279
Epoch: 45 Idx: 5000 Loss: 0.015295880600991168
Epoch: 46 Idx: 0 Loss: 0.018156771479085076
Epoch: 46 Idx: 5000 Loss: 0.008648631768049413
Epoch: 47 Idx: 0 Loss: 0.013955796746213134
Epoch: 47 Idx: 5000 Loss: 0.015967903357144313
Epoch: 48 Idx: 0 Loss: 0.025838430094060588
Epoch: 48 Idx: 5000 Loss: 0.020592132129038154
Epoch: 49 Idx: 0 Loss: 0.035270427707716843
Epoch: 49 Idx: 5000 Loss: 0.016867765791272554
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.18471377912530093
Epoch: 0 Idx: 5000 Loss: 0.012876501109455013
Epoch: 1 Idx: 0 Loss: 0.018445070356936343
Epoch: 1 Idx: 5000 Loss: 0.007782324068656139
Epoch: 2 Idx: 0 Loss: 0.015398684775740135
Epoch: 2 Idx: 5000 Loss: 0.013216960788744452
Epoch: 3 Idx: 0 Loss: 0.012068438184110934
Epoch: 3 Idx: 5000 Loss: 0.008944128270271036
Epoch: 4 Idx: 0 Loss: 0.012717619724680962
Epoch: 4 Idx: 5000 Loss: 0.014183298615220705
Epoch: 5 Idx: 0 Loss: 0.009390833339757012
Epoch: 5 Idx: 5000 Loss: 0.00638565993473688
Epoch: 6 Idx: 0 Loss: 0.013659184692929248
Epoch: 6 Idx: 5000 Loss: 0.009530157706089446
Epoch: 7 Idx: 0 Loss: 0.02603336456976827
Epoch: 7 Idx: 5000 Loss: 0.017175631731289276
Epoch: 8 Idx: 0 Loss: 0.011394282445897528
Epoch: 8 Idx: 5000 Loss: 0.010172467075075336
Epoch: 9 Idx: 0 Loss: 0.014243399601083569
Epoch: 9 Idx: 5000 Loss: 0.017220446042922312
Epoch: 10 Idx: 0 Loss: 0.02018339290594523
Epoch: 10 Idx: 5000 Loss: 0.023042023818748005
Epoch: 11 Idx: 0 Loss: 0.007700995964271158
Epoch: 11 Idx: 5000 Loss: 0.01168568589897922
Epoch: 12 Idx: 0 Loss: 0.010513169243865066
Epoch: 12 Idx: 5000 Loss: 0.011270313787579108
Epoch: 13 Idx: 0 Loss: 0.007441131771932926
Epoch: 13 Idx: 5000 Loss: 0.011990846962085988
Epoch: 14 Idx: 0 Loss: 0.0033022248906486216
Epoch: 14 Idx: 5000 Loss: 0.010537176257779987
Epoch: 15 Idx: 0 Loss: 0.020056872061767407
Epoch: 15 Idx: 5000 Loss: 0.024313061364526285
Epoch: 16 Idx: 0 Loss: 0.021738903850537044
Epoch: 16 Idx: 5000 Loss: 0.014378220647458233
Epoch: 17 Idx: 0 Loss: 0.015433394767396108
Epoch: 17 Idx: 5000 Loss: 0.007359144266621092
Epoch: 18 Idx: 0 Loss: 0.02336304377289549
Epoch: 18 Idx: 5000 Loss: 0.02617676666710439
Epoch: 19 Idx: 0 Loss: 0.01808160323021345
Epoch: 19 Idx: 5000 Loss: 0.03957515725646151
Epoch: 20 Idx: 0 Loss: 0.0097372568317215
Epoch: 20 Idx: 5000 Loss: 0.028342209235476458
Epoch: 21 Idx: 0 Loss: 0.029691126195136672
Epoch: 21 Idx: 5000 Loss: 0.006800350790495593
Epoch: 22 Idx: 0 Loss: 0.016675758339426687
Epoch: 22 Idx: 5000 Loss: 0.016843311053021247
Epoch: 23 Idx: 0 Loss: 0.029817090472952182
Epoch: 23 Idx: 5000 Loss: 0.01279558251444401
Epoch: 24 Idx: 0 Loss: 0.008057191399539167
Epoch: 24 Idx: 5000 Loss: 0.01463437730219224
Epoch: 25 Idx: 0 Loss: 0.010161806031763001
Epoch: 25 Idx: 5000 Loss: 0.011045152452415885
Epoch: 26 Idx: 0 Loss: 0.005576977372189741
Epoch: 26 Idx: 5000 Loss: 0.038951513921085014
Epoch: 27 Idx: 0 Loss: 0.021103535379151675
Epoch: 27 Idx: 5000 Loss: 0.009438346953271008
Epoch: 28 Idx: 0 Loss: 0.0269226399833082
Epoch: 28 Idx: 5000 Loss: 0.025031690546628505
Epoch: 29 Idx: 0 Loss: 0.00942301304688322
Epoch: 29 Idx: 5000 Loss: 0.0064891284232542305
Epoch: 30 Idx: 0 Loss: 0.01870127155613982
Epoch: 30 Idx: 5000 Loss: 0.015105738711911895
Epoch: 31 Idx: 0 Loss: 0.011867161109911876
Epoch: 31 Idx: 5000 Loss: 0.018944074608518414
Epoch: 32 Idx: 0 Loss: 0.004589129540138143
Epoch: 32 Idx: 5000 Loss: 0.008375446880019788
Epoch: 33 Idx: 0 Loss: 0.006458360644553496
Epoch: 33 Idx: 5000 Loss: 0.013205806285798613
Epoch: 34 Idx: 0 Loss: 0.028098267330276566
Epoch: 34 Idx: 5000 Loss: 0.011818487179671704
Epoch: 35 Idx: 0 Loss: 0.0213327238289358
Epoch: 35 Idx: 5000 Loss: 0.009063291897794111
Epoch: 36 Idx: 0 Loss: 0.022135774397132525
Epoch: 36 Idx: 5000 Loss: 0.013962457974960114
Epoch: 37 Idx: 0 Loss: 0.011249664487807058
Epoch: 37 Idx: 5000 Loss: 0.012291947087930017
Epoch: 38 Idx: 0 Loss: 0.020359586381076367
Epoch: 38 Idx: 5000 Loss: 0.004513312708177531
Epoch: 39 Idx: 0 Loss: 0.011212403232458095
Epoch: 39 Idx: 5000 Loss: 0.009001311828655793
Epoch: 40 Idx: 0 Loss: 0.0095294609610781
Epoch: 40 Idx: 5000 Loss: 0.024051469488473545
Epoch: 41 Idx: 0 Loss: 0.015261543835311815
Epoch: 41 Idx: 5000 Loss: 0.005711835449931595
Epoch: 42 Idx: 0 Loss: 0.017460027402167788
Epoch: 42 Idx: 5000 Loss: 0.01845886148684516
Epoch: 43 Idx: 0 Loss: 0.01979637584777292
Epoch: 43 Idx: 5000 Loss: 0.03367395715482175
Epoch: 44 Idx: 0 Loss: 0.009283491266701938
Epoch: 44 Idx: 5000 Loss: 0.029129781187505956
Epoch: 45 Idx: 0 Loss: 0.007763931430076299
Epoch: 45 Idx: 5000 Loss: 0.013090768027988794
Epoch: 46 Idx: 0 Loss: 0.014213293471893844
Epoch: 46 Idx: 5000 Loss: 0.014317703526248534
Epoch: 47 Idx: 0 Loss: 0.01014792822145849
Epoch: 47 Idx: 5000 Loss: 0.009733391412382494
Epoch: 48 Idx: 0 Loss: 0.013043168504711416
Epoch: 48 Idx: 5000 Loss: 0.025635283648546114
Epoch: 49 Idx: 0 Loss: 0.013726576325428695
Epoch: 49 Idx: 5000 Loss: 0.0165430675052147
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.21509538992187505
Epoch: 1 Idx: 0 Loss: 0.012893245507414252
Epoch: 2 Idx: 0 Loss: 0.013651069511202742
Epoch: 3 Idx: 0 Loss: 0.005675575033060615
Epoch: 4 Idx: 0 Loss: 0.007254786637672518
Epoch: 5 Idx: 0 Loss: 0.021586891275987764
Epoch: 6 Idx: 0 Loss: 0.008935296296133013
Epoch: 7 Idx: 0 Loss: 0.01522756514857491
Epoch: 8 Idx: 0 Loss: 0.014769120005325511
Epoch: 9 Idx: 0 Loss: 0.01582549282632001
Epoch: 10 Idx: 0 Loss: 0.008988112982889483
Epoch: 11 Idx: 0 Loss: 0.02000743462085688
Epoch: 12 Idx: 0 Loss: 0.04731741743553392
Epoch: 13 Idx: 0 Loss: 0.01275769274403521
Epoch: 14 Idx: 0 Loss: 0.025572534235744394
Epoch: 15 Idx: 0 Loss: 0.01608595566151135
Epoch: 16 Idx: 0 Loss: 0.007191383252995171
Epoch: 17 Idx: 0 Loss: 0.016626224885098996
Epoch: 18 Idx: 0 Loss: 0.01380223158660518
Epoch: 19 Idx: 0 Loss: 0.0051414803184354355
Epoch: 20 Idx: 0 Loss: 0.007475386574889662
Epoch: 21 Idx: 0 Loss: 0.01821119085624727
Epoch: 22 Idx: 0 Loss: 0.010838094815156532
Epoch: 23 Idx: 0 Loss: 0.013318920598393897
Epoch: 24 Idx: 0 Loss: 0.019862610050090008
Epoch: 25 Idx: 0 Loss: 0.02912953867443435
Epoch: 26 Idx: 0 Loss: 0.013868138307639513
Epoch: 27 Idx: 0 Loss: 0.015784352498160452
Epoch: 28 Idx: 0 Loss: 0.01823366757787708
Epoch: 29 Idx: 0 Loss: 0.01827323415855619
Epoch: 30 Idx: 0 Loss: 0.0057517392176746705
Epoch: 31 Idx: 0 Loss: 0.006676687181296546
Epoch: 32 Idx: 0 Loss: 0.013029449610241611
Epoch: 33 Idx: 0 Loss: 0.00520859863378004
Epoch: 34 Idx: 0 Loss: 0.018578460772247344
Epoch: 35 Idx: 0 Loss: 0.008965581494809386
Epoch: 36 Idx: 0 Loss: 0.017939599749766534
Epoch: 37 Idx: 0 Loss: 0.02320473183826889
Epoch: 38 Idx: 0 Loss: 0.005876584269843992
Epoch: 39 Idx: 0 Loss: 0.013504978241994071
Epoch: 40 Idx: 0 Loss: 0.03210034995889965
Epoch: 41 Idx: 0 Loss: 0.01852493651255488
Epoch: 42 Idx: 0 Loss: 0.007718136760993456
Epoch: 43 Idx: 0 Loss: 0.00828799897558525
Epoch: 44 Idx: 0 Loss: 0.0149814102485908
Epoch: 45 Idx: 0 Loss: 0.02948195982640616
Epoch: 46 Idx: 0 Loss: 0.027433554544982423
Epoch: 47 Idx: 0 Loss: 0.0158122343735454
Epoch: 48 Idx: 0 Loss: 0.006425711045143862
Epoch: 49 Idx: 0 Loss: 0.0074249406185213146
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.14336791526781287
Epoch: 0 Idx: 5000 Loss: 0.02091273782837979
Epoch: 1 Idx: 0 Loss: 0.017638302079245754
Epoch: 1 Idx: 5000 Loss: 0.022488894697772918
Epoch: 2 Idx: 0 Loss: 0.01661438866549383
Epoch: 2 Idx: 5000 Loss: 0.014505962392413864
Epoch: 3 Idx: 0 Loss: 0.018531387935178584
Epoch: 3 Idx: 5000 Loss: 0.013863339798937729
Epoch: 4 Idx: 0 Loss: 0.016291686920519573
Epoch: 4 Idx: 5000 Loss: 0.022597981374062263
Epoch: 5 Idx: 0 Loss: 0.012662482295514747
Epoch: 5 Idx: 5000 Loss: 0.010835648175513937
Epoch: 6 Idx: 0 Loss: 0.010449922371250845
Epoch: 6 Idx: 5000 Loss: 0.01667159988858559
Epoch: 7 Idx: 0 Loss: 0.012744763699187684
Epoch: 7 Idx: 5000 Loss: 0.018679215771883202
Epoch: 8 Idx: 0 Loss: 0.009936773327872172
Epoch: 8 Idx: 5000 Loss: 0.02738003864969986
Epoch: 9 Idx: 0 Loss: 0.01010355539584798
Epoch: 9 Idx: 5000 Loss: 0.013978378875327511
Epoch: 10 Idx: 0 Loss: 0.006329549446772054
Epoch: 10 Idx: 5000 Loss: 0.014497730349516789
Epoch: 11 Idx: 0 Loss: 0.019638128779762204
Epoch: 11 Idx: 5000 Loss: 0.013331650942891998
Epoch: 12 Idx: 0 Loss: 0.009930129033598053
Epoch: 12 Idx: 5000 Loss: 0.02897462260444281
Epoch: 13 Idx: 0 Loss: 0.02189472588203706
Epoch: 13 Idx: 5000 Loss: 0.008696401956130334
Epoch: 14 Idx: 0 Loss: 0.007914168327694378
Epoch: 14 Idx: 5000 Loss: 0.017833460122756994
Epoch: 15 Idx: 0 Loss: 0.016945781217526823
Epoch: 15 Idx: 5000 Loss: 0.028952496789556536
Epoch: 16 Idx: 0 Loss: 0.008350028994364312
Epoch: 16 Idx: 5000 Loss: 0.018616892164598928
Epoch: 17 Idx: 0 Loss: 0.016752226190959302
Epoch: 17 Idx: 5000 Loss: 0.02308474444538744
Epoch: 18 Idx: 0 Loss: 0.005925406484936531
Epoch: 18 Idx: 5000 Loss: 0.021076565986500286
Epoch: 19 Idx: 0 Loss: 0.02018349427246269
Epoch: 19 Idx: 5000 Loss: 0.01397512611293494
Epoch: 20 Idx: 0 Loss: 0.010570811223674391
Epoch: 20 Idx: 5000 Loss: 0.010908282917003536
Epoch: 21 Idx: 0 Loss: 0.010083811570860754
Epoch: 21 Idx: 5000 Loss: 0.013817476893119325
Epoch: 22 Idx: 0 Loss: 0.007974594891672817
Epoch: 22 Idx: 5000 Loss: 0.01585661743150532
Epoch: 23 Idx: 0 Loss: 0.0064855336551055826
Epoch: 23 Idx: 5000 Loss: 0.02763105996742797
Epoch: 24 Idx: 0 Loss: 0.014134114933971641
Epoch: 24 Idx: 5000 Loss: 0.010291294727045333
Epoch: 25 Idx: 0 Loss: 0.00970887776229799
Epoch: 25 Idx: 5000 Loss: 0.011908433178224147
Epoch: 26 Idx: 0 Loss: 0.011268131845293674
Epoch: 26 Idx: 5000 Loss: 0.019693819219534416
Epoch: 27 Idx: 0 Loss: 0.01273222693337893
Epoch: 27 Idx: 5000 Loss: 0.01880660021703408
Epoch: 28 Idx: 0 Loss: 0.024502751143318395
Epoch: 28 Idx: 5000 Loss: 0.01302388152837635
Epoch: 29 Idx: 0 Loss: 0.012656432852679258
Epoch: 29 Idx: 5000 Loss: 0.020583698809908516
Epoch: 30 Idx: 0 Loss: 0.0402828250891709
Epoch: 30 Idx: 5000 Loss: 0.015525097334285578
Epoch: 31 Idx: 0 Loss: 0.01061760137706718
Epoch: 31 Idx: 5000 Loss: 0.01637770433350693
Epoch: 32 Idx: 0 Loss: 0.01597256225529525
Epoch: 32 Idx: 5000 Loss: 0.0073523967821467065
Epoch: 33 Idx: 0 Loss: 0.015607398084977731
Epoch: 33 Idx: 5000 Loss: 0.015168570197548815
Epoch: 34 Idx: 0 Loss: 0.027757562300367394
Epoch: 34 Idx: 5000 Loss: 0.018434597673790402
Epoch: 35 Idx: 0 Loss: 0.003009210707332284
Epoch: 35 Idx: 5000 Loss: 0.01409368344533609
Epoch: 36 Idx: 0 Loss: 0.013078867561501624
Epoch: 36 Idx: 5000 Loss: 0.028102261669185648
Epoch: 37 Idx: 0 Loss: 0.004796048687039571
Epoch: 37 Idx: 5000 Loss: 0.04476406994477902
Epoch: 38 Idx: 0 Loss: 0.01587656053907268
Epoch: 38 Idx: 5000 Loss: 0.014849050477331968
Epoch: 39 Idx: 0 Loss: 0.022775252121045832
Epoch: 39 Idx: 5000 Loss: 0.022340216632551237
Epoch: 40 Idx: 0 Loss: 0.02613240019068852
Epoch: 40 Idx: 5000 Loss: 0.010284606600826762
Epoch: 41 Idx: 0 Loss: 0.01354248729764727
Epoch: 41 Idx: 5000 Loss: 0.016188854638473884
Epoch: 42 Idx: 0 Loss: 0.013983199530148972
Epoch: 42 Idx: 5000 Loss: 0.014901846881331556
Epoch: 43 Idx: 0 Loss: 0.019557020467970893
Epoch: 43 Idx: 5000 Loss: 0.01044810633007645
Epoch: 44 Idx: 0 Loss: 0.010685689352949144
Epoch: 44 Idx: 5000 Loss: 0.015335912701895195
Epoch: 45 Idx: 0 Loss: 0.007236596574500809
Epoch: 45 Idx: 5000 Loss: 0.014016405742922709
Epoch: 46 Idx: 0 Loss: 0.01370553379797337
Epoch: 46 Idx: 5000 Loss: 0.02314384478303417
Epoch: 47 Idx: 0 Loss: 0.020346449764282896
Epoch: 47 Idx: 5000 Loss: 0.009729270196442869
Epoch: 48 Idx: 0 Loss: 0.024436113571191048
Epoch: 48 Idx: 5000 Loss: 0.011606619304677403
Epoch: 49 Idx: 0 Loss: 0.012712837360853258
Epoch: 49 Idx: 5000 Loss: 0.011542476588396383
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.17700466882613358
Epoch: 1 Idx: 0 Loss: 0.021775125120528135
Epoch: 2 Idx: 0 Loss: 0.011846861549776494
Epoch: 3 Idx: 0 Loss: 0.010942353451641332
Epoch: 4 Idx: 0 Loss: 0.023097793569770084
Epoch: 5 Idx: 0 Loss: 0.031216082728175228
Epoch: 6 Idx: 0 Loss: 0.013796575869552899
Epoch: 7 Idx: 0 Loss: 0.004589806300879127
Epoch: 8 Idx: 0 Loss: 0.01802287384681675
Epoch: 9 Idx: 0 Loss: 0.020709274036606277
Epoch: 10 Idx: 0 Loss: 0.012625345955576857
Epoch: 11 Idx: 0 Loss: 0.013460814692285116
Epoch: 12 Idx: 0 Loss: 0.014775958392323362
Epoch: 13 Idx: 0 Loss: 0.025832555271864833
Epoch: 14 Idx: 0 Loss: 0.00636200250636226
Epoch: 15 Idx: 0 Loss: 0.020979282477506474
Epoch: 16 Idx: 0 Loss: 0.02560361450143657
Epoch: 17 Idx: 0 Loss: 0.011072445929342721
Epoch: 18 Idx: 0 Loss: 0.010663228044271798
Epoch: 19 Idx: 0 Loss: 0.007770385197295655
Epoch: 20 Idx: 0 Loss: 0.014010578031990354
Epoch: 21 Idx: 0 Loss: 0.009070237313933683
Epoch: 22 Idx: 0 Loss: 0.011953169720324439
Epoch: 23 Idx: 0 Loss: 0.010492316948813035
Epoch: 24 Idx: 0 Loss: 0.03645955569249431
Epoch: 25 Idx: 0 Loss: 0.024358902794187932
Epoch: 26 Idx: 0 Loss: 0.01988368357384923
Epoch: 27 Idx: 0 Loss: 0.0070120136614263496
Epoch: 28 Idx: 0 Loss: 0.012220206504834996
Epoch: 29 Idx: 0 Loss: 0.027670149152978947
Epoch: 30 Idx: 0 Loss: 0.0067852208837809996
Epoch: 31 Idx: 0 Loss: 0.010221367829191558
Epoch: 32 Idx: 0 Loss: 0.011750187609457993
Epoch: 33 Idx: 0 Loss: 0.009541133399267404
Epoch: 34 Idx: 0 Loss: 0.018220894091374396
Epoch: 35 Idx: 0 Loss: 0.012696407397376144
Epoch: 36 Idx: 0 Loss: 0.011918488078339444
Epoch: 37 Idx: 0 Loss: 0.025610803860104413
Epoch: 38 Idx: 0 Loss: 0.014158114045617152
Epoch: 39 Idx: 0 Loss: 0.03384848087975597
Epoch: 40 Idx: 0 Loss: 0.015141783743809306
Epoch: 41 Idx: 0 Loss: 0.020532653758656504
Epoch: 42 Idx: 0 Loss: 0.01830051612727483
Epoch: 43 Idx: 0 Loss: 0.024792952655143065
Epoch: 44 Idx: 0 Loss: 0.011791098104827744
Epoch: 45 Idx: 0 Loss: 0.008188735514518685
Epoch: 46 Idx: 0 Loss: 0.024993995914419073
Epoch: 47 Idx: 0 Loss: 0.02317968223611864
Epoch: 48 Idx: 0 Loss: 0.0088539880141034
Epoch: 49 Idx: 0 Loss: 0.006883647640663605
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.6470588235294118, 0.7333333333333333, 0.6875, 0.7142857142857143, 0.6626506024096386)
Performance for  [('ekaw', 'sigkdd')] is : (0.7333333333333333, 1.0, 0.846153846153846, 0.9322033898305084, 0.7746478873239436)
Performance for  [('conference', 'edas')] is : (0.6956521739130435, 0.9411764705882353, 0.7999999999999999, 0.8791208791208791, 0.7339449541284403)
Performance for  [('cmt', 'ekaw')] is : (0.46153846153846156, 0.5454545454545454, 0.4999999999999999, 0.5263157894736842, 0.4761904761904762)
Performance for  [('confOf', 'edas')] is : (0.52, 0.6842105263157895, 0.5909090909090909, 0.6435643564356437, 0.546218487394958)
Performance for  [('iasted', 'sigkdd')] is : (0.4, 0.8, 0.5333333333333333, 0.6666666666666666, 0.4444444444444445)
Performance for  [('confOf', 'iasted')] is : (0.875, 0.7777777777777778, 0.823529411764706, 0.7954545454545454, 0.8536585365853658)
Final Results: [0.6189404  0.78313609 0.68306081 0.73680162 0.64167934]
Threshold:  0.847

------------------------------------------------------------
Sender: LSF System <rer@dccxc278>
Subject: Job 4142544: <python main.py 1 3 False False> in cluster <dcc> Done

Job <python main.py 1 3 False False> was submitted from host <dccxl001> by user <naveen9> in cluster <dcc> at Wed Sep 16 06:55:09 2020
Job was executed on host(s) <dccxc278>, in queue <x86_24h>, as user <naveen9> in cluster <dcc> at Wed Sep 16 07:27:56 2020
</u/naveen9> was used as the home directory.
</u/naveen9/arvind/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:27:56 2020
Terminated at Wed Sep 16 18:20:36 2020
Results reported at Wed Sep 16 18:20:36 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 1 3 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   39145.71 sec.
    Max Memory :                                 2890 MB
    Average Memory :                             2711.95 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40527.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   39174 sec.
    Turnaround time :                            41127 sec.

The output (if any) is above this job summary.

