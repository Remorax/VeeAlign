2020-09-15 15:48:44.000463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.850818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:50.963461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:50.963528: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.965781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.967501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.967948: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.970117: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.971661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.971926: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.971949: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.972344: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:51.003883: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599810000 Hz
2020-09-15 15:48:51.004108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560cf64fa5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:51.004131: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:51.005771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:51.005793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20694428456956346
Epoch: 0 Idx: 5000 Loss: 0.009964606155091253
Epoch: 1 Idx: 0 Loss: 0.026820360311489346
Epoch: 1 Idx: 5000 Loss: 0.02183251620629807
Epoch: 2 Idx: 0 Loss: 0.029215908097238487
Epoch: 2 Idx: 5000 Loss: 0.013495829635114129
Epoch: 3 Idx: 0 Loss: 0.011149873162007311
Epoch: 3 Idx: 5000 Loss: 0.009417103309473394
Epoch: 4 Idx: 0 Loss: 0.013067248813218312
Epoch: 4 Idx: 5000 Loss: 0.018585882519229352
Epoch: 5 Idx: 0 Loss: 0.006263967311851588
Epoch: 5 Idx: 5000 Loss: 0.01748309082129642
Epoch: 6 Idx: 0 Loss: 0.014688420032372102
Epoch: 6 Idx: 5000 Loss: 0.014914410066081416
Epoch: 7 Idx: 0 Loss: 0.015363845388621442
Epoch: 7 Idx: 5000 Loss: 0.017909988540890587
Epoch: 8 Idx: 0 Loss: 0.007522792248808179
Epoch: 8 Idx: 5000 Loss: 0.010736425110495652
Epoch: 9 Idx: 0 Loss: 0.021187467040532572
Epoch: 9 Idx: 5000 Loss: 0.01862270273264906
Epoch: 10 Idx: 0 Loss: 0.016824303115417428
Epoch: 10 Idx: 5000 Loss: 0.012473868604577902
Epoch: 11 Idx: 0 Loss: 0.014397748599767234
Epoch: 11 Idx: 5000 Loss: 0.022353490603512407
Epoch: 12 Idx: 0 Loss: 0.011834997211655941
Epoch: 12 Idx: 5000 Loss: 0.013854851291517697
Epoch: 13 Idx: 0 Loss: 0.008923114899660039
Epoch: 13 Idx: 5000 Loss: 0.013658735920929484
Epoch: 14 Idx: 0 Loss: 0.029418708408245585
Epoch: 14 Idx: 5000 Loss: 0.028400238363546836
Epoch: 15 Idx: 0 Loss: 0.028993758098282377
Epoch: 15 Idx: 5000 Loss: 0.004387487560565004
Epoch: 16 Idx: 0 Loss: 0.011373409360504133
Epoch: 16 Idx: 5000 Loss: 0.009604186992712488
Epoch: 17 Idx: 0 Loss: 0.008247123807021849
Epoch: 17 Idx: 5000 Loss: 0.018547061923214123
Epoch: 18 Idx: 0 Loss: 0.017639047996039648
Epoch: 18 Idx: 5000 Loss: 0.013182470713046623
Epoch: 19 Idx: 0 Loss: 0.017210423408927783
Epoch: 19 Idx: 5000 Loss: 0.012009423879561061
Epoch: 20 Idx: 0 Loss: 0.007512041613148319
Epoch: 20 Idx: 5000 Loss: 0.015195035058213135
Epoch: 21 Idx: 0 Loss: 0.01663061242531822
Epoch: 21 Idx: 5000 Loss: 0.008392902048358297
Epoch: 22 Idx: 0 Loss: 0.029355079638984056
Epoch: 22 Idx: 5000 Loss: 0.012740296825724867
Epoch: 23 Idx: 0 Loss: 0.024413694809587216
Epoch: 23 Idx: 5000 Loss: 0.03237218035874493
Epoch: 24 Idx: 0 Loss: 0.009759835239214068
Epoch: 24 Idx: 5000 Loss: 0.017651715314975187
Epoch: 25 Idx: 0 Loss: 0.014699956827460135
Epoch: 25 Idx: 5000 Loss: 0.012131046447802987
Epoch: 26 Idx: 0 Loss: 0.01586101367540596
Epoch: 26 Idx: 5000 Loss: 0.02717712491343345
Epoch: 27 Idx: 0 Loss: 0.015749336614196877
Epoch: 27 Idx: 5000 Loss: 0.016578616985704522
Epoch: 28 Idx: 0 Loss: 0.011589753757702525
Epoch: 28 Idx: 5000 Loss: 0.011338770386852166
Epoch: 29 Idx: 0 Loss: 0.020950559640959855
Epoch: 29 Idx: 5000 Loss: 0.025697831328567265
Epoch: 30 Idx: 0 Loss: 0.03405082940557332
Epoch: 30 Idx: 5000 Loss: 0.020239052387689714
Epoch: 31 Idx: 0 Loss: 0.02524760720772146
Epoch: 31 Idx: 5000 Loss: 0.02783374176240596
Epoch: 32 Idx: 0 Loss: 0.03187868379301746
Epoch: 32 Idx: 5000 Loss: 0.01389997417233485
Epoch: 33 Idx: 0 Loss: 0.01385226884306883
Epoch: 33 Idx: 5000 Loss: 0.0115739501813265
Epoch: 34 Idx: 0 Loss: 0.009008655213479912
Epoch: 34 Idx: 5000 Loss: 0.01476036943501485
Epoch: 35 Idx: 0 Loss: 0.016410348314631097
Epoch: 35 Idx: 5000 Loss: 0.030347757253643252
Epoch: 36 Idx: 0 Loss: 0.012041129558455675
Epoch: 36 Idx: 5000 Loss: 0.010448895955351119
Epoch: 37 Idx: 0 Loss: 0.006131669190576865
Epoch: 37 Idx: 5000 Loss: 0.023132311811906
Epoch: 38 Idx: 0 Loss: 0.01030432889372232
Epoch: 38 Idx: 5000 Loss: 0.01948665829148697
Epoch: 39 Idx: 0 Loss: 0.003677011874844888
Epoch: 39 Idx: 5000 Loss: 0.02856004913731311
Epoch: 40 Idx: 0 Loss: 0.03435249878823369
Epoch: 40 Idx: 5000 Loss: 0.008959370324781338
Epoch: 41 Idx: 0 Loss: 0.006295183557652549
Epoch: 41 Idx: 5000 Loss: 0.008428919748018964
Epoch: 42 Idx: 0 Loss: 0.006637377105346932
Epoch: 42 Idx: 5000 Loss: 0.011130710570763102
Epoch: 43 Idx: 0 Loss: 0.03476505042253591
Epoch: 43 Idx: 5000 Loss: 0.025958293316678774
Epoch: 44 Idx: 0 Loss: 0.021550102463329075
Epoch: 44 Idx: 5000 Loss: 0.01771595278934624
Epoch: 45 Idx: 0 Loss: 0.006944914374927273
Epoch: 45 Idx: 5000 Loss: 0.008175749429227821
Epoch: 46 Idx: 0 Loss: 0.013091972888911393
Epoch: 46 Idx: 5000 Loss: 0.011723881029095507
Epoch: 47 Idx: 0 Loss: 0.02203936935975838
Epoch: 47 Idx: 5000 Loss: 0.014645545099129312
Epoch: 48 Idx: 0 Loss: 0.026212081051448132
Epoch: 48 Idx: 5000 Loss: 0.009350185976432522
Epoch: 49 Idx: 0 Loss: 0.025206016007569783
Epoch: 49 Idx: 5000 Loss: 0.018024892076132656
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15258842929483923
Epoch: 0 Idx: 5000 Loss: 0.02422330932788405
Epoch: 1 Idx: 0 Loss: 0.01186495254292168
Epoch: 1 Idx: 5000 Loss: 0.01859947295802247
Epoch: 2 Idx: 0 Loss: 0.02422498791551756
Epoch: 2 Idx: 5000 Loss: 0.01260427648317997
Epoch: 3 Idx: 0 Loss: 0.008271095251014965
Epoch: 3 Idx: 5000 Loss: 0.01492851427590139
Epoch: 4 Idx: 0 Loss: 0.020876363666010946
Epoch: 4 Idx: 5000 Loss: 0.010385044445281183
Epoch: 5 Idx: 0 Loss: 0.01297655016397703
Epoch: 5 Idx: 5000 Loss: 0.013723017713048472
Epoch: 6 Idx: 0 Loss: 0.028822596053653986
Epoch: 6 Idx: 5000 Loss: 0.015496577688623253
Epoch: 7 Idx: 0 Loss: 0.02029828644475061
Epoch: 7 Idx: 5000 Loss: 0.019681823583077497
Epoch: 8 Idx: 0 Loss: 0.022848105313632336
Epoch: 8 Idx: 5000 Loss: 0.018912644922440894
Epoch: 9 Idx: 0 Loss: 0.02157444329442089
Epoch: 9 Idx: 5000 Loss: 0.00867319560418404
Epoch: 10 Idx: 0 Loss: 0.016433801377174196
Epoch: 10 Idx: 5000 Loss: 0.02608869897803538
Epoch: 11 Idx: 0 Loss: 0.009920670547157593
Epoch: 11 Idx: 5000 Loss: 0.004197152464960332
Epoch: 12 Idx: 0 Loss: 0.009765169444580467
Epoch: 12 Idx: 5000 Loss: 0.0216155826028622
Epoch: 13 Idx: 0 Loss: 0.016351577392121334
Epoch: 13 Idx: 5000 Loss: 0.008521700277053137
Epoch: 14 Idx: 0 Loss: 0.020936082650686978
Epoch: 14 Idx: 5000 Loss: 0.01467102653025781
Epoch: 15 Idx: 0 Loss: 0.01628790348647117
Epoch: 15 Idx: 5000 Loss: 0.021537075218364666
Epoch: 16 Idx: 0 Loss: 0.06133042450268225
Epoch: 16 Idx: 5000 Loss: 0.024701969436918256
Epoch: 17 Idx: 0 Loss: 0.023387906208763333
Epoch: 17 Idx: 5000 Loss: 0.008887491044318081
Epoch: 18 Idx: 0 Loss: 0.01934790709533566
Epoch: 18 Idx: 5000 Loss: 0.011601692391902847
Epoch: 19 Idx: 0 Loss: 0.03363012379537882
Epoch: 19 Idx: 5000 Loss: 0.013169303755518693
Epoch: 20 Idx: 0 Loss: 0.017299560571258282
Epoch: 20 Idx: 5000 Loss: 0.019098689682966363
Epoch: 21 Idx: 0 Loss: 0.011936435844376422
Epoch: 21 Idx: 5000 Loss: 0.036094157960439605
Epoch: 22 Idx: 0 Loss: 0.011790469371766962
Epoch: 22 Idx: 5000 Loss: 0.009253258781470526
Epoch: 23 Idx: 0 Loss: 0.012882929462067563
Epoch: 23 Idx: 5000 Loss: 0.008625154573144826
Epoch: 24 Idx: 0 Loss: 0.03300040243058335
Epoch: 24 Idx: 5000 Loss: 0.010728196641144239
Epoch: 25 Idx: 0 Loss: 0.027098070066904418
Epoch: 25 Idx: 5000 Loss: 0.03768860182804059
Epoch: 26 Idx: 0 Loss: 0.019523327339479
Epoch: 26 Idx: 5000 Loss: 0.009232595555144368
Epoch: 27 Idx: 0 Loss: 0.021684234042857888
Epoch: 27 Idx: 5000 Loss: 0.009834833655612196
Epoch: 28 Idx: 0 Loss: 0.011814546888586953
Epoch: 28 Idx: 5000 Loss: 0.010781583131930787
Epoch: 29 Idx: 0 Loss: 0.04054959304489997
Epoch: 29 Idx: 5000 Loss: 0.01569151873000874
Epoch: 30 Idx: 0 Loss: 0.021442584643275437
Epoch: 30 Idx: 5000 Loss: 0.014529538071682469
Epoch: 31 Idx: 0 Loss: 0.026865607867870796
Epoch: 31 Idx: 5000 Loss: 0.02157443042114669
Epoch: 32 Idx: 0 Loss: 0.014042520012659505
Epoch: 32 Idx: 5000 Loss: 0.03386102273501668
Epoch: 33 Idx: 0 Loss: 0.01783056431438491
Epoch: 33 Idx: 5000 Loss: 0.010090985518170418
Epoch: 34 Idx: 0 Loss: 0.007675771641941101
Epoch: 34 Idx: 5000 Loss: 0.03979558337671129
Epoch: 35 Idx: 0 Loss: 0.007297697831038114
Epoch: 35 Idx: 5000 Loss: 0.00770180993372438
Epoch: 36 Idx: 0 Loss: 0.01380258265874803
Epoch: 36 Idx: 5000 Loss: 0.034786038466800825
Epoch: 37 Idx: 0 Loss: 0.005962569221097587
Epoch: 37 Idx: 5000 Loss: 0.0203263437042409
Epoch: 38 Idx: 0 Loss: 0.015746358338199505
Epoch: 38 Idx: 5000 Loss: 0.013455366009479056
Epoch: 39 Idx: 0 Loss: 0.01458561150941894
Epoch: 39 Idx: 5000 Loss: 0.013569804030012744
Epoch: 40 Idx: 0 Loss: 0.010720181270795017
Epoch: 40 Idx: 5000 Loss: 0.02343635702318783
Epoch: 41 Idx: 0 Loss: 0.010104337588536003
Epoch: 41 Idx: 5000 Loss: 0.012345656579088333
Epoch: 42 Idx: 0 Loss: 0.006406653163927167
Epoch: 42 Idx: 5000 Loss: 0.010016759739224345
Epoch: 43 Idx: 0 Loss: 0.011033693430005594
Epoch: 43 Idx: 5000 Loss: 0.007690689918043182
Epoch: 44 Idx: 0 Loss: 0.026397081658984786
Epoch: 44 Idx: 5000 Loss: 0.01946751248711677
Epoch: 45 Idx: 0 Loss: 0.028488963597833823
Epoch: 45 Idx: 5000 Loss: 0.006744523771362818
Epoch: 46 Idx: 0 Loss: 0.0116945021012878
Epoch: 46 Idx: 5000 Loss: 0.018418994419335512
Epoch: 47 Idx: 0 Loss: 0.011193074649731207
Epoch: 47 Idx: 5000 Loss: 0.008307745112391771
Epoch: 48 Idx: 0 Loss: 0.010073473951442213
Epoch: 48 Idx: 5000 Loss: 0.007732582178931411
Epoch: 49 Idx: 0 Loss: 0.009262706889187986
Epoch: 49 Idx: 5000 Loss: 0.009719818542554335
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13616527964073288
Epoch: 0 Idx: 5000 Loss: 0.011907033841301215
Epoch: 1 Idx: 0 Loss: 0.011760970049679442
Epoch: 1 Idx: 5000 Loss: 0.019833701298688045
Epoch: 2 Idx: 0 Loss: 0.05006498439155945
Epoch: 2 Idx: 5000 Loss: 0.0059910061106843585
Epoch: 3 Idx: 0 Loss: 0.007619047122760982
Epoch: 3 Idx: 5000 Loss: 0.013107128804670902
Epoch: 4 Idx: 0 Loss: 0.010700154251687006
Epoch: 4 Idx: 5000 Loss: 0.009295713492123022
Epoch: 5 Idx: 0 Loss: 0.05726681998464514
Epoch: 5 Idx: 5000 Loss: 0.009778414515048985
Epoch: 6 Idx: 0 Loss: 0.004181132839337893
Epoch: 6 Idx: 5000 Loss: 0.04731165480209596
Epoch: 7 Idx: 0 Loss: 0.017608549658049918
Epoch: 7 Idx: 5000 Loss: 0.04221239393736167
Epoch: 8 Idx: 0 Loss: 0.022314353945784588
Epoch: 8 Idx: 5000 Loss: 0.016674716538895275
Epoch: 9 Idx: 0 Loss: 0.03886262593416184
Epoch: 9 Idx: 5000 Loss: 0.014986791815022975
Epoch: 10 Idx: 0 Loss: 0.010066572110156715
Epoch: 10 Idx: 5000 Loss: 0.00848728314193917
Epoch: 11 Idx: 0 Loss: 0.01883597418889266
Epoch: 11 Idx: 5000 Loss: 0.014848750500146269
Epoch: 12 Idx: 0 Loss: 0.011840363182855806
Epoch: 12 Idx: 5000 Loss: 0.01758300280577121
Epoch: 13 Idx: 0 Loss: 0.02025704542630765
Epoch: 13 Idx: 5000 Loss: 0.021040767109148716
Epoch: 14 Idx: 0 Loss: 0.01802965710076935
Epoch: 14 Idx: 5000 Loss: 0.013447079737917943
Epoch: 15 Idx: 0 Loss: 0.00785145148410515
Epoch: 15 Idx: 5000 Loss: 0.01000351694786434
Epoch: 16 Idx: 0 Loss: 0.048508705836331045
Epoch: 16 Idx: 5000 Loss: 0.014932381238620823
Epoch: 17 Idx: 0 Loss: 0.013454230487975234
Epoch: 17 Idx: 5000 Loss: 0.008909907103307503
Epoch: 18 Idx: 0 Loss: 0.012853829763255884
Epoch: 18 Idx: 5000 Loss: 0.01042896097218697
Epoch: 19 Idx: 0 Loss: 0.011382683145757883
Epoch: 19 Idx: 5000 Loss: 0.008980925520251173
Epoch: 20 Idx: 0 Loss: 0.009396896400686517
Epoch: 20 Idx: 5000 Loss: 0.017165873991262875
Epoch: 21 Idx: 0 Loss: 0.009759132862332235
Epoch: 21 Idx: 5000 Loss: 0.013998565950226301
Epoch: 22 Idx: 0 Loss: 0.005840356728858852
Epoch: 22 Idx: 5000 Loss: 0.0038449195585966707
Epoch: 23 Idx: 0 Loss: 0.009274778690219986
Epoch: 23 Idx: 5000 Loss: 0.028039096754009212
Epoch: 24 Idx: 0 Loss: 0.00905096366134009
Epoch: 24 Idx: 5000 Loss: 0.006819521827214613
Epoch: 25 Idx: 0 Loss: 0.02033698233480589
Epoch: 25 Idx: 5000 Loss: 0.011026029136015393
Epoch: 26 Idx: 0 Loss: 0.012133707534640164
Epoch: 26 Idx: 5000 Loss: 0.014666958160553545
Epoch: 27 Idx: 0 Loss: 0.009127090488633033
Epoch: 27 Idx: 5000 Loss: 0.008448498618685085
Epoch: 28 Idx: 0 Loss: 0.01813426781735608
Epoch: 28 Idx: 5000 Loss: 0.017043750330978817
Epoch: 29 Idx: 0 Loss: 0.014163804796678217
Epoch: 29 Idx: 5000 Loss: 0.010841475859503676
Epoch: 30 Idx: 0 Loss: 0.02828870711789059
Epoch: 30 Idx: 5000 Loss: 0.012054061170848177
Epoch: 31 Idx: 0 Loss: 0.02676392006640681
Epoch: 31 Idx: 5000 Loss: 0.013416912032825684
Epoch: 32 Idx: 0 Loss: 0.011905530871960203
Epoch: 32 Idx: 5000 Loss: 0.008692977631625003
Epoch: 33 Idx: 0 Loss: 0.012789688010338937
Epoch: 33 Idx: 5000 Loss: 0.009327002123409782
Epoch: 34 Idx: 0 Loss: 0.011677001723668874
Epoch: 34 Idx: 5000 Loss: 0.01474297214940769
Epoch: 35 Idx: 0 Loss: 0.019484162548245018
Epoch: 35 Idx: 5000 Loss: 0.006131057698982648
Epoch: 36 Idx: 0 Loss: 0.01347788831229475
Epoch: 36 Idx: 5000 Loss: 0.016020516161017198
Epoch: 37 Idx: 0 Loss: 0.008172512475993082
Epoch: 37 Idx: 5000 Loss: 0.009293671147411208
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 312, in forward
    feature_emb = self.name_embedding(features[i]) #  dim: (2, batch_size, max_types, max_paths, max_pathlen, 512)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1814, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc202>
Subject: Job 4066837: <python main.py 4 20 False False> in cluster <dcc> Exited

Job <python main.py 4 20 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
Job was executed on host(s) <dccxc202>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:38 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 20 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46180.36 sec.
    Max Memory :                                 2967 MB
    Average Memory :                             2737.94 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40450.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46201 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

