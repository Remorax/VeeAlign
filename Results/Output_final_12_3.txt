2020-09-15 15:48:41.748440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:48.991113: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.110362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.110434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.112793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.136886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.172345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.223597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.246293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.246893: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.246916: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.247404: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.289782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599855000 Hz
2020-09-15 15:48:49.290074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ab0d33d2f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.290095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.293018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.293048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18546696834354293
Epoch: 0 Idx: 5000 Loss: 0.004605871363794013
Epoch: 1 Idx: 0 Loss: 0.00882621223275688
Epoch: 1 Idx: 5000 Loss: 0.010711104998360163
Epoch: 2 Idx: 0 Loss: 0.012028350388294803
Epoch: 2 Idx: 5000 Loss: 0.0197113938552484
Epoch: 3 Idx: 0 Loss: 0.018977115551366358
Epoch: 3 Idx: 5000 Loss: 0.016298370490692115
Epoch: 4 Idx: 0 Loss: 0.009527378467184305
Epoch: 4 Idx: 5000 Loss: 0.013837850804923535
Epoch: 5 Idx: 0 Loss: 0.013247549768792086
Epoch: 5 Idx: 5000 Loss: 0.01409849315491402
Epoch: 6 Idx: 0 Loss: 0.017970314259684657
Epoch: 6 Idx: 5000 Loss: 0.05062291477791756
Epoch: 7 Idx: 0 Loss: 0.018562154759358483
Epoch: 7 Idx: 5000 Loss: 0.009004900060931844
Epoch: 8 Idx: 0 Loss: 0.011354777445809485
Epoch: 8 Idx: 5000 Loss: 0.0064107020340984765
Epoch: 9 Idx: 0 Loss: 0.014479245981598107
Epoch: 9 Idx: 5000 Loss: 0.007932196128887804
Epoch: 10 Idx: 0 Loss: 0.011599040258773723
Epoch: 10 Idx: 5000 Loss: 0.029994310507227333
Epoch: 11 Idx: 0 Loss: 0.00852284040381679
Epoch: 11 Idx: 5000 Loss: 0.013764570658248793
Epoch: 12 Idx: 0 Loss: 0.00466803110417249
Epoch: 12 Idx: 5000 Loss: 0.03052148035104249
Epoch: 13 Idx: 0 Loss: 0.01192271233373491
Epoch: 13 Idx: 5000 Loss: 0.004997950219989462
Epoch: 14 Idx: 0 Loss: 0.01209803756191094
Epoch: 14 Idx: 5000 Loss: 0.019099358088441133
Epoch: 15 Idx: 0 Loss: 0.00863992488432068
Epoch: 15 Idx: 5000 Loss: 0.013445282085128766
Epoch: 16 Idx: 0 Loss: 0.009995961474242712
Epoch: 16 Idx: 5000 Loss: 0.01461745142635729
Epoch: 17 Idx: 0 Loss: 0.008676231245572546
Epoch: 17 Idx: 5000 Loss: 0.016497363432933232
Epoch: 18 Idx: 0 Loss: 0.012905833308530967
Epoch: 18 Idx: 5000 Loss: 0.012230886789251941
Epoch: 19 Idx: 0 Loss: 0.014682393290064941
Epoch: 19 Idx: 5000 Loss: 0.006324971427454996
Epoch: 20 Idx: 0 Loss: 0.020358659330810238
Epoch: 20 Idx: 5000 Loss: 0.010072538632793315
Epoch: 21 Idx: 0 Loss: 0.010978457476798958
Epoch: 21 Idx: 5000 Loss: 0.014454005965299041
Epoch: 22 Idx: 0 Loss: 0.01083971598411462
Epoch: 22 Idx: 5000 Loss: 0.018948651676032952
Epoch: 23 Idx: 0 Loss: 0.0199522480815711
Epoch: 23 Idx: 5000 Loss: 0.012728935803205405
Epoch: 24 Idx: 0 Loss: 0.013366471093214222
Epoch: 24 Idx: 5000 Loss: 0.022166989198753356
Epoch: 25 Idx: 0 Loss: 0.028270499908780933
Epoch: 25 Idx: 5000 Loss: 0.020596314643739858
Epoch: 26 Idx: 0 Loss: 0.0075773752047196136
Epoch: 26 Idx: 5000 Loss: 0.02165641913438211
Epoch: 27 Idx: 0 Loss: 0.0056716451425594975
Epoch: 27 Idx: 5000 Loss: 0.03748293933023608
Epoch: 28 Idx: 0 Loss: 0.00732230608115009
Epoch: 28 Idx: 5000 Loss: 0.01814053493856929
Epoch: 29 Idx: 0 Loss: 0.015750918591676776
Epoch: 29 Idx: 5000 Loss: 0.012530260792540764
Epoch: 30 Idx: 0 Loss: 0.034216616922239436
Epoch: 30 Idx: 5000 Loss: 0.0050406129044236955
Epoch: 31 Idx: 0 Loss: 0.022396499749039303
Epoch: 31 Idx: 5000 Loss: 0.021737961934837374
Epoch: 32 Idx: 0 Loss: 0.019030478728820008
Epoch: 32 Idx: 5000 Loss: 0.011100141728460858
Epoch: 33 Idx: 0 Loss: 0.011128234355434627
Epoch: 33 Idx: 5000 Loss: 0.008663218052414455
Epoch: 34 Idx: 0 Loss: 0.01179273595756634
Epoch: 34 Idx: 5000 Loss: 0.016567543814773242
Epoch: 35 Idx: 0 Loss: 0.02483546897295076
Epoch: 35 Idx: 5000 Loss: 0.013181916381115337
Epoch: 36 Idx: 0 Loss: 0.011658481868202867
Epoch: 36 Idx: 5000 Loss: 0.009430855499705676
Epoch: 37 Idx: 0 Loss: 0.03053120992947991
Epoch: 37 Idx: 5000 Loss: 0.02638223125663848
Epoch: 38 Idx: 0 Loss: 0.015158899959420293
Epoch: 38 Idx: 5000 Loss: 0.03148835445246425
Epoch: 39 Idx: 0 Loss: 0.01904733709576487
Epoch: 39 Idx: 5000 Loss: 0.011793128596065123
Epoch: 40 Idx: 0 Loss: 0.01300663834109823
Epoch: 40 Idx: 5000 Loss: 0.013945773097290585
Epoch: 41 Idx: 0 Loss: 0.015599020657920973
Epoch: 41 Idx: 5000 Loss: 0.04485405456615481
Epoch: 42 Idx: 0 Loss: 0.021515267247293142
Epoch: 42 Idx: 5000 Loss: 0.016316718704120648
Epoch: 43 Idx: 0 Loss: 0.01677318493703443
Epoch: 43 Idx: 5000 Loss: 0.047647191133682334
Epoch: 44 Idx: 0 Loss: 0.008210801997330049
Epoch: 44 Idx: 5000 Loss: 0.025071770109716035
Epoch: 45 Idx: 0 Loss: 0.008200742079127908
Epoch: 45 Idx: 5000 Loss: 0.015339393357342863
Epoch: 46 Idx: 0 Loss: 0.010745228159544424
Epoch: 46 Idx: 5000 Loss: 0.036714520210800836
Epoch: 47 Idx: 0 Loss: 0.01625061609330171
Epoch: 47 Idx: 5000 Loss: 0.014033286279845143
Epoch: 48 Idx: 0 Loss: 0.008421209666888045
Epoch: 48 Idx: 5000 Loss: 0.03462313164069919
Epoch: 49 Idx: 0 Loss: 0.014197958683656108
Epoch: 49 Idx: 5000 Loss: 0.01163254028976044
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1454100866461058
Epoch: 0 Idx: 5000 Loss: 0.027946967766750756
Epoch: 1 Idx: 0 Loss: 0.04452727937895665
Epoch: 1 Idx: 5000 Loss: 0.03597847967857354
Epoch: 2 Idx: 0 Loss: 0.021416810838678517
Epoch: 2 Idx: 5000 Loss: 0.005605591787043591
Epoch: 3 Idx: 0 Loss: 0.051480417903099304
Epoch: 3 Idx: 5000 Loss: 0.044829367678061255
Epoch: 4 Idx: 0 Loss: 0.01531168224603535
Epoch: 4 Idx: 5000 Loss: 0.007044785488854988
Epoch: 5 Idx: 0 Loss: 0.020283842641025333
Epoch: 5 Idx: 5000 Loss: 0.01603421683083536
Epoch: 6 Idx: 0 Loss: 0.012228210738463328
Epoch: 6 Idx: 5000 Loss: 0.011373849879320419
Epoch: 7 Idx: 0 Loss: 0.016233079378179794
Epoch: 7 Idx: 5000 Loss: 0.00951081761877914
Epoch: 8 Idx: 0 Loss: 0.01100787703931727
Epoch: 8 Idx: 5000 Loss: 0.014606921359934789
Epoch: 9 Idx: 0 Loss: 0.010716244493548807
Epoch: 9 Idx: 5000 Loss: 0.009675840159238657
Epoch: 10 Idx: 0 Loss: 0.009355978493852918
Epoch: 10 Idx: 5000 Loss: 0.014420548948632227
Epoch: 11 Idx: 0 Loss: 0.008405308502135353
Epoch: 11 Idx: 5000 Loss: 0.010242830978861068
Epoch: 12 Idx: 0 Loss: 0.014409027158144162
Epoch: 12 Idx: 5000 Loss: 0.020670754663389863
Epoch: 13 Idx: 0 Loss: 0.008264909587182085
Epoch: 13 Idx: 5000 Loss: 0.01924586357236496
Epoch: 14 Idx: 0 Loss: 0.010425049231813508
Epoch: 14 Idx: 5000 Loss: 0.010067684116297401
Epoch: 15 Idx: 0 Loss: 0.02606703447332693
Epoch: 15 Idx: 5000 Loss: 0.04618003870372361
Epoch: 16 Idx: 0 Loss: 0.01704920119477397
Epoch: 16 Idx: 5000 Loss: 0.03948861382109112
Epoch: 17 Idx: 0 Loss: 0.00814459997030143
Epoch: 17 Idx: 5000 Loss: 0.03288937796904392
Epoch: 18 Idx: 0 Loss: 0.0204912046312391
Epoch: 18 Idx: 5000 Loss: 0.029944353179135335
Epoch: 19 Idx: 0 Loss: 0.018341683002045514
Epoch: 19 Idx: 5000 Loss: 0.011007679559720073
Epoch: 20 Idx: 0 Loss: 0.029377529097707848
Epoch: 20 Idx: 5000 Loss: 0.009465886288049086
Epoch: 21 Idx: 0 Loss: 0.00827342049458898
Epoch: 21 Idx: 5000 Loss: 0.02010117649439603
Epoch: 22 Idx: 0 Loss: 0.015383222686098088
Epoch: 22 Idx: 5000 Loss: 0.01193853869693508
Epoch: 23 Idx: 0 Loss: 0.03407118347101305
Epoch: 23 Idx: 5000 Loss: 0.0075348091649275455
Epoch: 24 Idx: 0 Loss: 0.014811591275203696
Epoch: 24 Idx: 5000 Loss: 0.01499456719167954
Epoch: 25 Idx: 0 Loss: 0.01000971517457478
Epoch: 25 Idx: 5000 Loss: 0.01491981630848721
Epoch: 26 Idx: 0 Loss: 0.005281906789098199
Epoch: 26 Idx: 5000 Loss: 0.022027952415703295
Epoch: 27 Idx: 0 Loss: 0.013233636786181962
Epoch: 27 Idx: 5000 Loss: 0.011993459266561788
Epoch: 28 Idx: 0 Loss: 0.015252158535261285
Epoch: 28 Idx: 5000 Loss: 0.00907284714986043
Epoch: 29 Idx: 0 Loss: 0.019532072208179187
Epoch: 29 Idx: 5000 Loss: 0.022725942128996812
Epoch: 30 Idx: 0 Loss: 0.020935603206959537
Epoch: 30 Idx: 5000 Loss: 0.023088307324871223
Epoch: 31 Idx: 0 Loss: 0.01365643386498241
Epoch: 31 Idx: 5000 Loss: 0.0099701416403883
Epoch: 32 Idx: 0 Loss: 0.015920956144195596
Epoch: 32 Idx: 5000 Loss: 0.020571321137993273
Epoch: 33 Idx: 0 Loss: 0.009181911032079304
Epoch: 33 Idx: 5000 Loss: 0.011682723496945855
Epoch: 34 Idx: 0 Loss: 0.010527654716576485
Epoch: 34 Idx: 5000 Loss: 0.01735490148777686
Epoch: 35 Idx: 0 Loss: 0.00836721773311657
Epoch: 35 Idx: 5000 Loss: 0.017909131395070426
Epoch: 36 Idx: 0 Loss: 0.0221504079843811
Epoch: 36 Idx: 5000 Loss: 0.010206182067087743
Epoch: 37 Idx: 0 Loss: 0.011711384788971671
Epoch: 37 Idx: 5000 Loss: 0.018760257925548248
Epoch: 38 Idx: 0 Loss: 0.01927517419752461
Epoch: 38 Idx: 5000 Loss: 0.042291847634229496
Epoch: 39 Idx: 0 Loss: 0.008785974170876643
Epoch: 39 Idx: 5000 Loss: 0.016120543647313544
Epoch: 40 Idx: 0 Loss: 0.00892233231165422
Epoch: 40 Idx: 5000 Loss: 0.020997963878544336
Epoch: 41 Idx: 0 Loss: 0.01015072439820427
Epoch: 41 Idx: 5000 Loss: 0.022562614807042383
Epoch: 42 Idx: 0 Loss: 0.02473214928113846
Epoch: 42 Idx: 5000 Loss: 0.01573803503312385
Epoch: 43 Idx: 0 Loss: 0.0068893248364691895
Epoch: 43 Idx: 5000 Loss: 0.009883962938724317
Epoch: 44 Idx: 0 Loss: 0.02512973939727259
Epoch: 44 Idx: 5000 Loss: 0.05139211179036519
Epoch: 45 Idx: 0 Loss: 0.028436599717251744
Epoch: 45 Idx: 5000 Loss: 0.010960742738013212
Epoch: 46 Idx: 0 Loss: 0.017647325886439295
Epoch: 46 Idx: 5000 Loss: 0.012741752610095552
Epoch: 47 Idx: 0 Loss: 0.022354025110306777
Epoch: 47 Idx: 5000 Loss: 0.018535921361009785
Epoch: 48 Idx: 0 Loss: 0.011398596302354376
Epoch: 48 Idx: 5000 Loss: 0.0049209594223795635
Epoch: 49 Idx: 0 Loss: 0.012517880892401887
Epoch: 49 Idx: 5000 Loss: 0.013129778403157185
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13180119714415162
Epoch: 0 Idx: 5000 Loss: 0.010679638937395038
Epoch: 1 Idx: 0 Loss: 0.007518262898772837
Epoch: 1 Idx: 5000 Loss: 0.012294914169302432
Epoch: 2 Idx: 0 Loss: 0.018597778525273
Epoch: 2 Idx: 5000 Loss: 0.007994684177300626
Epoch: 3 Idx: 0 Loss: 0.014054983464635355
Epoch: 3 Idx: 5000 Loss: 0.014671107247886532
Epoch: 4 Idx: 0 Loss: 0.014286858964844693
Epoch: 4 Idx: 5000 Loss: 0.007954194097350513
Epoch: 5 Idx: 0 Loss: 0.015463343001606816
Epoch: 5 Idx: 5000 Loss: 0.013986957157621388
Epoch: 6 Idx: 0 Loss: 0.00949214393299802
Epoch: 6 Idx: 5000 Loss: 0.010388234197652411
Epoch: 7 Idx: 0 Loss: 0.018663218414230423
Epoch: 7 Idx: 5000 Loss: 0.016388469048113675
Epoch: 8 Idx: 0 Loss: 0.005548404823380573
Epoch: 8 Idx: 5000 Loss: 0.020626390287401156
Epoch: 9 Idx: 0 Loss: 0.0092618597807628
Epoch: 9 Idx: 5000 Loss: 0.010180443396705076
Epoch: 10 Idx: 0 Loss: 0.022712869864892085
Epoch: 10 Idx: 5000 Loss: 0.01221808618701392
Epoch: 11 Idx: 0 Loss: 0.009879007067755245
Epoch: 11 Idx: 5000 Loss: 0.007864724797954453
Epoch: 12 Idx: 0 Loss: 0.017882193909585616
Epoch: 12 Idx: 5000 Loss: 0.012398674183919054
Epoch: 13 Idx: 0 Loss: 0.014090219296926573
Epoch: 13 Idx: 5000 Loss: 0.007380563215642276
Epoch: 14 Idx: 0 Loss: 0.030750508260285164
Epoch: 14 Idx: 5000 Loss: 0.006696350034699559
Epoch: 15 Idx: 0 Loss: 0.014948021718938822
Epoch: 15 Idx: 5000 Loss: 0.015084606908178377
Epoch: 16 Idx: 0 Loss: 0.024307872352593116
Epoch: 16 Idx: 5000 Loss: 0.00868711935521624
Epoch: 17 Idx: 0 Loss: 0.011991105785589467
Epoch: 17 Idx: 5000 Loss: 0.012076387363382471
Epoch: 18 Idx: 0 Loss: 0.006761750571143945
Epoch: 18 Idx: 5000 Loss: 0.005475899699923749
Epoch: 19 Idx: 0 Loss: 0.022634848171410586
Epoch: 19 Idx: 5000 Loss: 0.01988667052301592
Epoch: 20 Idx: 0 Loss: 0.018342342055444473
Epoch: 20 Idx: 5000 Loss: 0.030314735157946783
Epoch: 21 Idx: 0 Loss: 0.006928040677938051
Epoch: 21 Idx: 5000 Loss: 0.01614025241237553
Epoch: 22 Idx: 0 Loss: 0.03049397857237739
Epoch: 22 Idx: 5000 Loss: 0.00347697019856344
Epoch: 23 Idx: 0 Loss: 0.01689810021707955
Epoch: 23 Idx: 5000 Loss: 0.02919657344954236
Epoch: 24 Idx: 0 Loss: 0.017802311583037654
Epoch: 24 Idx: 5000 Loss: 0.0063527368117817515
Epoch: 25 Idx: 0 Loss: 0.03227484095386765
Epoch: 25 Idx: 5000 Loss: 0.016912349436690444
Epoch: 26 Idx: 0 Loss: 0.013162396192804862
Epoch: 26 Idx: 5000 Loss: 0.014856319452311414
Epoch: 27 Idx: 0 Loss: 0.023048388256395037
Epoch: 27 Idx: 5000 Loss: 0.017077145942479312
Epoch: 28 Idx: 0 Loss: 0.013345982649516794
Epoch: 28 Idx: 5000 Loss: 0.013106929319258696
Epoch: 29 Idx: 0 Loss: 0.008170795861267132
Epoch: 29 Idx: 5000 Loss: 0.03160840345493286
Epoch: 30 Idx: 0 Loss: 0.009396507887627635
Epoch: 30 Idx: 5000 Loss: 0.019883269292769585
Epoch: 31 Idx: 0 Loss: 0.010390699277838132
Epoch: 31 Idx: 5000 Loss: 0.019271286387090823
Epoch: 32 Idx: 0 Loss: 0.0055814046655336454
Epoch: 32 Idx: 5000 Loss: 0.01520591231004515
Epoch: 33 Idx: 0 Loss: 0.021670182295597598
Epoch: 33 Idx: 5000 Loss: 0.012190730072114004
Epoch: 34 Idx: 0 Loss: 0.014457009686760575
Epoch: 34 Idx: 5000 Loss: 0.009804270312545424
Epoch: 35 Idx: 0 Loss: 0.010379619600658911
Epoch: 35 Idx: 5000 Loss: 0.008944508030398455
Epoch: 36 Idx: 0 Loss: 0.008919763945375669
Epoch: 36 Idx: 5000 Loss: 0.007525389464895717
Epoch: 37 Idx: 0 Loss: 0.009995574937037755
Epoch: 37 Idx: 5000 Loss: 0.00885909846094368
Epoch: 38 Idx: 0 Loss: 0.00786990666157585
Epoch: 38 Idx: 5000 Loss: 0.027119401540016456
Epoch: 39 Idx: 0 Loss: 0.015665538866173948
Epoch: 39 Idx: 5000 Loss: 0.011397967065126783
Epoch: 40 Idx: 0 Loss: 0.03805849232009191
Epoch: 40 Idx: 5000 Loss: 0.016237822426687334
Epoch: 41 Idx: 0 Loss: 0.007377019574548065
Epoch: 41 Idx: 5000 Loss: 0.012027147757427463
Epoch: 42 Idx: 0 Loss: 0.028863801730916704
Epoch: 42 Idx: 5000 Loss: 0.01381740629950995
Epoch: 43 Idx: 0 Loss: 0.031005488312972375
Epoch: 43 Idx: 5000 Loss: 0.01069795720318555
Epoch: 44 Idx: 0 Loss: 0.014858275053937036
Epoch: 44 Idx: 5000 Loss: 0.012793985313901256
Epoch: 45 Idx: 0 Loss: 0.015454852392817861
Epoch: 45 Idx: 5000 Loss: 0.0056261751186334995
Epoch: 46 Idx: 0 Loss: 0.017584369321900713
Epoch: 46 Idx: 5000 Loss: 0.018643839404183987
Epoch: 47 Idx: 0 Loss: 0.015535565183178172
Epoch: 47 Idx: 5000 Loss: 0.013104208611883692
Epoch: 48 Idx: 0 Loss: 0.024812632336206543
Epoch: 48 Idx: 5000 Loss: 0.029594849691325264
Epoch: 49 Idx: 0 Loss: 0.025924628383020974
Epoch: 49 Idx: 5000 Loss: 0.009634623524750266
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.24339723514868217
Epoch: 0 Idx: 5000 Loss: 0.016959147450743985
Epoch: 1 Idx: 0 Loss: 0.022465736506340428
Epoch: 1 Idx: 5000 Loss: 0.017730039795591755
Epoch: 2 Idx: 0 Loss: 0.024829112110933693
Epoch: 2 Idx: 5000 Loss: 0.03050425187018215
Epoch: 3 Idx: 0 Loss: 0.014389730287526197
Epoch: 3 Idx: 5000 Loss: 0.01412265471989545
Epoch: 4 Idx: 0 Loss: 0.011887248214532195
Epoch: 4 Idx: 5000 Loss: 0.016943352590275563
Epoch: 5 Idx: 0 Loss: 0.01713071373839655
Epoch: 5 Idx: 5000 Loss: 0.008916680339829446
Epoch: 6 Idx: 0 Loss: 0.013474647992205518
Epoch: 6 Idx: 5000 Loss: 0.007937926990154772
Epoch: 7 Idx: 0 Loss: 0.01268125555013894
Epoch: 7 Idx: 5000 Loss: 0.01318702872098101
Epoch: 8 Idx: 0 Loss: 0.014553160680807007
Epoch: 8 Idx: 5000 Loss: 0.019140359665214574
Epoch: 9 Idx: 0 Loss: 0.03841552073652795
Epoch: 9 Idx: 5000 Loss: 0.005897816582839549
Epoch: 10 Idx: 0 Loss: 0.014443361500782587
Epoch: 10 Idx: 5000 Loss: 0.010825185416305462
Epoch: 11 Idx: 0 Loss: 0.01327760673043895
Epoch: 11 Idx: 5000 Loss: 0.028078143865585135
Epoch: 12 Idx: 0 Loss: 0.016089007367447335
Epoch: 12 Idx: 5000 Loss: 0.017933023717007973
Epoch: 13 Idx: 0 Loss: 0.005684454321630784
Epoch: 13 Idx: 5000 Loss: 0.018330503638388004
Epoch: 14 Idx: 0 Loss: 0.027823992789863257
Epoch: 14 Idx: 5000 Loss: 0.0106145107221205
Epoch: 15 Idx: 0 Loss: 0.033269178533338134
Epoch: 15 Idx: 5000 Loss: 0.019994972352733415
Epoch: 16 Idx: 0 Loss: 0.012101741807257501
Epoch: 16 Idx: 5000 Loss: 0.014698697365494137
Epoch: 17 Idx: 0 Loss: 0.0159110421589634
Epoch: 17 Idx: 5000 Loss: 0.010506315462275614
Epoch: 18 Idx: 0 Loss: 0.025069197706582884
Epoch: 18 Idx: 5000 Loss: 0.03927090044673188
Epoch: 19 Idx: 0 Loss: 0.04185953690390706
Epoch: 19 Idx: 5000 Loss: 0.009604128003608818
Epoch: 20 Idx: 0 Loss: 0.013805844471350645
Epoch: 20 Idx: 5000 Loss: 0.007881700661553208
Epoch: 21 Idx: 0 Loss: 0.008223423565604269
Epoch: 21 Idx: 5000 Loss: 0.03076322780643373
Epoch: 22 Idx: 0 Loss: 0.0054365850177116835
Epoch: 22 Idx: 5000 Loss: 0.012051982455655516
Epoch: 23 Idx: 0 Loss: 0.008695523510297204
Epoch: 23 Idx: 5000 Loss: 0.017434110433627012
Epoch: 24 Idx: 0 Loss: 0.007653349737658056
Epoch: 24 Idx: 5000 Loss: 0.018592398313718637
Epoch: 25 Idx: 0 Loss: 0.022738728183390997
Epoch: 25 Idx: 5000 Loss: 0.010655488035908246
Epoch: 26 Idx: 0 Loss: 0.013755696450453665
Epoch: 26 Idx: 5000 Loss: 0.014229830700944726
Epoch: 27 Idx: 0 Loss: 0.013295692668782196
Epoch: 27 Idx: 5000 Loss: 0.008135866962483425
Epoch: 28 Idx: 0 Loss: 0.005703724490617089
Epoch: 28 Idx: 5000 Loss: 0.03055241125521676
Epoch: 29 Idx: 0 Loss: 0.008344120286002362
Epoch: 29 Idx: 5000 Loss: 0.01967505047139331
Epoch: 30 Idx: 0 Loss: 0.022120128797664135
Epoch: 30 Idx: 5000 Loss: 0.012327168439535525
Epoch: 31 Idx: 0 Loss: 0.013946967504143995
Epoch: 31 Idx: 5000 Loss: 0.018210880505168045
Epoch: 32 Idx: 0 Loss: 0.02116792728760117
Epoch: 32 Idx: 5000 Loss: 0.01784662865363033
Epoch: 33 Idx: 0 Loss: 0.0077849217005844015
Epoch: 33 Idx: 5000 Loss: 0.01080886460575306
Epoch: 34 Idx: 0 Loss: 0.016918196646100437
Epoch: 34 Idx: 5000 Loss: 0.012768959908893786
Epoch: 35 Idx: 0 Loss: 0.04005392011511152
Epoch: 35 Idx: 5000 Loss: 0.03797417275223745
Epoch: 36 Idx: 0 Loss: 0.021437776583581557
Epoch: 36 Idx: 5000 Loss: 0.007346522479064633
Epoch: 37 Idx: 0 Loss: 0.015623765910183352
Epoch: 37 Idx: 5000 Loss: 0.0074233129976917014
Epoch: 38 Idx: 0 Loss: 0.015479114320400196
Epoch: 38 Idx: 5000 Loss: 0.005478532912553421
Epoch: 39 Idx: 0 Loss: 0.00956826211959597
Epoch: 39 Idx: 5000 Loss: 0.02028510973098682
Epoch: 40 Idx: 0 Loss: 0.011867937111185098
Epoch: 40 Idx: 5000 Loss: 0.02316394369585283
Epoch: 41 Idx: 0 Loss: 0.00887229240277035
Epoch: 41 Idx: 5000 Loss: 0.013197147312480412
Epoch: 42 Idx: 0 Loss: 0.009623287553807591
Epoch: 42 Idx: 5000 Loss: 0.007212440591313905
Epoch: 43 Idx: 0 Loss: 0.006718210006464276
Epoch: 43 Idx: 5000 Loss: 0.02514390628486759
Epoch: 44 Idx: 0 Loss: 0.015311764054885976
Epoch: 44 Idx: 5000 Loss: 0.020387063658262324
Epoch: 45 Idx: 0 Loss: 0.018490543566573682
Epoch: 45 Idx: 5000 Loss: 0.012584379165793736
Epoch: 46 Idx: 0 Loss: 0.020424596899692185
Epoch: 46 Idx: 5000 Loss: 0.017089592585243316
Epoch: 47 Idx: 0 Loss: 0.009786893895399506
Epoch: 47 Idx: 5000 Loss: 0.014106787850713825
Epoch: 48 Idx: 0 Loss: 0.028048147947494745
Epoch: 48 Idx: 5000 Loss: 0.0478580531761359
Epoch: 49 Idx: 0 Loss: 0.011785866355329517
Epoch: 49 Idx: 5000 Loss: 0.011367900663112492
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.23112750246611857
Epoch: 0 Idx: 5000 Loss: 0.012448804146144719
Epoch: 1 Idx: 0 Loss: 0.011542232353163906
Epoch: 1 Idx: 5000 Loss: 0.013908834803214523
Epoch: 2 Idx: 0 Loss: 0.012869701397883734
Epoch: 2 Idx: 5000 Loss: 0.015088196720263965
Epoch: 3 Idx: 0 Loss: 0.011764348245510304
Epoch: 3 Idx: 5000 Loss: 0.012812845205324185
Epoch: 4 Idx: 0 Loss: 0.011905190833657429
Epoch: 4 Idx: 5000 Loss: 0.019234122096956723
Epoch: 5 Idx: 0 Loss: 0.00882086230489292
Epoch: 5 Idx: 5000 Loss: 0.00943563776110301
Epoch: 6 Idx: 0 Loss: 0.01611883024039818
Epoch: 6 Idx: 5000 Loss: 0.037933303715583434
Epoch: 7 Idx: 0 Loss: 0.012010371530345594
Epoch: 7 Idx: 5000 Loss: 0.00936300986880897
Epoch: 8 Idx: 0 Loss: 0.008558143769281074
Epoch: 8 Idx: 5000 Loss: 0.011008993927453466
Epoch: 9 Idx: 0 Loss: 0.01410807378354306
Epoch: 9 Idx: 5000 Loss: 0.02792524429607521
Epoch: 10 Idx: 0 Loss: 0.022472711219720578
Epoch: 10 Idx: 5000 Loss: 0.005822216058715858
Epoch: 11 Idx: 0 Loss: 0.021595981768554418
Epoch: 11 Idx: 5000 Loss: 0.01807204833126651
Epoch: 12 Idx: 0 Loss: 0.012741604008505394
Epoch: 12 Idx: 5000 Loss: 0.01771113855779352
Epoch: 13 Idx: 0 Loss: 0.02625975820200552
Epoch: 13 Idx: 5000 Loss: 0.016151326308211422
Epoch: 14 Idx: 0 Loss: 0.020160809303244126
Epoch: 14 Idx: 5000 Loss: 0.013243275140394757
Epoch: 15 Idx: 0 Loss: 0.01802744814315406
Epoch: 15 Idx: 5000 Loss: 0.01524141364248682
Epoch: 16 Idx: 0 Loss: 0.017842902198106032
Epoch: 16 Idx: 5000 Loss: 0.011170434008573423
Epoch: 17 Idx: 0 Loss: 0.012047844737260584
Epoch: 17 Idx: 5000 Loss: 0.032517218996542974
Epoch: 18 Idx: 0 Loss: 0.03974451904300488
Epoch: 18 Idx: 5000 Loss: 0.02042204316104306
Epoch: 19 Idx: 0 Loss: 0.013924706534433508
Epoch: 19 Idx: 5000 Loss: 0.01979751634067014
Epoch: 20 Idx: 0 Loss: 0.016935260955818453
Epoch: 20 Idx: 5000 Loss: 0.010118816518171418
Epoch: 21 Idx: 0 Loss: 0.012994166634524346
Epoch: 21 Idx: 5000 Loss: 0.014160152270333674
Epoch: 22 Idx: 0 Loss: 0.017044708181260526
Epoch: 22 Idx: 5000 Loss: 0.019718093072523476
Epoch: 23 Idx: 0 Loss: 0.007657191852021005
Epoch: 23 Idx: 5000 Loss: 0.016516094517001048
Epoch: 24 Idx: 0 Loss: 0.021489172802907963
Epoch: 24 Idx: 5000 Loss: 0.029974936650327147
Epoch: 25 Idx: 0 Loss: 0.009526373765626601
Epoch: 25 Idx: 5000 Loss: 0.018750203839261695
Epoch: 26 Idx: 0 Loss: 0.019702925690403054
Epoch: 26 Idx: 5000 Loss: 0.010401233876390815
Epoch: 27 Idx: 0 Loss: 0.008153893670536726
Epoch: 27 Idx: 5000 Loss: 0.011140897077434396
Epoch: 28 Idx: 0 Loss: 0.02023827705874134
Epoch: 28 Idx: 5000 Loss: 0.009948856852406365
Epoch: 29 Idx: 0 Loss: 0.021741319582893947
Epoch: 29 Idx: 5000 Loss: 0.008846719643668286
Epoch: 30 Idx: 0 Loss: 0.024874035943074205
Epoch: 30 Idx: 5000 Loss: 0.025581231232695407
Epoch: 31 Idx: 0 Loss: 0.011893594652958691
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 357, in forward
    output_node_emb = self.output(contextual_node_emb)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 91, in forward
    return F.linear(input, self.weight, self.bias)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in linear
    ret = torch.addmm(bias, input, weight.t())
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc257>
Subject: Job 4066798: <python main.py 3 12 False False> in cluster <dcc> Exited

Job <python main.py 3 12 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc257>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:36 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 12 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46131.87 sec.
    Max Memory :                                 2918 MB
    Average Memory :                             2737.76 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40499.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46210 sec.
    Turnaround time :                            46205 sec.

The output (if any) is above this job summary.

