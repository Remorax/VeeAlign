2020-09-15 15:48:44.840197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.203396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:52.321233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:52.321323: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:52.323706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:52.363571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:52.420922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:52.490276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:52.518176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:52.518747: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:52.518772: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:52.519225: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:52.563537: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600065000 Hz
2020-09-15 15:48:52.563848: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55de150411a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:52.563870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:52.566911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:52.566963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20053021716302333
Epoch: 0 Idx: 5000 Loss: 0.02075039309936276
Epoch: 1 Idx: 0 Loss: 0.030623899608401058
Epoch: 1 Idx: 5000 Loss: 0.03548545011068795
Epoch: 2 Idx: 0 Loss: 0.010846121958517823
Epoch: 2 Idx: 5000 Loss: 0.012173840691134695
Epoch: 3 Idx: 0 Loss: 0.02585570124689286
Epoch: 3 Idx: 5000 Loss: 0.006871267213818667
Epoch: 4 Idx: 0 Loss: 0.008513164889941506
Epoch: 4 Idx: 5000 Loss: 0.008106847508019833
Epoch: 5 Idx: 0 Loss: 0.005544610097278583
Epoch: 5 Idx: 5000 Loss: 0.014196089709387703
Epoch: 6 Idx: 0 Loss: 0.024532690136129378
Epoch: 6 Idx: 5000 Loss: 0.040912131445757026
Epoch: 7 Idx: 0 Loss: 0.016878987003498002
Epoch: 7 Idx: 5000 Loss: 0.009240263441385019
Epoch: 8 Idx: 0 Loss: 0.011422768677805397
Epoch: 8 Idx: 5000 Loss: 0.00718853482282514
Epoch: 9 Idx: 0 Loss: 0.008940816332517627
Epoch: 9 Idx: 5000 Loss: 0.011260605051280142
Epoch: 10 Idx: 0 Loss: 0.01264288976158634
Epoch: 10 Idx: 5000 Loss: 0.029539663129765224
Epoch: 11 Idx: 0 Loss: 0.021087539851955505
Epoch: 11 Idx: 5000 Loss: 0.018790925418651336
Epoch: 12 Idx: 0 Loss: 0.008780014839190338
Epoch: 12 Idx: 5000 Loss: 0.009321319614744845
Epoch: 13 Idx: 0 Loss: 0.02171804100251867
Epoch: 13 Idx: 5000 Loss: 0.00792041391941262
Epoch: 14 Idx: 0 Loss: 0.00859394788267652
Epoch: 14 Idx: 5000 Loss: 0.015772773164089687
Epoch: 15 Idx: 0 Loss: 0.01333968879008857
Epoch: 15 Idx: 5000 Loss: 0.03604480055696553
Epoch: 16 Idx: 0 Loss: 0.030944705561177593
Epoch: 16 Idx: 5000 Loss: 0.013380624346626038
Epoch: 17 Idx: 0 Loss: 0.015029298698511155
Epoch: 17 Idx: 5000 Loss: 0.009904660412508171
Epoch: 18 Idx: 0 Loss: 0.023776964591638083
Epoch: 18 Idx: 5000 Loss: 0.024739688990979242
Epoch: 19 Idx: 0 Loss: 0.015676762874621445
Epoch: 19 Idx: 5000 Loss: 0.03506844571260975
Epoch: 20 Idx: 0 Loss: 0.008524762212837919
Epoch: 20 Idx: 5000 Loss: 0.008034335029974284
Epoch: 21 Idx: 0 Loss: 0.011267732475997308
Epoch: 21 Idx: 5000 Loss: 0.024634953586082024
Epoch: 22 Idx: 0 Loss: 0.008841354442593527
Epoch: 22 Idx: 5000 Loss: 0.013196250789001444
Epoch: 23 Idx: 0 Loss: 0.026898559786619
Epoch: 23 Idx: 5000 Loss: 0.014252231425522842
Epoch: 24 Idx: 0 Loss: 0.012597397338348026
Epoch: 24 Idx: 5000 Loss: 0.0121878577246597
Epoch: 25 Idx: 0 Loss: 0.040929161864642925
Epoch: 25 Idx: 5000 Loss: 0.035890807883118665
Epoch: 26 Idx: 0 Loss: 0.009912869299357476
Epoch: 26 Idx: 5000 Loss: 0.023085864181473428
Epoch: 27 Idx: 0 Loss: 0.010674647450616241
Epoch: 27 Idx: 5000 Loss: 0.014005854626839846
Epoch: 28 Idx: 0 Loss: 0.018181644100811203
Epoch: 28 Idx: 5000 Loss: 0.029252432984694154
Epoch: 29 Idx: 0 Loss: 0.01450367794779757
Epoch: 29 Idx: 5000 Loss: 0.005683825855409419
Epoch: 30 Idx: 0 Loss: 0.008510934349642896
Epoch: 30 Idx: 5000 Loss: 0.006047886515769072
Epoch: 31 Idx: 0 Loss: 0.01018651024246336
Epoch: 31 Idx: 5000 Loss: 0.020606805582947668
Epoch: 32 Idx: 0 Loss: 0.01093897204913063
Epoch: 32 Idx: 5000 Loss: 0.01180985805513943
Epoch: 33 Idx: 0 Loss: 0.012154985309647683
Epoch: 33 Idx: 5000 Loss: 0.014730453981702567
Epoch: 34 Idx: 0 Loss: 0.00822915392918526
Epoch: 34 Idx: 5000 Loss: 0.009773758557714278
Epoch: 35 Idx: 0 Loss: 0.011323958735190518
Epoch: 35 Idx: 5000 Loss: 0.015963958589447713
Epoch: 36 Idx: 0 Loss: 0.010203339958937597
Epoch: 36 Idx: 5000 Loss: 0.016152612022861616
Epoch: 37 Idx: 0 Loss: 0.0506545125636514
Epoch: 37 Idx: 5000 Loss: 0.01334274070708433
Epoch: 38 Idx: 0 Loss: 0.01813502611105309
Epoch: 38 Idx: 5000 Loss: 0.03472195306316255
Epoch: 39 Idx: 0 Loss: 0.03721614896179072
Epoch: 39 Idx: 5000 Loss: 0.03643679684354263
Epoch: 40 Idx: 0 Loss: 0.009602710052658406
Epoch: 40 Idx: 5000 Loss: 0.006435529010880325
Epoch: 41 Idx: 0 Loss: 0.011559680155060587
Epoch: 41 Idx: 5000 Loss: 0.012878888643144662
Epoch: 42 Idx: 0 Loss: 0.011416746274991748
Epoch: 42 Idx: 5000 Loss: 0.011017712052878955
Epoch: 43 Idx: 0 Loss: 0.021685877220017337
Epoch: 43 Idx: 5000 Loss: 0.01808661330450562
Epoch: 44 Idx: 0 Loss: 0.010794040787733244
Epoch: 44 Idx: 5000 Loss: 0.008793757494125445
Epoch: 45 Idx: 0 Loss: 0.017677682114373386
Epoch: 45 Idx: 5000 Loss: 0.011079640142785887
Epoch: 46 Idx: 0 Loss: 0.01221679712286032
Epoch: 46 Idx: 5000 Loss: 0.020644346132473
Epoch: 47 Idx: 0 Loss: 0.010543489272684276
Epoch: 47 Idx: 5000 Loss: 0.030751848688899113
Epoch: 48 Idx: 0 Loss: 0.0325061606034732
Epoch: 48 Idx: 5000 Loss: 0.01379114480029197
Epoch: 49 Idx: 0 Loss: 0.028222399103513995
Epoch: 49 Idx: 5000 Loss: 0.016448295171500274
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.13814612144356808
Epoch: 0 Idx: 5000 Loss: 0.01816409630689808
Epoch: 1 Idx: 0 Loss: 0.01900449662855949
Epoch: 1 Idx: 5000 Loss: 0.03898355998184315
Epoch: 2 Idx: 0 Loss: 0.014336916323040209
Epoch: 2 Idx: 5000 Loss: 0.013002887774294803
Epoch: 3 Idx: 0 Loss: 0.045296524061433356
Epoch: 3 Idx: 5000 Loss: 0.01887976913952701
Epoch: 4 Idx: 0 Loss: 0.023838635066743333
Epoch: 4 Idx: 5000 Loss: 0.01572674595723462
Epoch: 5 Idx: 0 Loss: 0.013746388730384591
Epoch: 5 Idx: 5000 Loss: 0.022033692879780152
Epoch: 6 Idx: 0 Loss: 0.03013244362969146
Epoch: 6 Idx: 5000 Loss: 0.02577791870055323
Epoch: 7 Idx: 0 Loss: 0.02022600817049484
Epoch: 7 Idx: 5000 Loss: 0.020702502555624128
Epoch: 8 Idx: 0 Loss: 0.01240554967143533
Epoch: 8 Idx: 5000 Loss: 0.01540867268394115
Epoch: 9 Idx: 0 Loss: 0.017514069736969055
Epoch: 9 Idx: 5000 Loss: 0.005008559208233508
Epoch: 10 Idx: 0 Loss: 0.024827096381546974
Epoch: 10 Idx: 5000 Loss: 0.019381855324309836
Epoch: 11 Idx: 0 Loss: 0.013227849713076702
Epoch: 11 Idx: 5000 Loss: 0.013987682127022071
Epoch: 12 Idx: 0 Loss: 0.01291118827902073
Epoch: 12 Idx: 5000 Loss: 0.013004903840279226
Epoch: 13 Idx: 0 Loss: 0.006170008054175358
Epoch: 13 Idx: 5000 Loss: 0.02090640334954229
Epoch: 14 Idx: 0 Loss: 0.008610679434716991
Epoch: 14 Idx: 5000 Loss: 0.009720891591881622
Epoch: 15 Idx: 0 Loss: 0.006833557327393582
Epoch: 15 Idx: 5000 Loss: 0.009834623600231119
Epoch: 16 Idx: 0 Loss: 0.03376763636216198
Epoch: 16 Idx: 5000 Loss: 0.030600483842887563
Epoch: 17 Idx: 0 Loss: 0.015619180667907122
Epoch: 17 Idx: 5000 Loss: 0.040729723045943675
Epoch: 18 Idx: 0 Loss: 0.009313492905534567
Epoch: 18 Idx: 5000 Loss: 0.015948863024345096
Epoch: 19 Idx: 0 Loss: 0.0183789830234053
Epoch: 19 Idx: 5000 Loss: 0.011224487577655134
Epoch: 20 Idx: 0 Loss: 0.01787465010606403
Epoch: 20 Idx: 5000 Loss: 0.011157047250056713
Epoch: 21 Idx: 0 Loss: 0.009265553816459894
Epoch: 21 Idx: 5000 Loss: 0.017877763660417274
Epoch: 22 Idx: 0 Loss: 0.017229984238656036
Epoch: 22 Idx: 5000 Loss: 0.007187986343526028
Epoch: 23 Idx: 0 Loss: 0.007171986898808855
Epoch: 23 Idx: 5000 Loss: 0.004760112410888135
Epoch: 24 Idx: 0 Loss: 0.01627334838954661
Epoch: 24 Idx: 5000 Loss: 0.01941297804172574
Epoch: 25 Idx: 0 Loss: 0.012383541622135237
Epoch: 25 Idx: 5000 Loss: 0.024866596106659693
Epoch: 26 Idx: 0 Loss: 0.01360200307980837
Epoch: 26 Idx: 5000 Loss: 0.027727956432599465
Epoch: 27 Idx: 0 Loss: 0.021816496443278544
Epoch: 27 Idx: 5000 Loss: 0.00750907575283434
Epoch: 28 Idx: 0 Loss: 0.030462050558843233
Epoch: 28 Idx: 5000 Loss: 0.013379762383512659
Epoch: 29 Idx: 0 Loss: 0.008579065894667885
Epoch: 29 Idx: 5000 Loss: 0.017093610146199093
Epoch: 30 Idx: 0 Loss: 0.012457164175128327
Epoch: 30 Idx: 5000 Loss: 0.02014397119796355
Epoch: 31 Idx: 0 Loss: 0.01661020326753756
Epoch: 31 Idx: 5000 Loss: 0.008921041486190216
Epoch: 32 Idx: 0 Loss: 0.01237771060786182
Epoch: 32 Idx: 5000 Loss: 0.01853367842572482
Epoch: 33 Idx: 0 Loss: 0.004340251145442823
Epoch: 33 Idx: 5000 Loss: 0.009611215802396413
Epoch: 34 Idx: 0 Loss: 0.010446409736114078
Epoch: 34 Idx: 5000 Loss: 0.005510232082601656
Epoch: 35 Idx: 0 Loss: 0.008625302153312902
Epoch: 35 Idx: 5000 Loss: 0.03152972834366557
Epoch: 36 Idx: 0 Loss: 0.016254315548073273
Epoch: 36 Idx: 5000 Loss: 0.01674388398582316
Epoch: 37 Idx: 0 Loss: 0.010711105654378546
Epoch: 37 Idx: 5000 Loss: 0.013183806512640462
Epoch: 38 Idx: 0 Loss: 0.020935157688171703
Epoch: 38 Idx: 5000 Loss: 0.03048499754821274
Epoch: 39 Idx: 0 Loss: 0.01068876317514987
Epoch: 39 Idx: 5000 Loss: 0.00660882994740805
Epoch: 40 Idx: 0 Loss: 0.020292576382805818
Epoch: 40 Idx: 5000 Loss: 0.017403639206649626
Epoch: 41 Idx: 0 Loss: 0.008951793594159858
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 387, in to_feature
    for elem in inputs_lenpadded]
  File "main.py", line 387, in <listcomp>
    for elem in inputs_lenpadded]
  File "main.py", line 386, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "main.py", line 386, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "main.py", line 385, in <listcomp>
    for i in range(max_paths - len(nbr_type))]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc230>
Subject: Job 4066844: <python main.py 4 26 False True> in cluster <dcc> Exited

Job <python main.py 4 26 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc230>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 26 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46186.24 sec.
    Max Memory :                                 2989 MB
    Average Memory :                             2749.80 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40428.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46224 sec.
    Turnaround time :                            46202 sec.

The output (if any) is above this job summary.

