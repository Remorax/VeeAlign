2020-09-15 15:48:41.887989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.319527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:49.434409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:49.434501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:49.436936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:49.456220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:49.492278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:49.533650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:49.559553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:49.560113: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:49.560138: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:49.560613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:49.603116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600110000 Hz
2020-09-15 15:48:49.603455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556d0df681b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:49.603476: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:49.606732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:49.606794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19527782854640235
Epoch: 0 Idx: 5000 Loss: 0.013612943693294409
Epoch: 1 Idx: 0 Loss: 0.024890664437228604
Epoch: 1 Idx: 5000 Loss: 0.015999358806984713
Epoch: 2 Idx: 0 Loss: 0.01250905430224052
Epoch: 2 Idx: 5000 Loss: 0.020084858213093436
Epoch: 3 Idx: 0 Loss: 0.014069499095592377
Epoch: 3 Idx: 5000 Loss: 0.018654806384788072
Epoch: 4 Idx: 0 Loss: 0.010390238845882388
Epoch: 4 Idx: 5000 Loss: 0.020986443500877656
Epoch: 5 Idx: 0 Loss: 0.008597840911703531
Epoch: 5 Idx: 5000 Loss: 0.011808828718078094
Epoch: 6 Idx: 0 Loss: 0.031008917057269336
Epoch: 6 Idx: 5000 Loss: 0.012283465276899984
Epoch: 7 Idx: 0 Loss: 0.029879958910721423
Epoch: 7 Idx: 5000 Loss: 0.010970983707336906
Epoch: 8 Idx: 0 Loss: 0.01591085032107853
Epoch: 8 Idx: 5000 Loss: 0.008283256089598519
Epoch: 9 Idx: 0 Loss: 0.007783032572141052
Epoch: 9 Idx: 5000 Loss: 0.017617730455942116
Epoch: 10 Idx: 0 Loss: 0.01113987099109789
Epoch: 10 Idx: 5000 Loss: 0.014740628757492753
Epoch: 11 Idx: 0 Loss: 0.024840427908673662
Epoch: 11 Idx: 5000 Loss: 0.025501042453760017
Epoch: 12 Idx: 0 Loss: 0.005811861662403825
Epoch: 12 Idx: 5000 Loss: 0.00731404960682322
Epoch: 13 Idx: 0 Loss: 0.01035119449806651
Epoch: 13 Idx: 5000 Loss: 0.019869533240074806
Epoch: 14 Idx: 0 Loss: 0.01869868736531847
Epoch: 14 Idx: 5000 Loss: 0.009000223218963061
Epoch: 15 Idx: 0 Loss: 0.024947186332945216
Epoch: 15 Idx: 5000 Loss: 0.02017477551572188
Epoch: 16 Idx: 0 Loss: 0.01850360123805062
Epoch: 16 Idx: 5000 Loss: 0.011051090934164653
Epoch: 17 Idx: 0 Loss: 0.014213973836166498
Epoch: 17 Idx: 5000 Loss: 0.030751673968759094
Epoch: 18 Idx: 0 Loss: 0.012543485635394093
Epoch: 18 Idx: 5000 Loss: 0.03477832474934889
Epoch: 19 Idx: 0 Loss: 0.013593006483343809
Epoch: 19 Idx: 5000 Loss: 0.020937178187784768
Epoch: 20 Idx: 0 Loss: 0.010234467995612388
Epoch: 20 Idx: 5000 Loss: 0.023928481479711824
Epoch: 21 Idx: 0 Loss: 0.018522306320283795
Epoch: 21 Idx: 5000 Loss: 0.017087888972790583
Epoch: 22 Idx: 0 Loss: 0.01280853120740556
Epoch: 22 Idx: 5000 Loss: 0.00605026281057126
Epoch: 23 Idx: 0 Loss: 0.02521367210863
Epoch: 23 Idx: 5000 Loss: 0.02457017122773746
Epoch: 24 Idx: 0 Loss: 0.007707016151277658
Epoch: 24 Idx: 5000 Loss: 0.029874692621172393
Epoch: 25 Idx: 0 Loss: 0.017415642024129083
Epoch: 25 Idx: 5000 Loss: 0.014829909196839327
Epoch: 26 Idx: 0 Loss: 0.004818969834037344
Epoch: 26 Idx: 5000 Loss: 0.01970347249758072
Epoch: 27 Idx: 0 Loss: 0.020593324339871405
Epoch: 27 Idx: 5000 Loss: 0.029014654987712107
Epoch: 28 Idx: 0 Loss: 0.009109856662051687
Epoch: 28 Idx: 5000 Loss: 0.009265171251638463
Epoch: 29 Idx: 0 Loss: 0.01612572920021474
Epoch: 29 Idx: 5000 Loss: 0.012310126373819298
Epoch: 30 Idx: 0 Loss: 0.016001502041040474
Epoch: 30 Idx: 5000 Loss: 0.01595867601083557
Epoch: 31 Idx: 0 Loss: 0.02118029005265922
Epoch: 31 Idx: 5000 Loss: 0.009854949289130766
Epoch: 32 Idx: 0 Loss: 0.01699001592981034
Epoch: 32 Idx: 5000 Loss: 0.015222195428763095
Epoch: 33 Idx: 0 Loss: 0.013577272798256206
Epoch: 33 Idx: 5000 Loss: 0.016291622975658882
Epoch: 34 Idx: 0 Loss: 0.03270109541634353
Epoch: 34 Idx: 5000 Loss: 0.009517864487686028
Epoch: 35 Idx: 0 Loss: 0.013846631407857668
Epoch: 35 Idx: 5000 Loss: 0.026731479593023535
Epoch: 36 Idx: 0 Loss: 0.011421034103837758
Epoch: 36 Idx: 5000 Loss: 0.017959671391284033
Epoch: 37 Idx: 0 Loss: 0.06695621203184113
Epoch: 37 Idx: 5000 Loss: 0.015957912884061117
Epoch: 38 Idx: 0 Loss: 0.013623649604489823
Epoch: 38 Idx: 5000 Loss: 0.029228953678591154
Epoch: 39 Idx: 0 Loss: 0.007874919258344543
Epoch: 39 Idx: 5000 Loss: 0.013798929999960569
Epoch: 40 Idx: 0 Loss: 0.01210705462932291
Epoch: 40 Idx: 5000 Loss: 0.052642333553170974
Epoch: 41 Idx: 0 Loss: 0.023923422757198484
Epoch: 41 Idx: 5000 Loss: 0.00741050649818461
Epoch: 42 Idx: 0 Loss: 0.016603122537202978
Epoch: 42 Idx: 5000 Loss: 0.014467228189601573
Epoch: 43 Idx: 0 Loss: 0.019573698796449518
Epoch: 43 Idx: 5000 Loss: 0.010029165593743884
Epoch: 44 Idx: 0 Loss: 0.006715706777379111
Epoch: 44 Idx: 5000 Loss: 0.019994672563058674
Epoch: 45 Idx: 0 Loss: 0.019291352175529505
Epoch: 45 Idx: 5000 Loss: 0.030319883223494708
Epoch: 46 Idx: 0 Loss: 0.008321331422769633
Epoch: 46 Idx: 5000 Loss: 0.009262995682187514
Epoch: 47 Idx: 0 Loss: 0.010552788545785102
Epoch: 47 Idx: 5000 Loss: 0.022435959904710933
Epoch: 48 Idx: 0 Loss: 0.014046697110377804
Epoch: 48 Idx: 5000 Loss: 0.019373943888060206
Epoch: 49 Idx: 0 Loss: 0.01040701681930832
Epoch: 49 Idx: 5000 Loss: 0.010141436225986377
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15621758681287856
Epoch: 0 Idx: 5000 Loss: 0.020035655604229544
Epoch: 1 Idx: 0 Loss: 0.012280429481018386
Epoch: 1 Idx: 5000 Loss: 0.010236022507810074
Epoch: 2 Idx: 0 Loss: 0.005990921446389769
Epoch: 2 Idx: 5000 Loss: 0.012002927776511775
Epoch: 3 Idx: 0 Loss: 0.01580300638359432
Epoch: 3 Idx: 5000 Loss: 0.013352586610394724
Epoch: 4 Idx: 0 Loss: 0.007697426276532268
Epoch: 4 Idx: 5000 Loss: 0.012047552556672985
Epoch: 5 Idx: 0 Loss: 0.010044346312273116
Epoch: 5 Idx: 5000 Loss: 0.01426798645441945
Epoch: 6 Idx: 0 Loss: 0.012092678174975688
Epoch: 6 Idx: 5000 Loss: 0.027629718510459093
Epoch: 7 Idx: 0 Loss: 0.01066915998382739
Epoch: 7 Idx: 5000 Loss: 0.02034461802443968
Epoch: 8 Idx: 0 Loss: 0.020623559789468858
Epoch: 8 Idx: 5000 Loss: 0.017517510569045963
Epoch: 9 Idx: 0 Loss: 0.024424988822354724
Epoch: 9 Idx: 5000 Loss: 0.028136030251879704
Epoch: 10 Idx: 0 Loss: 0.026948507944482822
Epoch: 10 Idx: 5000 Loss: 0.01040435868948827
Epoch: 11 Idx: 0 Loss: 0.010256079558734836
Epoch: 11 Idx: 5000 Loss: 0.01050514007531081
Epoch: 12 Idx: 0 Loss: 0.01857447841215211
Epoch: 12 Idx: 5000 Loss: 0.011024246606752195
Epoch: 13 Idx: 0 Loss: 0.015986542727446332
Epoch: 13 Idx: 5000 Loss: 0.035181434050946744
Epoch: 14 Idx: 0 Loss: 0.006470923988361537
Epoch: 14 Idx: 5000 Loss: 0.008612859835332689
Epoch: 15 Idx: 0 Loss: 0.032734723325094854
Epoch: 15 Idx: 5000 Loss: 0.04931367162620437
Epoch: 16 Idx: 0 Loss: 0.020940371393473566
Epoch: 16 Idx: 5000 Loss: 0.012077638843140101
Epoch: 17 Idx: 0 Loss: 0.028746105098006517
Epoch: 17 Idx: 5000 Loss: 0.028955368739175293
Epoch: 18 Idx: 0 Loss: 0.010815277692109052
Epoch: 18 Idx: 5000 Loss: 0.02791929967137325
Epoch: 19 Idx: 0 Loss: 0.009844045282829866
Epoch: 19 Idx: 5000 Loss: 0.012953705644271389
Epoch: 20 Idx: 0 Loss: 0.0103240836668013
Epoch: 20 Idx: 5000 Loss: 0.018468353755097804
Epoch: 21 Idx: 0 Loss: 0.012319193697020826
Epoch: 21 Idx: 5000 Loss: 0.01543280369872659
Epoch: 22 Idx: 0 Loss: 0.00848557810975521
Epoch: 22 Idx: 5000 Loss: 0.008104715765137951
Epoch: 23 Idx: 0 Loss: 0.03633705814061747
Epoch: 23 Idx: 5000 Loss: 0.006845803652811063
Epoch: 24 Idx: 0 Loss: 0.011198059869310828
Epoch: 24 Idx: 5000 Loss: 0.02392194132863553
Epoch: 25 Idx: 0 Loss: 0.024034327275813866
Epoch: 25 Idx: 5000 Loss: 0.024313896862717996
Epoch: 26 Idx: 0 Loss: 0.01562220232830355
Epoch: 26 Idx: 5000 Loss: 0.017217831558054505
Epoch: 27 Idx: 0 Loss: 0.013485487877202572
Epoch: 27 Idx: 5000 Loss: 0.021612204888815944
Epoch: 28 Idx: 0 Loss: 0.058228065216336194
Epoch: 28 Idx: 5000 Loss: 0.017865820572933885
Epoch: 29 Idx: 0 Loss: 0.01382091643664793
Epoch: 29 Idx: 5000 Loss: 0.011548877138657957
Epoch: 30 Idx: 0 Loss: 0.01932429530989967
Epoch: 30 Idx: 5000 Loss: 0.018580615948705317
Epoch: 31 Idx: 0 Loss: 0.014308084559297366
Epoch: 31 Idx: 5000 Loss: 0.015833377809207613
Epoch: 32 Idx: 0 Loss: 0.010437965741805872
Epoch: 32 Idx: 5000 Loss: 0.012785007596204516
Epoch: 33 Idx: 0 Loss: 0.019973906051517068
Epoch: 33 Idx: 5000 Loss: 0.02523098284939642
Epoch: 34 Idx: 0 Loss: 0.007704435085814586
Epoch: 34 Idx: 5000 Loss: 0.00980340754315401
Epoch: 35 Idx: 0 Loss: 0.01564015369856736
Epoch: 35 Idx: 5000 Loss: 0.00912749579416277
Epoch: 36 Idx: 0 Loss: 0.013234047010450454
Epoch: 36 Idx: 5000 Loss: 0.008246008061206681
Epoch: 37 Idx: 0 Loss: 0.02446238306588288
Epoch: 37 Idx: 5000 Loss: 0.01460355975478982
Epoch: 38 Idx: 0 Loss: 0.013124562502261662
Epoch: 38 Idx: 5000 Loss: 0.014435241862722789
Epoch: 39 Idx: 0 Loss: 0.009544284077724653
Epoch: 39 Idx: 5000 Loss: 0.013323592597259562
Epoch: 40 Idx: 0 Loss: 0.01565208101941134
Epoch: 40 Idx: 5000 Loss: 0.012571188053051172
Epoch: 41 Idx: 0 Loss: 0.012501581809439196
Epoch: 41 Idx: 5000 Loss: 0.04325947691776727
Epoch: 42 Idx: 0 Loss: 0.020747274604330207
Epoch: 42 Idx: 5000 Loss: 0.011503852759510592
Epoch: 43 Idx: 0 Loss: 0.009855353452594806
Epoch: 43 Idx: 5000 Loss: 0.010116421369117858
Epoch: 44 Idx: 0 Loss: 0.033449564685600015
Epoch: 44 Idx: 5000 Loss: 0.05241096699602595
Epoch: 45 Idx: 0 Loss: 0.0263087715950347
Epoch: 45 Idx: 5000 Loss: 0.022361569174952883
Epoch: 46 Idx: 0 Loss: 0.01741249741768144
Epoch: 46 Idx: 5000 Loss: 0.011686496711307268
Epoch: 47 Idx: 0 Loss: 0.00935493993352245
Epoch: 47 Idx: 5000 Loss: 0.021316913916952073
Epoch: 48 Idx: 0 Loss: 0.011346355640645902
Epoch: 48 Idx: 5000 Loss: 0.016106765433750496
Epoch: 49 Idx: 0 Loss: 0.008761360213556231
Epoch: 49 Idx: 5000 Loss: 0.02575898892115836
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.16093751053765293
Epoch: 0 Idx: 5000 Loss: 0.011425389276851775
Epoch: 1 Idx: 0 Loss: 0.02014838290584732
Epoch: 1 Idx: 5000 Loss: 0.006968493799246429
Epoch: 2 Idx: 0 Loss: 0.0310825538910173
Epoch: 2 Idx: 5000 Loss: 0.009073472947398072
Epoch: 3 Idx: 0 Loss: 0.00914034878806841
Epoch: 3 Idx: 5000 Loss: 0.018966347033945615
Epoch: 4 Idx: 0 Loss: 0.018780869250502825
Epoch: 4 Idx: 5000 Loss: 0.027567789992767003
Epoch: 5 Idx: 0 Loss: 0.01884329226442376
Epoch: 5 Idx: 5000 Loss: 0.02626161792625819
Epoch: 6 Idx: 0 Loss: 0.010246177966172604
Epoch: 6 Idx: 5000 Loss: 0.020397331812881517
Epoch: 7 Idx: 0 Loss: 0.01440905072296574
Epoch: 7 Idx: 5000 Loss: 0.014629937710113004
Epoch: 8 Idx: 0 Loss: 0.01540990511175248
Epoch: 8 Idx: 5000 Loss: 0.005002562534056025
Epoch: 9 Idx: 0 Loss: 0.01864213970716272
Epoch: 9 Idx: 5000 Loss: 0.009616352266109775
Epoch: 10 Idx: 0 Loss: 0.01979245819897052
Epoch: 10 Idx: 5000 Loss: 0.008556994048097545
Epoch: 11 Idx: 0 Loss: 0.019872960179648833
Epoch: 11 Idx: 5000 Loss: 0.025664280834987358
Epoch: 12 Idx: 0 Loss: 0.025296764896033542
Epoch: 12 Idx: 5000 Loss: 0.01775705054871618
Epoch: 13 Idx: 0 Loss: 0.014931251151945307
Epoch: 13 Idx: 5000 Loss: 0.011304540715217404
Epoch: 14 Idx: 0 Loss: 0.020471750645359766
Epoch: 14 Idx: 5000 Loss: 0.020712870803730646
Epoch: 15 Idx: 0 Loss: 0.006642287552775942
Epoch: 15 Idx: 5000 Loss: 0.024696027785248667
Epoch: 16 Idx: 0 Loss: 0.014402461699218792
Epoch: 16 Idx: 5000 Loss: 0.013062013612274277
Epoch: 17 Idx: 0 Loss: 0.017336469711538734
Epoch: 17 Idx: 5000 Loss: 0.010325673468278958
Epoch: 18 Idx: 0 Loss: 0.0105348910981909
Epoch: 18 Idx: 5000 Loss: 0.009270567244213383
Epoch: 19 Idx: 0 Loss: 0.00880330613911712
Epoch: 19 Idx: 5000 Loss: 0.020318559563720164
Epoch: 20 Idx: 0 Loss: 0.029853169605366818
Epoch: 20 Idx: 5000 Loss: 0.020158282511369426
Epoch: 21 Idx: 0 Loss: 0.008655139447422522
Epoch: 21 Idx: 5000 Loss: 0.03775172663315669
Epoch: 22 Idx: 0 Loss: 0.027109063753904497
Epoch: 22 Idx: 5000 Loss: 0.012069738280521557
Epoch: 23 Idx: 0 Loss: 0.01872685501105859
Epoch: 23 Idx: 5000 Loss: 0.013701205378069618
Epoch: 24 Idx: 0 Loss: 0.022891003813733067
Epoch: 24 Idx: 5000 Loss: 0.010415124554623277
Epoch: 25 Idx: 0 Loss: 0.008087548343679096
Epoch: 25 Idx: 5000 Loss: 0.011239244159557524
Epoch: 26 Idx: 0 Loss: 0.01780417503485858
Epoch: 26 Idx: 5000 Loss: 0.01956896391459443
Epoch: 27 Idx: 0 Loss: 0.005733973288127867
Epoch: 27 Idx: 5000 Loss: 0.04073038948045226
Epoch: 28 Idx: 0 Loss: 0.011228881264496511
Epoch: 28 Idx: 5000 Loss: 0.033775299203847524
Epoch: 29 Idx: 0 Loss: 0.01698307164821632
Epoch: 29 Idx: 5000 Loss: 0.03050530372807501
Epoch: 30 Idx: 0 Loss: 0.007086494764043047
Epoch: 30 Idx: 5000 Loss: 0.01059756608799784
Epoch: 31 Idx: 0 Loss: 0.025088994159234847
Epoch: 31 Idx: 5000 Loss: 0.013987721884454914
Epoch: 32 Idx: 0 Loss: 0.014661302046559837
Epoch: 32 Idx: 5000 Loss: 0.010236812935633782
Epoch: 33 Idx: 0 Loss: 0.008278400020561088
Epoch: 33 Idx: 5000 Loss: 0.017143576729883023
Epoch: 34 Idx: 0 Loss: 0.0501729154233949
Epoch: 34 Idx: 5000 Loss: 0.0049569810255040946
Epoch: 35 Idx: 0 Loss: 0.0368111165728573
Epoch: 35 Idx: 5000 Loss: 0.007470601089430274
Epoch: 36 Idx: 0 Loss: 0.00986125917922517
Epoch: 36 Idx: 5000 Loss: 0.011953905651741389
Epoch: 37 Idx: 0 Loss: 0.006373514401212521
Epoch: 37 Idx: 5000 Loss: 0.015589320916580916
Epoch: 38 Idx: 0 Loss: 0.011422801353393122
Epoch: 38 Idx: 5000 Loss: 0.024747345411186485
Epoch: 39 Idx: 0 Loss: 0.019103663924478126
Epoch: 39 Idx: 5000 Loss: 0.011930744103590046
Epoch: 40 Idx: 0 Loss: 0.0098289964372375
Epoch: 40 Idx: 5000 Loss: 0.00992244420199305
Epoch: 41 Idx: 0 Loss: 0.0039300949834426635
Epoch: 41 Idx: 5000 Loss: 0.015104013541257594
Epoch: 42 Idx: 0 Loss: 0.01127374881222474
Epoch: 42 Idx: 5000 Loss: 0.015030303668170592
Epoch: 43 Idx: 0 Loss: 0.008558434260184645
Epoch: 43 Idx: 5000 Loss: 0.008387005474317743
Epoch: 44 Idx: 0 Loss: 0.009842030078962179
Epoch: 44 Idx: 5000 Loss: 0.009831832625242407
Epoch: 45 Idx: 0 Loss: 0.03558197642120314
Epoch: 45 Idx: 5000 Loss: 0.010843348182461139
Epoch: 46 Idx: 0 Loss: 0.012114725927176832
Epoch: 46 Idx: 5000 Loss: 0.018275176854956585
Epoch: 47 Idx: 0 Loss: 0.009854509629520041
Epoch: 47 Idx: 5000 Loss: 0.02159736280102548
Epoch: 48 Idx: 0 Loss: 0.017046438348516085
Epoch: 48 Idx: 5000 Loss: 0.017035100653405813
Epoch: 49 Idx: 0 Loss: 0.01597472472071826
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc237>
Subject: Job 4066802: <python main.py 3 20 False False> in cluster <dcc> Exited

Job <python main.py 3 20 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:35 2020
Job was executed on host(s) <dccxc237>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:36 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 20 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46187.68 sec.
    Max Memory :                                 2937 MB
    Average Memory :                             2728.13 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40480.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46204 sec.
    Turnaround time :                            46205 sec.

The output (if any) is above this job summary.

