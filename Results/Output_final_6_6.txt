2020-09-15 15:49:38.981559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.303155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:42.415217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:42.415308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:42.417423: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:42.419008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:42.419523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:42.421529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:42.423034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:42.423250: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:42.423272: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:42.423615: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:42.431951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600025000 Hz
2020-09-15 15:49:42.432144: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557f238b36f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:42.432166: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:42.434282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:42.434319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19598978221814933
Epoch: 0 Idx: 5000 Loss: 0.003012060102295942
Epoch: 1 Idx: 0 Loss: 0.03139301304947124
Epoch: 1 Idx: 5000 Loss: 0.014762236636834694
Epoch: 2 Idx: 0 Loss: 0.010843880845274004
Epoch: 2 Idx: 5000 Loss: 0.013166420902378077
Epoch: 3 Idx: 0 Loss: 0.008634712295614279
Epoch: 3 Idx: 5000 Loss: 0.034315694544729713
Epoch: 4 Idx: 0 Loss: 0.012929475344473477
Epoch: 4 Idx: 5000 Loss: 0.008421155425758445
Epoch: 5 Idx: 0 Loss: 0.02441722237059029
Epoch: 5 Idx: 5000 Loss: 0.02423104104286016
Epoch: 6 Idx: 0 Loss: 0.013544809053872994
Epoch: 6 Idx: 5000 Loss: 0.015348086685025825
Epoch: 7 Idx: 0 Loss: 0.016352419799127195
Epoch: 7 Idx: 5000 Loss: 0.015181673147067433
Epoch: 8 Idx: 0 Loss: 0.012440276585715792
Epoch: 8 Idx: 5000 Loss: 0.04374048498955944
Epoch: 9 Idx: 0 Loss: 0.0157461120049271
Epoch: 9 Idx: 5000 Loss: 0.018823490635254212
Epoch: 10 Idx: 0 Loss: 0.02257764462710227
Epoch: 10 Idx: 5000 Loss: 0.024906022562255534
Epoch: 11 Idx: 0 Loss: 0.018471732447224016
Epoch: 11 Idx: 5000 Loss: 0.03786687573423016
Epoch: 12 Idx: 0 Loss: 0.019335634505010878
Epoch: 12 Idx: 5000 Loss: 0.03457688756881744
Epoch: 13 Idx: 0 Loss: 0.011446947402654579
Epoch: 13 Idx: 5000 Loss: 0.010420759492297198
Epoch: 14 Idx: 0 Loss: 0.008793678286457916
Epoch: 14 Idx: 5000 Loss: 0.03115694362937863
Epoch: 15 Idx: 0 Loss: 0.011952790178980025
Epoch: 15 Idx: 5000 Loss: 0.02321531484102675
Epoch: 16 Idx: 0 Loss: 0.01079342060970052
Epoch: 16 Idx: 5000 Loss: 0.011575930749824895
Epoch: 17 Idx: 0 Loss: 0.0064419837680052975
Epoch: 17 Idx: 5000 Loss: 0.013746592660017647
Epoch: 18 Idx: 0 Loss: 0.015719274502026565
Epoch: 18 Idx: 5000 Loss: 0.004708303023660831
Epoch: 19 Idx: 0 Loss: 0.011703302882588666
Epoch: 19 Idx: 5000 Loss: 0.023991873026040576
Epoch: 20 Idx: 0 Loss: 0.007798517208491923
Epoch: 20 Idx: 5000 Loss: 0.016677774821104434
Epoch: 21 Idx: 0 Loss: 0.009047383027131588
Epoch: 21 Idx: 5000 Loss: 0.017417787810372128
Epoch: 22 Idx: 0 Loss: 0.015819534447572555
Epoch: 22 Idx: 5000 Loss: 0.017864294559545583
Epoch: 23 Idx: 0 Loss: 0.016818215169402406
Epoch: 23 Idx: 5000 Loss: 0.026972262305547483
Epoch: 24 Idx: 0 Loss: 0.009486385320352161
Epoch: 24 Idx: 5000 Loss: 0.0249221804185968
Epoch: 25 Idx: 0 Loss: 0.006854949699590256
Epoch: 25 Idx: 5000 Loss: 0.010962629080427867
Epoch: 26 Idx: 0 Loss: 0.013683767207518033
Epoch: 26 Idx: 5000 Loss: 0.01461197090964448
Epoch: 27 Idx: 0 Loss: 0.023742262496196532
Epoch: 27 Idx: 5000 Loss: 0.03895198263469107
Epoch: 28 Idx: 0 Loss: 0.024861201122385077
Epoch: 28 Idx: 5000 Loss: 0.01970973510152935
Epoch: 29 Idx: 0 Loss: 0.027990210491224146
Epoch: 29 Idx: 5000 Loss: 0.009320356307065488
Epoch: 30 Idx: 0 Loss: 0.034133418477843014
Epoch: 30 Idx: 5000 Loss: 0.012880520349982152
Epoch: 31 Idx: 0 Loss: 0.013473680219192237
Epoch: 31 Idx: 5000 Loss: 0.004590402761006802
Epoch: 32 Idx: 0 Loss: 0.02415296548716909
Epoch: 32 Idx: 5000 Loss: 0.014930665079113536
Epoch: 33 Idx: 0 Loss: 0.006392702390055791
Epoch: 33 Idx: 5000 Loss: 0.012510646972392328
Epoch: 34 Idx: 0 Loss: 0.009211983021124165
Epoch: 34 Idx: 5000 Loss: 0.011066905136295381
Epoch: 35 Idx: 0 Loss: 0.016693730214550895
Epoch: 35 Idx: 5000 Loss: 0.012936466463388762
Epoch: 36 Idx: 0 Loss: 0.025957753427088774
Epoch: 36 Idx: 5000 Loss: 0.00956128225637326
Epoch: 37 Idx: 0 Loss: 0.03986753954420698
Epoch: 37 Idx: 5000 Loss: 0.022694007052725576
Epoch: 38 Idx: 0 Loss: 0.01351245141593934
Epoch: 38 Idx: 5000 Loss: 0.008576272664927245
Epoch: 39 Idx: 0 Loss: 0.015215764897649715
Epoch: 39 Idx: 5000 Loss: 0.016966295528056435
Epoch: 40 Idx: 0 Loss: 0.009581501109503406
Epoch: 40 Idx: 5000 Loss: 0.042631970485434066
Epoch: 41 Idx: 0 Loss: 0.008734238106159871
Epoch: 41 Idx: 5000 Loss: 0.012069044457546658
Epoch: 42 Idx: 0 Loss: 0.020383387737617567
Epoch: 42 Idx: 5000 Loss: 0.023437598440614146
Epoch: 43 Idx: 0 Loss: 0.019182953191051424
Epoch: 43 Idx: 5000 Loss: 0.012511154733581177
Epoch: 44 Idx: 0 Loss: 0.00914704905891537
Epoch: 44 Idx: 5000 Loss: 0.0077660720827191655
Epoch: 45 Idx: 0 Loss: 0.008407285969352876
Epoch: 45 Idx: 5000 Loss: 0.01094109847612231
Epoch: 46 Idx: 0 Loss: 0.017390255463764843
Epoch: 46 Idx: 5000 Loss: 0.008978585044846726
Epoch: 47 Idx: 0 Loss: 0.009567166287973244
Epoch: 47 Idx: 5000 Loss: 0.007261756056777979
Epoch: 48 Idx: 0 Loss: 0.016085906004230995
Epoch: 48 Idx: 5000 Loss: 0.028202614956907103
Epoch: 49 Idx: 0 Loss: 0.023496189742321268
Epoch: 49 Idx: 5000 Loss: 0.009835532846048184
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.12910141172127443
Epoch: 0 Idx: 5000 Loss: 0.015162373612045586
Epoch: 1 Idx: 0 Loss: 0.026832310727546375
Epoch: 1 Idx: 5000 Loss: 0.013556519485981269
Epoch: 2 Idx: 0 Loss: 0.016864935203088276
Epoch: 2 Idx: 5000 Loss: 0.016262086128926944
Epoch: 3 Idx: 0 Loss: 0.023794917002442205
Epoch: 3 Idx: 5000 Loss: 0.018273528244688766
Epoch: 4 Idx: 0 Loss: 0.01563627264657646
Epoch: 4 Idx: 5000 Loss: 0.010172676370470084
Epoch: 5 Idx: 0 Loss: 0.015279151327914405
Epoch: 5 Idx: 5000 Loss: 0.01619045405994563
Epoch: 6 Idx: 0 Loss: 0.008432725814418453
Epoch: 6 Idx: 5000 Loss: 0.03678906691700399
Epoch: 7 Idx: 0 Loss: 0.0074910325975689526
Epoch: 7 Idx: 5000 Loss: 0.03390760545113873
Epoch: 8 Idx: 0 Loss: 0.01075553360701183
Epoch: 8 Idx: 5000 Loss: 0.015306724139742083
Epoch: 9 Idx: 0 Loss: 0.00793376589429596
Epoch: 9 Idx: 5000 Loss: 0.007054323839814294
Epoch: 10 Idx: 0 Loss: 0.03022311480283473
Epoch: 10 Idx: 5000 Loss: 0.012177778265838494
Epoch: 11 Idx: 0 Loss: 0.005673306361534148
Epoch: 11 Idx: 5000 Loss: 0.011038634808541939
Epoch: 12 Idx: 0 Loss: 0.01518336938576425
Epoch: 12 Idx: 5000 Loss: 0.016012309023169052
Epoch: 13 Idx: 0 Loss: 0.012802581772648872
Epoch: 13 Idx: 5000 Loss: 0.023948259287101866
Epoch: 14 Idx: 0 Loss: 0.019636184820557987
Epoch: 14 Idx: 5000 Loss: 0.005326782247775771
Epoch: 15 Idx: 0 Loss: 0.024243099736045697
Epoch: 15 Idx: 5000 Loss: 0.013348513415310192
Epoch: 16 Idx: 0 Loss: 0.03188158600661646
Epoch: 16 Idx: 5000 Loss: 0.019908638732520963
Epoch: 17 Idx: 0 Loss: 0.016701302762086638
Epoch: 17 Idx: 5000 Loss: 0.014469801225178297
Epoch: 18 Idx: 0 Loss: 0.016426889271759025
Epoch: 18 Idx: 5000 Loss: 0.009436928771777583
Epoch: 19 Idx: 0 Loss: 0.01760646309006566
Epoch: 19 Idx: 5000 Loss: 0.015831300484561453
Epoch: 20 Idx: 0 Loss: 0.014978218985530303
Epoch: 20 Idx: 5000 Loss: 0.021690487451637076
Epoch: 21 Idx: 0 Loss: 0.02359296518508491
Epoch: 21 Idx: 5000 Loss: 0.019010235298822738
Epoch: 22 Idx: 0 Loss: 0.010172515743290422
Epoch: 22 Idx: 5000 Loss: 0.028448952781627786
Epoch: 23 Idx: 0 Loss: 0.015472625259314332
Epoch: 23 Idx: 5000 Loss: 0.007710216397300599
Epoch: 24 Idx: 0 Loss: 0.017514741535311885
Epoch: 24 Idx: 5000 Loss: 0.01695843147959678
Epoch: 25 Idx: 0 Loss: 0.021984526630610544
Epoch: 25 Idx: 5000 Loss: 0.009754492447504978
Epoch: 26 Idx: 0 Loss: 0.012832667146246153
Epoch: 26 Idx: 5000 Loss: 0.0067683527907661176
Epoch: 27 Idx: 0 Loss: 0.007279275706004004
Epoch: 27 Idx: 5000 Loss: 0.02596224159438965
Epoch: 28 Idx: 0 Loss: 0.012584216679021796
Epoch: 28 Idx: 5000 Loss: 0.010093324590247164
Epoch: 29 Idx: 0 Loss: 0.0092735243736484
Epoch: 29 Idx: 5000 Loss: 0.008386196264082501
Epoch: 30 Idx: 0 Loss: 0.012988534568043806
Epoch: 30 Idx: 5000 Loss: 0.02889647685668028
Epoch: 31 Idx: 0 Loss: 0.027149863029045505
Epoch: 31 Idx: 5000 Loss: 0.00830303009003924
Epoch: 32 Idx: 0 Loss: 0.01745979260320412
Epoch: 32 Idx: 5000 Loss: 0.00834056767183917
Epoch: 33 Idx: 0 Loss: 0.011337198656702793
Epoch: 33 Idx: 5000 Loss: 0.027397250460619263
Epoch: 34 Idx: 0 Loss: 0.011721239666890797
Epoch: 34 Idx: 5000 Loss: 0.007963420954164161
Epoch: 35 Idx: 0 Loss: 0.018096105332638557
Epoch: 35 Idx: 5000 Loss: 0.02174009947978276
Epoch: 36 Idx: 0 Loss: 0.030678843379068857
Epoch: 36 Idx: 5000 Loss: 0.022854231834912034
Epoch: 37 Idx: 0 Loss: 0.008619276828990566
Epoch: 37 Idx: 5000 Loss: 0.018248607829990385
Epoch: 38 Idx: 0 Loss: 0.025081173638340372
Epoch: 38 Idx: 5000 Loss: 0.006279472470662825
Epoch: 39 Idx: 0 Loss: 0.013998924197036713
Epoch: 39 Idx: 5000 Loss: 0.014276197625705199
Epoch: 40 Idx: 0 Loss: 0.03203945622773701
Epoch: 40 Idx: 5000 Loss: 0.012384043192423748
Epoch: 41 Idx: 0 Loss: 0.019687315009499582
Epoch: 41 Idx: 5000 Loss: 0.003936648642615701
Epoch: 42 Idx: 0 Loss: 0.014291277522241883
Epoch: 42 Idx: 5000 Loss: 0.024307657153384954
Epoch: 43 Idx: 0 Loss: 0.01869143886819731
Epoch: 43 Idx: 5000 Loss: 0.022333922370799973
Epoch: 44 Idx: 0 Loss: 0.027905050200184533
Epoch: 44 Idx: 5000 Loss: 0.011220428762222293
Epoch: 45 Idx: 0 Loss: 0.011564570830261531
Epoch: 45 Idx: 5000 Loss: 0.007138014193127605
Epoch: 46 Idx: 0 Loss: 0.014761750112017202
Epoch: 46 Idx: 5000 Loss: 0.016673632653203454
Epoch: 47 Idx: 0 Loss: 0.011028884554574247
Epoch: 47 Idx: 5000 Loss: 0.043974649569804014
Epoch: 48 Idx: 0 Loss: 0.00841850932624627
Epoch: 48 Idx: 5000 Loss: 0.02005664376387719
Epoch: 49 Idx: 0 Loss: 0.019465366652402016
Epoch: 49 Idx: 5000 Loss: 0.014777133351835796
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.13526698742859694
Epoch: 0 Idx: 5000 Loss: 0.014513621507393538
Epoch: 1 Idx: 0 Loss: 0.03726701367213275
Epoch: 1 Idx: 5000 Loss: 0.020044454757220012
Epoch: 2 Idx: 0 Loss: 0.022732806737264147
Epoch: 2 Idx: 5000 Loss: 0.01214253000943572
Epoch: 3 Idx: 0 Loss: 0.01112949801523893
Epoch: 3 Idx: 5000 Loss: 0.00808555264310873
Epoch: 4 Idx: 0 Loss: 0.01624788932279809
Epoch: 4 Idx: 5000 Loss: 0.016035310747444177
Epoch: 5 Idx: 0 Loss: 0.01921915779514628
Epoch: 5 Idx: 5000 Loss: 0.009382084041517347
Epoch: 6 Idx: 0 Loss: 0.04770780195048826
Epoch: 6 Idx: 5000 Loss: 0.05523115648945866
Epoch: 7 Idx: 0 Loss: 0.02527354820890779
Epoch: 7 Idx: 5000 Loss: 0.012218306849840089
Epoch: 8 Idx: 0 Loss: 0.007818889417853811
Epoch: 8 Idx: 5000 Loss: 0.010797639982521198
Epoch: 9 Idx: 0 Loss: 0.01509088287992583
Epoch: 9 Idx: 5000 Loss: 0.014589814343407856
Epoch: 10 Idx: 0 Loss: 0.023724373674594214
Epoch: 10 Idx: 5000 Loss: 0.021340306325932104
Epoch: 11 Idx: 0 Loss: 0.028535922625908147
Epoch: 11 Idx: 5000 Loss: 0.009604227335561943
Epoch: 12 Idx: 0 Loss: 0.024858663263478072
Epoch: 12 Idx: 5000 Loss: 0.024552654548071623
Epoch: 13 Idx: 0 Loss: 0.017412308865087663
Epoch: 13 Idx: 5000 Loss: 0.017151911384078698
Epoch: 14 Idx: 0 Loss: 0.011117435240484568
Epoch: 14 Idx: 5000 Loss: 0.011870643791908185
Epoch: 15 Idx: 0 Loss: 0.007082793369234534
Epoch: 15 Idx: 5000 Loss: 0.015100870996594438
Epoch: 16 Idx: 0 Loss: 0.029763042886709605
Epoch: 16 Idx: 5000 Loss: 0.01630036794578893
Epoch: 17 Idx: 0 Loss: 0.020125340759762373
Epoch: 17 Idx: 5000 Loss: 0.02350400084280823
Epoch: 18 Idx: 0 Loss: 0.01730800572665715
Epoch: 18 Idx: 5000 Loss: 0.020130250049487493
Epoch: 19 Idx: 0 Loss: 0.020886631196110984
Epoch: 19 Idx: 5000 Loss: 0.013495756492089067
Epoch: 20 Idx: 0 Loss: 0.00843137051000228
Epoch: 20 Idx: 5000 Loss: 0.03706947362492266
Epoch: 21 Idx: 0 Loss: 0.00738179016910946
Epoch: 21 Idx: 5000 Loss: 0.012708108099342504
Epoch: 22 Idx: 0 Loss: 0.016458398964622378
Epoch: 22 Idx: 5000 Loss: 0.009560212586200833
Epoch: 23 Idx: 0 Loss: 0.007155849802655258
Epoch: 23 Idx: 5000 Loss: 0.008093987535429246
Epoch: 24 Idx: 0 Loss: 0.012168621169056034
Epoch: 24 Idx: 5000 Loss: 0.011686495103420076
Epoch: 25 Idx: 0 Loss: 0.015360582286684049
Epoch: 25 Idx: 5000 Loss: 0.014484848231484125
Epoch: 26 Idx: 0 Loss: 0.015418555246100994
Epoch: 26 Idx: 5000 Loss: 0.005337355119453378
Epoch: 27 Idx: 0 Loss: 0.010642131024013676
Epoch: 27 Idx: 5000 Loss: 0.007894043683342702
Epoch: 28 Idx: 0 Loss: 0.008556077014973367
Epoch: 28 Idx: 5000 Loss: 0.011266229851094756
Epoch: 29 Idx: 0 Loss: 0.008919551882991147
Epoch: 29 Idx: 5000 Loss: 0.02743273608806475
Epoch: 30 Idx: 0 Loss: 0.010775705625847655
Epoch: 30 Idx: 5000 Loss: 0.0065658535419370525
Epoch: 31 Idx: 0 Loss: 0.014879562236221475
Epoch: 31 Idx: 5000 Loss: 0.01682230453898819
Epoch: 32 Idx: 0 Loss: 0.014253636440294181
Epoch: 32 Idx: 5000 Loss: 0.005496089567353651
Epoch: 33 Idx: 0 Loss: 0.006997297788948445
Epoch: 33 Idx: 5000 Loss: 0.01576617747309217
Epoch: 34 Idx: 0 Loss: 0.01677406925285776
Epoch: 34 Idx: 5000 Loss: 0.008703680431182123
Epoch: 35 Idx: 0 Loss: 0.01174098477321154
Epoch: 35 Idx: 5000 Loss: 0.019544516579855127
Epoch: 36 Idx: 0 Loss: 0.018511503913961228
Epoch: 36 Idx: 5000 Loss: 0.026349921391274442
Epoch: 37 Idx: 0 Loss: 0.014230894626918117
Epoch: 37 Idx: 5000 Loss: 0.016902952198749488
Epoch: 38 Idx: 0 Loss: 0.017576954499291936
Epoch: 38 Idx: 5000 Loss: 0.007308772836207202
Epoch: 39 Idx: 0 Loss: 0.01248973546644202
Epoch: 39 Idx: 5000 Loss: 0.007159117969632964
Epoch: 40 Idx: 0 Loss: 0.02152988363797872
Epoch: 40 Idx: 5000 Loss: 0.011255873370372847
Epoch: 41 Idx: 0 Loss: 0.020921639594176596
Epoch: 41 Idx: 5000 Loss: 0.008688691002225354
Epoch: 42 Idx: 0 Loss: 0.006778454685708861
Epoch: 42 Idx: 5000 Loss: 0.008777802741353816
Epoch: 43 Idx: 0 Loss: 0.005590210423395718
Epoch: 43 Idx: 5000 Loss: 0.009133106028466105
Epoch: 44 Idx: 0 Loss: 0.019575471059506223
Epoch: 44 Idx: 5000 Loss: 0.019786054220758357
Epoch: 45 Idx: 0 Loss: 0.027062687453207196
Epoch: 45 Idx: 5000 Loss: 0.01847110422472343
Epoch: 46 Idx: 0 Loss: 0.01852101274611707
Epoch: 46 Idx: 5000 Loss: 0.014025907482036942
Epoch: 47 Idx: 0 Loss: 0.01268041793571606
Epoch: 47 Idx: 5000 Loss: 0.017498253144107186
Epoch: 48 Idx: 0 Loss: 0.015119233635652018
Epoch: 48 Idx: 5000 Loss: 0.007442102107778164
Epoch: 49 Idx: 0 Loss: 0.017793442024754774
Epoch: 49 Idx: 5000 Loss: 0.005457248639486031
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.2225049216607332
Epoch: 0 Idx: 5000 Loss: 0.012652999528648585
Epoch: 1 Idx: 0 Loss: 0.023241803104685106
Epoch: 1 Idx: 5000 Loss: 0.014378089879030156
Epoch: 2 Idx: 0 Loss: 0.006607420844567987
Epoch: 2 Idx: 5000 Loss: 0.027443745224311204
Epoch: 3 Idx: 0 Loss: 0.011238783499756783
Epoch: 3 Idx: 5000 Loss: 0.03141097207774114
Epoch: 4 Idx: 0 Loss: 0.026934552129966816
Epoch: 4 Idx: 5000 Loss: 0.009737976811936151
Epoch: 5 Idx: 0 Loss: 0.02891161247126119
Epoch: 5 Idx: 5000 Loss: 0.008241048058809642
Epoch: 6 Idx: 0 Loss: 0.01272336205844506
Epoch: 6 Idx: 5000 Loss: 0.008809465739408296
Epoch: 7 Idx: 0 Loss: 0.031155510638109233
Epoch: 7 Idx: 5000 Loss: 0.015338282134484325
Epoch: 8 Idx: 0 Loss: 0.0585845726536022
Epoch: 8 Idx: 5000 Loss: 0.011364292080011107
Epoch: 9 Idx: 0 Loss: 0.018019068236159456
Epoch: 9 Idx: 5000 Loss: 0.005312016693856636
Epoch: 10 Idx: 0 Loss: 0.01660603948876744
Epoch: 10 Idx: 5000 Loss: 0.0030078537040105066
Epoch: 11 Idx: 0 Loss: 0.013590553620620834
Epoch: 11 Idx: 5000 Loss: 0.018355362403409275
Epoch: 12 Idx: 0 Loss: 0.006929434839190708
Epoch: 12 Idx: 5000 Loss: 0.02676982960522867
Epoch: 13 Idx: 0 Loss: 0.014481560367690938
Epoch: 13 Idx: 5000 Loss: 0.03220795425442799
Epoch: 14 Idx: 0 Loss: 0.027647565215550465
Epoch: 14 Idx: 5000 Loss: 0.011067788352941057
Epoch: 15 Idx: 0 Loss: 0.016863643944570753
Epoch: 15 Idx: 5000 Loss: 0.010129666960401492
Epoch: 16 Idx: 0 Loss: 0.01814767009213545
Epoch: 16 Idx: 5000 Loss: 0.023283579837737697
Epoch: 17 Idx: 0 Loss: 0.01094708233779798
Epoch: 17 Idx: 5000 Loss: 0.032368649516665376
Epoch: 18 Idx: 0 Loss: 0.01001107199645298
Epoch: 18 Idx: 5000 Loss: 0.016189136693556476
Epoch: 19 Idx: 0 Loss: 0.010617381448060424
Epoch: 19 Idx: 5000 Loss: 0.013194887551335962
Epoch: 20 Idx: 0 Loss: 0.00638904826054844
Epoch: 20 Idx: 5000 Loss: 0.007579925733774999
Epoch: 21 Idx: 0 Loss: 0.020768849967327842
Epoch: 21 Idx: 5000 Loss: 0.01348641485436385
Epoch: 22 Idx: 0 Loss: 0.008754978533816878
Epoch: 22 Idx: 5000 Loss: 0.018280234149233635
Epoch: 23 Idx: 0 Loss: 0.014478595612935196
Epoch: 23 Idx: 5000 Loss: 0.02343202179079713
Epoch: 24 Idx: 0 Loss: 0.00943714575013346
Epoch: 24 Idx: 5000 Loss: 0.006172030734476419
Epoch: 25 Idx: 0 Loss: 0.012688134057839974
Epoch: 25 Idx: 5000 Loss: 0.022175704429466182
Epoch: 26 Idx: 0 Loss: 0.010779148174202582
Epoch: 26 Idx: 5000 Loss: 0.013432166705856912
Epoch: 27 Idx: 0 Loss: 0.008020192323250228
Epoch: 27 Idx: 5000 Loss: 0.008819503623079324
Epoch: 28 Idx: 0 Loss: 0.02354860866949142
Epoch: 28 Idx: 5000 Loss: 0.015159230647809939
Epoch: 29 Idx: 0 Loss: 0.005950471076929991
Epoch: 29 Idx: 5000 Loss: 0.01538960366136239
Epoch: 30 Idx: 0 Loss: 0.014422823864756316
Epoch: 30 Idx: 5000 Loss: 0.023781206464253107
Epoch: 31 Idx: 0 Loss: 0.020895873171823943
Epoch: 31 Idx: 5000 Loss: 0.0182234952980125
Epoch: 32 Idx: 0 Loss: 0.018010024111647864
Epoch: 32 Idx: 5000 Loss: 0.014685207070967788
Epoch: 33 Idx: 0 Loss: 0.009917998560432116
Epoch: 33 Idx: 5000 Loss: 0.013830245594713495
Epoch: 34 Idx: 0 Loss: 0.022307023865188923
Epoch: 34 Idx: 5000 Loss: 0.005903817444695928
Epoch: 35 Idx: 0 Loss: 0.007615741775094428
Epoch: 35 Idx: 5000 Loss: 0.01160881554008722
Epoch: 36 Idx: 0 Loss: 0.02275555288038096
Epoch: 36 Idx: 5000 Loss: 0.009442123269008755
Epoch: 37 Idx: 0 Loss: 0.01973347477081573
Epoch: 37 Idx: 5000 Loss: 0.015948586110643977
Epoch: 38 Idx: 0 Loss: 0.053096688018435256
Epoch: 38 Idx: 5000 Loss: 0.00967793579537322
Epoch: 39 Idx: 0 Loss: 0.01777795582259109
Epoch: 39 Idx: 5000 Loss: 0.027901352238622078
Epoch: 40 Idx: 0 Loss: 0.03749199005470054
Epoch: 40 Idx: 5000 Loss: 0.020654973860514656
Epoch: 41 Idx: 0 Loss: 0.012559535357521853
Epoch: 41 Idx: 5000 Loss: 0.05665275056654871
Epoch: 42 Idx: 0 Loss: 0.010985449365270924
Epoch: 42 Idx: 5000 Loss: 0.013488684955786184
Epoch: 43 Idx: 0 Loss: 0.012411115944618908
Epoch: 43 Idx: 5000 Loss: 0.019753058447012296
Epoch: 44 Idx: 0 Loss: 0.012767655301041842
Epoch: 44 Idx: 5000 Loss: 0.016856443456871165
Epoch: 45 Idx: 0 Loss: 0.010466065367128569
Epoch: 45 Idx: 5000 Loss: 0.01511792652620584
Epoch: 46 Idx: 0 Loss: 0.019653757798316546
Epoch: 46 Idx: 5000 Loss: 0.010067116047082617
Epoch: 47 Idx: 0 Loss: 0.020464520921560488
Epoch: 47 Idx: 5000 Loss: 0.006502280560733205
Epoch: 48 Idx: 0 Loss: 0.010631032712622609
Epoch: 48 Idx: 5000 Loss: 0.017480986802192688
Epoch: 49 Idx: 0 Loss: 0.01896066170578054
Epoch: 49 Idx: 5000 Loss: 0.01837780749013511
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.215838013055194
Epoch: 0 Idx: 5000 Loss: 0.020856320367278813
Epoch: 1 Idx: 0 Loss: 0.01333500394937212
Epoch: 1 Idx: 5000 Loss: 0.02557175595424497
Epoch: 2 Idx: 0 Loss: 0.023332735445212444
Epoch: 2 Idx: 5000 Loss: 0.01475387713473214
Epoch: 3 Idx: 0 Loss: 0.013120189844695538
Epoch: 3 Idx: 5000 Loss: 0.010101487529789278
Epoch: 4 Idx: 0 Loss: 0.016013018469855006
Epoch: 4 Idx: 5000 Loss: 0.024476319463296273
Epoch: 5 Idx: 0 Loss: 0.01269551980764728
Epoch: 5 Idx: 5000 Loss: 0.01327094902930783
Epoch: 6 Idx: 0 Loss: 0.0076298656394915305
Epoch: 6 Idx: 5000 Loss: 0.010163921372059025
Epoch: 7 Idx: 0 Loss: 0.01731370016098796
Epoch: 7 Idx: 5000 Loss: 0.008019109923379852
Epoch: 8 Idx: 0 Loss: 0.008530679479816667
Epoch: 8 Idx: 5000 Loss: 0.02081178967450359
Epoch: 9 Idx: 0 Loss: 0.01644465106686001
Epoch: 9 Idx: 5000 Loss: 0.014357267549523467
Epoch: 10 Idx: 0 Loss: 0.012687431711052896
Epoch: 10 Idx: 5000 Loss: 0.010331803162708642
Epoch: 11 Idx: 0 Loss: 0.04651906268844953
Epoch: 11 Idx: 5000 Loss: 0.017618081140492903
Epoch: 12 Idx: 0 Loss: 0.012965602660251386
Epoch: 12 Idx: 5000 Loss: 0.017880067816516475
Epoch: 13 Idx: 0 Loss: 0.034758312346566754
Epoch: 13 Idx: 5000 Loss: 0.02326304294475006
Epoch: 14 Idx: 0 Loss: 0.013195733005180467
Epoch: 14 Idx: 5000 Loss: 0.020625371179381357
Epoch: 15 Idx: 0 Loss: 0.014853772514681183
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc227>
Subject: Job 4066879: <python main.py 6 6 False False> in cluster <dcc> Exited

Job <python main.py 6 6 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc227>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 6 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46141.00 sec.
    Max Memory :                                 2920 MB
    Average Memory :                             2734.62 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40497.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46143 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

