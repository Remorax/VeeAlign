2020-09-15 15:48:43.156751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.554036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:50.679253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:50.679333: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.681767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.710183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.746048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.788764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.814335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.814874: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.814899: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.815387: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.858889: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600025000 Hz
2020-09-15 15:48:50.859203: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55beaf347aa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.859225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.862288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.862325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18194123883201221
Epoch: 0 Idx: 5000 Loss: 0.00522942350680709
Epoch: 1 Idx: 0 Loss: 0.03549487086041095
Epoch: 1 Idx: 5000 Loss: 0.011506852003215226
Epoch: 2 Idx: 0 Loss: 0.009512235898798503
Epoch: 2 Idx: 5000 Loss: 0.029391361623429993
Epoch: 3 Idx: 0 Loss: 0.014708713340985329
Epoch: 3 Idx: 5000 Loss: 0.011606187687279316
Epoch: 4 Idx: 0 Loss: 0.019464374810716535
Epoch: 4 Idx: 5000 Loss: 0.02218285841451604
Epoch: 5 Idx: 0 Loss: 0.02183706327559151
Epoch: 5 Idx: 5000 Loss: 0.015542756882645356
Epoch: 6 Idx: 0 Loss: 0.022776398543543554
Epoch: 6 Idx: 5000 Loss: 0.02979928420471558
Epoch: 7 Idx: 0 Loss: 0.02655893696835235
Epoch: 7 Idx: 5000 Loss: 0.040341695343968524
Epoch: 8 Idx: 0 Loss: 0.008636412935109875
Epoch: 8 Idx: 5000 Loss: 0.012111536622717866
Epoch: 9 Idx: 0 Loss: 0.01057848919706782
Epoch: 9 Idx: 5000 Loss: 0.008365237117968173
Epoch: 10 Idx: 0 Loss: 0.01197581972133598
Epoch: 10 Idx: 5000 Loss: 0.013638266723967757
Epoch: 11 Idx: 0 Loss: 0.0111962142727043
Epoch: 11 Idx: 5000 Loss: 0.017974598477808013
Epoch: 12 Idx: 0 Loss: 0.010076812410599715
Epoch: 12 Idx: 5000 Loss: 0.015387301715060345
Epoch: 13 Idx: 0 Loss: 0.03990927882122411
Epoch: 13 Idx: 5000 Loss: 0.007853462763157702
Epoch: 14 Idx: 0 Loss: 0.01372066523417791
Epoch: 14 Idx: 5000 Loss: 0.028433169070081338
Epoch: 15 Idx: 0 Loss: 0.01461348511229537
Epoch: 15 Idx: 5000 Loss: 0.016346558485720766
Epoch: 16 Idx: 0 Loss: 0.01018464088509147
Epoch: 16 Idx: 5000 Loss: 0.0230860463340913
Epoch: 17 Idx: 0 Loss: 0.014360875022344528
Epoch: 17 Idx: 5000 Loss: 0.01206996444906476
Epoch: 18 Idx: 0 Loss: 0.013012414421429128
Epoch: 18 Idx: 5000 Loss: 0.030163768370272993
Epoch: 19 Idx: 0 Loss: 0.03441612402128488
Epoch: 19 Idx: 5000 Loss: 0.008826109568311676
Epoch: 20 Idx: 0 Loss: 0.012303658247441278
Epoch: 20 Idx: 5000 Loss: 0.012483650503439163
Epoch: 21 Idx: 0 Loss: 0.0284407400686884
Epoch: 21 Idx: 5000 Loss: 0.01865031453926736
Epoch: 22 Idx: 0 Loss: 0.01624645177636828
Epoch: 22 Idx: 5000 Loss: 0.0221872221075606
Epoch: 23 Idx: 0 Loss: 0.03259154727161839
Epoch: 23 Idx: 5000 Loss: 0.012116176423809659
Epoch: 24 Idx: 0 Loss: 0.014421627273039365
Epoch: 24 Idx: 5000 Loss: 0.021999653963496915
Epoch: 25 Idx: 0 Loss: 0.007856980422302214
Epoch: 25 Idx: 5000 Loss: 0.014017550274903185
Epoch: 26 Idx: 0 Loss: 0.009006431849185158
Epoch: 26 Idx: 5000 Loss: 0.011972211509789757
Epoch: 27 Idx: 0 Loss: 0.011301238720247875
Epoch: 27 Idx: 5000 Loss: 0.008745954618081133
Epoch: 28 Idx: 0 Loss: 0.02390442711994719
Epoch: 28 Idx: 5000 Loss: 0.01637327567319843
Epoch: 29 Idx: 0 Loss: 0.023111001176158923
Epoch: 29 Idx: 5000 Loss: 0.015844174911023193
Epoch: 30 Idx: 0 Loss: 0.009826887134018497
Epoch: 30 Idx: 5000 Loss: 0.008488767192933275
Epoch: 31 Idx: 0 Loss: 0.01766994594241015
Epoch: 31 Idx: 5000 Loss: 0.020857948616624735
Epoch: 32 Idx: 0 Loss: 0.021297892396792733
Epoch: 32 Idx: 5000 Loss: 0.013945030078283498
Epoch: 33 Idx: 0 Loss: 0.014960273775325631
Epoch: 33 Idx: 5000 Loss: 0.011165718501118763
Epoch: 34 Idx: 0 Loss: 0.01154091931269556
Epoch: 34 Idx: 5000 Loss: 0.02690120451019751
Epoch: 35 Idx: 0 Loss: 0.013889450071324224
Epoch: 35 Idx: 5000 Loss: 0.009964670843281237
Epoch: 36 Idx: 0 Loss: 0.047659596889775786
Epoch: 36 Idx: 5000 Loss: 0.012516846836831009
Epoch: 37 Idx: 0 Loss: 0.022260052317065585
Epoch: 37 Idx: 5000 Loss: 0.03335324654787726
Epoch: 38 Idx: 0 Loss: 0.024685286296502375
Epoch: 38 Idx: 5000 Loss: 0.009903036355835386
Epoch: 39 Idx: 0 Loss: 0.021477689153816627
Epoch: 39 Idx: 5000 Loss: 0.02647830169481544
Epoch: 40 Idx: 0 Loss: 0.012450772817370215
Epoch: 40 Idx: 5000 Loss: 0.008277153139072431
Epoch: 41 Idx: 0 Loss: 0.010064589960491635
Epoch: 41 Idx: 5000 Loss: 0.03048961037305808
Epoch: 42 Idx: 0 Loss: 0.004449925661347033
Epoch: 42 Idx: 5000 Loss: 0.013222225892934352
Epoch: 43 Idx: 0 Loss: 0.02520488869433616
Epoch: 43 Idx: 5000 Loss: 0.010139330068767327
Epoch: 44 Idx: 0 Loss: 0.013501599493767268
Epoch: 44 Idx: 5000 Loss: 0.008334804370022122
Epoch: 45 Idx: 0 Loss: 0.006430896547254584
Epoch: 45 Idx: 5000 Loss: 0.019594867069006136
Epoch: 46 Idx: 0 Loss: 0.016244994542773394
Epoch: 46 Idx: 5000 Loss: 0.011359203689739406
Epoch: 47 Idx: 0 Loss: 0.009790435619741774
Epoch: 47 Idx: 5000 Loss: 0.03178396866807017
Epoch: 48 Idx: 0 Loss: 0.0330167671026293
Epoch: 48 Idx: 5000 Loss: 0.012195632558897428
Epoch: 49 Idx: 0 Loss: 0.011262903000771401
Epoch: 49 Idx: 5000 Loss: 0.009199083488752303
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15503709834140017
Epoch: 0 Idx: 5000 Loss: 0.012951801496938583
Epoch: 1 Idx: 0 Loss: 0.011402424594772843
Epoch: 1 Idx: 5000 Loss: 0.03751883568131135
Epoch: 2 Idx: 0 Loss: 0.009728388609331833
Epoch: 2 Idx: 5000 Loss: 0.01705101100708248
Epoch: 3 Idx: 0 Loss: 0.011442156950934574
Epoch: 3 Idx: 5000 Loss: 0.007114051730443236
Epoch: 4 Idx: 0 Loss: 0.029412985318559435
Epoch: 4 Idx: 5000 Loss: 0.013789126853662063
Epoch: 5 Idx: 0 Loss: 0.010076473146160718
Epoch: 5 Idx: 5000 Loss: 0.01038676044931286
Epoch: 6 Idx: 0 Loss: 0.0170744391771258
Epoch: 6 Idx: 5000 Loss: 0.018952437101210053
Epoch: 7 Idx: 0 Loss: 0.0104895911900852
Epoch: 7 Idx: 5000 Loss: 0.006828739024264325
Epoch: 8 Idx: 0 Loss: 0.008794686324452069
Epoch: 8 Idx: 5000 Loss: 0.012942542876759713
Epoch: 9 Idx: 0 Loss: 0.007710320880592724
Epoch: 9 Idx: 5000 Loss: 0.0132828576528853
Epoch: 10 Idx: 0 Loss: 0.02016891020501235
Epoch: 10 Idx: 5000 Loss: 0.03179296030266678
Epoch: 11 Idx: 0 Loss: 0.04680031593823257
Epoch: 11 Idx: 5000 Loss: 0.02300993869831211
Epoch: 12 Idx: 0 Loss: 0.015783836380341466
Epoch: 12 Idx: 5000 Loss: 0.007703487431119927
Epoch: 13 Idx: 0 Loss: 0.012663705826438089
Epoch: 13 Idx: 5000 Loss: 0.013465723807455742
Epoch: 14 Idx: 0 Loss: 0.008271373770950568
Epoch: 14 Idx: 5000 Loss: 0.00926429212267442
Epoch: 15 Idx: 0 Loss: 0.013883754368081959
Epoch: 15 Idx: 5000 Loss: 0.006178745784338994
Epoch: 16 Idx: 0 Loss: 0.02527272345049058
Epoch: 16 Idx: 5000 Loss: 0.015450284992467036
Epoch: 17 Idx: 0 Loss: 0.015673941028279768
Epoch: 17 Idx: 5000 Loss: 0.020123605487229863
Epoch: 18 Idx: 0 Loss: 0.007751524659324173
Epoch: 18 Idx: 5000 Loss: 0.006215156548613231
Epoch: 19 Idx: 0 Loss: 0.02360772868496207
Epoch: 19 Idx: 5000 Loss: 0.01280592649042049
Epoch: 20 Idx: 0 Loss: 0.02368705595083267
Epoch: 20 Idx: 5000 Loss: 0.011683327999080714
Epoch: 21 Idx: 0 Loss: 0.009584386791228978
Epoch: 21 Idx: 5000 Loss: 0.01728172458691688
Epoch: 22 Idx: 0 Loss: 0.01267284421785148
Epoch: 22 Idx: 5000 Loss: 0.006048833607106275
Epoch: 23 Idx: 0 Loss: 0.01193667443819561
Epoch: 23 Idx: 5000 Loss: 0.018008931840625693
Epoch: 24 Idx: 0 Loss: 0.009902025667488793
Epoch: 24 Idx: 5000 Loss: 0.022485365014025094
Epoch: 25 Idx: 0 Loss: 0.020561463295543758
Epoch: 25 Idx: 5000 Loss: 0.008794312716817416
Epoch: 26 Idx: 0 Loss: 0.020570394515595253
Epoch: 26 Idx: 5000 Loss: 0.01698476505322767
Epoch: 27 Idx: 0 Loss: 0.027899833597723356
Epoch: 27 Idx: 5000 Loss: 0.007714484282386932
Epoch: 28 Idx: 0 Loss: 0.012790346649102865
Epoch: 28 Idx: 5000 Loss: 0.011288536145902658
Epoch: 29 Idx: 0 Loss: 0.019232922565055554
Epoch: 29 Idx: 5000 Loss: 0.01744094959275061
Epoch: 30 Idx: 0 Loss: 0.01788858804572733
Epoch: 30 Idx: 5000 Loss: 0.015716627286918236
Epoch: 31 Idx: 0 Loss: 0.023747926411294903
Epoch: 31 Idx: 5000 Loss: 0.043732897260495354
Epoch: 32 Idx: 0 Loss: 0.011557296589685375
Epoch: 32 Idx: 5000 Loss: 0.01931115093374683
Epoch: 33 Idx: 0 Loss: 0.009315381278477603
Epoch: 33 Idx: 5000 Loss: 0.005498100513943527
Epoch: 34 Idx: 0 Loss: 0.010627374886518135
Epoch: 34 Idx: 5000 Loss: 0.010727026811273
Epoch: 35 Idx: 0 Loss: 0.01238368836758989
Epoch: 35 Idx: 5000 Loss: 0.02749387886422315
Epoch: 36 Idx: 0 Loss: 0.01340060152542912
Epoch: 36 Idx: 5000 Loss: 0.005504889158405258
Epoch: 37 Idx: 0 Loss: 0.010342807619635401
Epoch: 37 Idx: 5000 Loss: 0.021832136980531124
Epoch: 38 Idx: 0 Loss: 0.017819201918076816
Epoch: 38 Idx: 5000 Loss: 0.025398056834901993
Epoch: 39 Idx: 0 Loss: 0.01140758893908908
Epoch: 39 Idx: 5000 Loss: 0.012720543727853986
Epoch: 40 Idx: 0 Loss: 0.012775539403414433
Epoch: 40 Idx: 5000 Loss: 0.017108149168915093
Epoch: 41 Idx: 0 Loss: 0.02342539194545539
Epoch: 41 Idx: 5000 Loss: 0.0158646411449344
Epoch: 42 Idx: 0 Loss: 0.015525995923835325
Epoch: 42 Idx: 5000 Loss: 0.021033816483964927
Epoch: 43 Idx: 0 Loss: 0.01196574615295519
Epoch: 43 Idx: 5000 Loss: 0.005322013235231217
Epoch: 44 Idx: 0 Loss: 0.03290134949057724
Epoch: 44 Idx: 5000 Loss: 0.02072445678942859
Epoch: 45 Idx: 0 Loss: 0.042981491866968626
Epoch: 45 Idx: 5000 Loss: 0.007624971759019164
Epoch: 46 Idx: 0 Loss: 0.01969585030629286
Epoch: 46 Idx: 5000 Loss: 0.028335522211053663
Epoch: 47 Idx: 0 Loss: 0.012941284805863068
Epoch: 47 Idx: 5000 Loss: 0.022176301010422724
Epoch: 48 Idx: 0 Loss: 0.03289147215075344
Epoch: 48 Idx: 5000 Loss: 0.012200662428565268
Epoch: 49 Idx: 0 Loss: 0.02194140117716178
Epoch: 49 Idx: 5000 Loss: 0.01322105143773553
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14281193488556992
Epoch: 0 Idx: 5000 Loss: 0.01911153819389804
Epoch: 1 Idx: 0 Loss: 0.010009325396043055
Epoch: 1 Idx: 5000 Loss: 0.008770318266977295
Epoch: 2 Idx: 0 Loss: 0.010279765914421774
Epoch: 2 Idx: 5000 Loss: 0.02993674904985153
Epoch: 3 Idx: 0 Loss: 0.0240731925716345
Epoch: 3 Idx: 5000 Loss: 0.030183996047879563
Epoch: 4 Idx: 0 Loss: 0.020630023800815946
Epoch: 4 Idx: 5000 Loss: 0.01712181302111439
Epoch: 5 Idx: 0 Loss: 0.02725458381395603
Epoch: 5 Idx: 5000 Loss: 0.01168914468010638
Epoch: 6 Idx: 0 Loss: 0.016439392796657223
Epoch: 6 Idx: 5000 Loss: 0.015221634707759866
Epoch: 7 Idx: 0 Loss: 0.0174156415047304
Epoch: 7 Idx: 5000 Loss: 0.02244020016141151
Epoch: 8 Idx: 0 Loss: 0.010957595621870294
Epoch: 8 Idx: 5000 Loss: 0.013027698893629178
Epoch: 9 Idx: 0 Loss: 0.009155408688965184
Epoch: 9 Idx: 5000 Loss: 0.007127278091723747
Epoch: 10 Idx: 0 Loss: 0.018516182728922078
Epoch: 10 Idx: 5000 Loss: 0.027901200267036408
Epoch: 11 Idx: 0 Loss: 0.01208654800988483
Epoch: 11 Idx: 5000 Loss: 0.009772910001300792
Epoch: 12 Idx: 0 Loss: 0.007520889769107734
Epoch: 12 Idx: 5000 Loss: 0.01334159075397467
Epoch: 13 Idx: 0 Loss: 0.007901991172874533
Epoch: 13 Idx: 5000 Loss: 0.01890091786067112
Epoch: 14 Idx: 0 Loss: 0.013655128130582846
Epoch: 14 Idx: 5000 Loss: 0.01655826361968125
Epoch: 15 Idx: 0 Loss: 0.012718852396064524
Epoch: 15 Idx: 5000 Loss: 0.034796554020216544
Epoch: 16 Idx: 0 Loss: 0.015835341929163256
Epoch: 16 Idx: 5000 Loss: 0.011655078143733854
Epoch: 17 Idx: 0 Loss: 0.005663378708967668
Epoch: 17 Idx: 5000 Loss: 0.02735709683948083
Epoch: 18 Idx: 0 Loss: 0.013621252408318097
Epoch: 18 Idx: 5000 Loss: 0.007721755952992596
Epoch: 19 Idx: 0 Loss: 0.01165603711858296
Epoch: 19 Idx: 5000 Loss: 0.008384165467583412
Epoch: 20 Idx: 0 Loss: 0.01108107520359358
Epoch: 20 Idx: 5000 Loss: 0.011240240361132421
Epoch: 21 Idx: 0 Loss: 0.0207031804728781
Epoch: 21 Idx: 5000 Loss: 0.021875220922034543
Epoch: 22 Idx: 0 Loss: 0.011138013078748841
Epoch: 22 Idx: 5000 Loss: 0.010848360126199937
Epoch: 23 Idx: 0 Loss: 0.015611980864685071
Epoch: 23 Idx: 5000 Loss: 0.013837043963935418
Epoch: 24 Idx: 0 Loss: 0.005393575552875698
Epoch: 24 Idx: 5000 Loss: 0.01445172393624861
Epoch: 25 Idx: 0 Loss: 0.010172251366978528
Epoch: 25 Idx: 5000 Loss: 0.029343410670853397
Epoch: 26 Idx: 0 Loss: 0.03227290355298784
Epoch: 26 Idx: 5000 Loss: 0.01830455981939078
Epoch: 27 Idx: 0 Loss: 0.034545316683861405
Epoch: 27 Idx: 5000 Loss: 0.021865119817927044
Epoch: 28 Idx: 0 Loss: 0.012484068857967217
Epoch: 28 Idx: 5000 Loss: 0.016379052460839358
Epoch: 29 Idx: 0 Loss: 0.012625466995030681
Epoch: 29 Idx: 5000 Loss: 0.019731656624478268
Epoch: 30 Idx: 0 Loss: 0.0052035692194484845
Epoch: 30 Idx: 5000 Loss: 0.02656070928734493
Epoch: 31 Idx: 0 Loss: 0.016092077397460193
Epoch: 31 Idx: 5000 Loss: 0.010572104454572243
Epoch: 32 Idx: 0 Loss: 0.012805923717086207
Epoch: 32 Idx: 5000 Loss: 0.008191392166750305
Epoch: 33 Idx: 0 Loss: 0.008148299537620463
Epoch: 33 Idx: 5000 Loss: 0.013283967613511654
Epoch: 34 Idx: 0 Loss: 0.018047061530160075
Epoch: 34 Idx: 5000 Loss: 0.0166451526993171
Epoch: 35 Idx: 0 Loss: 0.011603111037361707
Epoch: 35 Idx: 5000 Loss: 0.012436547200218893
Epoch: 36 Idx: 0 Loss: 0.006027123996959573
Epoch: 36 Idx: 5000 Loss: 0.03206216261978831
Epoch: 37 Idx: 0 Loss: 0.009914498207407436
Epoch: 37 Idx: 5000 Loss: 0.03672905738422465
Epoch: 38 Idx: 0 Loss: 0.010898344794589804
Epoch: 38 Idx: 5000 Loss: 0.013968496729134664
Epoch: 39 Idx: 0 Loss: 0.020137403107135736
Epoch: 39 Idx: 5000 Loss: 0.009673007730546482
Epoch: 40 Idx: 0 Loss: 0.01488027948305137
Epoch: 40 Idx: 5000 Loss: 0.009181689830357175
Epoch: 41 Idx: 0 Loss: 0.013764198759360823
Epoch: 41 Idx: 5000 Loss: 0.03639268397887206
Epoch: 42 Idx: 0 Loss: 0.00904166649008851
Epoch: 42 Idx: 5000 Loss: 0.011139220280529582
Epoch: 43 Idx: 0 Loss: 0.0046161338245079234
Epoch: 43 Idx: 5000 Loss: 0.012129264257897657
Epoch: 44 Idx: 0 Loss: 0.011615749845069455
Epoch: 44 Idx: 5000 Loss: 0.016834674622464338
Epoch: 45 Idx: 0 Loss: 0.017289163761104207
Epoch: 45 Idx: 5000 Loss: 0.014162302320914361
Epoch: 46 Idx: 0 Loss: 0.04474541362666262
Epoch: 46 Idx: 5000 Loss: 0.009478924968131833
Epoch: 47 Idx: 0 Loss: 0.019372361878825732
Epoch: 47 Idx: 5000 Loss: 0.028916646240264708
Epoch: 48 Idx: 0 Loss: 0.03099978321103646
Epoch: 48 Idx: 5000 Loss: 0.007754320517212329
Epoch: 49 Idx: 0 Loss: 0.00833806627331168
Epoch: 49 Idx: 5000 Loss: 0.017915047280880905
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.22035335326341743
Epoch: 0 Idx: 5000 Loss: 0.02829652244025682
Epoch: 1 Idx: 0 Loss: 0.011010614157591005
Epoch: 1 Idx: 5000 Loss: 0.011207683402720355
Epoch: 2 Idx: 0 Loss: 0.008685858637511335
Epoch: 2 Idx: 5000 Loss: 0.011319030715773969
Epoch: 3 Idx: 0 Loss: 0.024042050095836418
Epoch: 3 Idx: 5000 Loss: 0.006132725083092074
Epoch: 4 Idx: 0 Loss: 0.014108112419423016
Epoch: 4 Idx: 5000 Loss: 0.014696173896925731
Epoch: 5 Idx: 0 Loss: 0.015688959072928072
Epoch: 5 Idx: 5000 Loss: 0.011251565307196709
Epoch: 6 Idx: 0 Loss: 0.02386555939650086
Epoch: 6 Idx: 5000 Loss: 0.017353715105646605
Epoch: 7 Idx: 0 Loss: 0.012318931316284008
Epoch: 7 Idx: 5000 Loss: 0.015056209286482703
Epoch: 8 Idx: 0 Loss: 0.02071796129030318
Epoch: 8 Idx: 5000 Loss: 0.015112797184023164
Epoch: 9 Idx: 0 Loss: 0.03940901413017016
Epoch: 9 Idx: 5000 Loss: 0.01640468071702114
Epoch: 10 Idx: 0 Loss: 0.009509115898258015
Epoch: 10 Idx: 5000 Loss: 0.02032574930302608
Epoch: 11 Idx: 0 Loss: 0.009835530774861361
Epoch: 11 Idx: 5000 Loss: 0.0166562184524155
Epoch: 12 Idx: 0 Loss: 0.010671521861942037
Epoch: 12 Idx: 5000 Loss: 0.019142772294591808
Epoch: 13 Idx: 0 Loss: 0.02169033787330068
Epoch: 13 Idx: 5000 Loss: 0.011374692068538892
Epoch: 14 Idx: 0 Loss: 0.012253948057370491
Epoch: 14 Idx: 5000 Loss: 0.011550732667727322
Epoch: 15 Idx: 0 Loss: 0.022735935223900744
Epoch: 15 Idx: 5000 Loss: 0.012724978167262
Epoch: 16 Idx: 0 Loss: 0.009306633939557593
Epoch: 16 Idx: 5000 Loss: 0.01789707660004663
Epoch: 17 Idx: 0 Loss: 0.009401975622907302
Epoch: 17 Idx: 5000 Loss: 0.021032827843613808
Epoch: 18 Idx: 0 Loss: 0.017962779853795057
Epoch: 18 Idx: 5000 Loss: 0.014414002268816305
Epoch: 19 Idx: 0 Loss: 0.010495467748270409
Epoch: 19 Idx: 5000 Loss: 0.011578714302259447
Epoch: 20 Idx: 0 Loss: 0.00734161585955249
Epoch: 20 Idx: 5000 Loss: 0.007559944482235563
Epoch: 21 Idx: 0 Loss: 0.012366398551486215
Epoch: 21 Idx: 5000 Loss: 0.01475581150741342
Epoch: 22 Idx: 0 Loss: 0.01502491096349056
Epoch: 22 Idx: 5000 Loss: 0.011968244875113037
Epoch: 23 Idx: 0 Loss: 0.015168399493488647
Epoch: 23 Idx: 5000 Loss: 0.03846077432594762
Epoch: 24 Idx: 0 Loss: 0.027539319087553513
Epoch: 24 Idx: 5000 Loss: 0.013679433818579431
Epoch: 25 Idx: 0 Loss: 0.025687966505366755
Epoch: 25 Idx: 5000 Loss: 0.015232822625273855
Epoch: 26 Idx: 0 Loss: 0.013526857681186645
Epoch: 26 Idx: 5000 Loss: 0.010524357252929809
Epoch: 27 Idx: 0 Loss: 0.02496956222821723
Epoch: 27 Idx: 5000 Loss: 0.010331774751971588
Epoch: 28 Idx: 0 Loss: 0.008389050753727785
Epoch: 28 Idx: 5000 Loss: 0.00970277839028633
Epoch: 29 Idx: 0 Loss: 0.006299208114608105
Epoch: 29 Idx: 5000 Loss: 0.03619907848997565
Epoch: 30 Idx: 0 Loss: 0.0173808445021787
Epoch: 30 Idx: 5000 Loss: 0.012583730018850348
Epoch: 31 Idx: 0 Loss: 0.004949169069930128
Epoch: 31 Idx: 5000 Loss: 0.01670871524807792
Epoch: 32 Idx: 0 Loss: 0.011576851581931088
Epoch: 32 Idx: 5000 Loss: 0.007372741911145672
Epoch: 33 Idx: 0 Loss: 0.003193979522353063
Epoch: 33 Idx: 5000 Loss: 0.018553029766654072
Epoch: 34 Idx: 0 Loss: 0.013081704648170468
Epoch: 34 Idx: 5000 Loss: 0.006797502114803914
Epoch: 35 Idx: 0 Loss: 0.016307446439350854
Epoch: 35 Idx: 5000 Loss: 0.011639342854184529
Epoch: 36 Idx: 0 Loss: 0.014428200078707848
Epoch: 36 Idx: 5000 Loss: 0.017129819296429368
Epoch: 37 Idx: 0 Loss: 0.022254413143990424
Epoch: 37 Idx: 5000 Loss: 0.007789303697179567
Epoch: 38 Idx: 0 Loss: 0.02488652047225739
Epoch: 38 Idx: 5000 Loss: 0.02156092321033572
Epoch: 39 Idx: 0 Loss: 0.006372868584512158
Epoch: 39 Idx: 5000 Loss: 0.013134812598604578
Epoch: 40 Idx: 0 Loss: 0.018520755178027454
Epoch: 40 Idx: 5000 Loss: 0.032846069099718496
Epoch: 41 Idx: 0 Loss: 0.01461941757763711
Epoch: 41 Idx: 5000 Loss: 0.009765120465627664
Epoch: 42 Idx: 0 Loss: 0.0070258464724659
Epoch: 42 Idx: 5000 Loss: 0.013407087066464415
Epoch: 43 Idx: 0 Loss: 0.015311953334541651
Epoch: 43 Idx: 5000 Loss: 0.05498862062295373
Epoch: 44 Idx: 0 Loss: 0.009389930471896657
Epoch: 44 Idx: 5000 Loss: 0.021623997043574122
Epoch: 45 Idx: 0 Loss: 0.02333307475814514
Epoch: 45 Idx: 5000 Loss: 0.0195481754011183
Epoch: 46 Idx: 0 Loss: 0.008401715330969802
Epoch: 46 Idx: 5000 Loss: 0.00650061437405553
Epoch: 47 Idx: 0 Loss: 0.017314064461339693
Epoch: 47 Idx: 5000 Loss: 0.018291544107034333
Epoch: 48 Idx: 0 Loss: 0.020547861509965577
Epoch: 48 Idx: 5000 Loss: 0.020645854224777663
Epoch: 49 Idx: 0 Loss: 0.010437421736629754
Epoch: 49 Idx: 5000 Loss: 0.016353879713147532
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.20465605611525306
Epoch: 0 Idx: 5000 Loss: 0.010839702918530335
Epoch: 1 Idx: 0 Loss: 0.009200313003558317
Epoch: 1 Idx: 5000 Loss: 0.011557436886484182
Epoch: 2 Idx: 0 Loss: 0.010887439972642647
Epoch: 2 Idx: 5000 Loss: 0.01263126734927358
Epoch: 3 Idx: 0 Loss: 0.013469920855921975
Epoch: 3 Idx: 5000 Loss: 0.05517580190245844
Epoch: 4 Idx: 0 Loss: 0.012904657552054976
Epoch: 4 Idx: 5000 Loss: 0.01151733593660504
Epoch: 5 Idx: 0 Loss: 0.029377178662908014
Epoch: 5 Idx: 5000 Loss: 0.01649808053256713
Epoch: 6 Idx: 0 Loss: 0.021765476030653236
Epoch: 6 Idx: 5000 Loss: 0.025931671045204573
Epoch: 7 Idx: 0 Loss: 0.021113124349195347
Epoch: 7 Idx: 5000 Loss: 0.015792208612826847
Epoch: 8 Idx: 0 Loss: 0.010598328774631818
Epoch: 8 Idx: 5000 Loss: 0.017339758211059132
Epoch: 9 Idx: 0 Loss: 0.037173812578606164
Epoch: 9 Idx: 5000 Loss: 0.01300239820281902
Epoch: 10 Idx: 0 Loss: 0.014126559449813808
Epoch: 10 Idx: 5000 Loss: 0.01117728191006425
Epoch: 11 Idx: 0 Loss: 0.006419511069847778
Epoch: 11 Idx: 5000 Loss: 0.014003186840716532
Epoch: 12 Idx: 0 Loss: 0.013565288653462728
Epoch: 12 Idx: 5000 Loss: 0.02661959173065235
Epoch: 13 Idx: 0 Loss: 0.04061120700832141
Epoch: 13 Idx: 5000 Loss: 0.010283149865131666
Epoch: 14 Idx: 0 Loss: 0.025054431147168717
Epoch: 14 Idx: 5000 Loss: 0.011904182026030479
Epoch: 15 Idx: 0 Loss: 0.006274306079520953
Epoch: 15 Idx: 5000 Loss: 0.03268302312288239
Epoch: 16 Idx: 0 Loss: 0.02599892514823291
Epoch: 16 Idx: 5000 Loss: 0.01259581542917058
Epoch: 17 Idx: 0 Loss: 0.014012642760810325
Epoch: 17 Idx: 5000 Loss: 0.010643816887348409
Epoch: 18 Idx: 0 Loss: 0.00891092739767409
Epoch: 18 Idx: 5000 Loss: 0.012901414488269328
Epoch: 19 Idx: 0 Loss: 0.0417795317158796
Epoch: 19 Idx: 5000 Loss: 0.01036863783704468
Epoch: 20 Idx: 0 Loss: 0.008658277033865536
Epoch: 20 Idx: 5000 Loss: 0.013373627300666881
Epoch: 21 Idx: 0 Loss: 0.020623490129132012
Epoch: 21 Idx: 5000 Loss: 0.009040022441756617
Epoch: 22 Idx: 0 Loss: 0.012105356046545324
Epoch: 22 Idx: 5000 Loss: 0.011167356561316958
Epoch: 23 Idx: 0 Loss: 0.031180040062648975
Epoch: 23 Idx: 5000 Loss: 0.008625185540805597
Epoch: 24 Idx: 0 Loss: 0.023439552871210786
Epoch: 24 Idx: 5000 Loss: 0.02369813339795561
Epoch: 25 Idx: 0 Loss: 0.01684598575227479
Epoch: 25 Idx: 5000 Loss: 0.013473029751013693
Epoch: 26 Idx: 0 Loss: 0.012273878512262847
Epoch: 26 Idx: 5000 Loss: 0.009091803283834115
Epoch: 27 Idx: 0 Loss: 0.016047471664922614
Epoch: 27 Idx: 5000 Loss: 0.01572493519591192
Epoch: 28 Idx: 0 Loss: 0.013109025398379019
Epoch: 28 Idx: 5000 Loss: 0.009634176576687942
Epoch: 29 Idx: 0 Loss: 0.010415949555014762
Epoch: 29 Idx: 5000 Loss: 0.005860077831578458
Epoch: 30 Idx: 0 Loss: 0.03628482088766394
Epoch: 30 Idx: 5000 Loss: 0.013510618642073941
Epoch: 31 Idx: 0 Loss: 0.012519605072324462
Epoch: 31 Idx: 5000 Loss: 0.04603120778439936
Epoch: 32 Idx: 0 Loss: 0.01966182934193746
Epoch: 32 Idx: 5000 Loss: 0.01715559753533599
Epoch: 33 Idx: 0 Loss: 0.007938902074630277
Epoch: 33 Idx: 5000 Loss: 0.02456200141001432
Epoch: 34 Idx: 0 Loss: 0.029972594780079086
Epoch: 34 Idx: 5000 Loss: 0.017876495505445008
Epoch: 35 Idx: 0 Loss: 0.014635555133408817
Epoch: 35 Idx: 5000 Loss: 0.033464164706204835
Epoch: 36 Idx: 0 Loss: 0.016645536099884922
Epoch: 36 Idx: 5000 Loss: 0.020515520292910334
Epoch: 37 Idx: 0 Loss: 0.017322037179955573
Epoch: 37 Idx: 5000 Loss: 0.020735495337279294
Epoch: 38 Idx: 0 Loss: 0.009588174851142706
Epoch: 38 Idx: 5000 Loss: 0.03467336580001873
Epoch: 39 Idx: 0 Loss: 0.009777465630868305
Epoch: 39 Idx: 5000 Loss: 0.011525861514863876
Epoch: 40 Idx: 0 Loss: 0.020235808779132003
Epoch: 40 Idx: 5000 Loss: 0.0076795884002291105
Epoch: 41 Idx: 0 Loss: 0.01417961372446543
Epoch: 41 Idx: 5000 Loss: 0.00965732822358966
Epoch: 42 Idx: 0 Loss: 0.010836992883298556
Epoch: 42 Idx: 5000 Loss: 0.027843351013482245
Epoch: 43 Idx: 0 Loss: 0.04063474562820184
Epoch: 43 Idx: 5000 Loss: 0.010241811176135736
Epoch: 44 Idx: 0 Loss: 0.028906141942352352
Epoch: 44 Idx: 5000 Loss: 0.044689532976163994
Epoch: 45 Idx: 0 Loss: 0.01169549555552733
Epoch: 45 Idx: 5000 Loss: 0.007606599625706697
Epoch: 46 Idx: 0 Loss: 0.015525094337945366
Epoch: 46 Idx: 5000 Loss: 0.013069381603770996
Epoch: 47 Idx: 0 Loss: 0.008739651017226943
Epoch: 47 Idx: 5000 Loss: 0.01855475363226674
Epoch: 48 Idx: 0 Loss: 0.014459352043954859
Epoch: 48 Idx: 5000 Loss: 0.023386433464491548
Epoch: 49 Idx: 0 Loss: 0.022506346348929035
Epoch: 49 Idx: 5000 Loss: 0.01554324412061999
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.19863960032808037
Epoch: 0 Idx: 5000 Loss: 0.038490261767997615
Epoch: 1 Idx: 0 Loss: 0.01813997147931211
Epoch: 1 Idx: 5000 Loss: 0.01254345067204731
Epoch: 2 Idx: 0 Loss: 0.004094347435370254
Epoch: 2 Idx: 5000 Loss: 0.009189679549812953
Epoch: 3 Idx: 0 Loss: 0.01550941170164085
Epoch: 3 Idx: 5000 Loss: 0.014608996950728585
Epoch: 4 Idx: 0 Loss: 0.023732546018325335
Epoch: 4 Idx: 5000 Loss: 0.01678071925369607
Epoch: 5 Idx: 0 Loss: 0.008446827335637825
Epoch: 5 Idx: 5000 Loss: 0.010004970380142116
Epoch: 6 Idx: 0 Loss: 0.007270620581704584
Epoch: 6 Idx: 5000 Loss: 0.012626277000733054
Epoch: 7 Idx: 0 Loss: 0.017504919990918154
Epoch: 7 Idx: 5000 Loss: 0.008221366158596055
Epoch: 8 Idx: 0 Loss: 0.009312534228462298
Epoch: 8 Idx: 5000 Loss: 0.049013789320379454
Epoch: 9 Idx: 0 Loss: 0.03796489007930211
Epoch: 9 Idx: 5000 Loss: 0.0165763499141227
Epoch: 10 Idx: 0 Loss: 0.007254099170742934
Epoch: 10 Idx: 5000 Loss: 0.01406186584932584
Epoch: 11 Idx: 0 Loss: 0.012157195210353945
Epoch: 11 Idx: 5000 Loss: 0.00915612921418689
Epoch: 12 Idx: 0 Loss: 0.012572105173888369
Epoch: 12 Idx: 5000 Loss: 0.026537472678012146
Epoch: 13 Idx: 0 Loss: 0.009843649383388678
Epoch: 13 Idx: 5000 Loss: 0.025891050427654137
Epoch: 14 Idx: 0 Loss: 0.011973013858322116
Epoch: 14 Idx: 5000 Loss: 0.009595630448473499
Epoch: 15 Idx: 0 Loss: 0.012242995830129624
Epoch: 15 Idx: 5000 Loss: 0.01919103522100668
Epoch: 16 Idx: 0 Loss: 0.007901114134587241
Epoch: 16 Idx: 5000 Loss: 0.004595770024028872
Epoch: 17 Idx: 0 Loss: 0.025392533840202715
Epoch: 17 Idx: 5000 Loss: 0.011802516802110202
Epoch: 18 Idx: 0 Loss: 0.012469433648220058
Epoch: 18 Idx: 5000 Loss: 0.009698206789707476
Epoch: 19 Idx: 0 Loss: 0.009075512718133819
Epoch: 19 Idx: 5000 Loss: 0.015754827278262093
Epoch: 20 Idx: 0 Loss: 0.011193246644128376
Epoch: 20 Idx: 5000 Loss: 0.01804909095627516
Epoch: 21 Idx: 0 Loss: 0.021788177172030535
Epoch: 21 Idx: 5000 Loss: 0.0169917768095705
Epoch: 22 Idx: 0 Loss: 0.037800835142220296
Epoch: 22 Idx: 5000 Loss: 0.0313001104941697
Epoch: 23 Idx: 0 Loss: 0.008575447635414587
Epoch: 23 Idx: 5000 Loss: 0.012905559975905598
Epoch: 24 Idx: 0 Loss: 0.02657400163664382
Epoch: 24 Idx: 5000 Loss: 0.03370874737884202
Epoch: 25 Idx: 0 Loss: 0.010365787361593881
Epoch: 25 Idx: 5000 Loss: 0.012683922484096218
Epoch: 26 Idx: 0 Loss: 0.012517254269140212
Epoch: 26 Idx: 5000 Loss: 0.021267988232293592
Epoch: 27 Idx: 0 Loss: 0.011040880002895662
Epoch: 27 Idx: 5000 Loss: 0.004367142700250171
Epoch: 28 Idx: 0 Loss: 0.012508402917314993
Epoch: 28 Idx: 5000 Loss: 0.014035727882547241
Epoch: 29 Idx: 0 Loss: 0.027813384601259136
Epoch: 29 Idx: 5000 Loss: 0.017590833358962825
Epoch: 30 Idx: 0 Loss: 0.016554026496252493
Epoch: 30 Idx: 5000 Loss: 0.035025518507610785
Epoch: 31 Idx: 0 Loss: 0.014076024397677451
Epoch: 31 Idx: 5000 Loss: 0.013356389490617852
Epoch: 32 Idx: 0 Loss: 0.008673602758444272
Epoch: 32 Idx: 5000 Loss: 0.00831255944873132
Epoch: 33 Idx: 0 Loss: 0.02270387759100259
Epoch: 33 Idx: 5000 Loss: 0.017146476808234376
Epoch: 34 Idx: 0 Loss: 0.028033960713611937
Epoch: 34 Idx: 5000 Loss: 0.00999357370185636
Epoch: 35 Idx: 0 Loss: 0.009116219417256429
Epoch: 35 Idx: 5000 Loss: 0.010281851203758862
Epoch: 36 Idx: 0 Loss: 0.02119270777259282
Epoch: 36 Idx: 5000 Loss: 0.01634906061975792
Epoch: 37 Idx: 0 Loss: 0.015706916317426798
Epoch: 37 Idx: 5000 Loss: 0.010525942448961807
Epoch: 38 Idx: 0 Loss: 0.02383822907272131
Epoch: 38 Idx: 5000 Loss: 0.007953105606989402
Epoch: 39 Idx: 0 Loss: 0.005566077604029729
Epoch: 39 Idx: 5000 Loss: 0.0153486434061623
Epoch: 40 Idx: 0 Loss: 0.014169977293847039
Epoch: 40 Idx: 5000 Loss: 0.007149330942461937
Epoch: 41 Idx: 0 Loss: 0.008480080591286522
Epoch: 41 Idx: 5000 Loss: 0.023036594686192458
Epoch: 42 Idx: 0 Loss: 0.011395128889183252
Epoch: 42 Idx: 5000 Loss: 0.013503394913845362
Epoch: 43 Idx: 0 Loss: 0.010434176973828433
Epoch: 43 Idx: 5000 Loss: 0.013599970980294963
Epoch: 44 Idx: 0 Loss: 0.010138562692578438
Epoch: 44 Idx: 5000 Loss: 0.01806208128565707
Epoch: 45 Idx: 0 Loss: 0.010010616395463698
Epoch: 45 Idx: 5000 Loss: 0.01840942669804157
Epoch: 46 Idx: 0 Loss: 0.020340955958997167
Epoch: 46 Idx: 5000 Loss: 0.034563669094809915
Epoch: 47 Idx: 0 Loss: 0.03138131528446366
Epoch: 47 Idx: 5000 Loss: 0.017475161855885844
Epoch: 48 Idx: 0 Loss: 0.008810388435448497
Epoch: 48 Idx: 5000 Loss: 0.02231963809853863
Epoch: 49 Idx: 0 Loss: 0.01007245908649205
Epoch: 49 Idx: 5000 Loss: 0.0290622089688146
Len (direct inputs):  1690
Inputs len 10074 10 11464
Len (direct inputs):  1400
Starting sliding window evaluation...
Step 12/7
Val onto:  [('conference', 'iasted')] test_onto:  [('confof', 'edas')]
Training size: 104813 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.19782938826226662
Epoch: 0 Idx: 5000 Loss: 0.013752693400514698
Epoch: 1 Idx: 0 Loss: 0.010815945191743538
Epoch: 1 Idx: 5000 Loss: 0.017539325684111
Epoch: 2 Idx: 0 Loss: 0.008474780977289646
Epoch: 2 Idx: 5000 Loss: 0.011046162030729133
Epoch: 3 Idx: 0 Loss: 0.04301426935899238
Epoch: 3 Idx: 5000 Loss: 0.019384429266450315
Epoch: 4 Idx: 0 Loss: 0.015246216172703192
Epoch: 4 Idx: 5000 Loss: 0.018159459868363485
Epoch: 5 Idx: 0 Loss: 0.012279159359045319
Epoch: 5 Idx: 5000 Loss: 0.01088920191607602
Epoch: 6 Idx: 0 Loss: 0.014130259094286049
Epoch: 6 Idx: 5000 Loss: 0.01734518699218729
Epoch: 7 Idx: 0 Loss: 0.010111570724522432
Epoch: 7 Idx: 5000 Loss: 0.013574471341459712
Epoch: 8 Idx: 0 Loss: 0.020598159368322867
Epoch: 8 Idx: 5000 Loss: 0.02101710691982242
Epoch: 9 Idx: 0 Loss: 0.01669138545332133
Epoch: 9 Idx: 5000 Loss: 0.019145007344881403
Epoch: 10 Idx: 0 Loss: 0.011058678274015347
Epoch: 10 Idx: 5000 Loss: 0.013552548171113876
Epoch: 11 Idx: 0 Loss: 0.02220943026936398
Epoch: 11 Idx: 5000 Loss: 0.009097224541912098
Epoch: 12 Idx: 0 Loss: 0.008846055751667876
Epoch: 12 Idx: 5000 Loss: 0.021401740883403117
Epoch: 13 Idx: 0 Loss: 0.014612048766640965
Epoch: 13 Idx: 5000 Loss: 0.035004113860463905
Epoch: 14 Idx: 0 Loss: 0.009328389763509026
Epoch: 14 Idx: 5000 Loss: 0.017723211157711437
Epoch: 15 Idx: 0 Loss: 0.008267030709541299
Epoch: 15 Idx: 5000 Loss: 0.01272833032002234
Epoch: 16 Idx: 0 Loss: 0.017150218394520852
Epoch: 16 Idx: 5000 Loss: 0.010747553550242636
Epoch: 17 Idx: 0 Loss: 0.01676045275065757
Epoch: 17 Idx: 5000 Loss: 0.03356800887419997
Epoch: 18 Idx: 0 Loss: 0.013580360450672511
Epoch: 18 Idx: 5000 Loss: 0.011463761044995139
Epoch: 19 Idx: 0 Loss: 0.013407964453318003
Epoch: 19 Idx: 5000 Loss: 0.020294472932203447
Epoch: 20 Idx: 0 Loss: 0.0199273059719189
Epoch: 20 Idx: 5000 Loss: 0.03541922265612606
Epoch: 21 Idx: 0 Loss: 0.01480439668225858
Epoch: 21 Idx: 5000 Loss: 0.010188027440025116
Epoch: 22 Idx: 0 Loss: 0.014684101279762864
Epoch: 22 Idx: 5000 Loss: 0.06345530630103668
Epoch: 23 Idx: 0 Loss: 0.01553213079763668
Epoch: 23 Idx: 5000 Loss: 0.013947256851454233
Epoch: 24 Idx: 0 Loss: 0.007895469335640186
Epoch: 24 Idx: 5000 Loss: 0.05205311503989729
Epoch: 25 Idx: 0 Loss: 0.008805858650866596
Epoch: 25 Idx: 5000 Loss: 0.008852482214839724
Epoch: 26 Idx: 0 Loss: 0.02620216645323592
Epoch: 26 Idx: 5000 Loss: 0.02632350394418368
Epoch: 27 Idx: 0 Loss: 0.008394257476169356
Epoch: 27 Idx: 5000 Loss: 0.015419833422888085
Epoch: 28 Idx: 0 Loss: 0.027678863840723933
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc227>
Subject: Job 4066810: <python main.py 4 2 False False> in cluster <dcc> Exited

Job <python main.py 4 2 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:36 2020
Job was executed on host(s) <dccxc227>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:37 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 2 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46070.11 sec.
    Max Memory :                                 2889 MB
    Average Memory :                             2752.87 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40528.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46213 sec.
    Turnaround time :                            46205 sec.

The output (if any) is above this job summary.

