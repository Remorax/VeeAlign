2020-09-15 15:48:43.460725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.412283: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:50.526346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:50.526407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:50.528564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:50.547860: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:50.584150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:50.626229: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:50.648240: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:50.648720: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:50.648743: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:50.649226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:50.686171: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600040000 Hz
2020-09-15 15:48:50.686436: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559110a70e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:50.686459: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:50.689284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:50.689309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18293070582709295
Epoch: 0 Idx: 5000 Loss: 0.013616059429683813
Epoch: 1 Idx: 0 Loss: 0.013415528927130368
Epoch: 1 Idx: 5000 Loss: 0.012198793542849216
Epoch: 2 Idx: 0 Loss: 0.011463938719946413
Epoch: 2 Idx: 5000 Loss: 0.01065095297824808
Epoch: 3 Idx: 0 Loss: 0.039145170090008466
Epoch: 3 Idx: 5000 Loss: 0.005524319588258492
Epoch: 4 Idx: 0 Loss: 0.014760252632762842
Epoch: 4 Idx: 5000 Loss: 0.028315097079135546
Epoch: 5 Idx: 0 Loss: 0.011732687413065039
Epoch: 5 Idx: 5000 Loss: 0.03251245876150557
Epoch: 6 Idx: 0 Loss: 0.01749719009550043
Epoch: 6 Idx: 5000 Loss: 0.013330383200601951
Epoch: 7 Idx: 0 Loss: 0.03119023900103992
Epoch: 7 Idx: 5000 Loss: 0.01819117520972457
Epoch: 8 Idx: 0 Loss: 0.031377112028167564
Epoch: 8 Idx: 5000 Loss: 0.005892931148838983
Epoch: 9 Idx: 0 Loss: 0.007794841795800365
Epoch: 9 Idx: 5000 Loss: 0.010476883568319145
Epoch: 10 Idx: 0 Loss: 0.013498467089379296
Epoch: 10 Idx: 5000 Loss: 0.0153394471425317
Epoch: 11 Idx: 0 Loss: 0.02428349747689746
Epoch: 11 Idx: 5000 Loss: 0.02315395399254143
Epoch: 12 Idx: 0 Loss: 0.006900097272690017
Epoch: 12 Idx: 5000 Loss: 0.010645317629047434
Epoch: 13 Idx: 0 Loss: 0.0063581767844340265
Epoch: 13 Idx: 5000 Loss: 0.010559397972064573
Epoch: 14 Idx: 0 Loss: 0.019529664537994346
Epoch: 14 Idx: 5000 Loss: 0.007378127023948055
Epoch: 15 Idx: 0 Loss: 0.014490695133984585
Epoch: 15 Idx: 5000 Loss: 0.013251727440005362
Epoch: 16 Idx: 0 Loss: 0.023706865191425643
Epoch: 16 Idx: 5000 Loss: 0.028036474588332028
Epoch: 17 Idx: 0 Loss: 0.01945678742717515
Epoch: 17 Idx: 5000 Loss: 0.018685258939034777
Epoch: 18 Idx: 0 Loss: 0.012418027570523113
Epoch: 18 Idx: 5000 Loss: 0.025280411008991997
Epoch: 19 Idx: 0 Loss: 0.015370344731044679
Epoch: 19 Idx: 5000 Loss: 0.02058817438238966
Epoch: 20 Idx: 0 Loss: 0.008618142408222654
Epoch: 20 Idx: 5000 Loss: 0.012247414472014257
Epoch: 21 Idx: 0 Loss: 0.01650562200057668
Epoch: 21 Idx: 5000 Loss: 0.01242440591039904
Epoch: 22 Idx: 0 Loss: 0.02470125351702305
Epoch: 22 Idx: 5000 Loss: 0.022374777387482777
Epoch: 23 Idx: 0 Loss: 0.010574251650191562
Epoch: 23 Idx: 5000 Loss: 0.016717375380855347
Epoch: 24 Idx: 0 Loss: 0.012808026268415101
Epoch: 24 Idx: 5000 Loss: 0.020543183801426237
Epoch: 25 Idx: 0 Loss: 0.00940990999664356
Epoch: 25 Idx: 5000 Loss: 0.022888419791989502
Epoch: 26 Idx: 0 Loss: 0.009181352065135404
Epoch: 26 Idx: 5000 Loss: 0.012989813944155605
Epoch: 27 Idx: 0 Loss: 0.006939056211039936
Epoch: 27 Idx: 5000 Loss: 0.015019817622970808
Epoch: 28 Idx: 0 Loss: 0.010051924720776758
Epoch: 28 Idx: 5000 Loss: 0.027670294393923746
Epoch: 29 Idx: 0 Loss: 0.01341965506764145
Epoch: 29 Idx: 5000 Loss: 0.00667324453269476
Epoch: 30 Idx: 0 Loss: 0.017258724785504782
Epoch: 30 Idx: 5000 Loss: 0.008912198164913357
Epoch: 31 Idx: 0 Loss: 0.011934355433582958
Epoch: 31 Idx: 5000 Loss: 0.014539988964102643
Epoch: 32 Idx: 0 Loss: 0.022811605559014837
Epoch: 32 Idx: 5000 Loss: 0.025236351420535638
Epoch: 33 Idx: 0 Loss: 0.013664766148356385
Epoch: 33 Idx: 5000 Loss: 0.030050911033040535
Epoch: 34 Idx: 0 Loss: 0.003427905330132353
Epoch: 34 Idx: 5000 Loss: 0.014511582970640962
Epoch: 35 Idx: 0 Loss: 0.01092931317399743
Epoch: 35 Idx: 5000 Loss: 0.024628608803158304
Epoch: 36 Idx: 0 Loss: 0.024227093230604096
Epoch: 36 Idx: 5000 Loss: 0.015850451664599006
Epoch: 37 Idx: 0 Loss: 0.019707500805941393
Epoch: 37 Idx: 5000 Loss: 0.02905250887901817
Epoch: 38 Idx: 0 Loss: 0.01606121783321076
Epoch: 38 Idx: 5000 Loss: 0.04289569843878488
Epoch: 39 Idx: 0 Loss: 0.01984684115820277
Epoch: 39 Idx: 5000 Loss: 0.042018010236992274
Epoch: 40 Idx: 0 Loss: 0.009167265763020755
Epoch: 40 Idx: 5000 Loss: 0.010295661724718987
Epoch: 41 Idx: 0 Loss: 0.028996764010176288
Epoch: 41 Idx: 5000 Loss: 0.011125633605020486
Epoch: 42 Idx: 0 Loss: 0.015210765824220304
Epoch: 42 Idx: 5000 Loss: 0.02003502227021397
Epoch: 43 Idx: 0 Loss: 0.01126450147343605
Epoch: 43 Idx: 5000 Loss: 0.03218397898989332
Epoch: 44 Idx: 0 Loss: 0.014510504468812822
Epoch: 44 Idx: 5000 Loss: 0.016964150924509733
Epoch: 45 Idx: 0 Loss: 0.026239071580560772
Epoch: 45 Idx: 5000 Loss: 0.017218577865145343
Epoch: 46 Idx: 0 Loss: 0.021272138779785038
Epoch: 46 Idx: 5000 Loss: 0.036420715288610156
Epoch: 47 Idx: 0 Loss: 0.011910877782183363
Epoch: 47 Idx: 5000 Loss: 0.0065881126434426925
Epoch: 48 Idx: 0 Loss: 0.016997998158259926
Epoch: 48 Idx: 5000 Loss: 0.011663554486757368
Epoch: 49 Idx: 0 Loss: 0.0328772669310136
Epoch: 49 Idx: 5000 Loss: 0.012749245892362322
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15388016281524808
Epoch: 0 Idx: 5000 Loss: 0.030632990467788473
Epoch: 1 Idx: 0 Loss: 0.0061507570661915294
Epoch: 1 Idx: 5000 Loss: 0.008394408280800156
Epoch: 2 Idx: 0 Loss: 0.030719722389006554
Epoch: 2 Idx: 5000 Loss: 0.017185580765945153
Epoch: 3 Idx: 0 Loss: 0.014765761265224399
Epoch: 3 Idx: 5000 Loss: 0.013634520755333869
Epoch: 4 Idx: 0 Loss: 0.011217620684636304
Epoch: 4 Idx: 5000 Loss: 0.024844759130087483
Epoch: 5 Idx: 0 Loss: 0.010142841712361482
Epoch: 5 Idx: 5000 Loss: 0.018632117473289314
Epoch: 6 Idx: 0 Loss: 0.01396786003050887
Epoch: 6 Idx: 5000 Loss: 0.021944551052606207
Epoch: 7 Idx: 0 Loss: 0.011800249798222117
Epoch: 7 Idx: 5000 Loss: 0.011548384141044471
Epoch: 8 Idx: 0 Loss: 0.007438538181463342
Epoch: 8 Idx: 5000 Loss: 0.020259221335700933
Epoch: 9 Idx: 0 Loss: 0.01279063679463186
Epoch: 9 Idx: 5000 Loss: 0.009300510368920524
Epoch: 10 Idx: 0 Loss: 0.01305747714216381
Epoch: 10 Idx: 5000 Loss: 0.019402000567838657
Epoch: 11 Idx: 0 Loss: 0.020146433349827995
Epoch: 11 Idx: 5000 Loss: 0.0099375071806545
Epoch: 12 Idx: 0 Loss: 0.01353566148060478
Epoch: 12 Idx: 5000 Loss: 0.013472777519154076
Epoch: 13 Idx: 0 Loss: 0.00967885253398305
Epoch: 13 Idx: 5000 Loss: 0.016313709996354328
Epoch: 14 Idx: 0 Loss: 0.007154894361007025
Epoch: 14 Idx: 5000 Loss: 0.008144258682229732
Epoch: 15 Idx: 0 Loss: 0.010546164949874207
Epoch: 15 Idx: 5000 Loss: 0.008177776628337647
Epoch: 16 Idx: 0 Loss: 0.026972740254876018
Epoch: 16 Idx: 5000 Loss: 0.018871217355112768
Epoch: 17 Idx: 0 Loss: 0.020746531110575193
Epoch: 17 Idx: 5000 Loss: 0.016588493159247854
Epoch: 18 Idx: 0 Loss: 0.01190673398457706
Epoch: 18 Idx: 5000 Loss: 0.016127351533479998
Epoch: 19 Idx: 0 Loss: 0.0528758902710308
Epoch: 19 Idx: 5000 Loss: 0.008783929629664821
Epoch: 20 Idx: 0 Loss: 0.025503069643793192
Epoch: 20 Idx: 5000 Loss: 0.00991654283048652
Epoch: 21 Idx: 0 Loss: 0.008420944574106581
Epoch: 21 Idx: 5000 Loss: 0.018165585009850146
Epoch: 22 Idx: 0 Loss: 0.012708770813159336
Epoch: 22 Idx: 5000 Loss: 0.011085595349122394
Epoch: 23 Idx: 0 Loss: 0.020885832691612656
Epoch: 23 Idx: 5000 Loss: 0.009115122511526536
Epoch: 24 Idx: 0 Loss: 0.01590077234852231
Epoch: 24 Idx: 5000 Loss: 0.00998626707179405
Epoch: 25 Idx: 0 Loss: 0.010253023076151144
Epoch: 25 Idx: 5000 Loss: 0.014338848524113624
Epoch: 26 Idx: 0 Loss: 0.013188582381091846
Epoch: 26 Idx: 5000 Loss: 0.01061878213583738
Epoch: 27 Idx: 0 Loss: 0.00814954071390619
Epoch: 27 Idx: 5000 Loss: 0.016229934850091304
Epoch: 28 Idx: 0 Loss: 0.012188043156461622
Epoch: 28 Idx: 5000 Loss: 0.010645230850390229
Epoch: 29 Idx: 0 Loss: 0.022037019749657438
Epoch: 29 Idx: 5000 Loss: 0.023818182701563995
Epoch: 30 Idx: 0 Loss: 0.017369831033488776
Epoch: 30 Idx: 5000 Loss: 0.026304074829899545
Epoch: 31 Idx: 0 Loss: 0.0118111191412168
Epoch: 31 Idx: 5000 Loss: 0.00992955919066178
Epoch: 32 Idx: 0 Loss: 0.008287574754123658
Epoch: 32 Idx: 5000 Loss: 0.01057296086789429
Epoch: 33 Idx: 0 Loss: 0.012255801058394265
Epoch: 33 Idx: 5000 Loss: 0.02333753919086932
Epoch: 34 Idx: 0 Loss: 0.007221575475326324
Epoch: 34 Idx: 5000 Loss: 0.008304308140514274
Epoch: 35 Idx: 0 Loss: 0.012086774870531768
Epoch: 35 Idx: 5000 Loss: 0.020951161969314167
Epoch: 36 Idx: 0 Loss: 0.016093240322453795
Epoch: 36 Idx: 5000 Loss: 0.02754340344152595
Epoch: 37 Idx: 0 Loss: 0.011346722905092772
Epoch: 37 Idx: 5000 Loss: 0.016482349471130992
Epoch: 38 Idx: 0 Loss: 0.015941407596608673
Epoch: 38 Idx: 5000 Loss: 0.012219245179680744
Epoch: 39 Idx: 0 Loss: 0.014007818012940317
Epoch: 39 Idx: 5000 Loss: 0.017263698698721925
Epoch: 40 Idx: 0 Loss: 0.014822401621674927
Epoch: 40 Idx: 5000 Loss: 0.013959711329864566
Epoch: 41 Idx: 0 Loss: 0.023163519701313435
Epoch: 41 Idx: 5000 Loss: 0.011337489202283436
Epoch: 42 Idx: 0 Loss: 0.04672027147125542
Epoch: 42 Idx: 5000 Loss: 0.03644788011396462
Epoch: 43 Idx: 0 Loss: 0.0193506449643564
Epoch: 43 Idx: 5000 Loss: 0.005948836739034489
Epoch: 44 Idx: 0 Loss: 0.016221142642143555
Epoch: 44 Idx: 5000 Loss: 0.019644647861092802
Epoch: 45 Idx: 0 Loss: 0.00923820638123878
Epoch: 45 Idx: 5000 Loss: 0.031515299611395986
Epoch: 46 Idx: 0 Loss: 0.012112509137269975
Epoch: 46 Idx: 5000 Loss: 0.022297309359358853
Epoch: 47 Idx: 0 Loss: 0.0075127746487582015
Epoch: 47 Idx: 5000 Loss: 0.011154243031457156
Epoch: 48 Idx: 0 Loss: 0.014481111439393717
Epoch: 48 Idx: 5000 Loss: 0.017226590296415482
Epoch: 49 Idx: 0 Loss: 0.03959392271455163
Epoch: 49 Idx: 5000 Loss: 0.007308252863148864
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1400927208699926
Epoch: 0 Idx: 5000 Loss: 0.010376246628978457
Epoch: 1 Idx: 0 Loss: 0.007690080723109351
Epoch: 1 Idx: 5000 Loss: 0.008281127376374655
Epoch: 2 Idx: 0 Loss: 0.015326098322585184
Epoch: 2 Idx: 5000 Loss: 0.01995720552592947
Epoch: 3 Idx: 0 Loss: 0.024980486003287318
Epoch: 3 Idx: 5000 Loss: 0.030473021690584686
Epoch: 4 Idx: 0 Loss: 0.020428199573192234
Epoch: 4 Idx: 5000 Loss: 0.011164644294355323
Epoch: 5 Idx: 0 Loss: 0.02258287195205505
Epoch: 5 Idx: 5000 Loss: 0.007144450199188242
Epoch: 6 Idx: 0 Loss: 0.007439825553324729
Epoch: 6 Idx: 5000 Loss: 0.01055406231129611
Epoch: 7 Idx: 0 Loss: 0.010700088988248015
Epoch: 7 Idx: 5000 Loss: 0.013836262262179147
Epoch: 8 Idx: 0 Loss: 0.010533978511744552
Epoch: 8 Idx: 5000 Loss: 0.018945227540296206
Epoch: 9 Idx: 0 Loss: 0.029589127013426596
Epoch: 9 Idx: 5000 Loss: 0.00842358902066884
Epoch: 10 Idx: 0 Loss: 0.018019710245198967
Epoch: 10 Idx: 5000 Loss: 0.0077450553479096644
Epoch: 11 Idx: 0 Loss: 0.020478376205080008
Epoch: 11 Idx: 5000 Loss: 0.02126826210893686
Epoch: 12 Idx: 0 Loss: 0.006479022320020958
Epoch: 12 Idx: 5000 Loss: 0.0373284390920472
Epoch: 13 Idx: 0 Loss: 0.009014257857838878
Epoch: 13 Idx: 5000 Loss: 0.00958591613733164
Epoch: 14 Idx: 0 Loss: 0.020596960360214155
Epoch: 14 Idx: 5000 Loss: 0.00967016259362075
Epoch: 15 Idx: 0 Loss: 0.01370568306438546
Epoch: 15 Idx: 5000 Loss: 0.007314280567265989
Epoch: 16 Idx: 0 Loss: 0.010197416798323852
Epoch: 16 Idx: 5000 Loss: 0.00881300764404271
Epoch: 17 Idx: 0 Loss: 0.012896190029111236
Epoch: 17 Idx: 5000 Loss: 0.02395669510396748
Epoch: 18 Idx: 0 Loss: 0.024602486360544622
Epoch: 18 Idx: 5000 Loss: 0.008003826484158158
Epoch: 19 Idx: 0 Loss: 0.014915520196794891
Epoch: 19 Idx: 5000 Loss: 0.01718694432164353
Epoch: 20 Idx: 0 Loss: 0.01423913171631035
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 383, in to_feature
    for elem in inputs]
  File "main.py", line 383, in <listcomp>
    for elem in inputs]
  File "main.py", line 382, in <listcomp>
    for ent in elem]
  File "main.py", line 381, in <listcomp>
    for nbr_type in ent[:max_types]]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc205>
Subject: Job 4066836: <python main.py 4 18 False True> in cluster <dcc> Exited

Job <python main.py 4 18 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
Job was executed on host(s) <dccxc205>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:38 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 18 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46075.21 sec.
    Max Memory :                                 2958 MB
    Average Memory :                             2728.95 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40459.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46201 sec.
    Turnaround time :                            46202 sec.

The output (if any) is above this job summary.

