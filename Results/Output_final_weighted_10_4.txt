2020-09-15 15:48:43.770231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:51.181976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:51.295045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:51.295124: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:51.297371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:51.316843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:51.358348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:51.400508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:51.423847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:51.424376: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:51.424399: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:51.424873: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:51.461516: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600205000 Hz
2020-09-15 15:48:51.461839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5570d974ec90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:51.461860: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:51.464925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:51.464983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18566202985259056
Epoch: 0 Idx: 5000 Loss: 0.024656813775105355
Epoch: 1 Idx: 0 Loss: 0.025453895426791315
Epoch: 1 Idx: 5000 Loss: 0.026870291947553984
Epoch: 2 Idx: 0 Loss: 0.017561920282421695
Epoch: 2 Idx: 5000 Loss: 0.025461789198089058
Epoch: 3 Idx: 0 Loss: 0.015977801115594024
Epoch: 3 Idx: 5000 Loss: 0.03037509367894426
Epoch: 4 Idx: 0 Loss: 0.03208094910649681
Epoch: 4 Idx: 5000 Loss: 0.011287170062372924
Epoch: 5 Idx: 0 Loss: 0.012336095265246594
Epoch: 5 Idx: 5000 Loss: 0.006354921294460543
Epoch: 6 Idx: 0 Loss: 0.008846360450615556
Epoch: 6 Idx: 5000 Loss: 0.008704466008645679
Epoch: 7 Idx: 0 Loss: 0.005894736882934304
Epoch: 7 Idx: 5000 Loss: 0.014003165749993964
Epoch: 8 Idx: 0 Loss: 0.00954134060310833
Epoch: 8 Idx: 5000 Loss: 0.0055574053088491985
Epoch: 9 Idx: 0 Loss: 0.01319076504321094
Epoch: 9 Idx: 5000 Loss: 0.006341791815823845
Epoch: 10 Idx: 0 Loss: 0.013239409229966265
Epoch: 10 Idx: 5000 Loss: 0.009490513383625816
Epoch: 11 Idx: 0 Loss: 0.013557137687162617
Epoch: 11 Idx: 5000 Loss: 0.026830107889293058
Epoch: 12 Idx: 0 Loss: 0.013352883870550475
Epoch: 12 Idx: 5000 Loss: 0.019628041096075067
Epoch: 13 Idx: 0 Loss: 0.013089220456473103
Epoch: 13 Idx: 5000 Loss: 0.006474611850333981
Epoch: 14 Idx: 0 Loss: 0.01805480625329032
Epoch: 14 Idx: 5000 Loss: 0.007848996599104098
Epoch: 15 Idx: 0 Loss: 0.021794604040593794
Epoch: 15 Idx: 5000 Loss: 0.012891016555587184
Epoch: 16 Idx: 0 Loss: 0.022787776925447877
Epoch: 16 Idx: 5000 Loss: 0.017588420058167336
Epoch: 17 Idx: 0 Loss: 0.01880217748277182
Epoch: 17 Idx: 5000 Loss: 0.02304901855039127
Epoch: 18 Idx: 0 Loss: 0.023116673048804784
Epoch: 18 Idx: 5000 Loss: 0.04155072227565043
Epoch: 19 Idx: 0 Loss: 0.02568019477701251
Epoch: 19 Idx: 5000 Loss: 0.023644818181847826
Epoch: 20 Idx: 0 Loss: 0.003741678079088048
Epoch: 20 Idx: 5000 Loss: 0.014852160087557888
Epoch: 21 Idx: 0 Loss: 0.014393110805705198
Epoch: 21 Idx: 5000 Loss: 0.020371936254501587
Epoch: 22 Idx: 0 Loss: 0.01234811733853099
Epoch: 22 Idx: 5000 Loss: 0.026264781540348586
Epoch: 23 Idx: 0 Loss: 0.02019860533629703
Epoch: 23 Idx: 5000 Loss: 0.015183152196778998
Epoch: 24 Idx: 0 Loss: 0.02526333674426644
Epoch: 24 Idx: 5000 Loss: 0.02713396173182952
Epoch: 25 Idx: 0 Loss: 0.010041736763106428
Epoch: 25 Idx: 5000 Loss: 0.05311577319349905
Epoch: 26 Idx: 0 Loss: 0.017544564093277055
Epoch: 26 Idx: 5000 Loss: 0.01079088318478242
Epoch: 27 Idx: 0 Loss: 0.00960882398383498
Epoch: 27 Idx: 5000 Loss: 0.03673210841112286
Epoch: 28 Idx: 0 Loss: 0.027299654984000415
Epoch: 28 Idx: 5000 Loss: 0.04503608496512743
Epoch: 29 Idx: 0 Loss: 0.015273907157192129
Epoch: 29 Idx: 5000 Loss: 0.025703651496349546
Epoch: 30 Idx: 0 Loss: 0.01523450484032016
Epoch: 30 Idx: 5000 Loss: 0.01809100617812705
Epoch: 31 Idx: 0 Loss: 0.02065154630616694
Epoch: 31 Idx: 5000 Loss: 0.013260077302382338
Epoch: 32 Idx: 0 Loss: 0.0067291554128940684
Epoch: 32 Idx: 5000 Loss: 0.010635507328128888
Epoch: 33 Idx: 0 Loss: 0.0070894300130318055
Epoch: 33 Idx: 5000 Loss: 0.012280734632402132
Epoch: 34 Idx: 0 Loss: 0.011853820375854914
Epoch: 34 Idx: 5000 Loss: 0.028772957211866595
Epoch: 35 Idx: 0 Loss: 0.015874208337683632
Epoch: 35 Idx: 5000 Loss: 0.013220248506354306
Epoch: 36 Idx: 0 Loss: 0.015027060434849925
Epoch: 36 Idx: 5000 Loss: 0.011673334565953106
Epoch: 37 Idx: 0 Loss: 0.029583710569875327
Epoch: 37 Idx: 5000 Loss: 0.007075830718386941
Epoch: 38 Idx: 0 Loss: 0.026155920760055407
Epoch: 38 Idx: 5000 Loss: 0.018102130469997417
Epoch: 39 Idx: 0 Loss: 0.022420662885770735
Epoch: 39 Idx: 5000 Loss: 0.02211122126446879
Epoch: 40 Idx: 0 Loss: 0.009052445998297238
Epoch: 40 Idx: 5000 Loss: 0.009661683036310193
Epoch: 41 Idx: 0 Loss: 0.021040121899063582
Epoch: 41 Idx: 5000 Loss: 0.0076823990578553224
Epoch: 42 Idx: 0 Loss: 0.017077384401072385
Epoch: 42 Idx: 5000 Loss: 0.0217972873388951
Epoch: 43 Idx: 0 Loss: 0.014930025710178686
Epoch: 43 Idx: 5000 Loss: 0.008928098731848983
Epoch: 44 Idx: 0 Loss: 0.006885951422024414
Epoch: 44 Idx: 5000 Loss: 0.021577651077890003
Epoch: 45 Idx: 0 Loss: 0.005876518451597816
Epoch: 45 Idx: 5000 Loss: 0.015508747102186096
Epoch: 46 Idx: 0 Loss: 0.011588371149412389
Epoch: 46 Idx: 5000 Loss: 0.029083211347279186
Epoch: 47 Idx: 0 Loss: 0.03370119142611523
Epoch: 47 Idx: 5000 Loss: 0.022057656168177963
Epoch: 48 Idx: 0 Loss: 0.01666769363772838
Epoch: 48 Idx: 5000 Loss: 0.011447745220359188
Epoch: 49 Idx: 0 Loss: 0.02313099800883205
Epoch: 49 Idx: 5000 Loss: 0.011299928447605934
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.16691307625008484
Epoch: 0 Idx: 5000 Loss: 0.015606498221396072
Epoch: 1 Idx: 0 Loss: 0.017165857055310617
Epoch: 1 Idx: 5000 Loss: 0.014622878649156176
Epoch: 2 Idx: 0 Loss: 0.018784508443870883
Epoch: 2 Idx: 5000 Loss: 0.024432270917028737
Epoch: 3 Idx: 0 Loss: 0.03148342959626325
Epoch: 3 Idx: 5000 Loss: 0.00873110898470154
Epoch: 4 Idx: 0 Loss: 0.011653085076687757
Epoch: 4 Idx: 5000 Loss: 0.023336486473135677
Epoch: 5 Idx: 0 Loss: 0.01214235986793289
Epoch: 5 Idx: 5000 Loss: 0.010309693600818607
Epoch: 6 Idx: 0 Loss: 0.01062643373350463
Epoch: 6 Idx: 5000 Loss: 0.00897481880770906
Epoch: 7 Idx: 0 Loss: 0.008600691236657135
Epoch: 7 Idx: 5000 Loss: 0.02004140702861527
Epoch: 8 Idx: 0 Loss: 0.04655466742898259
Epoch: 8 Idx: 5000 Loss: 0.03250564252582699
Epoch: 9 Idx: 0 Loss: 0.02526454353442382
Epoch: 9 Idx: 5000 Loss: 0.008200927401427176
Epoch: 10 Idx: 0 Loss: 0.012233556593979992
Epoch: 10 Idx: 5000 Loss: 0.014913468482164172
Epoch: 11 Idx: 0 Loss: 0.025640076557601275
Epoch: 11 Idx: 5000 Loss: 0.010659493704062896
Epoch: 12 Idx: 0 Loss: 0.023019832555026834
Epoch: 12 Idx: 5000 Loss: 0.03991690054203455
Epoch: 13 Idx: 0 Loss: 0.029460248457300428
Epoch: 13 Idx: 5000 Loss: 0.016559405721476083
Epoch: 14 Idx: 0 Loss: 0.03726289560662997
Epoch: 14 Idx: 5000 Loss: 0.00418623475105007
Epoch: 15 Idx: 0 Loss: 0.02359965874439252
Epoch: 15 Idx: 5000 Loss: 0.041310131082136055
Epoch: 16 Idx: 0 Loss: 0.01600385451475188
Epoch: 16 Idx: 5000 Loss: 0.02219169286512952
Epoch: 17 Idx: 0 Loss: 0.024890113264419138
Epoch: 17 Idx: 5000 Loss: 0.02520919200321903
Epoch: 18 Idx: 0 Loss: 0.012932737941318351
Epoch: 18 Idx: 5000 Loss: 0.017881215776236165
Epoch: 19 Idx: 0 Loss: 0.012394663343727061
Epoch: 19 Idx: 5000 Loss: 0.008344887603674295
Epoch: 20 Idx: 0 Loss: 0.01124632435208783
Epoch: 20 Idx: 5000 Loss: 0.01603599655824868
Epoch: 21 Idx: 0 Loss: 0.012069425434273733
Epoch: 21 Idx: 5000 Loss: 0.008802565510495906
Epoch: 22 Idx: 0 Loss: 0.015894654161156416
Epoch: 22 Idx: 5000 Loss: 0.0065917417317518925
Epoch: 23 Idx: 0 Loss: 0.02577208998850681
Epoch: 23 Idx: 5000 Loss: 0.014738387810252607
Epoch: 24 Idx: 0 Loss: 0.014546287871112605
Epoch: 24 Idx: 5000 Loss: 0.03393194588403048
Epoch: 25 Idx: 0 Loss: 0.02476646873875354
Epoch: 25 Idx: 5000 Loss: 0.009485546252434907
Epoch: 26 Idx: 0 Loss: 0.00988294781258615
Epoch: 26 Idx: 5000 Loss: 0.014485369867560426
Epoch: 27 Idx: 0 Loss: 0.01926075190841693
Epoch: 27 Idx: 5000 Loss: 0.034102460006501176
Epoch: 28 Idx: 0 Loss: 0.021453953643481332
Epoch: 28 Idx: 5000 Loss: 0.011918389854051257
Epoch: 29 Idx: 0 Loss: 0.00940279212850775
Epoch: 29 Idx: 5000 Loss: 0.026856371491159055
Epoch: 30 Idx: 0 Loss: 0.015391923152815224
Epoch: 30 Idx: 5000 Loss: 0.01883424909308028
Epoch: 31 Idx: 0 Loss: 0.012161086798849013
Epoch: 31 Idx: 5000 Loss: 0.009129233949652574
Epoch: 32 Idx: 0 Loss: 0.012730036625824653
Epoch: 32 Idx: 5000 Loss: 0.019079933603882132
Epoch: 33 Idx: 0 Loss: 0.01503169759132455
Epoch: 33 Idx: 5000 Loss: 0.010085921280261775
Epoch: 34 Idx: 0 Loss: 0.023299433343305278
Epoch: 34 Idx: 5000 Loss: 0.011268282685261323
Epoch: 35 Idx: 0 Loss: 0.008971897159300211
Epoch: 35 Idx: 5000 Loss: 0.01547427179509926
Epoch: 36 Idx: 0 Loss: 0.015172321716455859
Epoch: 36 Idx: 5000 Loss: 0.022932812538060565
Epoch: 37 Idx: 0 Loss: 0.03857906509838353
Epoch: 37 Idx: 5000 Loss: 0.02101102199652705
Epoch: 38 Idx: 0 Loss: 0.014499978228304542
Epoch: 38 Idx: 5000 Loss: 0.02500942513105194
Epoch: 39 Idx: 0 Loss: 0.00886801567314884
Epoch: 39 Idx: 5000 Loss: 0.03147076418565537
Epoch: 40 Idx: 0 Loss: 0.010631776764722297
Epoch: 40 Idx: 5000 Loss: 0.03863947652389907
Epoch: 41 Idx: 0 Loss: 0.01726586762328913
Epoch: 41 Idx: 5000 Loss: 0.009633275881810628
Epoch: 42 Idx: 0 Loss: 0.011311293066794792
Epoch: 42 Idx: 5000 Loss: 0.0208925623002715
Epoch: 43 Idx: 0 Loss: 0.019815009416898885
Epoch: 43 Idx: 5000 Loss: 0.012538896900441063
Epoch: 44 Idx: 0 Loss: 0.020878828290402496
Epoch: 44 Idx: 5000 Loss: 0.01292306627265507
Epoch: 45 Idx: 0 Loss: 0.031172557479883827
Epoch: 45 Idx: 5000 Loss: 0.015054409222777057
Epoch: 46 Idx: 0 Loss: 0.022077429181916162
Epoch: 46 Idx: 5000 Loss: 0.02101646071440417
Epoch: 47 Idx: 0 Loss: 0.0064640257484170766
Epoch: 47 Idx: 5000 Loss: 0.025083750615232776
Epoch: 48 Idx: 0 Loss: 0.009134402416884
Epoch: 48 Idx: 5000 Loss: 0.03310722965255934
Epoch: 49 Idx: 0 Loss: 0.015469380909478185
Epoch: 49 Idx: 5000 Loss: 0.022075133211081052
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.1749830247759842
Epoch: 0 Idx: 5000 Loss: 0.026513184558543575
Epoch: 1 Idx: 0 Loss: 0.014348806719597842
Epoch: 1 Idx: 5000 Loss: 0.005687791534398094
Epoch: 2 Idx: 0 Loss: 0.02006079291624491
Epoch: 2 Idx: 5000 Loss: 0.020131847985882752
Epoch: 3 Idx: 0 Loss: 0.015677961613589978
Epoch: 3 Idx: 5000 Loss: 0.011833002140892841
Epoch: 4 Idx: 0 Loss: 0.01691033066641255
Epoch: 4 Idx: 5000 Loss: 0.018613519440094338
Epoch: 5 Idx: 0 Loss: 0.030683976850522723
Epoch: 5 Idx: 5000 Loss: 0.012225775070092287
Epoch: 6 Idx: 0 Loss: 0.009447679222240041
Epoch: 6 Idx: 5000 Loss: 0.017615962937183465
Epoch: 7 Idx: 0 Loss: 0.018948917376001795
Epoch: 7 Idx: 5000 Loss: 0.01588576813352631
Epoch: 8 Idx: 0 Loss: 0.011844443479860307
Epoch: 8 Idx: 5000 Loss: 0.01471736493094789
Epoch: 9 Idx: 0 Loss: 0.013964404206176742
Epoch: 9 Idx: 5000 Loss: 0.011922492571876402
Epoch: 10 Idx: 0 Loss: 0.010391417428347382
Epoch: 10 Idx: 5000 Loss: 0.017407159727175055
Epoch: 11 Idx: 0 Loss: 0.026188442234051444
Epoch: 11 Idx: 5000 Loss: 0.014190417041096151
Epoch: 12 Idx: 0 Loss: 0.012667041827529785
Epoch: 12 Idx: 5000 Loss: 0.012104460502212954
Epoch: 13 Idx: 0 Loss: 0.011789016269714327
Epoch: 13 Idx: 5000 Loss: 0.018210596739029316
Epoch: 14 Idx: 0 Loss: 0.022891853786433297
Epoch: 14 Idx: 5000 Loss: 0.024088896990652156
Epoch: 15 Idx: 0 Loss: 0.012283434343111035
Epoch: 15 Idx: 5000 Loss: 0.014348837310701355
Epoch: 16 Idx: 0 Loss: 0.013502751074258352
Epoch: 16 Idx: 5000 Loss: 0.007016697290883841
Epoch: 17 Idx: 0 Loss: 0.022523086028889788
Epoch: 17 Idx: 5000 Loss: 0.01213606930340881
Epoch: 18 Idx: 0 Loss: 0.006258518746639506
Epoch: 18 Idx: 5000 Loss: 0.007358821804973778
Epoch: 19 Idx: 0 Loss: 0.019385044610781707
Epoch: 19 Idx: 5000 Loss: 0.02534764757701529
Epoch: 20 Idx: 0 Loss: 0.012236823831079111
Epoch: 20 Idx: 5000 Loss: 0.010465530112117925
Epoch: 21 Idx: 0 Loss: 0.012660180391754237
Epoch: 21 Idx: 5000 Loss: 0.0070257829441497405
Epoch: 22 Idx: 0 Loss: 0.012051929095415782
Epoch: 22 Idx: 5000 Loss: 0.01457394421009458
Epoch: 23 Idx: 0 Loss: 0.01051703709553899
Epoch: 23 Idx: 5000 Loss: 0.027620676017978858
Epoch: 24 Idx: 0 Loss: 0.010442526918596276
Epoch: 24 Idx: 5000 Loss: 0.024198126104676972
Epoch: 25 Idx: 0 Loss: 0.029777128033504373
Epoch: 25 Idx: 5000 Loss: 0.0263131625765761
Epoch: 26 Idx: 0 Loss: 0.014919882014368101
Epoch: 26 Idx: 5000 Loss: 0.012188246661473825
Epoch: 27 Idx: 0 Loss: 0.027531276354111685
Epoch: 27 Idx: 5000 Loss: 0.016723869449930658
Epoch: 28 Idx: 0 Loss: 0.019806420955120446
Epoch: 28 Idx: 5000 Loss: 0.006609169006105612
Epoch: 29 Idx: 0 Loss: 0.007451340877143935
Epoch: 29 Idx: 5000 Loss: 0.009540543913770948
Epoch: 30 Idx: 0 Loss: 0.011877896846637991
Epoch: 30 Idx: 5000 Loss: 0.014368353985460613
Epoch: 31 Idx: 0 Loss: 0.009078927628390902
Epoch: 31 Idx: 5000 Loss: 0.008561280198850545
Epoch: 32 Idx: 0 Loss: 0.02056732669934737
Epoch: 32 Idx: 5000 Loss: 0.006813115401172296
Epoch: 33 Idx: 0 Loss: 0.005733196935979476
Epoch: 33 Idx: 5000 Loss: 0.025234464428049032
Epoch: 34 Idx: 0 Loss: 0.02970294476009081
Epoch: 34 Idx: 5000 Loss: 0.007468875333712778
Epoch: 35 Idx: 0 Loss: 0.037975011081960365
Epoch: 35 Idx: 5000 Loss: 0.018443669070407124
Epoch: 36 Idx: 0 Loss: 0.014682507545986184
Epoch: 36 Idx: 5000 Loss: 0.015357608687607521
Epoch: 37 Idx: 0 Loss: 0.012388425249817576
Epoch: 37 Idx: 5000 Loss: 0.01593185048983286
Epoch: 38 Idx: 0 Loss: 0.006076785551228921
Epoch: 38 Idx: 5000 Loss: 0.014370499349673733
Epoch: 39 Idx: 0 Loss: 0.018778807521636656
Epoch: 39 Idx: 5000 Loss: 0.02424033049908985
Epoch: 40 Idx: 0 Loss: 0.030635977007701255
Epoch: 40 Idx: 5000 Loss: 0.011944618917344923
Epoch: 41 Idx: 0 Loss: 0.014026654915609697
Epoch: 41 Idx: 5000 Loss: 0.01901363121201692
Epoch: 42 Idx: 0 Loss: 0.014912165461936334
Epoch: 42 Idx: 5000 Loss: 0.014630158585288211
Epoch: 43 Idx: 0 Loss: 0.006204263010087247
Epoch: 43 Idx: 5000 Loss: 0.011232370172926942
Epoch: 44 Idx: 0 Loss: 0.04680684590004952
Epoch: 44 Idx: 5000 Loss: 0.009116170583680833
Epoch: 45 Idx: 0 Loss: 0.06548840040458506
Epoch: 45 Idx: 5000 Loss: 0.01061139227093364
Epoch: 46 Idx: 0 Loss: 0.006987759562681264
Epoch: 46 Idx: 5000 Loss: 0.01739740410333357
Epoch: 47 Idx: 0 Loss: 0.012532509426229027
Epoch: 47 Idx: 5000 Loss: 0.016076288907656586
Epoch: 48 Idx: 0 Loss: 0.009959715734744813
Epoch: 48 Idx: 5000 Loss: 0.012529694873642331
Epoch: 49 Idx: 0 Loss: 0.0144993016655462
Epoch: 49 Idx: 5000 Loss: 0.008424428955199546
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.2290973031343802
Epoch: 0 Idx: 5000 Loss: 0.009834662616709157
Epoch: 1 Idx: 0 Loss: 0.006531753718194217
Epoch: 1 Idx: 5000 Loss: 0.016577801541663034
Epoch: 2 Idx: 0 Loss: 0.008832964990483534
Epoch: 2 Idx: 5000 Loss: 0.02344251276403906
Epoch: 3 Idx: 0 Loss: 0.00733502189622837
Epoch: 3 Idx: 5000 Loss: 0.013690528847457195
Epoch: 4 Idx: 0 Loss: 0.016554412306753388
Epoch: 4 Idx: 5000 Loss: 0.005694842626261828
Epoch: 5 Idx: 0 Loss: 0.022714473562568564
Epoch: 5 Idx: 5000 Loss: 0.011616744985069571
Epoch: 6 Idx: 0 Loss: 0.017478727855906845
Epoch: 6 Idx: 5000 Loss: 0.024097843327062822
Epoch: 7 Idx: 0 Loss: 0.011055773446203279
Epoch: 7 Idx: 5000 Loss: 0.012064064865526539
Epoch: 8 Idx: 0 Loss: 0.030963507718983985
Epoch: 8 Idx: 5000 Loss: 0.02175973319649444
Epoch: 9 Idx: 0 Loss: 0.008989877768762798
Epoch: 9 Idx: 5000 Loss: 0.014749568964107614
Epoch: 10 Idx: 0 Loss: 0.022788793080889068
Epoch: 10 Idx: 5000 Loss: 0.010224413285911189
Epoch: 11 Idx: 0 Loss: 0.01401793409066871
Epoch: 11 Idx: 5000 Loss: 0.012068047843828918
Epoch: 12 Idx: 0 Loss: 0.036434243201401206
Epoch: 12 Idx: 5000 Loss: 0.05025307573603993
Epoch: 13 Idx: 0 Loss: 0.012247822143823568
Epoch: 13 Idx: 5000 Loss: 0.024290901185644587
Epoch: 14 Idx: 0 Loss: 0.01772496087369556
Epoch: 14 Idx: 5000 Loss: 0.013807486483401575
Epoch: 15 Idx: 0 Loss: 0.014646156002324209
Epoch: 15 Idx: 5000 Loss: 0.008732166098747931
Epoch: 16 Idx: 0 Loss: 0.01195459350018806
Epoch: 16 Idx: 5000 Loss: 0.01344967304384863
Epoch: 17 Idx: 0 Loss: 0.013299349321335025
Epoch: 17 Idx: 5000 Loss: 0.007230357883748834
Epoch: 18 Idx: 0 Loss: 0.02199733412313797
Epoch: 18 Idx: 5000 Loss: 0.014050553189975744
Epoch: 19 Idx: 0 Loss: 0.01755036571484986
Epoch: 19 Idx: 5000 Loss: 0.03809282170700974
Epoch: 20 Idx: 0 Loss: 0.005796083094186222
Epoch: 20 Idx: 5000 Loss: 0.014826825895751912
Epoch: 21 Idx: 0 Loss: 0.006547436570619172
Epoch: 21 Idx: 5000 Loss: 0.026422159299720943
Epoch: 22 Idx: 0 Loss: 0.013642129457434728
Epoch: 22 Idx: 5000 Loss: 0.015178700311635932
Epoch: 23 Idx: 0 Loss: 0.02133346855467587
Epoch: 23 Idx: 5000 Loss: 0.011704679478199868
Epoch: 24 Idx: 0 Loss: 0.008354825888173935
Epoch: 24 Idx: 5000 Loss: 0.021751491976010204
Epoch: 25 Idx: 0 Loss: 0.007695965621069728
Epoch: 25 Idx: 5000 Loss: 0.023668499578316425
Epoch: 26 Idx: 0 Loss: 0.017363556840764127
Epoch: 26 Idx: 5000 Loss: 0.02168139763420909
Epoch: 27 Idx: 0 Loss: 0.012806623192705893
Epoch: 27 Idx: 5000 Loss: 0.01572793706565894
Epoch: 28 Idx: 0 Loss: 0.00992879184173192
Epoch: 28 Idx: 5000 Loss: 0.0111510634435493
Epoch: 29 Idx: 0 Loss: 0.008966726622544914
Epoch: 29 Idx: 5000 Loss: 0.01891560423883442
Epoch: 30 Idx: 0 Loss: 0.02665474443641629
Epoch: 30 Idx: 5000 Loss: 0.020694761954816135
Epoch: 31 Idx: 0 Loss: 0.009717829485090873
Epoch: 31 Idx: 5000 Loss: 0.008512890018857827
Epoch: 32 Idx: 0 Loss: 0.04329148189390017
Epoch: 32 Idx: 5000 Loss: 0.037177462321182644
Epoch: 33 Idx: 0 Loss: 0.009728756063839434
Epoch: 33 Idx: 5000 Loss: 0.009431534626085376
Epoch: 34 Idx: 0 Loss: 0.013370584814935907
Epoch: 34 Idx: 5000 Loss: 0.021887948427291328
Epoch: 35 Idx: 0 Loss: 0.00927697789258236
Epoch: 35 Idx: 5000 Loss: 0.023056200597515723
Epoch: 36 Idx: 0 Loss: 0.03950831661688629
Epoch: 36 Idx: 5000 Loss: 0.009760796391061692
Epoch: 37 Idx: 0 Loss: 0.017968599275587468
Epoch: 37 Idx: 5000 Loss: 0.005260520915416002
Epoch: 38 Idx: 0 Loss: 0.023353835440210993
Epoch: 38 Idx: 5000 Loss: 0.005931281463167135
Epoch: 39 Idx: 0 Loss: 0.03392768816513196
Epoch: 39 Idx: 5000 Loss: 0.02080176093938424
Epoch: 40 Idx: 0 Loss: 0.020297503700155393
Epoch: 40 Idx: 5000 Loss: 0.018135528325340662
Epoch: 41 Idx: 0 Loss: 0.013041961593122191
Epoch: 41 Idx: 5000 Loss: 0.020524700414408337
Epoch: 42 Idx: 0 Loss: 0.00862287948054574
Epoch: 42 Idx: 5000 Loss: 0.017376179572780467
Epoch: 43 Idx: 0 Loss: 0.013798434183617501
Epoch: 43 Idx: 5000 Loss: 0.014501180930561679
Epoch: 44 Idx: 0 Loss: 0.019117169337179486
Epoch: 44 Idx: 5000 Loss: 0.014234206476299974
Epoch: 45 Idx: 0 Loss: 0.011087575635199857
Epoch: 45 Idx: 5000 Loss: 0.011759276785898151
Epoch: 46 Idx: 0 Loss: 0.02096379331911237
Epoch: 46 Idx: 5000 Loss: 0.03167077518109247
Epoch: 47 Idx: 0 Loss: 0.016005177867624776
Epoch: 47 Idx: 5000 Loss: 0.01212475186944761
Epoch: 48 Idx: 0 Loss: 0.015864655161828597
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc246>
Subject: Job 4066832: <python main.py 4 10 False True> in cluster <dcc> Exited

Job <python main.py 4 10 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:37 2020
Job was executed on host(s) <dccxc246>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:38 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 10 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46184.81 sec.
    Max Memory :                                 2935 MB
    Average Memory :                             2740.61 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40482.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46221 sec.
    Turnaround time :                            46203 sec.

The output (if any) is above this job summary.

