2020-09-16 07:38:34.370714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:38:43.049611: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:38:43.164235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:38:43.164318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:38:43.166205: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:38:43.167568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:38:43.167892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:38:43.169690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:38:43.170980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:38:43.171136: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 07:38:43.171158: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:38:43.171469: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:38:43.178766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600145000 Hz
2020-09-16 07:38:43.178945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605d925f500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:38:43.178965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:38:43.180741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:38:43.180766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.206143652062808
Epoch: 0 Idx: 5000 Loss: 0.004986622608546293
Epoch: 1 Idx: 0 Loss: 0.017971388090624856
Epoch: 1 Idx: 5000 Loss: 0.012356823735622236
Epoch: 2 Idx: 0 Loss: 0.008503006971729928
Epoch: 2 Idx: 5000 Loss: 0.012384345317013374
Epoch: 3 Idx: 0 Loss: 0.016952988362870326
Epoch: 3 Idx: 5000 Loss: 0.006572445907441726
Epoch: 4 Idx: 0 Loss: 0.012106888393399148
Epoch: 4 Idx: 5000 Loss: 0.003801106113632281
Epoch: 5 Idx: 0 Loss: 0.008997370571856619
Epoch: 5 Idx: 5000 Loss: 0.0157632796543918
Epoch: 6 Idx: 0 Loss: 0.02290967912631491
Epoch: 6 Idx: 5000 Loss: 0.015088454523464518
Epoch: 7 Idx: 0 Loss: 0.011294848137898664
Epoch: 7 Idx: 5000 Loss: 0.011523595037388094
Epoch: 8 Idx: 0 Loss: 0.03408394149681594
Epoch: 8 Idx: 5000 Loss: 0.010460579169237635
Epoch: 9 Idx: 0 Loss: 0.012340355015688084
Epoch: 9 Idx: 5000 Loss: 0.019458751306520014
Epoch: 10 Idx: 0 Loss: 0.010792948038627365
Epoch: 10 Idx: 5000 Loss: 0.04511181678930112
Epoch: 11 Idx: 0 Loss: 0.013713514544079637
Epoch: 11 Idx: 5000 Loss: 0.03216470821646456
Epoch: 12 Idx: 0 Loss: 0.011725866079925686
Epoch: 12 Idx: 5000 Loss: 0.03133511648381127
Epoch: 13 Idx: 0 Loss: 0.008277376276139312
Epoch: 13 Idx: 5000 Loss: 0.007516678787158334
Epoch: 14 Idx: 0 Loss: 0.03865317902205577
Epoch: 14 Idx: 5000 Loss: 0.01555708047037136
Epoch: 15 Idx: 0 Loss: 0.012519825587130133
Epoch: 15 Idx: 5000 Loss: 0.004752824221715522
Epoch: 16 Idx: 0 Loss: 0.010873796410990458
Epoch: 16 Idx: 5000 Loss: 0.014001861867217538
Epoch: 17 Idx: 0 Loss: 0.03646814545902027
Epoch: 17 Idx: 5000 Loss: 0.016043814597599217
Epoch: 18 Idx: 0 Loss: 0.03038961536539746
Epoch: 18 Idx: 5000 Loss: 0.010118159684948405
Epoch: 19 Idx: 0 Loss: 0.016135763168325247
Epoch: 19 Idx: 5000 Loss: 0.007689113635582828
Epoch: 20 Idx: 0 Loss: 0.005397999809877503
Epoch: 20 Idx: 5000 Loss: 0.010962013308540318
Epoch: 21 Idx: 0 Loss: 0.00903169429812139
Epoch: 21 Idx: 5000 Loss: 0.010379328001662986
Epoch: 22 Idx: 0 Loss: 0.01597722255940507
Epoch: 22 Idx: 5000 Loss: 0.013699441128148263
Epoch: 23 Idx: 0 Loss: 0.010413302881404879
Epoch: 23 Idx: 5000 Loss: 0.02600367086262728
Epoch: 24 Idx: 0 Loss: 0.017399411054123837
Epoch: 24 Idx: 5000 Loss: 0.04014890072918486
Epoch: 25 Idx: 0 Loss: 0.01461915312725328
Epoch: 25 Idx: 5000 Loss: 0.014889212191106158
Epoch: 26 Idx: 0 Loss: 0.008866196879330981
Epoch: 26 Idx: 5000 Loss: 0.03053079900679002
Epoch: 27 Idx: 0 Loss: 0.018760219323597532
Epoch: 27 Idx: 5000 Loss: 0.0201754882540799
Epoch: 28 Idx: 0 Loss: 0.020907839648481887
Epoch: 28 Idx: 5000 Loss: 0.02775220849693842
Epoch: 29 Idx: 0 Loss: 0.010393427722665272
Epoch: 29 Idx: 5000 Loss: 0.012227051021194313
Epoch: 30 Idx: 0 Loss: 0.019714946736403897
Epoch: 30 Idx: 5000 Loss: 0.00784465504934056
Epoch: 31 Idx: 0 Loss: 0.018548522068368017
Epoch: 31 Idx: 5000 Loss: 0.013988661800930178
Epoch: 32 Idx: 0 Loss: 0.01961855089062595
Epoch: 32 Idx: 5000 Loss: 0.013256831147394574
Epoch: 33 Idx: 0 Loss: 0.019312636613780784
Epoch: 33 Idx: 5000 Loss: 0.006616222888910214
Epoch: 34 Idx: 0 Loss: 0.024067961707677037
Epoch: 34 Idx: 5000 Loss: 0.01553053253581899
Epoch: 35 Idx: 0 Loss: 0.020968230971960676
Epoch: 35 Idx: 5000 Loss: 0.006563194883825455
Epoch: 36 Idx: 0 Loss: 0.04308784816998341
Epoch: 36 Idx: 5000 Loss: 0.009881722641247887
Epoch: 37 Idx: 0 Loss: 0.03719056113598087
Epoch: 37 Idx: 5000 Loss: 0.01253886449936666
Epoch: 38 Idx: 0 Loss: 0.03643822653153332
Epoch: 38 Idx: 5000 Loss: 0.025023681047469385
Epoch: 39 Idx: 0 Loss: 0.012857148925366664
Epoch: 39 Idx: 5000 Loss: 0.019669677211807575
Epoch: 40 Idx: 0 Loss: 0.029494109587863065
Epoch: 40 Idx: 5000 Loss: 0.015674681701775696
Epoch: 41 Idx: 0 Loss: 0.010988323994332552
Epoch: 41 Idx: 5000 Loss: 0.009333034159152091
Epoch: 42 Idx: 0 Loss: 0.007745097182322396
Epoch: 42 Idx: 5000 Loss: 0.017021559590035793
Epoch: 43 Idx: 0 Loss: 0.006027467940972187
Epoch: 43 Idx: 5000 Loss: 0.011997652246651952
Epoch: 44 Idx: 0 Loss: 0.02214689458753797
Epoch: 44 Idx: 5000 Loss: 0.008805528896145998
Epoch: 45 Idx: 0 Loss: 0.005918522775872152
Epoch: 45 Idx: 5000 Loss: 0.012755493451969819
Epoch: 46 Idx: 0 Loss: 0.016943494069780712
Epoch: 46 Idx: 5000 Loss: 0.01121138485663958
Epoch: 47 Idx: 0 Loss: 0.02262947175383983
Epoch: 47 Idx: 5000 Loss: 0.0046995982966501195
Epoch: 48 Idx: 0 Loss: 0.008500336805905402
Epoch: 48 Idx: 5000 Loss: 0.014763480048436233
Epoch: 49 Idx: 0 Loss: 0.012327149735101331
Epoch: 49 Idx: 5000 Loss: 0.008342814142311921
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.23943292161381108
Epoch: 0 Idx: 5000 Loss: 0.0432017734966772
Epoch: 1 Idx: 0 Loss: 0.012444938559019944
Epoch: 1 Idx: 5000 Loss: 0.02048659262880209
Epoch: 2 Idx: 0 Loss: 0.01780183563452073
Epoch: 2 Idx: 5000 Loss: 0.022272258097974215
Epoch: 3 Idx: 0 Loss: 0.009990882719558555
Epoch: 3 Idx: 5000 Loss: 0.02414499184791277
Epoch: 4 Idx: 0 Loss: 0.012771954020072758
Epoch: 4 Idx: 5000 Loss: 0.004853630845654565
Epoch: 5 Idx: 0 Loss: 0.012813086804828996
Epoch: 5 Idx: 5000 Loss: 0.009955521746937899
Epoch: 6 Idx: 0 Loss: 0.006522649412984374
Epoch: 6 Idx: 5000 Loss: 0.00652070275564573
Epoch: 7 Idx: 0 Loss: 0.00803269325575394
Epoch: 7 Idx: 5000 Loss: 0.021613503147877307
Epoch: 8 Idx: 0 Loss: 0.00977517374106074
Epoch: 8 Idx: 5000 Loss: 0.009856007925261227
Epoch: 9 Idx: 0 Loss: 0.04966598520567943
Epoch: 9 Idx: 5000 Loss: 0.005814193830798461
Epoch: 10 Idx: 0 Loss: 0.017091968327350174
Epoch: 10 Idx: 5000 Loss: 0.011592752180686026
Epoch: 11 Idx: 0 Loss: 0.03494701401418907
Epoch: 11 Idx: 5000 Loss: 0.008878832767578193
Epoch: 12 Idx: 0 Loss: 0.012394606489936351
Epoch: 12 Idx: 5000 Loss: 0.011770636330984664
Epoch: 13 Idx: 0 Loss: 0.01411976401542987
Epoch: 13 Idx: 5000 Loss: 0.017773114209483045
Epoch: 14 Idx: 0 Loss: 0.01353900846204583
Epoch: 14 Idx: 5000 Loss: 0.017045389162838803
Epoch: 15 Idx: 0 Loss: 0.008811806721144337
Epoch: 15 Idx: 5000 Loss: 0.020771142726983084
Epoch: 16 Idx: 0 Loss: 0.012583479771741297
Epoch: 16 Idx: 5000 Loss: 0.014680273628776296
Epoch: 17 Idx: 0 Loss: 0.018104266322779755
Epoch: 17 Idx: 5000 Loss: 0.020094523359099288
Epoch: 18 Idx: 0 Loss: 0.03421392863259758
Epoch: 18 Idx: 5000 Loss: 0.023850643468465847
Epoch: 19 Idx: 0 Loss: 0.016639758166319057
Epoch: 19 Idx: 5000 Loss: 0.01768960350170969
Epoch: 20 Idx: 0 Loss: 0.013148434798314904
Epoch: 20 Idx: 5000 Loss: 0.03458065126601311
Epoch: 21 Idx: 0 Loss: 0.0075092228409805025
Epoch: 21 Idx: 5000 Loss: 0.018814624615272047
Epoch: 22 Idx: 0 Loss: 0.00470609767466461
Epoch: 22 Idx: 5000 Loss: 0.05415314742034603
Epoch: 23 Idx: 0 Loss: 0.013849666282944626
Epoch: 23 Idx: 5000 Loss: 0.029577447391349838
Epoch: 24 Idx: 0 Loss: 0.013297217645456699
Epoch: 24 Idx: 5000 Loss: 0.024859751113430625
Epoch: 25 Idx: 0 Loss: 0.015421494911416476
Epoch: 25 Idx: 5000 Loss: 0.03479690062279857
Epoch: 26 Idx: 0 Loss: 0.03801030938595892
Epoch: 26 Idx: 5000 Loss: 0.006466783913829814
Epoch: 27 Idx: 0 Loss: 0.01742939711359532
Epoch: 27 Idx: 5000 Loss: 0.0081313101058153
Epoch: 28 Idx: 0 Loss: 0.023013549149830496
Epoch: 28 Idx: 5000 Loss: 0.01646137469914783
Epoch: 29 Idx: 0 Loss: 0.02435001012514261
Epoch: 29 Idx: 5000 Loss: 0.01048552120939221
Epoch: 30 Idx: 0 Loss: 0.01813548265000173
Epoch: 30 Idx: 5000 Loss: 0.031174325066516163
Epoch: 31 Idx: 0 Loss: 0.021377641730079458
Epoch: 31 Idx: 5000 Loss: 0.007165508061523936
Epoch: 32 Idx: 0 Loss: 0.01562780673563448
Epoch: 32 Idx: 5000 Loss: 0.011018611672452789
Epoch: 33 Idx: 0 Loss: 0.012961173125360777
Epoch: 33 Idx: 5000 Loss: 0.011621310554665684
Epoch: 34 Idx: 0 Loss: 0.016797175141210235
Epoch: 34 Idx: 5000 Loss: 0.014042315044000771
Epoch: 35 Idx: 0 Loss: 0.025929909943335716
Epoch: 35 Idx: 5000 Loss: 0.017038931550044403
Epoch: 36 Idx: 0 Loss: 0.014864633144283103
Epoch: 36 Idx: 5000 Loss: 0.015073014403669661
Epoch: 37 Idx: 0 Loss: 0.018542039370114186
Epoch: 37 Idx: 5000 Loss: 0.015482229535833166
Epoch: 38 Idx: 0 Loss: 0.034296740822237715
Epoch: 38 Idx: 5000 Loss: 0.01714183727564709
Epoch: 39 Idx: 0 Loss: 0.010859401177867933
Epoch: 39 Idx: 5000 Loss: 0.012980749808158436
Epoch: 40 Idx: 0 Loss: 0.013320259669929481
Epoch: 40 Idx: 5000 Loss: 0.020396929774015783
Epoch: 41 Idx: 0 Loss: 0.009099991007508523
Epoch: 41 Idx: 5000 Loss: 0.008588661680047011
Epoch: 42 Idx: 0 Loss: 0.027403331678820506
Epoch: 42 Idx: 5000 Loss: 0.02064150401333461
Epoch: 43 Idx: 0 Loss: 0.02151076969042208
Epoch: 43 Idx: 5000 Loss: 0.021655809045690345
Epoch: 44 Idx: 0 Loss: 0.015372803185248302
Epoch: 44 Idx: 5000 Loss: 0.0163675619109764
Epoch: 45 Idx: 0 Loss: 0.020557549890450333
Epoch: 45 Idx: 5000 Loss: 0.0201014180594023
Epoch: 46 Idx: 0 Loss: 0.017152031277688752
Epoch: 46 Idx: 5000 Loss: 0.011421293590143445
Epoch: 47 Idx: 0 Loss: 0.013512258604102543
Epoch: 47 Idx: 5000 Loss: 0.005094333101164483
Epoch: 48 Idx: 0 Loss: 0.015332984769207431
Epoch: 48 Idx: 5000 Loss: 0.011821098347404434
Epoch: 49 Idx: 0 Loss: 0.012995202294459836
Epoch: 49 Idx: 5000 Loss: 0.023590500763036037
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.18685642541856784
Epoch: 0 Idx: 5000 Loss: 0.017278304886299577
Epoch: 1 Idx: 0 Loss: 0.016662352766949454
Epoch: 1 Idx: 5000 Loss: 0.022194550124335237
Epoch: 2 Idx: 0 Loss: 0.009733818580692161
Epoch: 2 Idx: 5000 Loss: 0.02299059792719761
Epoch: 3 Idx: 0 Loss: 0.016035110256809388
Epoch: 3 Idx: 5000 Loss: 0.005311420280827135
Epoch: 4 Idx: 0 Loss: 0.008808589777217228
Epoch: 4 Idx: 5000 Loss: 0.013553580588282365
Epoch: 5 Idx: 0 Loss: 0.03368050823804859
Epoch: 5 Idx: 5000 Loss: 0.006063522011890053
Epoch: 6 Idx: 0 Loss: 0.01399789014204429
Epoch: 6 Idx: 5000 Loss: 0.02398896346587231
Epoch: 7 Idx: 0 Loss: 0.00824865527280441
Epoch: 7 Idx: 5000 Loss: 0.015035052512359304
Epoch: 8 Idx: 0 Loss: 0.021084436369166664
Epoch: 8 Idx: 5000 Loss: 0.03262365583932638
Epoch: 9 Idx: 0 Loss: 0.009570903112511119
Epoch: 9 Idx: 5000 Loss: 0.0053124471822560285
Epoch: 10 Idx: 0 Loss: 0.007683089547383892
Epoch: 10 Idx: 5000 Loss: 0.02462693269162669
Epoch: 11 Idx: 0 Loss: 0.009648612985747991
Epoch: 11 Idx: 5000 Loss: 0.013888491336529106
Epoch: 12 Idx: 0 Loss: 0.006912973759820647
Epoch: 12 Idx: 5000 Loss: 0.03814664757689171
Epoch: 13 Idx: 0 Loss: 0.02693355617447617
Epoch: 13 Idx: 5000 Loss: 0.0161388186727623
Epoch: 14 Idx: 0 Loss: 0.017980351615434747
Epoch: 14 Idx: 5000 Loss: 0.019674604064189916
Epoch: 15 Idx: 0 Loss: 0.037551355127322376
Epoch: 15 Idx: 5000 Loss: 0.007176466312689158
Epoch: 16 Idx: 0 Loss: 0.010958310993217889
Epoch: 16 Idx: 5000 Loss: 0.013403343664984897
Epoch: 17 Idx: 0 Loss: 0.00967973462291486
Epoch: 17 Idx: 5000 Loss: 0.008766522409262983
Epoch: 18 Idx: 0 Loss: 0.01912941223435208
Epoch: 18 Idx: 5000 Loss: 0.006407387684007454
Epoch: 19 Idx: 0 Loss: 0.00782040802788365
Epoch: 19 Idx: 5000 Loss: 0.02814171638826555
Epoch: 20 Idx: 0 Loss: 0.019604516972235815
Epoch: 20 Idx: 5000 Loss: 0.013222965436531259
Epoch: 21 Idx: 0 Loss: 0.013833123829401182
Epoch: 21 Idx: 5000 Loss: 0.009287322834860745
Epoch: 22 Idx: 0 Loss: 0.009272170307253646
Epoch: 22 Idx: 5000 Loss: 0.01014084001619105
Epoch: 23 Idx: 0 Loss: 0.028966001439944825
Epoch: 23 Idx: 5000 Loss: 0.005650084681521384
Epoch: 24 Idx: 0 Loss: 0.01178886180856994
Epoch: 24 Idx: 5000 Loss: 0.011690668328484762
Epoch: 25 Idx: 0 Loss: 0.009088724039738264
Epoch: 25 Idx: 5000 Loss: 0.020663105164047763
Epoch: 26 Idx: 0 Loss: 0.02471248343514372
Epoch: 26 Idx: 5000 Loss: 0.011938680348307935
Epoch: 27 Idx: 0 Loss: 0.02249858875644256
Epoch: 27 Idx: 5000 Loss: 0.03646713921352503
Epoch: 28 Idx: 0 Loss: 0.022700826154919994
Epoch: 28 Idx: 5000 Loss: 0.013772784744245575
Epoch: 29 Idx: 0 Loss: 0.005433516004003006
Epoch: 29 Idx: 5000 Loss: 0.017458613474208722
Epoch: 30 Idx: 0 Loss: 0.008693853393603512
Epoch: 30 Idx: 5000 Loss: 0.02298507003710589
Epoch: 31 Idx: 0 Loss: 0.008313174554248662
Epoch: 31 Idx: 5000 Loss: 0.011960315953365264
Epoch: 32 Idx: 0 Loss: 0.015373109342384679
Epoch: 32 Idx: 5000 Loss: 0.009684540234060391
Epoch: 33 Idx: 0 Loss: 0.00829982286833143
Epoch: 33 Idx: 5000 Loss: 0.015945757501427398
Epoch: 34 Idx: 0 Loss: 0.01428870867273278
Epoch: 34 Idx: 5000 Loss: 0.012868825767386578
Epoch: 35 Idx: 0 Loss: 0.006813261528248668
Epoch: 35 Idx: 5000 Loss: 0.02037738837687656
Epoch: 36 Idx: 0 Loss: 0.008557194802090785
Epoch: 36 Idx: 5000 Loss: 0.01115546625481777
Epoch: 37 Idx: 0 Loss: 0.02785191789066993
Epoch: 37 Idx: 5000 Loss: 0.009061815990743717
Epoch: 38 Idx: 0 Loss: 0.015464146701445285
Epoch: 38 Idx: 5000 Loss: 0.021211121778088267
Epoch: 39 Idx: 0 Loss: 0.009008880076976014
Epoch: 39 Idx: 5000 Loss: 0.013679621495639577
Epoch: 40 Idx: 0 Loss: 0.008935518037684088
Epoch: 40 Idx: 5000 Loss: 0.013971681403572918
Epoch: 41 Idx: 0 Loss: 0.008587306345174251
Epoch: 41 Idx: 5000 Loss: 0.016434427936886674
Epoch: 42 Idx: 0 Loss: 0.015898910548631646
Epoch: 42 Idx: 5000 Loss: 0.010869009264337176
Epoch: 43 Idx: 0 Loss: 0.022244823632308654
Epoch: 43 Idx: 5000 Loss: 0.008108846682365601
Epoch: 44 Idx: 0 Loss: 0.015270811547807522
Epoch: 44 Idx: 5000 Loss: 0.013576116288159376
Epoch: 45 Idx: 0 Loss: 0.03395254717120414
Epoch: 45 Idx: 5000 Loss: 0.010283543928131716
Epoch: 46 Idx: 0 Loss: 0.010470296593295653
Epoch: 46 Idx: 5000 Loss: 0.016706813055715915
Epoch: 47 Idx: 0 Loss: 0.008166373738830189
Epoch: 47 Idx: 5000 Loss: 0.03813895128468636
Epoch: 48 Idx: 0 Loss: 0.014759282052660774
Epoch: 48 Idx: 5000 Loss: 0.037499631989494804
Epoch: 49 Idx: 0 Loss: 0.02598905019540757
Epoch: 49 Idx: 5000 Loss: 0.014312106289334783
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.2093739847825637
Epoch: 0 Idx: 5000 Loss: 0.01365881210219522
Epoch: 1 Idx: 0 Loss: 0.014075072521326759
Epoch: 1 Idx: 5000 Loss: 0.010628544885028256
Epoch: 2 Idx: 0 Loss: 0.011265893819235314
Epoch: 2 Idx: 5000 Loss: 0.022845326638179696
Epoch: 3 Idx: 0 Loss: 0.021968449364735583
Epoch: 3 Idx: 5000 Loss: 0.028918259180916818
Epoch: 4 Idx: 0 Loss: 0.015479755359160064
Epoch: 4 Idx: 5000 Loss: 0.020471395124603102
Epoch: 5 Idx: 0 Loss: 0.015067251752996707
Epoch: 5 Idx: 5000 Loss: 0.011646241766134343
Epoch: 6 Idx: 0 Loss: 0.015058224144651423
Epoch: 6 Idx: 5000 Loss: 0.008360511659276414
Epoch: 7 Idx: 0 Loss: 0.012897127035093683
Epoch: 7 Idx: 5000 Loss: 0.009273239088170324
Epoch: 8 Idx: 0 Loss: 0.01247107573991487
Epoch: 8 Idx: 5000 Loss: 0.006118583714583056
Epoch: 9 Idx: 0 Loss: 0.023612401252380122
Epoch: 9 Idx: 5000 Loss: 0.012099444981265245
Epoch: 10 Idx: 0 Loss: 0.018286277254904587
Epoch: 10 Idx: 5000 Loss: 0.010839614497120391
Epoch: 11 Idx: 0 Loss: 0.022070555317348143
Epoch: 11 Idx: 5000 Loss: 0.015356914661841387
Epoch: 12 Idx: 0 Loss: 0.014734492477135274
Epoch: 12 Idx: 5000 Loss: 0.03578565784020616
Epoch: 13 Idx: 0 Loss: 0.010927378558062636
Epoch: 13 Idx: 5000 Loss: 0.017129416798544166
Epoch: 14 Idx: 0 Loss: 0.0075133205191843105
Epoch: 14 Idx: 5000 Loss: 0.039529966447989076
Epoch: 15 Idx: 0 Loss: 0.02810441821393002
Epoch: 15 Idx: 5000 Loss: 0.00853560252124664
Epoch: 16 Idx: 0 Loss: 0.019769048279636537
Epoch: 16 Idx: 5000 Loss: 0.029029406082714388
Epoch: 17 Idx: 0 Loss: 0.009133605269039585
Epoch: 17 Idx: 5000 Loss: 0.01164110945080686
Epoch: 18 Idx: 0 Loss: 0.006130443366379281
Epoch: 18 Idx: 5000 Loss: 0.01334946496610271
Epoch: 19 Idx: 0 Loss: 0.046052967162410405
Epoch: 19 Idx: 5000 Loss: 0.023930147422086066
Epoch: 20 Idx: 0 Loss: 0.013306220794843868
Epoch: 20 Idx: 5000 Loss: 0.02002042066829427
Epoch: 21 Idx: 0 Loss: 0.009356714512270293
Epoch: 21 Idx: 5000 Loss: 0.0107232783179797
Epoch: 22 Idx: 0 Loss: 0.01671151543684124
Epoch: 22 Idx: 5000 Loss: 0.012904983622079093
Epoch: 23 Idx: 0 Loss: 0.010413297094440405
Epoch: 23 Idx: 5000 Loss: 0.00916905360674363
Epoch: 24 Idx: 0 Loss: 0.012118416663966491
Epoch: 24 Idx: 5000 Loss: 0.00744774885600332
Epoch: 25 Idx: 0 Loss: 0.0292451192269194
Epoch: 25 Idx: 5000 Loss: 0.01109513272718659
Epoch: 26 Idx: 0 Loss: 0.010061336555085487
Epoch: 26 Idx: 5000 Loss: 0.014776230163613206
Epoch: 27 Idx: 0 Loss: 0.006342637691535124
Epoch: 27 Idx: 5000 Loss: 0.01550723409085881
Epoch: 28 Idx: 0 Loss: 0.009202749525631701
Epoch: 28 Idx: 5000 Loss: 0.01701754387142642
Epoch: 29 Idx: 0 Loss: 0.01296400102103443
Epoch: 29 Idx: 5000 Loss: 0.012683122287107412
Epoch: 30 Idx: 0 Loss: 0.026991471722107238
Epoch: 30 Idx: 5000 Loss: 0.013601743854958936
Epoch: 31 Idx: 0 Loss: 0.03204918660643792
Epoch: 31 Idx: 5000 Loss: 0.00850527954628601
Epoch: 32 Idx: 0 Loss: 0.007226388437213404
Epoch: 32 Idx: 5000 Loss: 0.009035090970823405
Epoch: 33 Idx: 0 Loss: 0.017328457869223834
Epoch: 33 Idx: 5000 Loss: 0.028276072895685306
Epoch: 34 Idx: 0 Loss: 0.02011540977728434
Epoch: 34 Idx: 5000 Loss: 0.04652029541586285
Epoch: 35 Idx: 0 Loss: 0.01602690888332669
Epoch: 35 Idx: 5000 Loss: 0.021404365588214975
Epoch: 36 Idx: 0 Loss: 0.035981753831201606
Epoch: 36 Idx: 5000 Loss: 0.009380330161910555
Epoch: 37 Idx: 0 Loss: 0.01772365917733589
Epoch: 37 Idx: 5000 Loss: 0.013489796411475073
Epoch: 38 Idx: 0 Loss: 0.027144786740227148
Epoch: 38 Idx: 5000 Loss: 0.0081355171990954
Epoch: 39 Idx: 0 Loss: 0.00828168975899769
Epoch: 39 Idx: 5000 Loss: 0.015259385956849333
Epoch: 40 Idx: 0 Loss: 0.014052145668644073
Epoch: 40 Idx: 5000 Loss: 0.009400181844451082
Epoch: 41 Idx: 0 Loss: 0.02343597992434696
Epoch: 41 Idx: 5000 Loss: 0.013323477332490608
Epoch: 42 Idx: 0 Loss: 0.005209110007683001
Epoch: 42 Idx: 5000 Loss: 0.022424680879467324
Epoch: 43 Idx: 0 Loss: 0.04460346977099467
Epoch: 43 Idx: 5000 Loss: 0.006796850592981314
Epoch: 44 Idx: 0 Loss: 0.01536590949016043
Epoch: 44 Idx: 5000 Loss: 0.012509946428545936
Epoch: 45 Idx: 0 Loss: 0.00855002010513996
Epoch: 45 Idx: 5000 Loss: 0.020633978313940482
Epoch: 46 Idx: 0 Loss: 0.028285571627898576
Epoch: 46 Idx: 5000 Loss: 0.017712629333942725
Epoch: 47 Idx: 0 Loss: 0.0158226446882307
Epoch: 47 Idx: 5000 Loss: 0.019910017834973606
Epoch: 48 Idx: 0 Loss: 0.012102309647387254
Epoch: 48 Idx: 5000 Loss: 0.008162062779425336
Epoch: 49 Idx: 0 Loss: 0.030397941594135523
Epoch: 49 Idx: 5000 Loss: 0.033074196098430764
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.21614013513383562
Epoch: 1 Idx: 0 Loss: 0.01849296796759295
Epoch: 2 Idx: 0 Loss: 0.03360188131943775
Epoch: 3 Idx: 0 Loss: 0.017135903433243508
Epoch: 4 Idx: 0 Loss: 0.011780845406297955
Epoch: 5 Idx: 0 Loss: 0.02330973900777014
Epoch: 6 Idx: 0 Loss: 0.011524200838756701
Epoch: 7 Idx: 0 Loss: 0.0070813201956395145
Epoch: 8 Idx: 0 Loss: 0.012320229111521037
Epoch: 9 Idx: 0 Loss: 0.009652040400799977
Epoch: 10 Idx: 0 Loss: 0.010284815206710329
Epoch: 11 Idx: 0 Loss: 0.008038592602081196
Epoch: 12 Idx: 0 Loss: 0.0176835644055194
Epoch: 13 Idx: 0 Loss: 0.021764021511251487
Epoch: 14 Idx: 0 Loss: 0.013847444438244687
Epoch: 15 Idx: 0 Loss: 0.015231631424402675
Epoch: 16 Idx: 0 Loss: 0.011141762908904168
Epoch: 17 Idx: 0 Loss: 0.018258713343879046
Epoch: 18 Idx: 0 Loss: 0.012224977251510281
Epoch: 19 Idx: 0 Loss: 0.005402512275387309
Epoch: 20 Idx: 0 Loss: 0.00945323507695624
Epoch: 21 Idx: 0 Loss: 0.016136639184998185
Epoch: 22 Idx: 0 Loss: 0.012307606163417643
Epoch: 23 Idx: 0 Loss: 0.006692560237685483
Epoch: 24 Idx: 0 Loss: 0.005711463222504134
Epoch: 25 Idx: 0 Loss: 0.023802450730784845
Epoch: 26 Idx: 0 Loss: 0.008631721433282924
Epoch: 27 Idx: 0 Loss: 0.030761152266891342
Epoch: 28 Idx: 0 Loss: 0.01939114429705354
Epoch: 29 Idx: 0 Loss: 0.03787644477994797
Epoch: 30 Idx: 0 Loss: 0.024292311953484046
Epoch: 31 Idx: 0 Loss: 0.010687400844493548
Epoch: 32 Idx: 0 Loss: 0.02311554012095362
Epoch: 33 Idx: 0 Loss: 0.011419394092538854
Epoch: 34 Idx: 0 Loss: 0.00927189954652249
Epoch: 35 Idx: 0 Loss: 0.007652649798085156
Epoch: 36 Idx: 0 Loss: 0.0175573917717421
Epoch: 37 Idx: 0 Loss: 0.0068490356943548296
Epoch: 38 Idx: 0 Loss: 0.01939869685800866
Epoch: 39 Idx: 0 Loss: 0.013038169158046734
Epoch: 40 Idx: 0 Loss: 0.029474542165156457
Epoch: 41 Idx: 0 Loss: 0.04961075036315575
Epoch: 42 Idx: 0 Loss: 0.027240684544720707
Epoch: 43 Idx: 0 Loss: 0.01583907685426693
Epoch: 44 Idx: 0 Loss: 0.008807173632058204
Epoch: 45 Idx: 0 Loss: 0.01665390276889285
Epoch: 46 Idx: 0 Loss: 0.005450476704460543
Epoch: 47 Idx: 0 Loss: 0.011723121626039857
Epoch: 48 Idx: 0 Loss: 0.018107983654362638
Epoch: 49 Idx: 0 Loss: 0.010675222383359181
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.17560649485150717
Epoch: 0 Idx: 5000 Loss: 0.01665997426137458
Epoch: 1 Idx: 0 Loss: 0.008568447537584333
Epoch: 1 Idx: 5000 Loss: 0.026817179532968555
Epoch: 2 Idx: 0 Loss: 0.020165309540886744
Epoch: 2 Idx: 5000 Loss: 0.019502320719802436
Epoch: 3 Idx: 0 Loss: 0.0202319324385994
Epoch: 3 Idx: 5000 Loss: 0.008760500028680132
Epoch: 4 Idx: 0 Loss: 0.011416609574553795
Epoch: 4 Idx: 5000 Loss: 0.010333286340048462
Epoch: 5 Idx: 0 Loss: 0.01384045489636924
Epoch: 5 Idx: 5000 Loss: 0.012393311741556376
Epoch: 6 Idx: 0 Loss: 0.017959600841056987
Epoch: 6 Idx: 5000 Loss: 0.03287191200891799
Epoch: 7 Idx: 0 Loss: 0.011739074285230498
Epoch: 7 Idx: 5000 Loss: 0.013174073434623774
Epoch: 8 Idx: 0 Loss: 0.01475453044077181
Epoch: 8 Idx: 5000 Loss: 0.01744926669646859
Epoch: 9 Idx: 0 Loss: 0.007662968583277844
Epoch: 9 Idx: 5000 Loss: 0.011389068550477242
Epoch: 10 Idx: 0 Loss: 0.01453018452259311
Epoch: 10 Idx: 5000 Loss: 0.008224530397246991
Epoch: 11 Idx: 0 Loss: 0.010112018469204096
Epoch: 11 Idx: 5000 Loss: 0.03978315979592822
Epoch: 12 Idx: 0 Loss: 0.029902500306877723
Epoch: 12 Idx: 5000 Loss: 0.012094557278315972
Epoch: 13 Idx: 0 Loss: 0.017034794463379
Epoch: 13 Idx: 5000 Loss: 0.015993973443096776
Epoch: 14 Idx: 0 Loss: 0.025239301758749003
Epoch: 14 Idx: 5000 Loss: 0.019881197469535435
Epoch: 15 Idx: 0 Loss: 0.02718054938705113
Epoch: 15 Idx: 5000 Loss: 0.022007351057073847
Epoch: 16 Idx: 0 Loss: 0.024538207389383324
Epoch: 16 Idx: 5000 Loss: 0.012548030249680328
Epoch: 17 Idx: 0 Loss: 0.018691558942500394
Epoch: 17 Idx: 5000 Loss: 0.013542615931490885
Epoch: 18 Idx: 0 Loss: 0.006979202911847128
Epoch: 18 Idx: 5000 Loss: 0.026900956991804368
Epoch: 19 Idx: 0 Loss: 0.008493873232072346
Epoch: 19 Idx: 5000 Loss: 0.020834644990467114
Epoch: 20 Idx: 0 Loss: 0.01327485027125435
Epoch: 20 Idx: 5000 Loss: 0.02505853746268484
Epoch: 21 Idx: 0 Loss: 0.0276518556567916
Epoch: 21 Idx: 5000 Loss: 0.01985634451751917
Epoch: 22 Idx: 0 Loss: 0.005008225436807252
Epoch: 22 Idx: 5000 Loss: 0.018139065870558795
Epoch: 23 Idx: 0 Loss: 0.007289156285796887
Epoch: 23 Idx: 5000 Loss: 0.02832694164256631
Epoch: 24 Idx: 0 Loss: 0.010838196368259584
Epoch: 24 Idx: 5000 Loss: 0.02303771564243877
Epoch: 25 Idx: 0 Loss: 0.009839162209577274
Epoch: 25 Idx: 5000 Loss: 0.01572017371938387
Epoch: 26 Idx: 0 Loss: 0.019156816915582197
Epoch: 26 Idx: 5000 Loss: 0.02597740576434345
Epoch: 27 Idx: 0 Loss: 0.015149996030101961
Epoch: 27 Idx: 5000 Loss: 0.00836859406923438
Epoch: 28 Idx: 0 Loss: 0.02681561294270314
Epoch: 28 Idx: 5000 Loss: 0.019150144805767478
Epoch: 29 Idx: 0 Loss: 0.011394127974780831
Epoch: 29 Idx: 5000 Loss: 0.029581000335131495
Epoch: 30 Idx: 0 Loss: 0.01658170038577285
Epoch: 30 Idx: 5000 Loss: 0.007772511790808289
Epoch: 31 Idx: 0 Loss: 0.010262678567442379
Epoch: 31 Idx: 5000 Loss: 0.02884049381650898
Epoch: 32 Idx: 0 Loss: 0.004187686871699646
Epoch: 32 Idx: 5000 Loss: 0.029184244513568294
Epoch: 33 Idx: 0 Loss: 0.009887537429428385
Epoch: 33 Idx: 5000 Loss: 0.019073705560903983
Epoch: 34 Idx: 0 Loss: 0.03229753176081753
Epoch: 34 Idx: 5000 Loss: 0.010383768715771853
Epoch: 35 Idx: 0 Loss: 0.006419633627698262
Epoch: 35 Idx: 5000 Loss: 0.019454953260543452
Epoch: 36 Idx: 0 Loss: 0.013316426157884644
Epoch: 36 Idx: 5000 Loss: 0.01951431039877355
Epoch: 37 Idx: 0 Loss: 0.023807412189516958
Epoch: 37 Idx: 5000 Loss: 0.01117497850419209
Epoch: 38 Idx: 0 Loss: 0.014578090687830903
Epoch: 38 Idx: 5000 Loss: 0.009526138665481187
Epoch: 39 Idx: 0 Loss: 0.015557991599431178
Epoch: 39 Idx: 5000 Loss: 0.009558412331689085
Epoch: 40 Idx: 0 Loss: 0.010808732298402207
Epoch: 40 Idx: 5000 Loss: 0.036606565701672186
Epoch: 41 Idx: 0 Loss: 0.014961056673972042
Epoch: 41 Idx: 5000 Loss: 0.01079414810339093
Epoch: 42 Idx: 0 Loss: 0.013842107454698242
Epoch: 42 Idx: 5000 Loss: 0.005727171347952976
Epoch: 43 Idx: 0 Loss: 0.024607148734426022
Epoch: 43 Idx: 5000 Loss: 0.010564658398366743
Epoch: 44 Idx: 0 Loss: 0.008012015509198453
Epoch: 44 Idx: 5000 Loss: 0.01400684816880777
Epoch: 45 Idx: 0 Loss: 0.011586632022049787
Epoch: 45 Idx: 5000 Loss: 0.026984575467568807
Epoch: 46 Idx: 0 Loss: 0.01833128414228535
Epoch: 46 Idx: 5000 Loss: 0.008154312322092835
Epoch: 47 Idx: 0 Loss: 0.016788370174129288
Epoch: 47 Idx: 5000 Loss: 0.009189162691709225
Epoch: 48 Idx: 0 Loss: 0.023915777881638973
Epoch: 48 Idx: 5000 Loss: 0.026720261778813845
Epoch: 49 Idx: 0 Loss: 0.016562212214831888
Epoch: 49 Idx: 5000 Loss: 0.012348111513175542
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.19212177410687503
Epoch: 1 Idx: 0 Loss: 0.012977568799123717
Epoch: 2 Idx: 0 Loss: 0.01403868956642335
Epoch: 3 Idx: 0 Loss: 0.01240427410485063
Epoch: 4 Idx: 0 Loss: 0.030934387136659303
Epoch: 5 Idx: 0 Loss: 0.03228989269816357
Epoch: 6 Idx: 0 Loss: 0.012193220772272135
Epoch: 7 Idx: 0 Loss: 0.02168275294406733
Epoch: 8 Idx: 0 Loss: 0.010409048290967237
Epoch: 9 Idx: 0 Loss: 0.014442968177761927
Epoch: 10 Idx: 0 Loss: 0.01648909652961761
Epoch: 11 Idx: 0 Loss: 0.008564988360032782
Epoch: 12 Idx: 0 Loss: 0.012218324725410769
Epoch: 13 Idx: 0 Loss: 0.017216475207005703
Epoch: 14 Idx: 0 Loss: 0.006433677441266258
Epoch: 15 Idx: 0 Loss: 0.01083658297130061
Epoch: 16 Idx: 0 Loss: 0.016806650117805293
Epoch: 17 Idx: 0 Loss: 0.016749102586069688
Epoch: 18 Idx: 0 Loss: 0.011463348612345792
Epoch: 19 Idx: 0 Loss: 0.02740170857740893
Epoch: 20 Idx: 0 Loss: 0.02578001645525893
Epoch: 21 Idx: 0 Loss: 0.006892808351359463
Epoch: 22 Idx: 0 Loss: 0.008202542452374308
Epoch: 23 Idx: 0 Loss: 0.006520031138072317
Epoch: 24 Idx: 0 Loss: 0.030742658901385108
Epoch: 25 Idx: 0 Loss: 0.018758075247225506
Epoch: 26 Idx: 0 Loss: 0.01272268357338618
Epoch: 27 Idx: 0 Loss: 0.011961216895845214
Epoch: 28 Idx: 0 Loss: 0.022835125256711986
Epoch: 29 Idx: 0 Loss: 0.030319625221386808
Epoch: 30 Idx: 0 Loss: 0.004588303123549036
Epoch: 31 Idx: 0 Loss: 0.025468040807254132
Epoch: 32 Idx: 0 Loss: 0.0340665434095912
Epoch: 33 Idx: 0 Loss: 0.004446521427094238
Epoch: 34 Idx: 0 Loss: 0.015426569353203185
Epoch: 35 Idx: 0 Loss: 0.01491616562694854
Epoch: 36 Idx: 0 Loss: 0.04209277373300547
Epoch: 37 Idx: 0 Loss: 0.011245962447702661
Epoch: 38 Idx: 0 Loss: 0.01152018591224334
Epoch: 39 Idx: 0 Loss: 0.0076782127820287545
Epoch: 40 Idx: 0 Loss: 0.01326585503663139
Epoch: 41 Idx: 0 Loss: 0.008857283035863448
Epoch: 42 Idx: 0 Loss: 0.007711750483754143
Epoch: 43 Idx: 0 Loss: 0.020400185371478495
Epoch: 44 Idx: 0 Loss: 0.02233254986428321
Epoch: 45 Idx: 0 Loss: 0.007418908832637705
Epoch: 46 Idx: 0 Loss: 0.020402099430003505
Epoch: 47 Idx: 0 Loss: 0.01615002135434001
Epoch: 48 Idx: 0 Loss: 0.01718296620314574
Epoch: 49 Idx: 0 Loss: 0.01964338345309876
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333)
Performance for  [('ekaw', 'sigkdd')] is : (0.7857142857142857, 1.0, 0.88, 0.9482758620689656, 0.8208955223880596)
Performance for  [('conference', 'edas')] is : (0.8, 0.7058823529411765, 0.7500000000000001, 0.7228915662650602, 0.7792207792207791)
Performance for  [('cmt', 'ekaw')] is : (0.6, 0.5454545454545454, 0.5714285714285713, 0.5555555555555556, 0.5882352941176471)
Performance for  [('confOf', 'edas')] is : (0.631578947368421, 0.631578947368421, 0.631578947368421, 0.631578947368421, 0.631578947368421)
Performance for  [('iasted', 'sigkdd')] is : (0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.75485141 0.70073401 0.71627999 0.70496067 0.73552374]
Threshold:  0.919
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2ac7167e7af0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc273>
Subject: Job 4142716: <python main.py 4 10 False True> in cluster <dcc> Done

Job <python main.py 4 10 False True> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:24 2020
Job was executed on host(s) <dccxc273>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 07:38:30 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:38:30 2020
Terminated at Wed Sep 16 14:03:47 2020
Results reported at Wed Sep 16 14:03:47 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 4 10 False True
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   23079.37 sec.
    Max Memory :                                 4142 MB
    Average Memory :                             3999.07 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39275.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   23142 sec.
    Turnaround time :                            25523 sec.

The output (if any) is above this job summary.

