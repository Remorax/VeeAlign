2020-09-16 10:13:26.696428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:13:35.874523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 10:13:35.985280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 10:13:35.985365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:13:35.987318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 10:13:35.988804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 10:13:35.989211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 10:13:35.991156: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 10:13:35.992655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 10:13:35.992908: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 10:13:35.992933: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 10:13:35.993250: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 10:13:36.000906: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600005000 Hz
2020-09-16 10:13:36.001098: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555d8d0fd5b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 10:13:36.001119: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 10:13:36.003312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 10:13:36.003375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.20357178965312522
Epoch: 0 Idx: 5000 Loss: 0.011219912409171274
Epoch: 1 Idx: 0 Loss: 0.013594648074549995
Epoch: 1 Idx: 5000 Loss: 0.008322851115893235
Epoch: 2 Idx: 0 Loss: 0.013978463248685208
Epoch: 2 Idx: 5000 Loss: 0.01759393856604411
Epoch: 3 Idx: 0 Loss: 0.025404632497945126
Epoch: 3 Idx: 5000 Loss: 0.01086573819656186
Epoch: 4 Idx: 0 Loss: 0.029841064947423074
Epoch: 4 Idx: 5000 Loss: 0.018979980619591164
Epoch: 5 Idx: 0 Loss: 0.015945514044802434
Epoch: 5 Idx: 5000 Loss: 0.010872260901846939
Epoch: 6 Idx: 0 Loss: 0.022129216792108282
Epoch: 6 Idx: 5000 Loss: 0.012908846542757188
Epoch: 7 Idx: 0 Loss: 0.01730974434086091
Epoch: 7 Idx: 5000 Loss: 0.020224971779058222
Epoch: 8 Idx: 0 Loss: 0.010000501321476524
Epoch: 8 Idx: 5000 Loss: 0.006758778066844103
Epoch: 9 Idx: 0 Loss: 0.030975163440423635
Epoch: 9 Idx: 5000 Loss: 0.0068532025509870555
Epoch: 10 Idx: 0 Loss: 0.015107834102672097
Epoch: 10 Idx: 5000 Loss: 0.02101927653824127
Epoch: 11 Idx: 0 Loss: 0.008643586016398124
Epoch: 11 Idx: 5000 Loss: 0.013081371010246937
Epoch: 12 Idx: 0 Loss: 0.009626721059925937
Epoch: 12 Idx: 5000 Loss: 0.007993045920562587
Epoch: 13 Idx: 0 Loss: 0.013979081167566125
Epoch: 13 Idx: 5000 Loss: 0.007458710156312182
Epoch: 14 Idx: 0 Loss: 0.011296979273126548
Epoch: 14 Idx: 5000 Loss: 0.02258886530962132
Epoch: 15 Idx: 0 Loss: 0.03185842885129625
Epoch: 15 Idx: 5000 Loss: 0.010504372240580252
Epoch: 16 Idx: 0 Loss: 0.005012049690306425
Epoch: 16 Idx: 5000 Loss: 0.00991466777393844
Epoch: 17 Idx: 0 Loss: 0.015008171292711757
Epoch: 17 Idx: 5000 Loss: 0.009761368594828644
Epoch: 18 Idx: 0 Loss: 0.018244478737557034
Epoch: 18 Idx: 5000 Loss: 0.032613868309890895
Epoch: 19 Idx: 0 Loss: 0.014214218862454202
Epoch: 19 Idx: 5000 Loss: 0.03225451210835914
Epoch: 20 Idx: 0 Loss: 0.007828620596916197
Epoch: 20 Idx: 5000 Loss: 0.007590774210940793
Epoch: 21 Idx: 0 Loss: 0.00440342777015889
Epoch: 21 Idx: 5000 Loss: 0.011420761948919469
Epoch: 22 Idx: 0 Loss: 0.02111461930768976
Epoch: 22 Idx: 5000 Loss: 0.012578844452908973
Epoch: 23 Idx: 0 Loss: 0.027930428455499257
Epoch: 23 Idx: 5000 Loss: 0.027664389817165038
Epoch: 24 Idx: 0 Loss: 0.012843929092225441
Epoch: 24 Idx: 5000 Loss: 0.016183331905207876
Epoch: 25 Idx: 0 Loss: 0.011192259511088862
Epoch: 25 Idx: 5000 Loss: 0.039410519194204865
Epoch: 26 Idx: 0 Loss: 0.006049624751149785
Epoch: 26 Idx: 5000 Loss: 0.026672961600900814
Epoch: 27 Idx: 0 Loss: 0.011760287728058072
Epoch: 27 Idx: 5000 Loss: 0.01408670332124508
Epoch: 28 Idx: 0 Loss: 0.015894388334183867
Epoch: 28 Idx: 5000 Loss: 0.02175297093507663
Epoch: 29 Idx: 0 Loss: 0.013957445571183152
Epoch: 29 Idx: 5000 Loss: 0.008300406859659834
Epoch: 30 Idx: 0 Loss: 0.011093096155918832
Epoch: 30 Idx: 5000 Loss: 0.013937942144473052
Epoch: 31 Idx: 0 Loss: 0.033256438007074986
Epoch: 31 Idx: 5000 Loss: 0.01382033109886589
Epoch: 32 Idx: 0 Loss: 0.009629222123099065
Epoch: 32 Idx: 5000 Loss: 0.014347791105587808
Epoch: 33 Idx: 0 Loss: 0.017626977787760234
Epoch: 33 Idx: 5000 Loss: 0.017013278412919403
Epoch: 34 Idx: 0 Loss: 0.01768072267849577
Epoch: 34 Idx: 5000 Loss: 0.018310112623527965
Epoch: 35 Idx: 0 Loss: 0.0123652565038731
Epoch: 35 Idx: 5000 Loss: 0.015720597596760137
Epoch: 36 Idx: 0 Loss: 0.020501528239911
Epoch: 36 Idx: 5000 Loss: 0.01837618598815015
Epoch: 37 Idx: 0 Loss: 0.02508539300365993
Epoch: 37 Idx: 5000 Loss: 0.019232723263704482
Epoch: 38 Idx: 0 Loss: 0.01297818877675395
Epoch: 38 Idx: 5000 Loss: 0.018341444750583833
Epoch: 39 Idx: 0 Loss: 0.009608841181022499
Epoch: 39 Idx: 5000 Loss: 0.02499563804470402
Epoch: 40 Idx: 0 Loss: 0.012785635802834101
Epoch: 40 Idx: 5000 Loss: 0.014587147566288046
Epoch: 41 Idx: 0 Loss: 0.006644072811982982
Epoch: 41 Idx: 5000 Loss: 0.00905460227019481
Epoch: 42 Idx: 0 Loss: 0.009885824321981212
Epoch: 42 Idx: 5000 Loss: 0.00938762537239702
Epoch: 43 Idx: 0 Loss: 0.042835770144780225
Epoch: 43 Idx: 5000 Loss: 0.0154635376219326
Epoch: 44 Idx: 0 Loss: 0.010693255059700505
Epoch: 44 Idx: 5000 Loss: 0.011616397259250792
Epoch: 45 Idx: 0 Loss: 0.016211181036189994
Epoch: 45 Idx: 5000 Loss: 0.01139619321244405
Epoch: 46 Idx: 0 Loss: 0.03463865975760716
Epoch: 46 Idx: 5000 Loss: 0.008312554443839342
Epoch: 47 Idx: 0 Loss: 0.022067440971205082
Epoch: 47 Idx: 5000 Loss: 0.008404232556833785
Epoch: 48 Idx: 0 Loss: 0.00880582077259396
Epoch: 48 Idx: 5000 Loss: 0.014360002070882207
Epoch: 49 Idx: 0 Loss: 0.015589633546460981
Epoch: 49 Idx: 5000 Loss: 0.008735072032593095
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.23968605918301822
Epoch: 0 Idx: 5000 Loss: 0.018416090800112778
Epoch: 1 Idx: 0 Loss: 0.02963359924883543
Epoch: 1 Idx: 5000 Loss: 0.023569825105472494
Epoch: 2 Idx: 0 Loss: 0.014928369711063049
Epoch: 2 Idx: 5000 Loss: 0.012241760513955062
Epoch: 3 Idx: 0 Loss: 0.008875595881244296
Epoch: 3 Idx: 5000 Loss: 0.03867582459894358
Epoch: 4 Idx: 0 Loss: 0.0125703536409972
Epoch: 4 Idx: 5000 Loss: 0.013921790059765186
Epoch: 5 Idx: 0 Loss: 0.01313570565658084
Epoch: 5 Idx: 5000 Loss: 0.01999736708573628
Epoch: 6 Idx: 0 Loss: 0.00846362049323469
Epoch: 6 Idx: 5000 Loss: 0.01592582827583334
Epoch: 7 Idx: 0 Loss: 0.006917751115357109
Epoch: 7 Idx: 5000 Loss: 0.009553847924290341
Epoch: 8 Idx: 0 Loss: 0.01162230430747006
Epoch: 8 Idx: 5000 Loss: 0.024148104965006773
Epoch: 9 Idx: 0 Loss: 0.016219252559008725
Epoch: 9 Idx: 5000 Loss: 0.012035852623049072
Epoch: 10 Idx: 0 Loss: 0.01493593509034867
Epoch: 10 Idx: 5000 Loss: 0.028816168675204503
Epoch: 11 Idx: 0 Loss: 0.0160727972254879
Epoch: 11 Idx: 5000 Loss: 0.009919670764182527
Epoch: 12 Idx: 0 Loss: 0.02848099357738648
Epoch: 12 Idx: 5000 Loss: 0.01636647639408327
Epoch: 13 Idx: 0 Loss: 0.005930081872222222
Epoch: 13 Idx: 5000 Loss: 0.009917009069429134
Epoch: 14 Idx: 0 Loss: 0.012156049273845879
Epoch: 14 Idx: 5000 Loss: 0.015264124818371647
Epoch: 15 Idx: 0 Loss: 0.011772096697365573
Epoch: 15 Idx: 5000 Loss: 0.010045677417849515
Epoch: 16 Idx: 0 Loss: 0.005124243795694917
Epoch: 16 Idx: 5000 Loss: 0.03819986881982986
Epoch: 17 Idx: 0 Loss: 0.019947582596038994
Epoch: 17 Idx: 5000 Loss: 0.03259167855587927
Epoch: 18 Idx: 0 Loss: 0.00927546549722478
Epoch: 18 Idx: 5000 Loss: 0.011893102330514632
Epoch: 19 Idx: 0 Loss: 0.010556715763339653
Epoch: 19 Idx: 5000 Loss: 0.0060729807022858046
Epoch: 20 Idx: 0 Loss: 0.011454998989722506
Epoch: 20 Idx: 5000 Loss: 0.029937047809967372
Epoch: 21 Idx: 0 Loss: 0.011481848194031384
Epoch: 21 Idx: 5000 Loss: 0.010386042798801499
Epoch: 22 Idx: 0 Loss: 0.01168579726667078
Epoch: 22 Idx: 5000 Loss: 0.025271183652803127
Epoch: 23 Idx: 0 Loss: 0.01890653897284319
Epoch: 23 Idx: 5000 Loss: 0.013690081288568459
Epoch: 24 Idx: 0 Loss: 0.02560198330355516
Epoch: 24 Idx: 5000 Loss: 0.007590185906730653
Epoch: 25 Idx: 0 Loss: 0.01980775411001192
Epoch: 25 Idx: 5000 Loss: 0.010539607531028682
Epoch: 26 Idx: 0 Loss: 0.029831393477823556
Epoch: 26 Idx: 5000 Loss: 0.024090631646038696
Epoch: 27 Idx: 0 Loss: 0.019590327294164593
Epoch: 27 Idx: 5000 Loss: 0.008461330737983587
Epoch: 28 Idx: 0 Loss: 0.03408591626828127
Epoch: 28 Idx: 5000 Loss: 0.005467524668356568
Epoch: 29 Idx: 0 Loss: 0.020879983836447652
Epoch: 29 Idx: 5000 Loss: 0.02112167925434911
Epoch: 30 Idx: 0 Loss: 0.015694113891605865
Epoch: 30 Idx: 5000 Loss: 0.01877180737388054
Epoch: 31 Idx: 0 Loss: 0.015388164615851827
Epoch: 31 Idx: 5000 Loss: 0.012202879653810679
Epoch: 32 Idx: 0 Loss: 0.018582172872336204
Epoch: 32 Idx: 5000 Loss: 0.022726107626737685
Epoch: 33 Idx: 0 Loss: 0.026891958160629857
Epoch: 33 Idx: 5000 Loss: 0.01166602366251088
Epoch: 34 Idx: 0 Loss: 0.011972897967822351
Epoch: 34 Idx: 5000 Loss: 0.012719170232876484
Epoch: 35 Idx: 0 Loss: 0.00994823899806286
Epoch: 35 Idx: 5000 Loss: 0.013313860248915017
Epoch: 36 Idx: 0 Loss: 0.02117795659009332
Epoch: 36 Idx: 5000 Loss: 0.02476052394683389
Epoch: 37 Idx: 0 Loss: 0.014126208013823433
Epoch: 37 Idx: 5000 Loss: 0.01358396313543132
Epoch: 38 Idx: 0 Loss: 0.007479879731604345
Epoch: 38 Idx: 5000 Loss: 0.02607446234109926
Epoch: 39 Idx: 0 Loss: 0.00985473367400561
Epoch: 39 Idx: 5000 Loss: 0.004737425265629658
Epoch: 40 Idx: 0 Loss: 0.018526286327017246
Epoch: 40 Idx: 5000 Loss: 0.007924504505344472
Epoch: 41 Idx: 0 Loss: 0.03139036912394788
Epoch: 41 Idx: 5000 Loss: 0.018998751002857042
Epoch: 42 Idx: 0 Loss: 0.020686097204385516
Epoch: 42 Idx: 5000 Loss: 0.012335893745265053
Epoch: 43 Idx: 0 Loss: 0.006985145916120284
Epoch: 43 Idx: 5000 Loss: 0.011481658016219885
Epoch: 44 Idx: 0 Loss: 0.009751504572015507
Epoch: 44 Idx: 5000 Loss: 0.022780782444661942
Epoch: 45 Idx: 0 Loss: 0.007953724888441142
Epoch: 45 Idx: 5000 Loss: 0.013846971315967535
Epoch: 46 Idx: 0 Loss: 0.0189246643461716
Epoch: 46 Idx: 5000 Loss: 0.014476571028515874
Epoch: 47 Idx: 0 Loss: 0.011489440719047917
Epoch: 47 Idx: 5000 Loss: 0.024118253414836897
Epoch: 48 Idx: 0 Loss: 0.014660340880740603
Epoch: 48 Idx: 5000 Loss: 0.011130716541064309
Epoch: 49 Idx: 0 Loss: 0.009237921670716746
Epoch: 49 Idx: 5000 Loss: 0.021865808528369148
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.16881620488830423
Epoch: 0 Idx: 5000 Loss: 0.015935194686308607
Epoch: 1 Idx: 0 Loss: 0.015961044203186732
Epoch: 1 Idx: 5000 Loss: 0.004473083960979465
Epoch: 2 Idx: 0 Loss: 0.006844924449952339
Epoch: 2 Idx: 5000 Loss: 0.012581410383726534
Epoch: 3 Idx: 0 Loss: 0.015139926398083366
Epoch: 3 Idx: 5000 Loss: 0.02049027952097814
Epoch: 4 Idx: 0 Loss: 0.015487793187659608
Epoch: 4 Idx: 5000 Loss: 0.009864285762180751
Epoch: 5 Idx: 0 Loss: 0.008339433298226763
Epoch: 5 Idx: 5000 Loss: 0.03328899713021307
Epoch: 6 Idx: 0 Loss: 0.02237701231177231
Epoch: 6 Idx: 5000 Loss: 0.03296864968135993
Epoch: 7 Idx: 0 Loss: 0.01985503158436673
Epoch: 7 Idx: 5000 Loss: 0.02702312268324312
Epoch: 8 Idx: 0 Loss: 0.03470441836794334
Epoch: 8 Idx: 5000 Loss: 0.01659980189119519
Epoch: 9 Idx: 0 Loss: 0.015170531809033548
Epoch: 9 Idx: 5000 Loss: 0.01136302746323085
Epoch: 10 Idx: 0 Loss: 0.008633150514823445
Epoch: 10 Idx: 5000 Loss: 0.02773805483807571
Epoch: 11 Idx: 0 Loss: 0.012451723979603396
Epoch: 11 Idx: 5000 Loss: 0.03528504574788928
Epoch: 12 Idx: 0 Loss: 0.02169267467422158
Epoch: 12 Idx: 5000 Loss: 0.013946203686885228
Epoch: 13 Idx: 0 Loss: 0.014282123674281966
Epoch: 13 Idx: 5000 Loss: 0.00835514196774174
Epoch: 14 Idx: 0 Loss: 0.030213034604494378
Epoch: 14 Idx: 5000 Loss: 0.009643060810693504
Epoch: 15 Idx: 0 Loss: 0.011147886201618364
Epoch: 15 Idx: 5000 Loss: 0.011650711657496047
Epoch: 16 Idx: 0 Loss: 0.015985356468495113
Epoch: 16 Idx: 5000 Loss: 0.00997582692027284
Epoch: 17 Idx: 0 Loss: 0.025934565683232862
Epoch: 17 Idx: 5000 Loss: 0.012386031048896856
Epoch: 18 Idx: 0 Loss: 0.012343180446785154
Epoch: 18 Idx: 5000 Loss: 0.04159277545920943
Epoch: 19 Idx: 0 Loss: 0.008147072573867598
Epoch: 19 Idx: 5000 Loss: 0.009612368310243218
Epoch: 20 Idx: 0 Loss: 0.014411043328396057
Epoch: 20 Idx: 5000 Loss: 0.025659193673951232
Epoch: 21 Idx: 0 Loss: 0.02653089506837992
Epoch: 21 Idx: 5000 Loss: 0.006341541037002929
Epoch: 22 Idx: 0 Loss: 0.015995271567412955
Epoch: 22 Idx: 5000 Loss: 0.008391028618831049
Epoch: 23 Idx: 0 Loss: 0.016973399169909753
Epoch: 23 Idx: 5000 Loss: 0.024297133761526032
Epoch: 24 Idx: 0 Loss: 0.011601199711162285
Epoch: 24 Idx: 5000 Loss: 0.011833031484606498
Epoch: 25 Idx: 0 Loss: 0.021537483734670453
Epoch: 25 Idx: 5000 Loss: 0.026902739128649288
Epoch: 26 Idx: 0 Loss: 0.017358261557886376
Epoch: 26 Idx: 5000 Loss: 0.010622083526612197
Epoch: 27 Idx: 0 Loss: 0.030522160665319202
Epoch: 27 Idx: 5000 Loss: 0.026767334421396078
Epoch: 28 Idx: 0 Loss: 0.008382809264932378
Epoch: 28 Idx: 5000 Loss: 0.03772428669313044
Epoch: 29 Idx: 0 Loss: 0.01245398094168432
Epoch: 29 Idx: 5000 Loss: 0.008260189572804569
Epoch: 30 Idx: 0 Loss: 0.024409483849696906
Epoch: 30 Idx: 5000 Loss: 0.03265775207806572
Epoch: 31 Idx: 0 Loss: 0.022158953882808054
Epoch: 31 Idx: 5000 Loss: 0.011634923538932026
Epoch: 32 Idx: 0 Loss: 0.014472038331139128
Epoch: 32 Idx: 5000 Loss: 0.014099374837768684
Epoch: 33 Idx: 0 Loss: 0.012448169202563732
Epoch: 33 Idx: 5000 Loss: 0.019381435476420225
Epoch: 34 Idx: 0 Loss: 0.01096850634305559
Epoch: 34 Idx: 5000 Loss: 0.03276479397513214
Epoch: 35 Idx: 0 Loss: 0.008672463848514372
Epoch: 35 Idx: 5000 Loss: 0.00504759144445284
Epoch: 36 Idx: 0 Loss: 0.014288825177771615
Epoch: 36 Idx: 5000 Loss: 0.016408545897885755
Epoch: 37 Idx: 0 Loss: 0.012832876951608441
Epoch: 37 Idx: 5000 Loss: 0.014442383012385639
Epoch: 38 Idx: 0 Loss: 0.012133171832648434
Epoch: 38 Idx: 5000 Loss: 0.011943361208448286
Epoch: 39 Idx: 0 Loss: 0.009551703076163397
Epoch: 39 Idx: 5000 Loss: 0.024197043801989428
Epoch: 40 Idx: 0 Loss: 0.007608639749633448
Epoch: 40 Idx: 5000 Loss: 0.030240815267045956
Epoch: 41 Idx: 0 Loss: 0.013152120896855713
Epoch: 41 Idx: 5000 Loss: 0.012276025033117463
Epoch: 42 Idx: 0 Loss: 0.045938406506120924
Epoch: 42 Idx: 5000 Loss: 0.026552811208608633
Epoch: 43 Idx: 0 Loss: 0.006298976906801505
Epoch: 43 Idx: 5000 Loss: 0.009063925530897167
Epoch: 44 Idx: 0 Loss: 0.005905276521982513
Epoch: 44 Idx: 5000 Loss: 0.0056484157945412596
Epoch: 45 Idx: 0 Loss: 0.02587250829246012
Epoch: 45 Idx: 5000 Loss: 0.007239873688117477
Epoch: 46 Idx: 0 Loss: 0.015273780101534153
Epoch: 46 Idx: 5000 Loss: 0.01556605045577226
Epoch: 47 Idx: 0 Loss: 0.011534207062884543
Epoch: 47 Idx: 5000 Loss: 0.016403396836381968
Epoch: 48 Idx: 0 Loss: 0.019814882949632014
Epoch: 48 Idx: 5000 Loss: 0.031156546170521483
Epoch: 49 Idx: 0 Loss: 0.014755191972861317
Epoch: 49 Idx: 5000 Loss: 0.017834488437679152
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.19309770568248255
Epoch: 0 Idx: 5000 Loss: 0.009967101932063665
Epoch: 1 Idx: 0 Loss: 0.016150881392649218
Epoch: 1 Idx: 5000 Loss: 0.015584410284224304
Epoch: 2 Idx: 0 Loss: 0.011230926926858219
Epoch: 2 Idx: 5000 Loss: 0.024079830228910797
Epoch: 3 Idx: 0 Loss: 0.007065343029666974
Epoch: 3 Idx: 5000 Loss: 0.01979667416425288
Epoch: 4 Idx: 0 Loss: 0.032190729555017124
Epoch: 4 Idx: 5000 Loss: 0.008208565686537541
Epoch: 5 Idx: 0 Loss: 0.021697483462493505
Epoch: 5 Idx: 5000 Loss: 0.027048677228110343
Epoch: 6 Idx: 0 Loss: 0.013614683540908203
Epoch: 6 Idx: 5000 Loss: 0.010533565197414045
Epoch: 7 Idx: 0 Loss: 0.017133087330575395
Epoch: 7 Idx: 5000 Loss: 0.013818429813052167
Epoch: 8 Idx: 0 Loss: 0.0297815969456943
Epoch: 8 Idx: 5000 Loss: 0.008826190206662005
Epoch: 9 Idx: 0 Loss: 0.012177692841447738
Epoch: 9 Idx: 5000 Loss: 0.008172041925489135
Epoch: 10 Idx: 0 Loss: 0.008617462155516935
Epoch: 10 Idx: 5000 Loss: 0.015923103390947976
Epoch: 11 Idx: 0 Loss: 0.009952421985865403
Epoch: 11 Idx: 5000 Loss: 0.013808339113955518
Epoch: 12 Idx: 0 Loss: 0.010351055234305219
Epoch: 12 Idx: 5000 Loss: 0.019225375455700536
Epoch: 13 Idx: 0 Loss: 0.013938394937105754
Epoch: 13 Idx: 5000 Loss: 0.0303515091869828
Epoch: 14 Idx: 0 Loss: 0.013034995826539306
Epoch: 14 Idx: 5000 Loss: 0.005758694789198433
Epoch: 15 Idx: 0 Loss: 0.03001883378125486
Epoch: 15 Idx: 5000 Loss: 0.0036352670663304734
Epoch: 16 Idx: 0 Loss: 0.015745509565681624
Epoch: 16 Idx: 5000 Loss: 0.016824445183144215
Epoch: 17 Idx: 0 Loss: 0.010439719948129731
Epoch: 17 Idx: 5000 Loss: 0.014148120417599186
Epoch: 18 Idx: 0 Loss: 0.017695432410299795
Epoch: 18 Idx: 5000 Loss: 0.011034497436830805
Epoch: 19 Idx: 0 Loss: 0.01245321765922968
Epoch: 19 Idx: 5000 Loss: 0.01001051879297818
Epoch: 20 Idx: 0 Loss: 0.010047778442231179
Epoch: 20 Idx: 5000 Loss: 0.013962538152614832
Epoch: 21 Idx: 0 Loss: 0.014913755001302417
Epoch: 21 Idx: 5000 Loss: 0.010574478458268047
Epoch: 22 Idx: 0 Loss: 0.019507190533537964
Epoch: 22 Idx: 5000 Loss: 0.0063260707160962375
Epoch: 23 Idx: 0 Loss: 0.015969269877867197
Epoch: 23 Idx: 5000 Loss: 0.017597327840906216
Epoch: 24 Idx: 0 Loss: 0.02088124120022409
Epoch: 24 Idx: 5000 Loss: 0.0075830350653016895
Epoch: 25 Idx: 0 Loss: 0.010284147637879822
Epoch: 25 Idx: 5000 Loss: 0.03101381202191223
Epoch: 26 Idx: 0 Loss: 0.006980937555291493
Epoch: 26 Idx: 5000 Loss: 0.029447336949152615
Epoch: 27 Idx: 0 Loss: 0.018190874321486958
Epoch: 27 Idx: 5000 Loss: 0.018392018467187847
Epoch: 28 Idx: 0 Loss: 0.005326430698513743
Epoch: 28 Idx: 5000 Loss: 0.01967953304010516
Epoch: 29 Idx: 0 Loss: 0.015095406904690144
Epoch: 29 Idx: 5000 Loss: 0.0076612402254385105
Epoch: 30 Idx: 0 Loss: 0.033730093224015906
Epoch: 30 Idx: 5000 Loss: 0.022014110484045692
Epoch: 31 Idx: 0 Loss: 0.011865258554032367
Epoch: 31 Idx: 5000 Loss: 0.01170524265291069
Epoch: 32 Idx: 0 Loss: 0.023434538625383156
Epoch: 32 Idx: 5000 Loss: 0.021020585760586383
Epoch: 33 Idx: 0 Loss: 0.00796058076701797
Epoch: 33 Idx: 5000 Loss: 0.015473173097268592
Epoch: 34 Idx: 0 Loss: 0.020434499920926125
Epoch: 34 Idx: 5000 Loss: 0.008811564650753502
Epoch: 35 Idx: 0 Loss: 0.01621306802518587
Epoch: 35 Idx: 5000 Loss: 0.0065122889557902765
Epoch: 36 Idx: 0 Loss: 0.012075077693924283
Epoch: 36 Idx: 5000 Loss: 0.031675158641420814
Epoch: 37 Idx: 0 Loss: 0.010768699165168268
Epoch: 37 Idx: 5000 Loss: 0.011624649331179899
Epoch: 38 Idx: 0 Loss: 0.01962109146291345
Epoch: 38 Idx: 5000 Loss: 0.023896804546885517
Epoch: 39 Idx: 0 Loss: 0.028377201785697553
Epoch: 39 Idx: 5000 Loss: 0.019661504982990297
Epoch: 40 Idx: 0 Loss: 0.01085806118040893
Epoch: 40 Idx: 5000 Loss: 0.014574561849084441
Epoch: 41 Idx: 0 Loss: 0.022530838072808555
Epoch: 41 Idx: 5000 Loss: 0.012881113364610104
Epoch: 42 Idx: 0 Loss: 0.00914580322237691
Epoch: 42 Idx: 5000 Loss: 0.0305643911270009
Epoch: 43 Idx: 0 Loss: 0.008372020799281248
Epoch: 43 Idx: 5000 Loss: 0.020912460309078208
Epoch: 44 Idx: 0 Loss: 0.01082818990757662
Epoch: 44 Idx: 5000 Loss: 0.012682556868802132
Epoch: 45 Idx: 0 Loss: 0.01699000868038837
Epoch: 45 Idx: 5000 Loss: 0.02085362078310988
Epoch: 46 Idx: 0 Loss: 0.021276866380500352
Epoch: 46 Idx: 5000 Loss: 0.022909876060415082
Epoch: 47 Idx: 0 Loss: 0.020442901546737675
Epoch: 47 Idx: 5000 Loss: 0.036083424458700795
Epoch: 48 Idx: 0 Loss: 0.03188710236913994
Epoch: 48 Idx: 5000 Loss: 0.020322323011007476
Epoch: 49 Idx: 0 Loss: 0.012971450499390587
Epoch: 49 Idx: 5000 Loss: 0.02431370908177162
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.2048974889341256
Epoch: 1 Idx: 0 Loss: 0.023727504162376265
Epoch: 2 Idx: 0 Loss: 0.015337418195307262
Epoch: 3 Idx: 0 Loss: 0.043585355742859516
Epoch: 4 Idx: 0 Loss: 0.015002517873685369
Epoch: 5 Idx: 0 Loss: 0.011441527199810078
Epoch: 6 Idx: 0 Loss: 0.04264216327595974
Epoch: 7 Idx: 0 Loss: 0.00848845438067039
Epoch: 8 Idx: 0 Loss: 0.02160440840001247
Epoch: 9 Idx: 0 Loss: 0.009102289675473399
Epoch: 10 Idx: 0 Loss: 0.012162661962445392
Epoch: 11 Idx: 0 Loss: 0.011517488731521343
Epoch: 12 Idx: 0 Loss: 0.009671589543018754
Epoch: 13 Idx: 0 Loss: 0.01661744836522555
Epoch: 14 Idx: 0 Loss: 0.015484372147733839
Epoch: 15 Idx: 0 Loss: 0.009393765412683278
Epoch: 16 Idx: 0 Loss: 0.01630196421736498
Epoch: 17 Idx: 0 Loss: 0.05392085063622158
Epoch: 18 Idx: 0 Loss: 0.018000651134497926
Epoch: 19 Idx: 0 Loss: 0.00543864796141072
Epoch: 20 Idx: 0 Loss: 0.010439147106951027
Epoch: 21 Idx: 0 Loss: 0.014370569599347007
Epoch: 22 Idx: 0 Loss: 0.009907114418713784
Epoch: 23 Idx: 0 Loss: 0.01177760033317319
Epoch: 24 Idx: 0 Loss: 0.008256096004108683
Epoch: 25 Idx: 0 Loss: 0.009907903807900258
Epoch: 26 Idx: 0 Loss: 0.00997262223135311
Epoch: 27 Idx: 0 Loss: 0.011146239671727846
Epoch: 28 Idx: 0 Loss: 0.013839816362014618
Epoch: 29 Idx: 0 Loss: 0.014005231803167753
Epoch: 30 Idx: 0 Loss: 0.021196796757121716
Epoch: 31 Idx: 0 Loss: 0.011707762533668741
Epoch: 32 Idx: 0 Loss: 0.021454210253725833
Epoch: 33 Idx: 0 Loss: 0.006650303064239022
Epoch: 34 Idx: 0 Loss: 0.03294645020172606
Epoch: 35 Idx: 0 Loss: 0.015062636617214008
Epoch: 36 Idx: 0 Loss: 0.011334119589450947
Epoch: 37 Idx: 0 Loss: 0.02048051852288608
Epoch: 38 Idx: 0 Loss: 0.02701021873990955
Epoch: 39 Idx: 0 Loss: 0.012164464661611248
Epoch: 40 Idx: 0 Loss: 0.025904813555399912
Epoch: 41 Idx: 0 Loss: 0.015576646972348224
Epoch: 42 Idx: 0 Loss: 0.006612491228913086
Epoch: 43 Idx: 0 Loss: 0.012029510687439397
Epoch: 44 Idx: 0 Loss: 0.00864219395402763
Epoch: 45 Idx: 0 Loss: 0.02540945460386629
Epoch: 46 Idx: 0 Loss: 0.011794593166433665
Epoch: 47 Idx: 0 Loss: 0.008840051931133268
Epoch: 48 Idx: 0 Loss: 0.014266563712836175
Epoch: 49 Idx: 0 Loss: 0.011793123086213811
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.17683674707181168
Epoch: 0 Idx: 5000 Loss: 0.024065885631743604
Epoch: 1 Idx: 0 Loss: 0.04452602327417719
Epoch: 1 Idx: 5000 Loss: 0.022862698389443034
Epoch: 2 Idx: 0 Loss: 0.011176163574112752
Epoch: 2 Idx: 5000 Loss: 0.008898488349658415
Epoch: 3 Idx: 0 Loss: 0.02022600062076279
Epoch: 3 Idx: 5000 Loss: 0.011726650703007817
Epoch: 4 Idx: 0 Loss: 0.010267135356208486
Epoch: 4 Idx: 5000 Loss: 0.018082101790166557
Epoch: 5 Idx: 0 Loss: 0.008847065774737393
Epoch: 5 Idx: 5000 Loss: 0.012242469854015801
Epoch: 6 Idx: 0 Loss: 0.02312359881812584
Epoch: 6 Idx: 5000 Loss: 0.022944075352319383
Epoch: 7 Idx: 0 Loss: 0.015049985867894192
Epoch: 7 Idx: 5000 Loss: 0.009827458948024222
Epoch: 8 Idx: 0 Loss: 0.01848112656028529
Epoch: 8 Idx: 5000 Loss: 0.019437062139443604
Epoch: 9 Idx: 0 Loss: 0.009892472768643176
Epoch: 9 Idx: 5000 Loss: 0.01760519153270803
Epoch: 10 Idx: 0 Loss: 0.024018779510479038
Epoch: 10 Idx: 5000 Loss: 0.011429789303285559
Epoch: 11 Idx: 0 Loss: 0.022946570522566392
Epoch: 11 Idx: 5000 Loss: 0.012322720868842958
Epoch: 12 Idx: 0 Loss: 0.004703962427090474
Epoch: 12 Idx: 5000 Loss: 0.01694235351111081
Epoch: 13 Idx: 0 Loss: 0.013517332596743384
Epoch: 13 Idx: 5000 Loss: 0.02093996050484273
Epoch: 14 Idx: 0 Loss: 0.013810780842054497
Epoch: 14 Idx: 5000 Loss: 0.019013876916239417
Epoch: 15 Idx: 0 Loss: 0.011258998086931506
Epoch: 15 Idx: 5000 Loss: 0.01291769714302361
Epoch: 16 Idx: 0 Loss: 0.01114054255101363
Epoch: 16 Idx: 5000 Loss: 0.006146036556457284
Epoch: 17 Idx: 0 Loss: 0.016135783812535248
Epoch: 17 Idx: 5000 Loss: 0.01429347837020671
Epoch: 18 Idx: 0 Loss: 0.01480864290920917
Epoch: 18 Idx: 5000 Loss: 0.01704249805068897
Epoch: 19 Idx: 0 Loss: 0.026104649577611966
Epoch: 19 Idx: 5000 Loss: 0.02349008769719707
Epoch: 20 Idx: 0 Loss: 0.019801017988120957
Epoch: 20 Idx: 5000 Loss: 0.014084575589977031
Epoch: 21 Idx: 0 Loss: 0.008255399366078952
Epoch: 21 Idx: 5000 Loss: 0.014270803875362741
Epoch: 22 Idx: 0 Loss: 0.016120684925553873
Epoch: 22 Idx: 5000 Loss: 0.009076066281352827
Epoch: 23 Idx: 0 Loss: 0.01120126644011718
Epoch: 23 Idx: 5000 Loss: 0.012094741551038955
Epoch: 24 Idx: 0 Loss: 0.006609219679108326
Epoch: 24 Idx: 5000 Loss: 0.016979398346226218
Epoch: 25 Idx: 0 Loss: 0.008953271859099178
Epoch: 25 Idx: 5000 Loss: 0.015362044958295486
Epoch: 26 Idx: 0 Loss: 0.02706321010038555
Epoch: 26 Idx: 5000 Loss: 0.012190117930343976
Epoch: 27 Idx: 0 Loss: 0.010433008148704322
Epoch: 27 Idx: 5000 Loss: 0.0072559773742387765
Epoch: 28 Idx: 0 Loss: 0.01713520536370999
Epoch: 28 Idx: 5000 Loss: 0.022499880239785455
Epoch: 29 Idx: 0 Loss: 0.03241328261769962
Epoch: 29 Idx: 5000 Loss: 0.022609191308606353
Epoch: 30 Idx: 0 Loss: 0.007855751297761882
Epoch: 30 Idx: 5000 Loss: 0.01687978804003034
Epoch: 31 Idx: 0 Loss: 0.012073914842198873
Epoch: 31 Idx: 5000 Loss: 0.012278107586016562
Epoch: 32 Idx: 0 Loss: 0.005230897512402135
Epoch: 32 Idx: 5000 Loss: 0.013849045517452524
Epoch: 33 Idx: 0 Loss: 0.012194917078504237
Epoch: 33 Idx: 5000 Loss: 0.0076090219371106205
Epoch: 34 Idx: 0 Loss: 0.014904097585823686
Epoch: 34 Idx: 5000 Loss: 0.028070881670726796
Epoch: 35 Idx: 0 Loss: 0.014567687830442077
Epoch: 35 Idx: 5000 Loss: 0.02101548415220527
Epoch: 36 Idx: 0 Loss: 0.023203285919467728
Epoch: 36 Idx: 5000 Loss: 0.022126574755522845
Epoch: 37 Idx: 0 Loss: 0.015197364338112626
Epoch: 37 Idx: 5000 Loss: 0.014974821672039389
Epoch: 38 Idx: 0 Loss: 0.01334147978960168
Epoch: 38 Idx: 5000 Loss: 0.011349225377003676
Epoch: 39 Idx: 0 Loss: 0.023088374593413376
Epoch: 39 Idx: 5000 Loss: 0.016025384438828085
Epoch: 40 Idx: 0 Loss: 0.017242624332388105
Epoch: 40 Idx: 5000 Loss: 0.009509992142896093
Epoch: 41 Idx: 0 Loss: 0.01270769743896558
Epoch: 41 Idx: 5000 Loss: 0.01650780243599872
Epoch: 42 Idx: 0 Loss: 0.011992286992685511
Epoch: 42 Idx: 5000 Loss: 0.0072765328109889735
Epoch: 43 Idx: 0 Loss: 0.019668781366705437
Epoch: 43 Idx: 5000 Loss: 0.008073209462388185
Epoch: 44 Idx: 0 Loss: 0.01159557370661618
Epoch: 44 Idx: 5000 Loss: 0.022572429423917635
Epoch: 45 Idx: 0 Loss: 0.01377361861744975
Epoch: 45 Idx: 5000 Loss: 0.011696965001913286
Epoch: 46 Idx: 0 Loss: 0.011383007206751786
Epoch: 46 Idx: 5000 Loss: 0.005235484863844457
Epoch: 47 Idx: 0 Loss: 0.018638870325671422
Epoch: 47 Idx: 5000 Loss: 0.03352902151798236
Epoch: 48 Idx: 0 Loss: 0.0201115696877531
Epoch: 48 Idx: 5000 Loss: 0.02671798063303386
Epoch: 49 Idx: 0 Loss: 0.013457169193787033
Epoch: 49 Idx: 5000 Loss: 0.012566470034233557
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.20109403592390987
Epoch: 1 Idx: 0 Loss: 0.016195999859650825
Epoch: 2 Idx: 0 Loss: 0.013467479475458271
Epoch: 3 Idx: 0 Loss: 0.01056529877284154
Epoch: 4 Idx: 0 Loss: 0.009224538151225023
Epoch: 5 Idx: 0 Loss: 0.00976337402041841
Epoch: 6 Idx: 0 Loss: 0.01051912658107159
Epoch: 7 Idx: 0 Loss: 0.011953063271445661
Epoch: 8 Idx: 0 Loss: 0.018438333272313565
Epoch: 9 Idx: 0 Loss: 0.016772258648170495
Epoch: 10 Idx: 0 Loss: 0.012670591913700877
Epoch: 11 Idx: 0 Loss: 0.015465859014066455
Epoch: 12 Idx: 0 Loss: 0.017444113601103192
Epoch: 13 Idx: 0 Loss: 0.012769331892921915
Epoch: 14 Idx: 0 Loss: 0.009027608902046652
Epoch: 15 Idx: 0 Loss: 0.017695837390800294
Epoch: 16 Idx: 0 Loss: 0.017660189564221586
Epoch: 17 Idx: 0 Loss: 0.0414684679533414
Epoch: 18 Idx: 0 Loss: 0.01588229286573387
Epoch: 19 Idx: 0 Loss: 0.010655640943298397
Epoch: 20 Idx: 0 Loss: 0.02313607676251513
Epoch: 21 Idx: 0 Loss: 0.006647611374564202
Epoch: 22 Idx: 0 Loss: 0.0120050519703607
Epoch: 23 Idx: 0 Loss: 0.017208335959759836
Epoch: 24 Idx: 0 Loss: 0.007130746330916968
Epoch: 25 Idx: 0 Loss: 0.018503597227879028
Epoch: 26 Idx: 0 Loss: 0.02101740693314927
Epoch: 27 Idx: 0 Loss: 0.006090860355018784
Epoch: 28 Idx: 0 Loss: 0.01646256148998884
Epoch: 29 Idx: 0 Loss: 0.022997544791719126
Epoch: 30 Idx: 0 Loss: 0.02219952188238676
Epoch: 31 Idx: 0 Loss: 0.03219189113778135
Epoch: 32 Idx: 0 Loss: 0.016392371455866316
Epoch: 33 Idx: 0 Loss: 0.011221849871853873
Epoch: 34 Idx: 0 Loss: 0.009791635128595575
Epoch: 35 Idx: 0 Loss: 0.016817547634250134
Epoch: 36 Idx: 0 Loss: 0.017619780192443465
Epoch: 37 Idx: 0 Loss: 0.016493023198988186
Epoch: 38 Idx: 0 Loss: 0.018055408599502352
Epoch: 39 Idx: 0 Loss: 0.011408618013337753
Epoch: 40 Idx: 0 Loss: 0.008489772768798533
Epoch: 41 Idx: 0 Loss: 0.007401893564017377
Epoch: 42 Idx: 0 Loss: 0.005373122680596823
Epoch: 43 Idx: 0 Loss: 0.03933958805364769
Epoch: 44 Idx: 0 Loss: 0.018399291497842946
Epoch: 45 Idx: 0 Loss: 0.013376504544934638
Epoch: 46 Idx: 0 Loss: 0.014590626427734203
Epoch: 47 Idx: 0 Loss: 0.017468511539785462
Epoch: 48 Idx: 0 Loss: 0.012193547746139809
Epoch: 49 Idx: 0 Loss: 0.013834407018709284
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666)
Performance for  [('ekaw', 'sigkdd')] is : (0.7692307692307693, 0.9090909090909091, 0.8333333333333333, 0.8771929824561403, 0.7936507936507936)
Performance for  [('conference', 'edas')] is : (0.8, 0.7058823529411765, 0.7500000000000001, 0.7228915662650602, 0.7792207792207791)
Performance for  [('cmt', 'ekaw')] is : (0.46153846153846156, 0.5454545454545454, 0.4999999999999999, 0.5263157894736842, 0.4761904761904762)
Performance for  [('confOf', 'edas')] is : (0.5652173913043478, 0.6842105263157895, 0.6190476190476191, 0.6565656565656566, 0.5855855855855856)
Performance for  [('iasted', 'sigkdd')] is : (0.48, 0.8, 0.6, 0.7058823529411765, 0.5217391304347826)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.6775219  0.69526579 0.66904762 0.68075302 0.6693032 ]
Threshold:  0.897
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2b61461c7af0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc268>
Subject: Job 4142778: <python main.py 6 24 False True> in cluster <dcc> Done

Job <python main.py 6 24 False True> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:28 2020
Job was executed on host(s) <dccxc268>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 10:13:22 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 10:13:22 2020
Terminated at Wed Sep 16 21:40:27 2020
Results reported at Wed Sep 16 21:40:27 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 24 False True
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   41147.59 sec.
    Max Memory :                                 4215 MB
    Average Memory :                             4054.90 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39202.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   41227 sec.
    Turnaround time :                            52919 sec.

The output (if any) is above this job summary.

