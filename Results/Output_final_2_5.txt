2020-09-16 09:21:36.514283: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 09:21:45.585035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 09:21:45.699637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 09:21:45.699732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 09:21:45.701646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 09:21:45.703055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 09:21:45.703406: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 09:21:45.705217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 09:21:45.706596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 09:21:45.706809: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 09:21:45.706832: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 09:21:45.707167: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 09:21:45.714589: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600005000 Hz
2020-09-16 09:21:45.714775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1b0170bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 09:21:45.714794: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 09:21:45.716811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 09:21:45.716869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18264778620674546
Epoch: 0 Idx: 5000 Loss: 0.010497352329725124
Epoch: 1 Idx: 0 Loss: 0.03551941412819302
Epoch: 1 Idx: 5000 Loss: 0.018139937268308273
Epoch: 2 Idx: 0 Loss: 0.004130642815259798
Epoch: 2 Idx: 5000 Loss: 0.01147011065044004
Epoch: 3 Idx: 0 Loss: 0.012874227288768199
Epoch: 3 Idx: 5000 Loss: 0.01057224923986986
Epoch: 4 Idx: 0 Loss: 0.005926072907171419
Epoch: 4 Idx: 5000 Loss: 0.015539803627218383
Epoch: 5 Idx: 0 Loss: 0.011458559411361455
Epoch: 5 Idx: 5000 Loss: 0.012168430088762686
Epoch: 6 Idx: 0 Loss: 0.023439469992434674
Epoch: 6 Idx: 5000 Loss: 0.013898257362810891
Epoch: 7 Idx: 0 Loss: 0.011437077361579813
Epoch: 7 Idx: 5000 Loss: 0.005588627643970532
Epoch: 8 Idx: 0 Loss: 0.011325872948490918
Epoch: 8 Idx: 5000 Loss: 0.010874938850854523
Epoch: 9 Idx: 0 Loss: 0.0276650918115168
Epoch: 9 Idx: 5000 Loss: 0.03419796183865405
Epoch: 10 Idx: 0 Loss: 0.015032681674789891
Epoch: 10 Idx: 5000 Loss: 0.01844055043717846
Epoch: 11 Idx: 0 Loss: 0.01155754829394632
Epoch: 11 Idx: 5000 Loss: 0.03244220225348954
Epoch: 12 Idx: 0 Loss: 0.010133765601273406
Epoch: 12 Idx: 5000 Loss: 0.007625248660721563
Epoch: 13 Idx: 0 Loss: 0.02207134093643146
Epoch: 13 Idx: 5000 Loss: 0.030467261804837074
Epoch: 14 Idx: 0 Loss: 0.01809992374447833
Epoch: 14 Idx: 5000 Loss: 0.012880645790494229
Epoch: 15 Idx: 0 Loss: 0.03125195699461213
Epoch: 15 Idx: 5000 Loss: 0.015047482272248683
Epoch: 16 Idx: 0 Loss: 0.011106714220999292
Epoch: 16 Idx: 5000 Loss: 0.01424533220142463
Epoch: 17 Idx: 0 Loss: 0.030245564152388184
Epoch: 17 Idx: 5000 Loss: 0.01365248206806187
Epoch: 18 Idx: 0 Loss: 0.009103481335592859
Epoch: 18 Idx: 5000 Loss: 0.013319319927970728
Epoch: 19 Idx: 0 Loss: 0.01224127311358525
Epoch: 19 Idx: 5000 Loss: 0.007800497981744537
Epoch: 20 Idx: 0 Loss: 0.0037534431560341864
Epoch: 20 Idx: 5000 Loss: 0.012508885728463629
Epoch: 21 Idx: 0 Loss: 0.013993005172937976
Epoch: 21 Idx: 5000 Loss: 0.013196003696512764
Epoch: 22 Idx: 0 Loss: 0.012342331204955884
Epoch: 22 Idx: 5000 Loss: 0.03154923279056532
Epoch: 23 Idx: 0 Loss: 0.010000770631301406
Epoch: 23 Idx: 5000 Loss: 0.01893330498295799
Epoch: 24 Idx: 0 Loss: 0.01969201760253368
Epoch: 24 Idx: 5000 Loss: 0.016664450997747195
Epoch: 25 Idx: 0 Loss: 0.008192306788746733
Epoch: 25 Idx: 5000 Loss: 0.02886212002666895
Epoch: 26 Idx: 0 Loss: 0.0066655811403984605
Epoch: 26 Idx: 5000 Loss: 0.010871705296252148
Epoch: 27 Idx: 0 Loss: 0.008255085293650431
Epoch: 27 Idx: 5000 Loss: 0.017872470860896942
Epoch: 28 Idx: 0 Loss: 0.011076314399479007
Epoch: 28 Idx: 5000 Loss: 0.022284430727157318
Epoch: 29 Idx: 0 Loss: 0.016546251657377123
Epoch: 29 Idx: 5000 Loss: 0.0071179860430047965
Epoch: 30 Idx: 0 Loss: 0.014570804184100568
Epoch: 30 Idx: 5000 Loss: 0.009749666887559927
Epoch: 31 Idx: 0 Loss: 0.02239574902009442
Epoch: 31 Idx: 5000 Loss: 0.00934693974925023
Epoch: 32 Idx: 0 Loss: 0.01865889161825771
Epoch: 32 Idx: 5000 Loss: 0.013182553354102712
Epoch: 33 Idx: 0 Loss: 0.011789280025504764
Epoch: 33 Idx: 5000 Loss: 0.013087416188804952
Epoch: 34 Idx: 0 Loss: 0.004675760452368489
Epoch: 34 Idx: 5000 Loss: 0.021069721305166874
Epoch: 35 Idx: 0 Loss: 0.006090882295598166
Epoch: 35 Idx: 5000 Loss: 0.01990108016749755
Epoch: 36 Idx: 0 Loss: 0.025632783391393278
Epoch: 36 Idx: 5000 Loss: 0.010714141814038541
Epoch: 37 Idx: 0 Loss: 0.018541464628500065
Epoch: 37 Idx: 5000 Loss: 0.01537627436305427
Epoch: 38 Idx: 0 Loss: 0.0108985555492557
Epoch: 38 Idx: 5000 Loss: 0.017041048552836405
Epoch: 39 Idx: 0 Loss: 0.015963712201507604
Epoch: 39 Idx: 5000 Loss: 0.01056463415597084
Epoch: 40 Idx: 0 Loss: 0.019472154956821905
Epoch: 40 Idx: 5000 Loss: 0.022336064991504426
Epoch: 41 Idx: 0 Loss: 0.005985769732721394
Epoch: 41 Idx: 5000 Loss: 0.019947234645847533
Epoch: 42 Idx: 0 Loss: 0.020691835632675015
Epoch: 42 Idx: 5000 Loss: 0.013989163853558575
Epoch: 43 Idx: 0 Loss: 0.005841082485430688
Epoch: 43 Idx: 5000 Loss: 0.011529884928632281
Epoch: 44 Idx: 0 Loss: 0.01799985060129504
Epoch: 44 Idx: 5000 Loss: 0.013857476051776096
Epoch: 45 Idx: 0 Loss: 0.005279877096981006
Epoch: 45 Idx: 5000 Loss: 0.022011670005813652
Epoch: 46 Idx: 0 Loss: 0.008588643680693318
Epoch: 46 Idx: 5000 Loss: 0.007549984218731578
Epoch: 47 Idx: 0 Loss: 0.0075470912693513005
Epoch: 47 Idx: 5000 Loss: 0.008528310950625137
Epoch: 48 Idx: 0 Loss: 0.022335799126872148
Epoch: 48 Idx: 5000 Loss: 0.019535526211165985
Epoch: 49 Idx: 0 Loss: 0.03105152568219418
Epoch: 49 Idx: 5000 Loss: 0.009416926187893408
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.24870931931279733
Epoch: 0 Idx: 5000 Loss: 0.01423744070493986
Epoch: 1 Idx: 0 Loss: 0.022690574934362814
Epoch: 1 Idx: 5000 Loss: 0.014818829396009033
Epoch: 2 Idx: 0 Loss: 0.010800457318338036
Epoch: 2 Idx: 5000 Loss: 0.009808483210732409
Epoch: 3 Idx: 0 Loss: 0.016274069489031276
Epoch: 3 Idx: 5000 Loss: 0.02310888539983778
Epoch: 4 Idx: 0 Loss: 0.006207283581637299
Epoch: 4 Idx: 5000 Loss: 0.007312249048118507
Epoch: 5 Idx: 0 Loss: 0.011041361494203657
Epoch: 5 Idx: 5000 Loss: 0.016522053639624522
Epoch: 6 Idx: 0 Loss: 0.007852003841483502
Epoch: 6 Idx: 5000 Loss: 0.035988212821555274
Epoch: 7 Idx: 0 Loss: 0.010612820865096326
Epoch: 7 Idx: 5000 Loss: 0.026959874236591762
Epoch: 8 Idx: 0 Loss: 0.021006814518299097
Epoch: 8 Idx: 5000 Loss: 0.032957943344258944
Epoch: 9 Idx: 0 Loss: 0.014982545729989628
Epoch: 9 Idx: 5000 Loss: 0.019349875734522334
Epoch: 10 Idx: 0 Loss: 0.016911242024532334
Epoch: 10 Idx: 5000 Loss: 0.007617946884419353
Epoch: 11 Idx: 0 Loss: 0.009929155849263741
Epoch: 11 Idx: 5000 Loss: 0.009014610988655764
Epoch: 12 Idx: 0 Loss: 0.013942755900170753
Epoch: 12 Idx: 5000 Loss: 0.014907611839904349
Epoch: 13 Idx: 0 Loss: 0.00901526679910741
Epoch: 13 Idx: 5000 Loss: 0.017966706046346585
Epoch: 14 Idx: 0 Loss: 0.017129875434032202
Epoch: 14 Idx: 5000 Loss: 0.006141920395478522
Epoch: 15 Idx: 0 Loss: 0.009114663095529198
Epoch: 15 Idx: 5000 Loss: 0.022600958815107198
Epoch: 16 Idx: 0 Loss: 0.012205586851800166
Epoch: 16 Idx: 5000 Loss: 0.013402586353219406
Epoch: 17 Idx: 0 Loss: 0.020984137099191322
Epoch: 17 Idx: 5000 Loss: 0.009213996740990958
Epoch: 18 Idx: 0 Loss: 0.020734894230716203
Epoch: 18 Idx: 5000 Loss: 0.01509207584376099
Epoch: 19 Idx: 0 Loss: 0.01121749922331819
Epoch: 19 Idx: 5000 Loss: 0.015122462323219912
Epoch: 20 Idx: 0 Loss: 0.010176291182790039
Epoch: 20 Idx: 5000 Loss: 0.02076099378994928
Epoch: 21 Idx: 0 Loss: 0.008662002669977482
Epoch: 21 Idx: 5000 Loss: 0.010806905789316673
Epoch: 22 Idx: 0 Loss: 0.018093115861135677
Epoch: 22 Idx: 5000 Loss: 0.011957561679794016
Epoch: 23 Idx: 0 Loss: 0.011152487370499231
Epoch: 23 Idx: 5000 Loss: 0.015387588031665053
Epoch: 24 Idx: 0 Loss: 0.0070408505888373465
Epoch: 24 Idx: 5000 Loss: 0.018596274484623886
Epoch: 25 Idx: 0 Loss: 0.01600699805932581
Epoch: 25 Idx: 5000 Loss: 0.015987612714452155
Epoch: 26 Idx: 0 Loss: 0.004685890999425645
Epoch: 26 Idx: 5000 Loss: 0.01663225844106164
Epoch: 27 Idx: 0 Loss: 0.015952216821744768
Epoch: 27 Idx: 5000 Loss: 0.01350180225026101
Epoch: 28 Idx: 0 Loss: 0.012782623788363014
Epoch: 28 Idx: 5000 Loss: 0.010921187718174925
Epoch: 29 Idx: 0 Loss: 0.03544690875045795
Epoch: 29 Idx: 5000 Loss: 0.013248613777985589
Epoch: 30 Idx: 0 Loss: 0.03651597323576187
Epoch: 30 Idx: 5000 Loss: 0.03520108770797815
Epoch: 31 Idx: 0 Loss: 0.013064265831192377
Epoch: 31 Idx: 5000 Loss: 0.029181592594721556
Epoch: 32 Idx: 0 Loss: 0.012626713104306606
Epoch: 32 Idx: 5000 Loss: 0.010409767125655892
Epoch: 33 Idx: 0 Loss: 0.009458120435449635
Epoch: 33 Idx: 5000 Loss: 0.0059657378310923525
Epoch: 34 Idx: 0 Loss: 0.013256856342181962
Epoch: 34 Idx: 5000 Loss: 0.015009025610900527
Epoch: 35 Idx: 0 Loss: 0.017019706511543255
Epoch: 35 Idx: 5000 Loss: 0.023406862431643728
Epoch: 36 Idx: 0 Loss: 0.01991159255645327
Epoch: 36 Idx: 5000 Loss: 0.01181241123360801
Epoch: 37 Idx: 0 Loss: 0.016134582220368662
Epoch: 37 Idx: 5000 Loss: 0.021656564217247043
Epoch: 38 Idx: 0 Loss: 0.012239895419793307
Epoch: 38 Idx: 5000 Loss: 0.009377726004181153
Epoch: 39 Idx: 0 Loss: 0.01149733413669285
Epoch: 39 Idx: 5000 Loss: 0.01645908481270447
Epoch: 40 Idx: 0 Loss: 0.031666189655534104
Epoch: 40 Idx: 5000 Loss: 0.011980229617430031
Epoch: 41 Idx: 0 Loss: 0.017289316142826035
Epoch: 41 Idx: 5000 Loss: 0.02198754491607833
Epoch: 42 Idx: 0 Loss: 0.017109862449520702
Epoch: 42 Idx: 5000 Loss: 0.017770488135506135
Epoch: 43 Idx: 0 Loss: 0.019968533080766536
Epoch: 43 Idx: 5000 Loss: 0.011453371164836777
Epoch: 44 Idx: 0 Loss: 0.006471446647456434
Epoch: 44 Idx: 5000 Loss: 0.016485214172097005
Epoch: 45 Idx: 0 Loss: 0.05846747898805768
Epoch: 45 Idx: 5000 Loss: 0.006775381533614336
Epoch: 46 Idx: 0 Loss: 0.02259647395805533
Epoch: 46 Idx: 5000 Loss: 0.012407479100040397
Epoch: 47 Idx: 0 Loss: 0.011630424126092342
Epoch: 47 Idx: 5000 Loss: 0.015422559895723335
Epoch: 48 Idx: 0 Loss: 0.014057511882529074
Epoch: 48 Idx: 5000 Loss: 0.007819282153696035
Epoch: 49 Idx: 0 Loss: 0.02929712739941207
Epoch: 49 Idx: 5000 Loss: 0.025037789582678518
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.1595606841748217
Epoch: 0 Idx: 5000 Loss: 0.014895676538145573
Epoch: 1 Idx: 0 Loss: 0.013093645563609646
Epoch: 1 Idx: 5000 Loss: 0.013073476173065453
Epoch: 2 Idx: 0 Loss: 0.01710426427634045
Epoch: 2 Idx: 5000 Loss: 0.012255370119234365
Epoch: 3 Idx: 0 Loss: 0.009525142764877814
Epoch: 3 Idx: 5000 Loss: 0.014459875298842025
Epoch: 4 Idx: 0 Loss: 0.009129012707486997
Epoch: 4 Idx: 5000 Loss: 0.006550452237974288
Epoch: 5 Idx: 0 Loss: 0.012644382518067194
Epoch: 5 Idx: 5000 Loss: 0.007593328048110642
Epoch: 6 Idx: 0 Loss: 0.02084353442707946
Epoch: 6 Idx: 5000 Loss: 0.066235241934917
Epoch: 7 Idx: 0 Loss: 0.010571473740086237
Epoch: 7 Idx: 5000 Loss: 0.014734727427007724
Epoch: 8 Idx: 0 Loss: 0.011901319525596183
Epoch: 8 Idx: 5000 Loss: 0.02018651524334801
Epoch: 9 Idx: 0 Loss: 0.015658845001406446
Epoch: 9 Idx: 5000 Loss: 0.009851567926085417
Epoch: 10 Idx: 0 Loss: 0.019441929956554752
Epoch: 10 Idx: 5000 Loss: 0.013036498970978604
Epoch: 11 Idx: 0 Loss: 0.009307192453301902
Epoch: 11 Idx: 5000 Loss: 0.013094150139689877
Epoch: 12 Idx: 0 Loss: 0.010597299196309404
Epoch: 12 Idx: 5000 Loss: 0.01753494561455512
Epoch: 13 Idx: 0 Loss: 0.012875116048470907
Epoch: 13 Idx: 5000 Loss: 0.011910657106644927
Epoch: 14 Idx: 0 Loss: 0.034113171417614115
Epoch: 14 Idx: 5000 Loss: 0.024416135949164555
Epoch: 15 Idx: 0 Loss: 0.01642093523553901
Epoch: 15 Idx: 5000 Loss: 0.0062662247822685745
Epoch: 16 Idx: 0 Loss: 0.0446154883647753
Epoch: 16 Idx: 5000 Loss: 0.017111717249920496
Epoch: 17 Idx: 0 Loss: 0.013677035650240256
Epoch: 17 Idx: 5000 Loss: 0.033526949869177494
Epoch: 18 Idx: 0 Loss: 0.005367716343449092
Epoch: 18 Idx: 5000 Loss: 0.01786592550371778
Epoch: 19 Idx: 0 Loss: 0.00990267268404743
Epoch: 19 Idx: 5000 Loss: 0.021957407017322374
Epoch: 20 Idx: 0 Loss: 0.01854456519289177
Epoch: 20 Idx: 5000 Loss: 0.011986796312215716
Epoch: 21 Idx: 0 Loss: 0.013840384136581164
Epoch: 21 Idx: 5000 Loss: 0.0245288414020303
Epoch: 22 Idx: 0 Loss: 0.011318440251883692
Epoch: 22 Idx: 5000 Loss: 0.013909129980531305
Epoch: 23 Idx: 0 Loss: 0.01671490485577517
Epoch: 23 Idx: 5000 Loss: 0.015080100758092057
Epoch: 24 Idx: 0 Loss: 0.008450618182165973
Epoch: 24 Idx: 5000 Loss: 0.01616375499436787
Epoch: 25 Idx: 0 Loss: 0.01706267006805886
Epoch: 25 Idx: 5000 Loss: 0.014479749878979244
Epoch: 26 Idx: 0 Loss: 0.012650362611589142
Epoch: 26 Idx: 5000 Loss: 0.029490206757246593
Epoch: 27 Idx: 0 Loss: 0.01668932062866868
Epoch: 27 Idx: 5000 Loss: 0.024040907707841327
Epoch: 28 Idx: 0 Loss: 0.020274623707197785
Epoch: 28 Idx: 5000 Loss: 0.00932776268112617
Epoch: 29 Idx: 0 Loss: 0.01297803465209765
Epoch: 29 Idx: 5000 Loss: 0.010061004243520568
Epoch: 30 Idx: 0 Loss: 0.01260777806816201
Epoch: 30 Idx: 5000 Loss: 0.0214923215814673
Epoch: 31 Idx: 0 Loss: 0.011020917833656507
Epoch: 31 Idx: 5000 Loss: 0.01951446057132247
Epoch: 32 Idx: 0 Loss: 0.033786456174770566
Epoch: 32 Idx: 5000 Loss: 0.0263793013406867
Epoch: 33 Idx: 0 Loss: 0.030383972747134932
Epoch: 33 Idx: 5000 Loss: 0.020142725172643164
Epoch: 34 Idx: 0 Loss: 0.014933912846408779
Epoch: 34 Idx: 5000 Loss: 0.018277034560202347
Epoch: 35 Idx: 0 Loss: 0.0181271343797128
Epoch: 35 Idx: 5000 Loss: 0.007144029639032153
Epoch: 36 Idx: 0 Loss: 0.009261208171979857
Epoch: 36 Idx: 5000 Loss: 0.02071830382668769
Epoch: 37 Idx: 0 Loss: 0.01690465098880936
Epoch: 37 Idx: 5000 Loss: 0.016492928853827936
Epoch: 38 Idx: 0 Loss: 0.009838369461915717
Epoch: 38 Idx: 5000 Loss: 0.008790600652979777
Epoch: 39 Idx: 0 Loss: 0.015809551740020966
Epoch: 39 Idx: 5000 Loss: 0.006084190368908164
Epoch: 40 Idx: 0 Loss: 0.007777851632991249
Epoch: 40 Idx: 5000 Loss: 0.013857666825134214
Epoch: 41 Idx: 0 Loss: 0.015742068775745056
Epoch: 41 Idx: 5000 Loss: 0.01500610050994368
Epoch: 42 Idx: 0 Loss: 0.026091939400511212
Epoch: 42 Idx: 5000 Loss: 0.017629106743028554
Epoch: 43 Idx: 0 Loss: 0.00820419500594606
Epoch: 43 Idx: 5000 Loss: 0.013402444181235054
Epoch: 44 Idx: 0 Loss: 0.01161663226036454
Epoch: 44 Idx: 5000 Loss: 0.013889385080124808
Epoch: 45 Idx: 0 Loss: 0.03533675303004078
Epoch: 45 Idx: 5000 Loss: 0.008413186864738117
Epoch: 46 Idx: 0 Loss: 0.014097938416893663
Epoch: 46 Idx: 5000 Loss: 0.02437329582462035
Epoch: 47 Idx: 0 Loss: 0.008621261205143053
Epoch: 47 Idx: 5000 Loss: 0.02083799739978187
Epoch: 48 Idx: 0 Loss: 0.010230336357968148
Epoch: 48 Idx: 5000 Loss: 0.018982962399364856
Epoch: 49 Idx: 0 Loss: 0.01140877727639698
Epoch: 49 Idx: 5000 Loss: 0.010521782446502285
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.18231480373414027
Epoch: 0 Idx: 5000 Loss: 0.009772651552956348
Epoch: 1 Idx: 0 Loss: 0.013127721943384425
Epoch: 1 Idx: 5000 Loss: 0.020460115753193245
Epoch: 2 Idx: 0 Loss: 0.02343364975404441
Epoch: 2 Idx: 5000 Loss: 0.03887548598157356
Epoch: 3 Idx: 0 Loss: 0.015488812252565381
Epoch: 3 Idx: 5000 Loss: 0.006461002829827948
Epoch: 4 Idx: 0 Loss: 0.013338118753740708
Epoch: 4 Idx: 5000 Loss: 0.02592015277921595
Epoch: 5 Idx: 0 Loss: 0.025863696032289586
Epoch: 5 Idx: 5000 Loss: 0.010655022833376703
Epoch: 6 Idx: 0 Loss: 0.009115997079615242
Epoch: 6 Idx: 5000 Loss: 0.01222220963099764
Epoch: 7 Idx: 0 Loss: 0.023123136121761888
Epoch: 7 Idx: 5000 Loss: 0.012488688373799923
Epoch: 8 Idx: 0 Loss: 0.018989394611387357
Epoch: 8 Idx: 5000 Loss: 0.01532399674969757
Epoch: 9 Idx: 0 Loss: 0.007988213770713508
Epoch: 9 Idx: 5000 Loss: 0.02575394058123837
Epoch: 10 Idx: 0 Loss: 0.038290192118879636
Epoch: 10 Idx: 5000 Loss: 0.030242040135190454
Epoch: 11 Idx: 0 Loss: 0.007271298337243
Epoch: 11 Idx: 5000 Loss: 0.016860432292859336
Epoch: 12 Idx: 0 Loss: 0.0160756993579552
Epoch: 12 Idx: 5000 Loss: 0.02258928338008756
Epoch: 13 Idx: 0 Loss: 0.017170932099626016
Epoch: 13 Idx: 5000 Loss: 0.013646819741407534
Epoch: 14 Idx: 0 Loss: 0.008281050528866341
Epoch: 14 Idx: 5000 Loss: 0.006972067384530653
Epoch: 15 Idx: 0 Loss: 0.01576848286632873
Epoch: 15 Idx: 5000 Loss: 0.010903917357726486
Epoch: 16 Idx: 0 Loss: 0.019480820712904776
Epoch: 16 Idx: 5000 Loss: 0.031722681223986735
Epoch: 17 Idx: 0 Loss: 0.010603440747147117
Epoch: 17 Idx: 5000 Loss: 0.004103051587801326
Epoch: 18 Idx: 0 Loss: 0.013250012757109198
Epoch: 18 Idx: 5000 Loss: 0.018879291686553227
Epoch: 19 Idx: 0 Loss: 0.01517276111721458
Epoch: 19 Idx: 5000 Loss: 0.0074875457325774795
Epoch: 20 Idx: 0 Loss: 0.016205757032894057
Epoch: 20 Idx: 5000 Loss: 0.01843272658705077
Epoch: 21 Idx: 0 Loss: 0.021670323743441335
Epoch: 21 Idx: 5000 Loss: 0.014263755567047436
Epoch: 22 Idx: 0 Loss: 0.01233105976896012
Epoch: 22 Idx: 5000 Loss: 0.02769149159022683
Epoch: 23 Idx: 0 Loss: 0.015756452150608023
Epoch: 23 Idx: 5000 Loss: 0.012252289613972305
Epoch: 24 Idx: 0 Loss: 0.012275412596534935
Epoch: 24 Idx: 5000 Loss: 0.014008832112340032
Epoch: 25 Idx: 0 Loss: 0.010521731241074346
Epoch: 25 Idx: 5000 Loss: 0.023412648784890994
Epoch: 26 Idx: 0 Loss: 0.006130086442013301
Epoch: 26 Idx: 5000 Loss: 0.01227234792315296
Epoch: 27 Idx: 0 Loss: 0.01573544011775048
Epoch: 27 Idx: 5000 Loss: 0.011419285324374421
Epoch: 28 Idx: 0 Loss: 0.025409668040773076
Epoch: 28 Idx: 5000 Loss: 0.007932311694084856
Epoch: 29 Idx: 0 Loss: 0.014150012675436467
Epoch: 29 Idx: 5000 Loss: 0.008572602090260872
Epoch: 30 Idx: 0 Loss: 0.03302743842832082
Epoch: 30 Idx: 5000 Loss: 0.02383380826173588
Epoch: 31 Idx: 0 Loss: 0.017620698879258073
Epoch: 31 Idx: 5000 Loss: 0.012061332058204982
Epoch: 32 Idx: 0 Loss: 0.012206665773332827
Epoch: 32 Idx: 5000 Loss: 0.022677636171522186
Epoch: 33 Idx: 0 Loss: 0.014228307936881941
Epoch: 33 Idx: 5000 Loss: 0.015577754596606628
Epoch: 34 Idx: 0 Loss: 0.017677048919612286
Epoch: 34 Idx: 5000 Loss: 0.027857722984306315
Epoch: 35 Idx: 0 Loss: 0.01173995103609958
Epoch: 35 Idx: 5000 Loss: 0.028579625145800692
Epoch: 36 Idx: 0 Loss: 0.021273744350362923
Epoch: 36 Idx: 5000 Loss: 0.012643527724388325
Epoch: 37 Idx: 0 Loss: 0.030493998549190472
Epoch: 37 Idx: 5000 Loss: 0.03966966045818559
Epoch: 38 Idx: 0 Loss: 0.010559153265478393
Epoch: 38 Idx: 5000 Loss: 0.010715513133081857
Epoch: 39 Idx: 0 Loss: 0.01430521224017518
Epoch: 39 Idx: 5000 Loss: 0.01727188121915077
Epoch: 40 Idx: 0 Loss: 0.010096646140416027
Epoch: 40 Idx: 5000 Loss: 0.013536005197985247
Epoch: 41 Idx: 0 Loss: 0.015193119360669263
Epoch: 41 Idx: 5000 Loss: 0.009076973083119007
Epoch: 42 Idx: 0 Loss: 0.01138826232267166
Epoch: 42 Idx: 5000 Loss: 0.031343052371503546
Epoch: 43 Idx: 0 Loss: 0.02391540382772166
Epoch: 43 Idx: 5000 Loss: 0.027975925483102883
Epoch: 44 Idx: 0 Loss: 0.019240543671770968
Epoch: 44 Idx: 5000 Loss: 0.01700210066444362
Epoch: 45 Idx: 0 Loss: 0.008664462176366522
Epoch: 45 Idx: 5000 Loss: 0.028817544877202707
Epoch: 46 Idx: 0 Loss: 0.018900856726392905
Epoch: 46 Idx: 5000 Loss: 0.013128956816946999
Epoch: 47 Idx: 0 Loss: 0.019102486958130285
Epoch: 47 Idx: 5000 Loss: 0.012798459629766584
Epoch: 48 Idx: 0 Loss: 0.02605960408583744
Epoch: 48 Idx: 5000 Loss: 0.018870446446793664
Epoch: 49 Idx: 0 Loss: 0.010282514348583993
Epoch: 49 Idx: 5000 Loss: 0.033163275287418296
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.2283179916385236
Epoch: 1 Idx: 0 Loss: 0.020349239573950663
Epoch: 2 Idx: 0 Loss: 0.007020815469270064
Epoch: 3 Idx: 0 Loss: 0.021114483467550908
Epoch: 4 Idx: 0 Loss: 0.01829719113215702
Epoch: 5 Idx: 0 Loss: 0.005117520814846966
Epoch: 6 Idx: 0 Loss: 0.018593508588543688
Epoch: 7 Idx: 0 Loss: 0.012310763276377007
Epoch: 8 Idx: 0 Loss: 0.01577334061550987
Epoch: 9 Idx: 0 Loss: 0.017399888243688648
Epoch: 10 Idx: 0 Loss: 0.011211786585883916
Epoch: 11 Idx: 0 Loss: 0.006048303450705044
Epoch: 12 Idx: 0 Loss: 0.018725814862489292
Epoch: 13 Idx: 0 Loss: 0.0214108326994331
Epoch: 14 Idx: 0 Loss: 0.012812529065134887
Epoch: 15 Idx: 0 Loss: 0.01516574533252188
Epoch: 16 Idx: 0 Loss: 0.009084749411494737
Epoch: 17 Idx: 0 Loss: 0.017977308989696357
Epoch: 18 Idx: 0 Loss: 0.024922426168999156
Epoch: 19 Idx: 0 Loss: 0.01049967046282271
Epoch: 20 Idx: 0 Loss: 0.0064420261853309
Epoch: 21 Idx: 0 Loss: 0.015245321996530605
Epoch: 22 Idx: 0 Loss: 0.017800511256598685
Epoch: 23 Idx: 0 Loss: 0.014457075235980124
Epoch: 24 Idx: 0 Loss: 0.009333192626874555
Epoch: 25 Idx: 0 Loss: 0.008008969892437759
Epoch: 26 Idx: 0 Loss: 0.012184978248852823
Epoch: 27 Idx: 0 Loss: 0.019118722936914512
Epoch: 28 Idx: 0 Loss: 0.015165268388754292
Epoch: 29 Idx: 0 Loss: 0.017608719574856185
Epoch: 30 Idx: 0 Loss: 0.009416292733763907
Epoch: 31 Idx: 0 Loss: 0.022114707746997198
Epoch: 32 Idx: 0 Loss: 0.03450845050789918
Epoch: 33 Idx: 0 Loss: 0.008942709065490868
Epoch: 34 Idx: 0 Loss: 0.009289657275594637
Epoch: 35 Idx: 0 Loss: 0.005273519417203765
Epoch: 36 Idx: 0 Loss: 0.02707930602825338
Epoch: 37 Idx: 0 Loss: 0.016110018373215174
Epoch: 38 Idx: 0 Loss: 0.006836611155813488
Epoch: 39 Idx: 0 Loss: 0.0073712816964898115
Epoch: 40 Idx: 0 Loss: 0.0192602575690292
Epoch: 41 Idx: 0 Loss: 0.022739466939634204
Epoch: 42 Idx: 0 Loss: 0.012683506836630758
Epoch: 43 Idx: 0 Loss: 0.011412705424220033
Epoch: 44 Idx: 0 Loss: 0.009386831121938456
Epoch: 45 Idx: 0 Loss: 0.04631174511761913
Epoch: 46 Idx: 0 Loss: 0.006179137880317433
Epoch: 47 Idx: 0 Loss: 0.009737643475291824
Epoch: 48 Idx: 0 Loss: 0.016687491447370802
Epoch: 49 Idx: 0 Loss: 0.01010974933117414
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.15212186049139817
Epoch: 0 Idx: 5000 Loss: 0.013247771385995224
Epoch: 1 Idx: 0 Loss: 0.02211795260598888
Epoch: 1 Idx: 5000 Loss: 0.01527082312204244
Epoch: 2 Idx: 0 Loss: 0.018340174653377006
Epoch: 2 Idx: 5000 Loss: 0.019278513280323168
Epoch: 3 Idx: 0 Loss: 0.007641220382400216
Epoch: 3 Idx: 5000 Loss: 0.013691046938701858
Epoch: 4 Idx: 0 Loss: 0.020710890993506877
Epoch: 4 Idx: 5000 Loss: 0.009887553137033609
Epoch: 5 Idx: 0 Loss: 0.004864111015080471
Epoch: 5 Idx: 5000 Loss: 0.010744071717724856
Epoch: 6 Idx: 0 Loss: 0.017761855120577152
Epoch: 6 Idx: 5000 Loss: 0.01754064707246979
Epoch: 7 Idx: 0 Loss: 0.024731173652307967
Epoch: 7 Idx: 5000 Loss: 0.014347778400787404
Epoch: 8 Idx: 0 Loss: 0.008225693099205606
Epoch: 8 Idx: 5000 Loss: 0.0121865723825793
Epoch: 9 Idx: 0 Loss: 0.010521147367006283
Epoch: 9 Idx: 5000 Loss: 0.032918419050246214
Epoch: 10 Idx: 0 Loss: 0.026273570869058016
Epoch: 10 Idx: 5000 Loss: 0.010482964650909086
Epoch: 11 Idx: 0 Loss: 0.02620109302133759
Epoch: 11 Idx: 5000 Loss: 0.02470662719819921
Epoch: 12 Idx: 0 Loss: 0.02229482548422868
Epoch: 12 Idx: 5000 Loss: 0.009427912456207024
Epoch: 13 Idx: 0 Loss: 0.01923166303979724
Epoch: 13 Idx: 5000 Loss: 0.028822443981553016
Epoch: 14 Idx: 0 Loss: 0.013295248434200942
Epoch: 14 Idx: 5000 Loss: 0.02186127480933369
Epoch: 15 Idx: 0 Loss: 0.009843528026294998
Epoch: 15 Idx: 5000 Loss: 0.02396010090991771
Epoch: 16 Idx: 0 Loss: 0.031736413556799174
Epoch: 16 Idx: 5000 Loss: 0.01128034244933913
Epoch: 17 Idx: 0 Loss: 0.025846855761220908
Epoch: 17 Idx: 5000 Loss: 0.0116147351316045
Epoch: 18 Idx: 0 Loss: 0.010177945884770343
Epoch: 18 Idx: 5000 Loss: 0.010050526425616834
Epoch: 19 Idx: 0 Loss: 0.027461053555006755
Epoch: 19 Idx: 5000 Loss: 0.0040650873484666585
Epoch: 20 Idx: 0 Loss: 0.0067349959912451855
Epoch: 20 Idx: 5000 Loss: 0.028447978770273268
Epoch: 21 Idx: 0 Loss: 0.012836911616464039
Epoch: 21 Idx: 5000 Loss: 0.036904644909999965
Epoch: 22 Idx: 0 Loss: 0.017889021448933805
Epoch: 22 Idx: 5000 Loss: 0.005762309558721101
Epoch: 23 Idx: 0 Loss: 0.009586161284202933
Epoch: 23 Idx: 5000 Loss: 0.01183939827685955
Epoch: 24 Idx: 0 Loss: 0.016649733600808153
Epoch: 24 Idx: 5000 Loss: 0.01808083421872202
Epoch: 25 Idx: 0 Loss: 0.017867925545721922
Epoch: 25 Idx: 5000 Loss: 0.0217036257815447
Epoch: 26 Idx: 0 Loss: 0.01281102584474159
Epoch: 26 Idx: 5000 Loss: 0.01456521411509085
Epoch: 27 Idx: 0 Loss: 0.021867288046999105
Epoch: 27 Idx: 5000 Loss: 0.008536587862583794
Epoch: 28 Idx: 0 Loss: 0.016008486815220768
Epoch: 28 Idx: 5000 Loss: 0.013443172972115124
Epoch: 29 Idx: 0 Loss: 0.017769861872770618
Epoch: 29 Idx: 5000 Loss: 0.030173980064473527
Epoch: 30 Idx: 0 Loss: 0.030695122346430227
Epoch: 30 Idx: 5000 Loss: 0.023076153537220194
Epoch: 31 Idx: 0 Loss: 0.017387528365973758
Epoch: 31 Idx: 5000 Loss: 0.009171621590001181
Epoch: 32 Idx: 0 Loss: 0.010945818194073876
Epoch: 32 Idx: 5000 Loss: 0.00874875010832897
Epoch: 33 Idx: 0 Loss: 0.010292929802446244
Epoch: 33 Idx: 5000 Loss: 0.022768025543873093
Epoch: 34 Idx: 0 Loss: 0.01010341153650046
Epoch: 34 Idx: 5000 Loss: 0.008682958298448572
Epoch: 35 Idx: 0 Loss: 0.012057264994742608
Epoch: 35 Idx: 5000 Loss: 0.01306986994884272
Epoch: 36 Idx: 0 Loss: 0.016900104340917856
Epoch: 36 Idx: 5000 Loss: 0.017828191416369803
Epoch: 37 Idx: 0 Loss: 0.021435747299038133
Epoch: 37 Idx: 5000 Loss: 0.015084380072303859
Epoch: 38 Idx: 0 Loss: 0.014365610812900732
Epoch: 38 Idx: 5000 Loss: 0.020879305267591252
Epoch: 39 Idx: 0 Loss: 0.015506336880160995
Epoch: 39 Idx: 5000 Loss: 0.01816352099838602
Epoch: 40 Idx: 0 Loss: 0.0037818391107413804
Epoch: 40 Idx: 5000 Loss: 0.013747540305236207
Epoch: 41 Idx: 0 Loss: 0.014520437006278638
Epoch: 41 Idx: 5000 Loss: 0.01291335709996444
Epoch: 42 Idx: 0 Loss: 0.024711536373674604
Epoch: 42 Idx: 5000 Loss: 0.02601122608674128
Epoch: 43 Idx: 0 Loss: 0.01784766644271913
Epoch: 43 Idx: 5000 Loss: 0.016419446634494593
Epoch: 44 Idx: 0 Loss: 0.015471735401260962
Epoch: 44 Idx: 5000 Loss: 0.011074400956774606
Epoch: 45 Idx: 0 Loss: 0.03007560727177361
Epoch: 45 Idx: 5000 Loss: 0.014826932776439324
Epoch: 46 Idx: 0 Loss: 0.01565226509767699
Epoch: 46 Idx: 5000 Loss: 0.00783374329603275
Epoch: 47 Idx: 0 Loss: 0.010887386496078703
Epoch: 47 Idx: 5000 Loss: 0.01842254297384484
Epoch: 48 Idx: 0 Loss: 0.021144776598662346
Epoch: 48 Idx: 5000 Loss: 0.016168274227244366
Epoch: 49 Idx: 0 Loss: 0.014767782998817543
Epoch: 49 Idx: 5000 Loss: 0.029133035141339143
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.20938553491588432
Epoch: 1 Idx: 0 Loss: 0.01990282461232929
Epoch: 2 Idx: 0 Loss: 0.05561273117810951
Epoch: 3 Idx: 0 Loss: 0.009791058473330566
Epoch: 4 Idx: 0 Loss: 0.011107392766393378
Epoch: 5 Idx: 0 Loss: 0.013415371561922834
Epoch: 6 Idx: 0 Loss: 0.00966744461667206
Epoch: 7 Idx: 0 Loss: 0.005781828655728959
Epoch: 8 Idx: 0 Loss: 0.022178951785185474
Epoch: 9 Idx: 0 Loss: 0.010371376781261106
Epoch: 10 Idx: 0 Loss: 0.014727018411266566
Epoch: 11 Idx: 0 Loss: 0.015688217341250615
Epoch: 12 Idx: 0 Loss: 0.015918950266681074
Epoch: 13 Idx: 0 Loss: 0.013919368193037662
Epoch: 14 Idx: 0 Loss: 0.007819956505861031
Epoch: 15 Idx: 0 Loss: 0.025776806513932327
Epoch: 16 Idx: 0 Loss: 0.01076864510048163
Epoch: 17 Idx: 0 Loss: 0.025239194867539956
Epoch: 18 Idx: 0 Loss: 0.03405477081603532
Epoch: 19 Idx: 0 Loss: 0.0115176845592232
Epoch: 20 Idx: 0 Loss: 0.0059650534075919165
Epoch: 21 Idx: 0 Loss: 0.006677292231252099
Epoch: 22 Idx: 0 Loss: 0.014378202242811952
Epoch: 23 Idx: 0 Loss: 0.012606237804752968
Epoch: 24 Idx: 0 Loss: 0.018960380575344743
Epoch: 25 Idx: 0 Loss: 0.01594264517139605
Epoch: 26 Idx: 0 Loss: 0.027878016097728133
Epoch: 27 Idx: 0 Loss: 0.025018525405765126
Epoch: 28 Idx: 0 Loss: 0.007691060014645184
Epoch: 29 Idx: 0 Loss: 0.008497217017801982
Epoch: 30 Idx: 0 Loss: 0.008536803011848788
Epoch: 31 Idx: 0 Loss: 0.009362022089917562
Epoch: 32 Idx: 0 Loss: 0.03004528243403752
Epoch: 33 Idx: 0 Loss: 0.011793742614042292
Epoch: 34 Idx: 0 Loss: 0.008082750911856184
Epoch: 35 Idx: 0 Loss: 0.03403311074477249
Epoch: 36 Idx: 0 Loss: 0.015749766361617477
Epoch: 37 Idx: 0 Loss: 0.009815158872239778
Epoch: 38 Idx: 0 Loss: 0.017106292937794892
Epoch: 39 Idx: 0 Loss: 0.01389019520281716
Epoch: 40 Idx: 0 Loss: 0.016784908520310407
Epoch: 41 Idx: 0 Loss: 0.013815500631209288
Epoch: 42 Idx: 0 Loss: 0.01140562254674722
Epoch: 43 Idx: 0 Loss: 0.012938338945028272
Epoch: 44 Idx: 0 Loss: 0.04197835449960438
Epoch: 45 Idx: 0 Loss: 0.006033931928117162
Epoch: 46 Idx: 0 Loss: 0.01059370868432781
Epoch: 47 Idx: 0 Loss: 0.010668300919506556
Epoch: 48 Idx: 0 Loss: 0.011672213552090561
Epoch: 49 Idx: 0 Loss: 0.019732894954913816
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.6875, 0.7333333333333333, 0.7096774193548386, 0.7236842105263157, 0.6962025316455696)
Performance for  [('ekaw', 'sigkdd')] is : (0.8461538461538461, 1.0, 0.9166666666666666, 0.9649122807017543, 0.8730158730158731)
Performance for  [('conference', 'edas')] is : (0.9285714285714286, 0.7647058823529411, 0.8387096774193549, 0.7926829268292683, 0.8904109589041096)
Performance for  [('cmt', 'ekaw')] is : (0.5, 0.5454545454545454, 0.5217391304347826, 0.5357142857142857, 0.5084745762711864)
Performance for  [('confOf', 'edas')] is : (0.65, 0.6842105263157895, 0.6666666666666667, 0.6770833333333334, 0.6565656565656566)
Performance for  [('iasted', 'sigkdd')] is : (0.55, 0.7333333333333333, 0.6285714285714286, 0.6874999999999999, 0.5789473684210527)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.73746075 0.71665617 0.71375953 0.71304759 0.72366942]
Threshold:  0.895
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2b5c1dd1caf0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc268>
Subject: Job 4142729: <python main.py 5 2 False False> in cluster <dcc> Done

Job <python main.py 5 2 False False> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:25 2020
Job was executed on host(s) <dccxc268>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 09:21:32 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 09:21:32 2020
Terminated at Wed Sep 16 14:19:01 2020
Results reported at Wed Sep 16 14:19:01 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 2 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17840.52 sec.
    Max Memory :                                 4146 MB
    Average Memory :                             3989.44 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39271.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   17867 sec.
    Turnaround time :                            26436 sec.

The output (if any) is above this job summary.

