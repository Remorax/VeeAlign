2020-09-15 15:49:41.992089: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.186504: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.302890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1f:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.302986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.305171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.306796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.307234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.309273: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.310727: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.310940: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.310960: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.311289: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.318819: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599975000 Hz
2020-09-15 15:49:45.319009: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f1b2d36510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.319028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.320985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.321034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.2154403148142809
Epoch: 0 Idx: 5000 Loss: 0.009685242481776395
Epoch: 1 Idx: 0 Loss: 0.02711991305089024
Epoch: 1 Idx: 5000 Loss: 0.012611272686889975
Epoch: 2 Idx: 0 Loss: 0.02407134578521522
Epoch: 2 Idx: 5000 Loss: 0.019387501903449726
Epoch: 3 Idx: 0 Loss: 0.021627793244542004
Epoch: 3 Idx: 5000 Loss: 0.012315172879598792
Epoch: 4 Idx: 0 Loss: 0.013711825484291574
Epoch: 4 Idx: 5000 Loss: 0.025163364289916865
Epoch: 5 Idx: 0 Loss: 0.012568290210098382
Epoch: 5 Idx: 5000 Loss: 0.017130128748210256
Epoch: 6 Idx: 0 Loss: 0.00915155360319036
Epoch: 6 Idx: 5000 Loss: 0.015541343287770636
Epoch: 7 Idx: 0 Loss: 0.026227410408202846
Epoch: 7 Idx: 5000 Loss: 0.01326542726864273
Epoch: 8 Idx: 0 Loss: 0.004456810384101307
Epoch: 8 Idx: 5000 Loss: 0.00653015321519931
Epoch: 9 Idx: 0 Loss: 0.03380763310834063
Epoch: 9 Idx: 5000 Loss: 0.009369981312266885
Epoch: 10 Idx: 0 Loss: 0.0196020471803177
Epoch: 10 Idx: 5000 Loss: 0.016044597131739197
Epoch: 11 Idx: 0 Loss: 0.010425646417294997
Epoch: 11 Idx: 5000 Loss: 0.026959096098790443
Epoch: 12 Idx: 0 Loss: 0.006586505984042644
Epoch: 12 Idx: 5000 Loss: 0.005495904572072888
Epoch: 13 Idx: 0 Loss: 0.012092754333388554
Epoch: 13 Idx: 5000 Loss: 0.00772756550140423
Epoch: 14 Idx: 0 Loss: 0.0117579610880224
Epoch: 14 Idx: 5000 Loss: 0.012648537851378254
Epoch: 15 Idx: 0 Loss: 0.017308685903327486
Epoch: 15 Idx: 5000 Loss: 0.02874522857198478
Epoch: 16 Idx: 0 Loss: 0.012728310600895675
Epoch: 16 Idx: 5000 Loss: 0.027976265732457026
Epoch: 17 Idx: 0 Loss: 0.014603330927930844
Epoch: 17 Idx: 5000 Loss: 0.02154255347090248
Epoch: 18 Idx: 0 Loss: 0.010741015452981832
Epoch: 18 Idx: 5000 Loss: 0.022342720904479155
Epoch: 19 Idx: 0 Loss: 0.020149642008727302
Epoch: 19 Idx: 5000 Loss: 0.007209227728742149
Epoch: 20 Idx: 0 Loss: 0.006466925831288635
Epoch: 20 Idx: 5000 Loss: 0.010756764392575172
Epoch: 21 Idx: 0 Loss: 0.04784917083340369
Epoch: 21 Idx: 5000 Loss: 0.010604920287869989
Epoch: 22 Idx: 0 Loss: 0.017937960328939448
Epoch: 22 Idx: 5000 Loss: 0.012314133162719728
Epoch: 23 Idx: 0 Loss: 0.014898536631655022
Epoch: 23 Idx: 5000 Loss: 0.0381097254287424
Epoch: 24 Idx: 0 Loss: 0.011453455638197205
Epoch: 24 Idx: 5000 Loss: 0.02102978304266765
Epoch: 25 Idx: 0 Loss: 0.015790183830990887
Epoch: 25 Idx: 5000 Loss: 0.011582932074475683
Epoch: 26 Idx: 0 Loss: 0.0067591615836809105
Epoch: 26 Idx: 5000 Loss: 0.04327692220482016
Epoch: 27 Idx: 0 Loss: 0.008994737839385699
Epoch: 27 Idx: 5000 Loss: 0.02073962790464918
Epoch: 28 Idx: 0 Loss: 0.01047252993377059
Epoch: 28 Idx: 5000 Loss: 0.024090369224818754
Epoch: 29 Idx: 0 Loss: 0.007532571249432628
Epoch: 29 Idx: 5000 Loss: 0.019891338500282282
Epoch: 30 Idx: 0 Loss: 0.01261849929457913
Epoch: 30 Idx: 5000 Loss: 0.0110918260922136
Epoch: 31 Idx: 0 Loss: 0.01270234105534079
Epoch: 31 Idx: 5000 Loss: 0.02615248312514927
Epoch: 32 Idx: 0 Loss: 0.01938375757941951
Epoch: 32 Idx: 5000 Loss: 0.012170023107090068
Epoch: 33 Idx: 0 Loss: 0.0073663916705412336
Epoch: 33 Idx: 5000 Loss: 0.009501534201914776
Epoch: 34 Idx: 0 Loss: 0.021986287676984864
Epoch: 34 Idx: 5000 Loss: 0.011610927324237668
Epoch: 35 Idx: 0 Loss: 0.010561994016024064
Epoch: 35 Idx: 5000 Loss: 0.008744555348652566
Epoch: 36 Idx: 0 Loss: 0.022094023998587228
Epoch: 36 Idx: 5000 Loss: 0.010507251172672542
Epoch: 37 Idx: 0 Loss: 0.03570858562097709
Epoch: 37 Idx: 5000 Loss: 0.040219626860447354
Epoch: 38 Idx: 0 Loss: 0.013415052933585817
Epoch: 38 Idx: 5000 Loss: 0.016923248729700392
Epoch: 39 Idx: 0 Loss: 0.008954356809694562
Epoch: 39 Idx: 5000 Loss: 0.011592464672294007
Epoch: 40 Idx: 0 Loss: 0.004940345506284231
Epoch: 40 Idx: 5000 Loss: 0.01069622851681941
Epoch: 41 Idx: 0 Loss: 0.009057210830807025
Epoch: 41 Idx: 5000 Loss: 0.013895023807294116
Epoch: 42 Idx: 0 Loss: 0.02983805473340438
Epoch: 42 Idx: 5000 Loss: 0.01945249018856127
Epoch: 43 Idx: 0 Loss: 0.019205138604159483
Epoch: 43 Idx: 5000 Loss: 0.05944278805748342
Epoch: 44 Idx: 0 Loss: 0.011139244825146674
Epoch: 44 Idx: 5000 Loss: 0.01198972302436552
Epoch: 45 Idx: 0 Loss: 0.008256466360846131
Epoch: 45 Idx: 5000 Loss: 0.026203229760509976
Epoch: 46 Idx: 0 Loss: 0.00796039373442813
Epoch: 46 Idx: 5000 Loss: 0.007067217578242666
Epoch: 47 Idx: 0 Loss: 0.012331968668750097
Epoch: 47 Idx: 5000 Loss: 0.00782628465691047
Epoch: 48 Idx: 0 Loss: 0.0188309256951035
Epoch: 48 Idx: 5000 Loss: 0.0423217189419576
Epoch: 49 Idx: 0 Loss: 0.0047814224517213335
Epoch: 49 Idx: 5000 Loss: 0.016036749416895247
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1409402435717763
Epoch: 0 Idx: 5000 Loss: 0.017596157822235288
Epoch: 1 Idx: 0 Loss: 0.006123536626721146
Epoch: 1 Idx: 5000 Loss: 0.02163697942661321
Epoch: 2 Idx: 0 Loss: 0.015426258189231774
Epoch: 2 Idx: 5000 Loss: 0.012144840043022046
Epoch: 3 Idx: 0 Loss: 0.014727919139757326
Epoch: 3 Idx: 5000 Loss: 0.004531802184988003
Epoch: 4 Idx: 0 Loss: 0.010773596106256958
Epoch: 4 Idx: 5000 Loss: 0.04773589263587658
Epoch: 5 Idx: 0 Loss: 0.03922693175032934
Epoch: 5 Idx: 5000 Loss: 0.030090328307227368
Epoch: 6 Idx: 0 Loss: 0.012687432821943855
Epoch: 6 Idx: 5000 Loss: 0.016399863289706936
Epoch: 7 Idx: 0 Loss: 0.015580018083380444
Epoch: 7 Idx: 5000 Loss: 0.013217593751301358
Epoch: 8 Idx: 0 Loss: 0.005089787407036507
Epoch: 8 Idx: 5000 Loss: 0.018519012899187705
Epoch: 9 Idx: 0 Loss: 0.007564354144171738
Epoch: 9 Idx: 5000 Loss: 0.01420152721538057
Epoch: 10 Idx: 0 Loss: 0.009023159618658218
Epoch: 10 Idx: 5000 Loss: 0.014174491427761938
Epoch: 11 Idx: 0 Loss: 0.01857222811180988
Epoch: 11 Idx: 5000 Loss: 0.020800591355681308
Epoch: 12 Idx: 0 Loss: 0.013418323031737348
Epoch: 12 Idx: 5000 Loss: 0.010238787373972446
Epoch: 13 Idx: 0 Loss: 0.0056263692684733945
Epoch: 13 Idx: 5000 Loss: 0.007399387563349005
Epoch: 14 Idx: 0 Loss: 0.008403652228723706
Epoch: 14 Idx: 5000 Loss: 0.013158273119749918
Epoch: 15 Idx: 0 Loss: 0.04426606260180722
Epoch: 15 Idx: 5000 Loss: 0.010276955984901151
Epoch: 16 Idx: 0 Loss: 0.02442288983328711
Epoch: 16 Idx: 5000 Loss: 0.014704551483533224
Epoch: 17 Idx: 0 Loss: 0.013456843854901823
Epoch: 17 Idx: 5000 Loss: 0.017651606495831227
Epoch: 18 Idx: 0 Loss: 0.012091551452688242
Epoch: 18 Idx: 5000 Loss: 0.03622044741873147
Epoch: 19 Idx: 0 Loss: 0.050357317235652024
Epoch: 19 Idx: 5000 Loss: 0.007151774209628512
Epoch: 20 Idx: 0 Loss: 0.025567258936822473
Epoch: 20 Idx: 5000 Loss: 0.011230162980819426
Epoch: 21 Idx: 0 Loss: 0.02449480312293604
Epoch: 21 Idx: 5000 Loss: 0.006963135693352034
Epoch: 22 Idx: 0 Loss: 0.011779579590209557
Epoch: 22 Idx: 5000 Loss: 0.01671353790892182
Epoch: 23 Idx: 0 Loss: 0.020225307197131576
Epoch: 23 Idx: 5000 Loss: 0.008084841195156876
Epoch: 24 Idx: 0 Loss: 0.014018833797661055
Epoch: 24 Idx: 5000 Loss: 0.013054014469646323
Epoch: 25 Idx: 0 Loss: 0.017083674249408962
Epoch: 25 Idx: 5000 Loss: 0.019986928276132767
Epoch: 26 Idx: 0 Loss: 0.005703797316877368
Epoch: 26 Idx: 5000 Loss: 0.01390715331846635
Epoch: 27 Idx: 0 Loss: 0.03905234914777414
Epoch: 27 Idx: 5000 Loss: 0.009560347278442422
Epoch: 28 Idx: 0 Loss: 0.02838565666117842
Epoch: 28 Idx: 5000 Loss: 0.013776749579144477
Epoch: 29 Idx: 0 Loss: 0.026781993629111878
Epoch: 29 Idx: 5000 Loss: 0.03843964808250287
Epoch: 30 Idx: 0 Loss: 0.02728471382747303
Epoch: 30 Idx: 5000 Loss: 0.010434491132494256
Epoch: 31 Idx: 0 Loss: 0.008891292796644298
Epoch: 31 Idx: 5000 Loss: 0.006413948134008187
Epoch: 32 Idx: 0 Loss: 0.027423898302222704
Epoch: 32 Idx: 5000 Loss: 0.017612313831560703
Epoch: 33 Idx: 0 Loss: 0.007920277784700171
Epoch: 33 Idx: 5000 Loss: 0.010770672712897283
Epoch: 34 Idx: 0 Loss: 0.0072062718889668335
Epoch: 34 Idx: 5000 Loss: 0.011578656052639816
Epoch: 35 Idx: 0 Loss: 0.016715946620905264
Epoch: 35 Idx: 5000 Loss: 0.010335936083150655
Epoch: 36 Idx: 0 Loss: 0.012404176157753449
Epoch: 36 Idx: 5000 Loss: 0.007445612697462411
Epoch: 37 Idx: 0 Loss: 0.009201680638870653
Epoch: 37 Idx: 5000 Loss: 0.021043078701451202
Epoch: 38 Idx: 0 Loss: 0.02490689149880406
Epoch: 38 Idx: 5000 Loss: 0.009349196351927894
Epoch: 39 Idx: 0 Loss: 0.01846039453374132
Epoch: 39 Idx: 5000 Loss: 0.012531939374240283
Epoch: 40 Idx: 0 Loss: 0.019703992832180914
Epoch: 40 Idx: 5000 Loss: 0.02079194847181709
Epoch: 41 Idx: 0 Loss: 0.009243092359025516
Epoch: 41 Idx: 5000 Loss: 0.013315785243455397
Epoch: 42 Idx: 0 Loss: 0.014711291751103969
Epoch: 42 Idx: 5000 Loss: 0.014454174986692249
Epoch: 43 Idx: 0 Loss: 0.015601242994855092
Epoch: 43 Idx: 5000 Loss: 0.01098486110828935
Epoch: 44 Idx: 0 Loss: 0.019702038940337483
Epoch: 44 Idx: 5000 Loss: 0.02827934648478509
Epoch: 45 Idx: 0 Loss: 0.02703358588407983
Epoch: 45 Idx: 5000 Loss: 0.014743536468085652
Epoch: 46 Idx: 0 Loss: 0.008119495559153773
Epoch: 46 Idx: 5000 Loss: 0.007701830017533215
Epoch: 47 Idx: 0 Loss: 0.022167492815031588
Epoch: 47 Idx: 5000 Loss: 0.023567855093553483
Epoch: 48 Idx: 0 Loss: 0.02343292316242184
Epoch: 48 Idx: 5000 Loss: 0.0108324782085427
Epoch: 49 Idx: 0 Loss: 0.039935395307771515
Epoch: 49 Idx: 5000 Loss: 0.019698656085692108
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.12550431048198604
Epoch: 0 Idx: 5000 Loss: 0.018586116096659916
Epoch: 1 Idx: 0 Loss: 0.011448061174032954
Epoch: 1 Idx: 5000 Loss: 0.008875347986281003
Epoch: 2 Idx: 0 Loss: 0.03923464640714881
Epoch: 2 Idx: 5000 Loss: 0.009983509187141928
Epoch: 3 Idx: 0 Loss: 0.025049415486047402
Epoch: 3 Idx: 5000 Loss: 0.042405991396480325
Epoch: 4 Idx: 0 Loss: 0.012119370874900491
Epoch: 4 Idx: 5000 Loss: 0.015779212639198594
Epoch: 5 Idx: 0 Loss: 0.011270910667038093
Epoch: 5 Idx: 5000 Loss: 0.017837395483044957
Epoch: 6 Idx: 0 Loss: 0.02870110064171144
Epoch: 6 Idx: 5000 Loss: 0.010364086252759464
Epoch: 7 Idx: 0 Loss: 0.020750680315587897
Epoch: 7 Idx: 5000 Loss: 0.022541988693544682
Epoch: 8 Idx: 0 Loss: 0.010612211575398219
Epoch: 8 Idx: 5000 Loss: 0.02761659918822653
Epoch: 9 Idx: 0 Loss: 0.00994272763120567
Epoch: 9 Idx: 5000 Loss: 0.01680279411792787
Epoch: 10 Idx: 0 Loss: 0.0202707532932037
Epoch: 10 Idx: 5000 Loss: 0.013869262185818116
Epoch: 11 Idx: 0 Loss: 0.019774657521258794
Epoch: 11 Idx: 5000 Loss: 0.01389427933125901
Epoch: 12 Idx: 0 Loss: 0.01552781890994482
Epoch: 12 Idx: 5000 Loss: 0.014029279938524254
Epoch: 13 Idx: 0 Loss: 0.018690800017556172
Epoch: 13 Idx: 5000 Loss: 0.00985094501754706
Epoch: 14 Idx: 0 Loss: 0.02415658888791387
Epoch: 14 Idx: 5000 Loss: 0.019128673626486105
Epoch: 15 Idx: 0 Loss: 0.0161859090025348
Epoch: 15 Idx: 5000 Loss: 0.013040965115987171
Epoch: 16 Idx: 0 Loss: 0.010564297076111184
Epoch: 16 Idx: 5000 Loss: 0.011627713617512489
Epoch: 17 Idx: 0 Loss: 0.013067197583444125
Epoch: 17 Idx: 5000 Loss: 0.011088400445562575
Epoch: 18 Idx: 0 Loss: 0.014480729899603143
Epoch: 18 Idx: 5000 Loss: 0.015590087693735662
Epoch: 19 Idx: 0 Loss: 0.02331286867120968
Epoch: 19 Idx: 5000 Loss: 0.016892519540276135
Epoch: 20 Idx: 0 Loss: 0.008366016174212013
Epoch: 20 Idx: 5000 Loss: 0.0051932877617673475
Epoch: 21 Idx: 0 Loss: 0.016251867631556106
Epoch: 21 Idx: 5000 Loss: 0.01221231548804766
Epoch: 22 Idx: 0 Loss: 0.02221245172713228
Epoch: 22 Idx: 5000 Loss: 0.011419159392431329
Epoch: 23 Idx: 0 Loss: 0.029458081823393885
Epoch: 23 Idx: 5000 Loss: 0.00862217453329691
Epoch: 24 Idx: 0 Loss: 0.030440659795381984
Epoch: 24 Idx: 5000 Loss: 0.016659858060325106
Epoch: 25 Idx: 0 Loss: 0.012796096223646865
Epoch: 25 Idx: 5000 Loss: 0.004448685260435015
Epoch: 26 Idx: 0 Loss: 0.00895096136497682
Epoch: 26 Idx: 5000 Loss: 0.037356309758211234
Epoch: 27 Idx: 0 Loss: 0.024609743967386473
Epoch: 27 Idx: 5000 Loss: 0.008560303211405454
Epoch: 28 Idx: 0 Loss: 0.015964529641127607
Epoch: 28 Idx: 5000 Loss: 0.02281658508819971
Epoch: 29 Idx: 0 Loss: 0.024477136805399174
Epoch: 29 Idx: 5000 Loss: 0.013564968394297529
Epoch: 30 Idx: 0 Loss: 0.012809403714826067
Epoch: 30 Idx: 5000 Loss: 0.010295850244355595
Epoch: 31 Idx: 0 Loss: 0.01577697502354227
Epoch: 31 Idx: 5000 Loss: 0.017241194766244014
Epoch: 32 Idx: 0 Loss: 0.009333600396066673
Epoch: 32 Idx: 5000 Loss: 0.012004962918597133
Epoch: 33 Idx: 0 Loss: 0.006786892921042771
Epoch: 33 Idx: 5000 Loss: 0.011772166868421136
Epoch: 34 Idx: 0 Loss: 0.042663500033666424
Epoch: 34 Idx: 5000 Loss: 0.011768493503143535
Epoch: 35 Idx: 0 Loss: 0.01180557342377185
Epoch: 35 Idx: 5000 Loss: 0.00831257075228202
Epoch: 36 Idx: 0 Loss: 0.01314250185315223
Epoch: 36 Idx: 5000 Loss: 0.010418659222778553
Epoch: 37 Idx: 0 Loss: 0.012566499210266459
Epoch: 37 Idx: 5000 Loss: 0.024887134271814854
Epoch: 38 Idx: 0 Loss: 0.012501999077224352
Epoch: 38 Idx: 5000 Loss: 0.02174800489174279
Epoch: 39 Idx: 0 Loss: 0.012645279652642796
Epoch: 39 Idx: 5000 Loss: 0.0074092760111977895
Epoch: 40 Idx: 0 Loss: 0.040616638165296155
Epoch: 40 Idx: 5000 Loss: 0.038670115115021275
Epoch: 41 Idx: 0 Loss: 0.014244866217334012
Epoch: 41 Idx: 5000 Loss: 0.008746712588403482
Epoch: 42 Idx: 0 Loss: 0.005908213790529552
Traceback (most recent call last):
  File "main.py", line 518, in <module>
    optimizer.step()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/adam.py", line 107, in step
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc239>
Subject: Job 4066903: <python main.py 20 2 True False> in cluster <dcc> Exited

Job <python main.py 20 2 True False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc239>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 20 2 True False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46021.07 sec.
    Max Memory :                                 2882 MB
    Average Memory :                             2688.81 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40535.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46168 sec.
    Turnaround time :                            46199 sec.

The output (if any) is above this job summary.

