2020-09-16 07:37:38.165991: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:49.641943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:37:49.758686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1f:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:37:49.758775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:49.760710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:37:49.762159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:37:49.763014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:37:49.764899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:37:49.766278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:37:49.766431: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib
2020-09-16 07:37:49.766453: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:37:49.766865: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:37:49.816420: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599830000 Hz
2020-09-16 07:37:49.816689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564a1f7746e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:37:49.816712: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:37:49.820160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:37:49.820219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/naveen9/arvind/VeeAlign/
Ontologies being aligned are:  [('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1868394843956858
Epoch: 0 Idx: 5000 Loss: 0.00858662079639462
Epoch: 1 Idx: 0 Loss: 0.01842984375477172
Epoch: 1 Idx: 5000 Loss: 0.016406665533814067
Epoch: 2 Idx: 0 Loss: 0.005015323896964855
Epoch: 2 Idx: 5000 Loss: 0.012195709412783008
Epoch: 3 Idx: 0 Loss: 0.017714439710083185
Epoch: 3 Idx: 5000 Loss: 0.012768953914244787
Epoch: 4 Idx: 0 Loss: 0.013999328698322077
Epoch: 4 Idx: 5000 Loss: 0.010687269424551945
Epoch: 5 Idx: 0 Loss: 0.015720326143293602
Epoch: 5 Idx: 5000 Loss: 0.03182929763657349
Epoch: 6 Idx: 0 Loss: 0.02215253854532854
Epoch: 6 Idx: 5000 Loss: 0.00672100071891734
Epoch: 7 Idx: 0 Loss: 0.0052671744172139035
Epoch: 7 Idx: 5000 Loss: 0.010472000815531278
Epoch: 8 Idx: 0 Loss: 0.021911703615334625
Epoch: 8 Idx: 5000 Loss: 0.007691241427914894
Epoch: 9 Idx: 0 Loss: 0.013917764250797108
Epoch: 9 Idx: 5000 Loss: 0.014602514328685387
Epoch: 10 Idx: 0 Loss: 0.013409890026208886
Epoch: 10 Idx: 5000 Loss: 0.010408093839937465
Epoch: 11 Idx: 0 Loss: 0.01130419775803457
Epoch: 11 Idx: 5000 Loss: 0.019285817357332993
Epoch: 12 Idx: 0 Loss: 0.012304121263368686
Epoch: 12 Idx: 5000 Loss: 0.028906721677305316
Epoch: 13 Idx: 0 Loss: 0.013089059369658821
Epoch: 13 Idx: 5000 Loss: 0.010475544768642018
Epoch: 14 Idx: 0 Loss: 0.017200708214421313
Epoch: 14 Idx: 5000 Loss: 0.012643022233220438
Epoch: 15 Idx: 0 Loss: 0.012852676881177336
Epoch: 15 Idx: 5000 Loss: 0.010394680963456686
Epoch: 16 Idx: 0 Loss: 0.013203818678328066
Epoch: 16 Idx: 5000 Loss: 0.012493523946519059
Epoch: 17 Idx: 0 Loss: 0.041144283322566415
Epoch: 17 Idx: 5000 Loss: 0.021015164018708204
Epoch: 18 Idx: 0 Loss: 0.03226137501002554
Epoch: 18 Idx: 5000 Loss: 0.010575253692214286
Epoch: 19 Idx: 0 Loss: 0.019966761127609093
Epoch: 19 Idx: 5000 Loss: 0.009750962184211703
Epoch: 20 Idx: 0 Loss: 0.0074545073226916616
Epoch: 20 Idx: 5000 Loss: 0.008529416448360284
Epoch: 21 Idx: 0 Loss: 0.01447787535638946
Epoch: 21 Idx: 5000 Loss: 0.013908229910356076
Epoch: 22 Idx: 0 Loss: 0.014330676028735266
Epoch: 22 Idx: 5000 Loss: 0.020963878433833755
Epoch: 23 Idx: 0 Loss: 0.013851658534320502
Epoch: 23 Idx: 5000 Loss: 0.014290270996434252
Epoch: 24 Idx: 0 Loss: 0.010956037849191743
Epoch: 24 Idx: 5000 Loss: 0.03797958773467712
Epoch: 25 Idx: 0 Loss: 0.01835524382962677
Epoch: 25 Idx: 5000 Loss: 0.019701741007504197
Epoch: 26 Idx: 0 Loss: 0.010364934247687838
Epoch: 26 Idx: 5000 Loss: 0.017908127030987698
Epoch: 27 Idx: 0 Loss: 0.009446804140550888
Epoch: 27 Idx: 5000 Loss: 0.01795706476556612
Epoch: 28 Idx: 0 Loss: 0.026474597716024402
Epoch: 28 Idx: 5000 Loss: 0.022933263109845024
Epoch: 29 Idx: 0 Loss: 0.03877840110926087
Epoch: 29 Idx: 5000 Loss: 0.011364313505535826
Epoch: 30 Idx: 0 Loss: 0.012875994468877827
Epoch: 30 Idx: 5000 Loss: 0.012402192961133592
Epoch: 31 Idx: 0 Loss: 0.01724112150686029
Epoch: 31 Idx: 5000 Loss: 0.022496389931588402
Epoch: 32 Idx: 0 Loss: 0.01330089955728802
Epoch: 32 Idx: 5000 Loss: 0.014862418930771993
Epoch: 33 Idx: 0 Loss: 0.01900817541684369
Epoch: 33 Idx: 5000 Loss: 0.006210809235713646
Epoch: 34 Idx: 0 Loss: 0.02639434042678838
Epoch: 34 Idx: 5000 Loss: 0.028348514511435167
Epoch: 35 Idx: 0 Loss: 0.007202143876556913
Epoch: 35 Idx: 5000 Loss: 0.01912191385643398
Epoch: 36 Idx: 0 Loss: 0.01984578582720992
Epoch: 36 Idx: 5000 Loss: 0.008823464879894171
Epoch: 37 Idx: 0 Loss: 0.010845846440493856
Epoch: 37 Idx: 5000 Loss: 0.01367191025282934
Epoch: 38 Idx: 0 Loss: 0.02553803863426513
Epoch: 38 Idx: 5000 Loss: 0.02246160426505932
Epoch: 39 Idx: 0 Loss: 0.030499961692473952
Epoch: 39 Idx: 5000 Loss: 0.007852855646484247
Epoch: 40 Idx: 0 Loss: 0.013093821456094983
Epoch: 40 Idx: 5000 Loss: 0.007532677973208422
Epoch: 41 Idx: 0 Loss: 0.016144478337159637
Epoch: 41 Idx: 5000 Loss: 0.028439406043169968
Epoch: 42 Idx: 0 Loss: 0.01219365917244235
Epoch: 42 Idx: 5000 Loss: 0.011976018144582452
Epoch: 43 Idx: 0 Loss: 0.02636568007743202
Epoch: 43 Idx: 5000 Loss: 0.021627874642057197
Epoch: 44 Idx: 0 Loss: 0.01036735553128313
Epoch: 44 Idx: 5000 Loss: 0.015175032277638986
Epoch: 45 Idx: 0 Loss: 0.010388908613494724
Epoch: 45 Idx: 5000 Loss: 0.014117998148592803
Epoch: 46 Idx: 0 Loss: 0.005797483639055601
Epoch: 46 Idx: 5000 Loss: 0.030435955337960802
Epoch: 47 Idx: 0 Loss: 0.02088842463838263
Epoch: 47 Idx: 5000 Loss: 0.01626275483238676
Epoch: 48 Idx: 0 Loss: 0.014877305815373467
Epoch: 48 Idx: 5000 Loss: 0.015011475054198638
Epoch: 49 Idx: 0 Loss: 0.011997574539095486
Epoch: 49 Idx: 5000 Loss: 0.017685836236455702
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.22356012313609086
Epoch: 0 Idx: 5000 Loss: 0.012298039018644931
Epoch: 1 Idx: 0 Loss: 0.015445225586446716
Epoch: 1 Idx: 5000 Loss: 0.02091626219686419
Epoch: 2 Idx: 0 Loss: 0.01281388600998109
Epoch: 2 Idx: 5000 Loss: 0.008608990455587582
Epoch: 3 Idx: 0 Loss: 0.01167543728496283
Epoch: 3 Idx: 5000 Loss: 0.04622929499956867
Epoch: 4 Idx: 0 Loss: 0.014973509612429558
Epoch: 4 Idx: 5000 Loss: 0.02493404064936807
Epoch: 5 Idx: 0 Loss: 0.016066858521353686
Epoch: 5 Idx: 5000 Loss: 0.013140993151955967
Epoch: 6 Idx: 0 Loss: 0.0068996053181231325
Epoch: 6 Idx: 5000 Loss: 0.023032413738505654
Epoch: 7 Idx: 0 Loss: 0.00920662462220806
Epoch: 7 Idx: 5000 Loss: 0.014022700001791585
Epoch: 8 Idx: 0 Loss: 0.008071843886757708
Epoch: 8 Idx: 5000 Loss: 0.010027112057530235
Epoch: 9 Idx: 0 Loss: 0.008826743495153447
Epoch: 9 Idx: 5000 Loss: 0.009353315071613823
Epoch: 10 Idx: 0 Loss: 0.011058877750612229
Epoch: 10 Idx: 5000 Loss: 0.02067118524447342
Epoch: 11 Idx: 0 Loss: 0.010376878725682742
Epoch: 11 Idx: 5000 Loss: 0.006514064248692218
Epoch: 12 Idx: 0 Loss: 0.01745188446605926
Epoch: 12 Idx: 5000 Loss: 0.014190463465550978
Epoch: 13 Idx: 0 Loss: 0.00916361269092869
Epoch: 13 Idx: 5000 Loss: 0.011070025131954563
Epoch: 14 Idx: 0 Loss: 0.013974213908982923
Epoch: 14 Idx: 5000 Loss: 0.023757867899330175
Epoch: 15 Idx: 0 Loss: 0.010477689133108831
Epoch: 15 Idx: 5000 Loss: 0.02388245820468423
Epoch: 16 Idx: 0 Loss: 0.006634472447388255
Epoch: 16 Idx: 5000 Loss: 0.01540473676293172
Epoch: 17 Idx: 0 Loss: 0.01260624845354253
Epoch: 17 Idx: 5000 Loss: 0.029268478134158366
Epoch: 18 Idx: 0 Loss: 0.013105188179813414
Epoch: 18 Idx: 5000 Loss: 0.015137517041453535
Epoch: 19 Idx: 0 Loss: 0.010360071890206757
Epoch: 19 Idx: 5000 Loss: 0.01320250281391719
Epoch: 20 Idx: 0 Loss: 0.020344673757588954
Epoch: 20 Idx: 5000 Loss: 0.01629991065784165
Epoch: 21 Idx: 0 Loss: 0.0124189048839501
Epoch: 21 Idx: 5000 Loss: 0.01584236341744712
Epoch: 22 Idx: 0 Loss: 0.00618827198615864
Epoch: 22 Idx: 5000 Loss: 0.051903283614754804
Epoch: 23 Idx: 0 Loss: 0.013716709449666752
Epoch: 23 Idx: 5000 Loss: 0.013242329708448816
Epoch: 24 Idx: 0 Loss: 0.011888434234348797
Epoch: 24 Idx: 5000 Loss: 0.012173772096649386
Epoch: 25 Idx: 0 Loss: 0.015319469810382447
Epoch: 25 Idx: 5000 Loss: 0.006590027373975068
Epoch: 26 Idx: 0 Loss: 0.023117342688109
Epoch: 26 Idx: 5000 Loss: 0.009655388134933328
Epoch: 27 Idx: 0 Loss: 0.028710875465591985
Epoch: 27 Idx: 5000 Loss: 0.004279603271280108
Epoch: 28 Idx: 0 Loss: 0.012199103491096824
Epoch: 28 Idx: 5000 Loss: 0.01402432715255745
Epoch: 29 Idx: 0 Loss: 0.012372030152042102
Epoch: 29 Idx: 5000 Loss: 0.02222323198531484
Epoch: 30 Idx: 0 Loss: 0.019294624819248103
Epoch: 30 Idx: 5000 Loss: 0.01331293785936671
Epoch: 31 Idx: 0 Loss: 0.012438225478840463
Epoch: 31 Idx: 5000 Loss: 0.017089734673361518
Epoch: 32 Idx: 0 Loss: 0.011596603402958969
Epoch: 32 Idx: 5000 Loss: 0.0185137091382348
Epoch: 33 Idx: 0 Loss: 0.011698193040870605
Epoch: 33 Idx: 5000 Loss: 0.013101681596508544
Epoch: 34 Idx: 0 Loss: 0.00898800118590521
Epoch: 34 Idx: 5000 Loss: 0.009067168944994377
Epoch: 35 Idx: 0 Loss: 0.012899264144280085
Epoch: 35 Idx: 5000 Loss: 0.006798044374985089
Epoch: 36 Idx: 0 Loss: 0.0055114864537184356
Epoch: 36 Idx: 5000 Loss: 0.01734221333505614
Epoch: 37 Idx: 0 Loss: 0.01717071895596932
Epoch: 37 Idx: 5000 Loss: 0.010781449575192259
Epoch: 38 Idx: 0 Loss: 0.013496399245498046
Epoch: 38 Idx: 5000 Loss: 0.03230982110218976
Epoch: 39 Idx: 0 Loss: 0.016843452332066244
Epoch: 39 Idx: 5000 Loss: 0.018778827882628725
Epoch: 40 Idx: 0 Loss: 0.018113540040307363
Epoch: 40 Idx: 5000 Loss: 0.012692194643053354
Epoch: 41 Idx: 0 Loss: 0.018658851160679942
Epoch: 41 Idx: 5000 Loss: 0.022548895336366635
Epoch: 42 Idx: 0 Loss: 0.018560394604037543
Epoch: 42 Idx: 5000 Loss: 0.014903372209598649
Epoch: 43 Idx: 0 Loss: 0.017332598342474446
Epoch: 43 Idx: 5000 Loss: 0.034948788611891844
Epoch: 44 Idx: 0 Loss: 0.03523848336231729
Epoch: 44 Idx: 5000 Loss: 0.01056595017552877
Epoch: 45 Idx: 0 Loss: 0.01792872690543823
Epoch: 45 Idx: 5000 Loss: 0.02942295388115721
Epoch: 46 Idx: 0 Loss: 0.030682152252985363
Epoch: 46 Idx: 5000 Loss: 0.008580751028557258
Epoch: 47 Idx: 0 Loss: 0.021196530824281506
Epoch: 47 Idx: 5000 Loss: 0.018336528312278395
Epoch: 48 Idx: 0 Loss: 0.028166068697224392
Epoch: 48 Idx: 5000 Loss: 0.01340042008820321
Epoch: 49 Idx: 0 Loss: 0.014001286906311203
Epoch: 49 Idx: 5000 Loss: 0.03379945153579406
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.1565816587882621
Epoch: 0 Idx: 5000 Loss: 0.01292946611371082
Epoch: 1 Idx: 0 Loss: 0.016191147216431195
Epoch: 1 Idx: 5000 Loss: 0.009784386929501367
Epoch: 2 Idx: 0 Loss: 0.008623749478495864
Epoch: 2 Idx: 5000 Loss: 0.041193474895678366
Epoch: 3 Idx: 0 Loss: 0.022815832933700868
Epoch: 3 Idx: 5000 Loss: 0.016396321494968478
Epoch: 4 Idx: 0 Loss: 0.02110168928687689
Epoch: 4 Idx: 5000 Loss: 0.009057996037978147
Epoch: 5 Idx: 0 Loss: 0.007866676964105156
Epoch: 5 Idx: 5000 Loss: 0.010744443023371186
Epoch: 6 Idx: 0 Loss: 0.028920356803182785
Epoch: 6 Idx: 5000 Loss: 0.012055409926184276
Epoch: 7 Idx: 0 Loss: 0.007989895451854169
Epoch: 7 Idx: 5000 Loss: 0.01077116621605716
Epoch: 8 Idx: 0 Loss: 0.02059903522368425
Epoch: 8 Idx: 5000 Loss: 0.02527208715639912
Epoch: 9 Idx: 0 Loss: 0.008188403778304373
Epoch: 9 Idx: 5000 Loss: 0.005753895399616714
Epoch: 10 Idx: 0 Loss: 0.022509887769914017
Epoch: 10 Idx: 5000 Loss: 0.03337368910893206
Epoch: 11 Idx: 0 Loss: 0.018863600697330882
Epoch: 11 Idx: 5000 Loss: 0.010579546978986628
Epoch: 12 Idx: 0 Loss: 0.009783301929892452
Epoch: 12 Idx: 5000 Loss: 0.017387756993567545
Epoch: 13 Idx: 0 Loss: 0.014816451713423865
Epoch: 13 Idx: 5000 Loss: 0.011981634447209396
Epoch: 14 Idx: 0 Loss: 0.020272727491320176
Epoch: 14 Idx: 5000 Loss: 0.011484515680939953
Epoch: 15 Idx: 0 Loss: 0.010607732407118636
Epoch: 15 Idx: 5000 Loss: 0.010126955140452877
Epoch: 16 Idx: 0 Loss: 0.019170543198049207
Epoch: 16 Idx: 5000 Loss: 0.011351749750342211
Epoch: 17 Idx: 0 Loss: 0.01303293290888425
Epoch: 17 Idx: 5000 Loss: 0.009900344602030693
Epoch: 18 Idx: 0 Loss: 0.009806721856894936
Epoch: 18 Idx: 5000 Loss: 0.022400135767790277
Epoch: 19 Idx: 0 Loss: 0.009940108463641135
Epoch: 19 Idx: 5000 Loss: 0.0159485826474846
Epoch: 20 Idx: 0 Loss: 0.0431268200200155
Epoch: 20 Idx: 5000 Loss: 0.014556417070129887
Epoch: 21 Idx: 0 Loss: 0.027503872150786944
Epoch: 21 Idx: 5000 Loss: 0.008072032270885808
Epoch: 22 Idx: 0 Loss: 0.009031331175908278
Epoch: 22 Idx: 5000 Loss: 0.012460075583837233
Epoch: 23 Idx: 0 Loss: 0.02175268878046112
Epoch: 23 Idx: 5000 Loss: 0.012185397531436914
Epoch: 24 Idx: 0 Loss: 0.01024479796055804
Epoch: 24 Idx: 5000 Loss: 0.016057096446200247
Epoch: 25 Idx: 0 Loss: 0.010282521576134167
Epoch: 25 Idx: 5000 Loss: 0.03031427451247579
Epoch: 26 Idx: 0 Loss: 0.03119515830974358
Epoch: 26 Idx: 5000 Loss: 0.024654617304745427
Epoch: 27 Idx: 0 Loss: 0.03809625922241235
Epoch: 27 Idx: 5000 Loss: 0.01513084264829219
Epoch: 28 Idx: 0 Loss: 0.018710862481171216
Epoch: 28 Idx: 5000 Loss: 0.020195257724849057
Epoch: 29 Idx: 0 Loss: 0.011053183533803732
Epoch: 29 Idx: 5000 Loss: 0.011350454648501217
Epoch: 30 Idx: 0 Loss: 0.005688907259719315
Epoch: 30 Idx: 5000 Loss: 0.02393632069334729
Epoch: 31 Idx: 0 Loss: 0.01741782351389807
Epoch: 31 Idx: 5000 Loss: 0.019408111275848884
Epoch: 32 Idx: 0 Loss: 0.01878766089579351
Epoch: 32 Idx: 5000 Loss: 0.0196035068375724
Epoch: 33 Idx: 0 Loss: 0.007987395420722063
Epoch: 33 Idx: 5000 Loss: 0.015904228273498966
Epoch: 34 Idx: 0 Loss: 0.012193481150154187
Epoch: 34 Idx: 5000 Loss: 0.02112345470788179
Epoch: 35 Idx: 0 Loss: 0.017357841756401364
Epoch: 35 Idx: 5000 Loss: 0.005279822344708285
Epoch: 36 Idx: 0 Loss: 0.017664578762910332
Epoch: 36 Idx: 5000 Loss: 0.012449801176681447
Epoch: 37 Idx: 0 Loss: 0.015512420164585395
Epoch: 37 Idx: 5000 Loss: 0.008791984972454082
Epoch: 38 Idx: 0 Loss: 0.013766688802897284
Epoch: 38 Idx: 5000 Loss: 0.015744895520300936
Epoch: 39 Idx: 0 Loss: 0.01600307452508855
Epoch: 39 Idx: 5000 Loss: 0.011927573369213653
Epoch: 40 Idx: 0 Loss: 0.007444110298666092
Epoch: 40 Idx: 5000 Loss: 0.011491546653337358
Epoch: 41 Idx: 0 Loss: 0.018082406301505226
Epoch: 41 Idx: 5000 Loss: 0.008389832042381291
Epoch: 42 Idx: 0 Loss: 0.016590265689810722
Epoch: 42 Idx: 5000 Loss: 0.011415028624430997
Epoch: 43 Idx: 0 Loss: 0.02443083818584582
Epoch: 43 Idx: 5000 Loss: 0.006799146379851259
Epoch: 44 Idx: 0 Loss: 0.009466162047880103
Epoch: 44 Idx: 5000 Loss: 0.009621148429148576
Epoch: 45 Idx: 0 Loss: 0.01987913940487853
Epoch: 45 Idx: 5000 Loss: 0.007741880739061329
Epoch: 46 Idx: 0 Loss: 0.023712546794206188
Epoch: 46 Idx: 5000 Loss: 0.015587934586098914
Epoch: 47 Idx: 0 Loss: 0.01104463784886426
Epoch: 47 Idx: 5000 Loss: 0.021980861949492236
Epoch: 48 Idx: 0 Loss: 0.015657036598773388
Epoch: 48 Idx: 5000 Loss: 0.02444851440723432
Epoch: 49 Idx: 0 Loss: 0.010045463926529165
Epoch: 49 Idx: 5000 Loss: 0.011356570105266342
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.2044283547901776
Epoch: 0 Idx: 5000 Loss: 0.032000531822214046
Epoch: 1 Idx: 0 Loss: 0.024104868094070295
Epoch: 1 Idx: 5000 Loss: 0.03207300105623183
Epoch: 2 Idx: 0 Loss: 0.013712967443238789
Epoch: 2 Idx: 5000 Loss: 0.01969846016170488
Epoch: 3 Idx: 0 Loss: 0.021646933287603035
Epoch: 3 Idx: 5000 Loss: 0.012969246885233219
Epoch: 4 Idx: 0 Loss: 0.0084615955380333
Epoch: 4 Idx: 5000 Loss: 0.009575498862985839
Epoch: 5 Idx: 0 Loss: 0.019142144152033188
Epoch: 5 Idx: 5000 Loss: 0.008438423620436744
Epoch: 6 Idx: 0 Loss: 0.009323679590761831
Epoch: 6 Idx: 5000 Loss: 0.02022217413740236
Epoch: 7 Idx: 0 Loss: 0.02568035366721297
Epoch: 7 Idx: 5000 Loss: 0.019726366005473076
Epoch: 8 Idx: 0 Loss: 0.016533404290555852
Epoch: 8 Idx: 5000 Loss: 0.009320771640793478
Epoch: 9 Idx: 0 Loss: 0.01678671030010641
Epoch: 9 Idx: 5000 Loss: 0.008123916039864912
Epoch: 10 Idx: 0 Loss: 0.04691249881335712
Epoch: 10 Idx: 5000 Loss: 0.013767389498740968
Epoch: 11 Idx: 0 Loss: 0.013194066675090484
Epoch: 11 Idx: 5000 Loss: 0.03177334771335165
Epoch: 12 Idx: 0 Loss: 0.03921875498836313
Epoch: 12 Idx: 5000 Loss: 0.020368262519838316
Epoch: 13 Idx: 0 Loss: 0.012057113656826258
Epoch: 13 Idx: 5000 Loss: 0.022854154922156988
Epoch: 14 Idx: 0 Loss: 0.02040255928970229
Epoch: 14 Idx: 5000 Loss: 0.013635128358928758
Epoch: 15 Idx: 0 Loss: 0.010729911874593368
Epoch: 15 Idx: 5000 Loss: 0.013444914288101878
Epoch: 16 Idx: 0 Loss: 0.01131099018618207
Epoch: 16 Idx: 5000 Loss: 0.019686103932432863
Epoch: 17 Idx: 0 Loss: 0.007789124333919879
Epoch: 17 Idx: 5000 Loss: 0.005669552285079235
Epoch: 18 Idx: 0 Loss: 0.008737447237544615
Epoch: 18 Idx: 5000 Loss: 0.019825607873093516
Epoch: 19 Idx: 0 Loss: 0.019971683915987963
Epoch: 19 Idx: 5000 Loss: 0.015871622550796917
Epoch: 20 Idx: 0 Loss: 0.018808680021928106
Epoch: 20 Idx: 5000 Loss: 0.02414658705045932
Epoch: 21 Idx: 0 Loss: 0.023691992168212595
Epoch: 21 Idx: 5000 Loss: 0.00967599493669797
Epoch: 22 Idx: 0 Loss: 0.03279922337138861
Epoch: 22 Idx: 5000 Loss: 0.018662652010810247
Epoch: 23 Idx: 0 Loss: 0.02663535796341481
Epoch: 23 Idx: 5000 Loss: 0.019722856668939515
Epoch: 24 Idx: 0 Loss: 0.014278800774312556
Epoch: 24 Idx: 5000 Loss: 0.031827806003286614
Epoch: 25 Idx: 0 Loss: 0.01708534386788133
Epoch: 25 Idx: 5000 Loss: 0.046604578076465494
Epoch: 26 Idx: 0 Loss: 0.013252257069829451
Epoch: 26 Idx: 5000 Loss: 0.01890440064380748
Epoch: 27 Idx: 0 Loss: 0.014069438721982625
Epoch: 27 Idx: 5000 Loss: 0.013117165483946678
Epoch: 28 Idx: 0 Loss: 0.01042682072412774
Epoch: 28 Idx: 5000 Loss: 0.007023929873362509
Epoch: 29 Idx: 0 Loss: 0.01223976204991396
Epoch: 29 Idx: 5000 Loss: 0.012819697979997945
Epoch: 30 Idx: 0 Loss: 0.015721647363392544
Epoch: 30 Idx: 5000 Loss: 0.030647411674900777
Epoch: 31 Idx: 0 Loss: 0.009940294684566978
Epoch: 31 Idx: 5000 Loss: 0.019730385304348886
Epoch: 32 Idx: 0 Loss: 0.025476741913950142
Epoch: 32 Idx: 5000 Loss: 0.011568197503993207
Epoch: 33 Idx: 0 Loss: 0.014406041667759547
Epoch: 33 Idx: 5000 Loss: 0.017972446688853554
Epoch: 34 Idx: 0 Loss: 0.019603571810711186
Epoch: 34 Idx: 5000 Loss: 0.021694517747537514
Epoch: 35 Idx: 0 Loss: 0.011804969712004072
Epoch: 35 Idx: 5000 Loss: 0.006689937097928734
Epoch: 36 Idx: 0 Loss: 0.013234725447755984
Epoch: 36 Idx: 5000 Loss: 0.012279890709785916
Epoch: 37 Idx: 0 Loss: 0.012709573184736306
Epoch: 37 Idx: 5000 Loss: 0.014813682197983642
Epoch: 38 Idx: 0 Loss: 0.03260726109500761
Epoch: 38 Idx: 5000 Loss: 0.006353454619950377
Epoch: 39 Idx: 0 Loss: 0.014763045591098005
Epoch: 39 Idx: 5000 Loss: 0.011510751018209229
Epoch: 40 Idx: 0 Loss: 0.00498490369205628
Epoch: 40 Idx: 5000 Loss: 0.04122547123206455
Epoch: 41 Idx: 0 Loss: 0.01510528212357717
Epoch: 41 Idx: 5000 Loss: 0.014119435604517302
Epoch: 42 Idx: 0 Loss: 0.011312641441838323
Epoch: 42 Idx: 5000 Loss: 0.029755087433882946
Epoch: 43 Idx: 0 Loss: 0.01180670547997648
Epoch: 43 Idx: 5000 Loss: 0.03178329988013414
Epoch: 44 Idx: 0 Loss: 0.03887625342609052
Epoch: 44 Idx: 5000 Loss: 0.01652895191039256
Epoch: 45 Idx: 0 Loss: 0.011934140172420778
Epoch: 45 Idx: 5000 Loss: 0.01260541810193146
Epoch: 46 Idx: 0 Loss: 0.010928951627532803
Epoch: 46 Idx: 5000 Loss: 0.010884060317811401
Epoch: 47 Idx: 0 Loss: 0.013271727130096608
Epoch: 47 Idx: 5000 Loss: 0.009169809229703976
Epoch: 48 Idx: 0 Loss: 0.012539087292381023
Epoch: 48 Idx: 5000 Loss: 0.01607044197416036
Epoch: 49 Idx: 0 Loss: 0.014410044452227096
Epoch: 49 Idx: 5000 Loss: 0.015230945552523908
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.21890908464543682
Epoch: 1 Idx: 0 Loss: 0.0156952056181548
Epoch: 2 Idx: 0 Loss: 0.010487117096279069
Epoch: 3 Idx: 0 Loss: 0.041551897722076514
Epoch: 4 Idx: 0 Loss: 0.007385924715694062
Epoch: 5 Idx: 0 Loss: 0.015797544343608683
Epoch: 6 Idx: 0 Loss: 0.03548159407935577
Epoch: 7 Idx: 0 Loss: 0.009192841948890073
Epoch: 8 Idx: 0 Loss: 0.027298017639474984
Epoch: 9 Idx: 0 Loss: 0.012148504061652864
Epoch: 10 Idx: 0 Loss: 0.015591277094267848
Epoch: 11 Idx: 0 Loss: 0.009208968151521685
Epoch: 12 Idx: 0 Loss: 0.013663838554805182
Epoch: 13 Idx: 0 Loss: 0.028868295687094238
Epoch: 14 Idx: 0 Loss: 0.00917988158668622
Epoch: 15 Idx: 0 Loss: 0.015416627238028828
Epoch: 16 Idx: 0 Loss: 0.008953253774314903
Epoch: 17 Idx: 0 Loss: 0.013567831270786162
Epoch: 18 Idx: 0 Loss: 0.01741230540414626
Epoch: 19 Idx: 0 Loss: 0.011165548225275627
Epoch: 20 Idx: 0 Loss: 0.020912088756278105
Epoch: 21 Idx: 0 Loss: 0.029859218907276094
Epoch: 22 Idx: 0 Loss: 0.02463913867174038
Epoch: 23 Idx: 0 Loss: 0.009498572339328933
Epoch: 24 Idx: 0 Loss: 0.02328394108230486
Epoch: 25 Idx: 0 Loss: 0.017265883220250702
Epoch: 26 Idx: 0 Loss: 0.010272417667695594
Epoch: 27 Idx: 0 Loss: 0.00493303847920369
Epoch: 28 Idx: 0 Loss: 0.013602237361783955
Epoch: 29 Idx: 0 Loss: 0.013740586728127106
Epoch: 30 Idx: 0 Loss: 0.009092779004394216
Epoch: 31 Idx: 0 Loss: 0.013954904097483628
Epoch: 32 Idx: 0 Loss: 0.03127708539318515
Epoch: 33 Idx: 0 Loss: 0.012339054583706632
Epoch: 34 Idx: 0 Loss: 0.018548408006032958
Epoch: 35 Idx: 0 Loss: 0.015381822977430848
Epoch: 36 Idx: 0 Loss: 0.013074455478841823
Epoch: 37 Idx: 0 Loss: 0.01000819236563723
Epoch: 38 Idx: 0 Loss: 0.013615142959258536
Epoch: 39 Idx: 0 Loss: 0.019153400756037074
Epoch: 40 Idx: 0 Loss: 0.017958563550565264
Epoch: 41 Idx: 0 Loss: 0.014941318084515254
Epoch: 42 Idx: 0 Loss: 0.0070210719038377055
Epoch: 43 Idx: 0 Loss: 0.02151941602935766
Epoch: 44 Idx: 0 Loss: 0.03221754946961791
Epoch: 45 Idx: 0 Loss: 0.016013825280249118
Epoch: 46 Idx: 0 Loss: 0.030587012955580813
Epoch: 47 Idx: 0 Loss: 0.012562542048601674
Epoch: 48 Idx: 0 Loss: 0.008708645538019325
Epoch: 49 Idx: 0 Loss: 0.031132535931913535
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.13910437320725366
Epoch: 0 Idx: 5000 Loss: 0.013058010959396545
Epoch: 1 Idx: 0 Loss: 0.023038361982014706
Epoch: 1 Idx: 5000 Loss: 0.03960073837021619
Epoch: 2 Idx: 0 Loss: 0.010404746448537597
Epoch: 2 Idx: 5000 Loss: 0.007331183328270418
Epoch: 3 Idx: 0 Loss: 0.02878495134412849
Epoch: 3 Idx: 5000 Loss: 0.0054177727440518145
Epoch: 4 Idx: 0 Loss: 0.015586889992818185
Epoch: 4 Idx: 5000 Loss: 0.019360621952909024
Epoch: 5 Idx: 0 Loss: 0.012305076900717471
Epoch: 5 Idx: 5000 Loss: 0.01178629086716656
Epoch: 6 Idx: 0 Loss: 0.011178275824186453
Epoch: 6 Idx: 5000 Loss: 0.012313232790765197
Epoch: 7 Idx: 0 Loss: 0.021723244925984417
Epoch: 7 Idx: 5000 Loss: 0.017449915259161543
Epoch: 8 Idx: 0 Loss: 0.007915634519063828
Epoch: 8 Idx: 5000 Loss: 0.03527263280948149
Epoch: 9 Idx: 0 Loss: 0.014412330240152461
Epoch: 9 Idx: 5000 Loss: 0.007074229756412881
Epoch: 10 Idx: 0 Loss: 0.013751565400322626
Epoch: 10 Idx: 5000 Loss: 0.03280118735576016
Epoch: 11 Idx: 0 Loss: 0.018570100470911476
Epoch: 11 Idx: 5000 Loss: 0.01148904685948568
Epoch: 12 Idx: 0 Loss: 0.008777354742264093
Epoch: 12 Idx: 5000 Loss: 0.03370629858839943
Epoch: 13 Idx: 0 Loss: 0.02862795637266808
Epoch: 13 Idx: 5000 Loss: 0.017683951649126384
Epoch: 14 Idx: 0 Loss: 0.011387241634510208
Epoch: 14 Idx: 5000 Loss: 0.029787739974643002
Epoch: 15 Idx: 0 Loss: 0.0076775328215627015
Epoch: 15 Idx: 5000 Loss: 0.02021432741278386
Epoch: 16 Idx: 0 Loss: 0.020758336371173573
Epoch: 16 Idx: 5000 Loss: 0.02280685463961836
Epoch: 17 Idx: 0 Loss: 0.039192507493691575
Epoch: 17 Idx: 5000 Loss: 0.014595952462547575
Epoch: 18 Idx: 0 Loss: 0.01753334140740892
Epoch: 18 Idx: 5000 Loss: 0.031443165376628106
Epoch: 19 Idx: 0 Loss: 0.008972608723525385
Epoch: 19 Idx: 5000 Loss: 0.01839409537456625
Epoch: 20 Idx: 0 Loss: 0.008502391185026272
Epoch: 20 Idx: 5000 Loss: 0.04594558979048681
Epoch: 21 Idx: 0 Loss: 0.007897001763320794
Epoch: 21 Idx: 5000 Loss: 0.01759973503508113
Epoch: 22 Idx: 0 Loss: 0.0160338584852893
Epoch: 22 Idx: 5000 Loss: 0.015897930869167742
Epoch: 23 Idx: 0 Loss: 0.017387127112776662
Epoch: 23 Idx: 5000 Loss: 0.01168819747814615
Epoch: 24 Idx: 0 Loss: 0.00742049387827831
Epoch: 24 Idx: 5000 Loss: 0.020756711241897936
Epoch: 25 Idx: 0 Loss: 0.016136938304685496
Epoch: 25 Idx: 5000 Loss: 0.04299224652917695
Epoch: 26 Idx: 0 Loss: 0.009525424763786417
Epoch: 26 Idx: 5000 Loss: 0.009887369389513196
Epoch: 27 Idx: 0 Loss: 0.011884381088387942
Epoch: 27 Idx: 5000 Loss: 0.011959507686740672
Epoch: 28 Idx: 0 Loss: 0.01856351535075755
Epoch: 28 Idx: 5000 Loss: 0.022644883654908077
Epoch: 29 Idx: 0 Loss: 0.011859989072252566
Epoch: 29 Idx: 5000 Loss: 0.0067333366219845415
Epoch: 30 Idx: 0 Loss: 0.01583206765280376
Epoch: 30 Idx: 5000 Loss: 0.015469880194313418
Epoch: 31 Idx: 0 Loss: 0.018840313825265124
Epoch: 31 Idx: 5000 Loss: 0.017777840125472535
Epoch: 32 Idx: 0 Loss: 0.011984286426033022
Epoch: 32 Idx: 5000 Loss: 0.02075981273776153
Epoch: 33 Idx: 0 Loss: 0.010788012483184933
Epoch: 33 Idx: 5000 Loss: 0.04908027353720455
Epoch: 34 Idx: 0 Loss: 0.009126441879345257
Epoch: 34 Idx: 5000 Loss: 0.02572387894277594
Epoch: 35 Idx: 0 Loss: 0.011140386909254242
Epoch: 35 Idx: 5000 Loss: 0.009204416458656783
Epoch: 36 Idx: 0 Loss: 0.05049561525926992
Epoch: 36 Idx: 5000 Loss: 0.010712454348031926
Epoch: 37 Idx: 0 Loss: 0.004714869956267222
Epoch: 37 Idx: 5000 Loss: 0.022086116698579683
Epoch: 38 Idx: 0 Loss: 0.01666967811696575
Epoch: 38 Idx: 5000 Loss: 0.02081838878734249
Epoch: 39 Idx: 0 Loss: 0.02050645367908577
Epoch: 39 Idx: 5000 Loss: 0.011903907438267485
Epoch: 40 Idx: 0 Loss: 0.006944592221463016
Epoch: 40 Idx: 5000 Loss: 0.010661235387084505
Epoch: 41 Idx: 0 Loss: 0.011446755390582106
Epoch: 41 Idx: 5000 Loss: 0.00516120202881701
Epoch: 42 Idx: 0 Loss: 0.019938027840307945
Epoch: 42 Idx: 5000 Loss: 0.029199325523822872
Epoch: 43 Idx: 0 Loss: 0.03424991577857556
Epoch: 43 Idx: 5000 Loss: 0.012589629899491583
Epoch: 44 Idx: 0 Loss: 0.019486999260572756
Epoch: 44 Idx: 5000 Loss: 0.01844876006666269
Epoch: 45 Idx: 0 Loss: 0.008977517763604469
Epoch: 45 Idx: 5000 Loss: 0.009231934038224941
Epoch: 46 Idx: 0 Loss: 0.008361351887207505
Epoch: 46 Idx: 5000 Loss: 0.00849500184404451
Epoch: 47 Idx: 0 Loss: 0.01032271694289787
Epoch: 47 Idx: 5000 Loss: 0.01689862909806165
Epoch: 48 Idx: 0 Loss: 0.02693000247943121
Epoch: 48 Idx: 5000 Loss: 0.011109974553581252
Epoch: 49 Idx: 0 Loss: 0.01362037286754213
Epoch: 49 Idx: 5000 Loss: 0.013451212199169865
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.20197861523339636
Epoch: 1 Idx: 0 Loss: 0.016328412318955036
Epoch: 2 Idx: 0 Loss: 0.007022375356564827
Epoch: 3 Idx: 0 Loss: 0.008496447897067869
Epoch: 4 Idx: 0 Loss: 0.010215242920310653
Epoch: 5 Idx: 0 Loss: 0.014822709803043885
Epoch: 6 Idx: 0 Loss: 0.007966633982907442
Epoch: 7 Idx: 0 Loss: 0.013053497906494
Epoch: 8 Idx: 0 Loss: 0.019566848435980336
Epoch: 9 Idx: 0 Loss: 0.02655127777062867
Epoch: 10 Idx: 0 Loss: 0.006177931707729122
Epoch: 11 Idx: 0 Loss: 0.02886917535361368
Epoch: 12 Idx: 0 Loss: 0.019594247252899436
Epoch: 13 Idx: 0 Loss: 0.007743644129986288
Epoch: 14 Idx: 0 Loss: 0.025151072098336655
Epoch: 15 Idx: 0 Loss: 0.023608846614058154
Epoch: 16 Idx: 0 Loss: 0.006711425641986734
Epoch: 17 Idx: 0 Loss: 0.023354629315486423
Epoch: 18 Idx: 0 Loss: 0.018335590055083142
Epoch: 19 Idx: 0 Loss: 0.01971036718934789
Epoch: 20 Idx: 0 Loss: 0.015896997208199058
Epoch: 21 Idx: 0 Loss: 0.010696222394304091
Epoch: 22 Idx: 0 Loss: 0.01428745534398635
Epoch: 23 Idx: 0 Loss: 0.012416872239806608
Epoch: 24 Idx: 0 Loss: 0.024138087504982506
Epoch: 25 Idx: 0 Loss: 0.015810847586950925
Epoch: 26 Idx: 0 Loss: 0.005297541115180044
Epoch: 27 Idx: 0 Loss: 0.011781765410060561
Epoch: 28 Idx: 0 Loss: 0.013711166987582915
Epoch: 29 Idx: 0 Loss: 0.012411875777283853
Epoch: 30 Idx: 0 Loss: 0.01029226646054534
Epoch: 31 Idx: 0 Loss: 0.023032288655326753
Epoch: 32 Idx: 0 Loss: 0.00903116783647273
Epoch: 33 Idx: 0 Loss: 0.003778491008996379
Epoch: 34 Idx: 0 Loss: 0.019128721475788642
Epoch: 35 Idx: 0 Loss: 0.01848441049107949
Epoch: 36 Idx: 0 Loss: 0.011540383957148292
Epoch: 37 Idx: 0 Loss: 0.005580714455899007
Epoch: 38 Idx: 0 Loss: 0.011864821907184913
Epoch: 39 Idx: 0 Loss: 0.0150135386737795
Epoch: 40 Idx: 0 Loss: 0.013912813117954361
Epoch: 41 Idx: 0 Loss: 0.041575234204880455
Epoch: 42 Idx: 0 Loss: 0.018779980871452523
Epoch: 43 Idx: 0 Loss: 0.022321359308023807
Epoch: 44 Idx: 0 Loss: 0.013265757186552917
Epoch: 45 Idx: 0 Loss: 0.016788466960673383
Epoch: 46 Idx: 0 Loss: 0.015576271363429976
Epoch: 47 Idx: 0 Loss: 0.030477947054500597
Epoch: 48 Idx: 0 Loss: 0.009101009794909017
Epoch: 49 Idx: 0 Loss: 0.025527516496638106
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333)
Performance for  [('ekaw', 'sigkdd')] is : (0.8461538461538461, 1.0, 0.9166666666666666, 0.9649122807017543, 0.8730158730158731)
Performance for  [('conference', 'edas')] is : (0.8823529411764706, 0.8823529411764706, 0.8823529411764706, 0.8823529411764706, 0.8823529411764706)
Performance for  [('cmt', 'ekaw')] is : (0.5, 0.5454545454545454, 0.5217391304347826, 0.5357142857142857, 0.5084745762711864)
Performance for  [('confOf', 'edas')] is : (0.6190476190476191, 0.6842105263157895, 0.6500000000000001, 0.6701030927835052, 0.6310679611650486)
Performance for  [('iasted', 'sigkdd')] is : (0.42857142857142855, 0.8, 0.5581395348837209, 0.6818181818181819, 0.4724409448818898)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.71563702 0.7429867  0.71093105 0.72542717 0.70896494]
Threshold:  0.878

------------------------------------------------------------
Sender: LSF System <rer@dccxc243>
Subject: Job 4142555: <python main.py 1 21 False True> in cluster <dcc> Done

Job <python main.py 1 21 False True> was submitted from host <dccxl001> by user <naveen9> in cluster <dcc> at Wed Sep 16 06:55:10 2020
Job was executed on host(s) <dccxc243>, in queue <x86_24h>, as user <naveen9> in cluster <dcc> at Wed Sep 16 07:37:31 2020
</u/naveen9> was used as the home directory.
</u/naveen9/arvind/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:37:31 2020
Terminated at Thu Sep 17 02:24:46 2020
Results reported at Thu Sep 17 02:24:46 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 1 21 False True
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   67515.52 sec.
    Max Memory :                                 2895 MB
    Average Memory :                             2721.78 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40522.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   67640 sec.
    Turnaround time :                            70176 sec.

The output (if any) is above this job summary.

