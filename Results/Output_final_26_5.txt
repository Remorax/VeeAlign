2020-09-15 15:49:37.766014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:41.052538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:41.182057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:41.182178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:41.184267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:41.185685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:41.186043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:41.187897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:41.189344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:41.189555: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:41.189577: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:41.189890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:41.196625: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599830000 Hz
2020-09-15 15:49:41.196813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559b6e464040 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:41.196833: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:41.198547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:41.198571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.19491749379898574
Epoch: 0 Idx: 5000 Loss: 0.02968958184196403
Epoch: 1 Idx: 0 Loss: 0.014314102568472615
Epoch: 1 Idx: 5000 Loss: 0.023517131146570967
Epoch: 2 Idx: 0 Loss: 0.010479777342957072
Epoch: 2 Idx: 5000 Loss: 0.025701800960804953
Epoch: 3 Idx: 0 Loss: 0.015260461576532125
Epoch: 3 Idx: 5000 Loss: 0.010303642430101193
Epoch: 4 Idx: 0 Loss: 0.01158425078018672
Epoch: 4 Idx: 5000 Loss: 0.007629319296907518
Epoch: 5 Idx: 0 Loss: 0.02211269051413438
Epoch: 5 Idx: 5000 Loss: 0.018409103649037913
Epoch: 6 Idx: 0 Loss: 0.007638104759699011
Epoch: 6 Idx: 5000 Loss: 0.010048570715519851
Epoch: 7 Idx: 0 Loss: 0.015922179628011516
Epoch: 7 Idx: 5000 Loss: 0.014583852332389995
Epoch: 8 Idx: 0 Loss: 0.014120782471191366
Epoch: 8 Idx: 5000 Loss: 0.015133838592811703
Epoch: 9 Idx: 0 Loss: 0.01761029915895903
Epoch: 9 Idx: 5000 Loss: 0.008897551492830634
Epoch: 10 Idx: 0 Loss: 0.017402861608128414
Epoch: 10 Idx: 5000 Loss: 0.014441371033396173
Epoch: 11 Idx: 0 Loss: 0.01032580029050724
Epoch: 11 Idx: 5000 Loss: 0.02202026049396349
Epoch: 12 Idx: 0 Loss: 0.006988019102222813
Epoch: 12 Idx: 5000 Loss: 0.010509696238058542
Epoch: 13 Idx: 0 Loss: 0.009821834792417394
Epoch: 13 Idx: 5000 Loss: 0.009194221566077146
Epoch: 14 Idx: 0 Loss: 0.011510016288387853
Epoch: 14 Idx: 5000 Loss: 0.014744519904724196
Epoch: 15 Idx: 0 Loss: 0.023090050885780578
Epoch: 15 Idx: 5000 Loss: 0.007724341072920951
Epoch: 16 Idx: 0 Loss: 0.024714690218439753
Epoch: 16 Idx: 5000 Loss: 0.01224244273282117
Epoch: 17 Idx: 0 Loss: 0.01781813368185068
Epoch: 17 Idx: 5000 Loss: 0.019129906334936872
Epoch: 18 Idx: 0 Loss: 0.013443588587592904
Epoch: 18 Idx: 5000 Loss: 0.05365679312666946
Epoch: 19 Idx: 0 Loss: 0.0374998841682145
Epoch: 19 Idx: 5000 Loss: 0.01602560162881316
Epoch: 20 Idx: 0 Loss: 0.00792218877560106
Epoch: 20 Idx: 5000 Loss: 0.034757452673032485
Epoch: 21 Idx: 0 Loss: 0.02347696387017851
Epoch: 21 Idx: 5000 Loss: 0.017031024505595342
Epoch: 22 Idx: 0 Loss: 0.029160101781456147
Epoch: 22 Idx: 5000 Loss: 0.02995792525422462
Epoch: 23 Idx: 0 Loss: 0.01555615701344348
Epoch: 23 Idx: 5000 Loss: 0.014885153171480606
Epoch: 24 Idx: 0 Loss: 0.012322078721858842
Epoch: 24 Idx: 5000 Loss: 0.018134937731460618
Epoch: 25 Idx: 0 Loss: 0.0180482602246085
Epoch: 25 Idx: 5000 Loss: 0.01048727174372394
Epoch: 26 Idx: 0 Loss: 0.01883266640830587
Epoch: 26 Idx: 5000 Loss: 0.04161823953201022
Epoch: 27 Idx: 0 Loss: 0.015256967076199696
Epoch: 27 Idx: 5000 Loss: 0.01855325350834522
Epoch: 28 Idx: 0 Loss: 0.01149416062662425
Epoch: 28 Idx: 5000 Loss: 0.016466233522800206
Epoch: 29 Idx: 0 Loss: 0.02726618000948958
Epoch: 29 Idx: 5000 Loss: 0.027023009281320613
Epoch: 30 Idx: 0 Loss: 0.01597179763083583
Epoch: 30 Idx: 5000 Loss: 0.008072191498005934
Epoch: 31 Idx: 0 Loss: 0.007943351284427712
Epoch: 31 Idx: 5000 Loss: 0.03314573023753876
Epoch: 32 Idx: 0 Loss: 0.029266546823023896
Epoch: 32 Idx: 5000 Loss: 0.007577996245622186
Epoch: 33 Idx: 0 Loss: 0.020878110664067376
Epoch: 33 Idx: 5000 Loss: 0.012137987056683945
Epoch: 34 Idx: 0 Loss: 0.009109279213974081
Epoch: 34 Idx: 5000 Loss: 0.031721053069754895
Epoch: 35 Idx: 0 Loss: 0.01450399122350111
Epoch: 35 Idx: 5000 Loss: 0.009867474432701697
Epoch: 36 Idx: 0 Loss: 0.011977510894792282
Epoch: 36 Idx: 5000 Loss: 0.006179931173117629
Epoch: 37 Idx: 0 Loss: 0.015546705858466719
Epoch: 37 Idx: 5000 Loss: 0.016035294581612024
Epoch: 38 Idx: 0 Loss: 0.017620514016076394
Epoch: 38 Idx: 5000 Loss: 0.039842285176716695
Epoch: 39 Idx: 0 Loss: 0.010050408128977374
Epoch: 39 Idx: 5000 Loss: 0.02072819931559337
Epoch: 40 Idx: 0 Loss: 0.0059489680920449565
Epoch: 40 Idx: 5000 Loss: 0.01918123390055651
Epoch: 41 Idx: 0 Loss: 0.012135904670728231
Epoch: 41 Idx: 5000 Loss: 0.029261983893261276
Epoch: 42 Idx: 0 Loss: 0.014230049815381986
Epoch: 42 Idx: 5000 Loss: 0.009594413739523133
Epoch: 43 Idx: 0 Loss: 0.025231387868438836
Epoch: 43 Idx: 5000 Loss: 0.017246638992161587
Epoch: 44 Idx: 0 Loss: 0.010951006813242353
Epoch: 44 Idx: 5000 Loss: 0.017975436834234644
Epoch: 45 Idx: 0 Loss: 0.011312464344310368
Epoch: 45 Idx: 5000 Loss: 0.026408286786100285
Epoch: 46 Idx: 0 Loss: 0.011833578330068865
Epoch: 46 Idx: 5000 Loss: 0.009975609641625395
Epoch: 47 Idx: 0 Loss: 0.02150262030760511
Epoch: 47 Idx: 5000 Loss: 0.021853193027375376
Epoch: 48 Idx: 0 Loss: 0.027005468216601984
Epoch: 48 Idx: 5000 Loss: 0.01095048432066981
Epoch: 49 Idx: 0 Loss: 0.01791483369739101
Epoch: 49 Idx: 5000 Loss: 0.01760793028952137
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.1362218305398084
Epoch: 0 Idx: 5000 Loss: 0.03497004158298523
Epoch: 1 Idx: 0 Loss: 0.010859356220688452
Epoch: 1 Idx: 5000 Loss: 0.020527689235284998
Epoch: 2 Idx: 0 Loss: 0.011352408427768912
Epoch: 2 Idx: 5000 Loss: 0.010146647953995357
Epoch: 3 Idx: 0 Loss: 0.026613377532458522
Epoch: 3 Idx: 5000 Loss: 0.006666328602039525
Epoch: 4 Idx: 0 Loss: 0.005443624213219034
Epoch: 4 Idx: 5000 Loss: 0.02175623216943231
Epoch: 5 Idx: 0 Loss: 0.011731948186062258
Epoch: 5 Idx: 5000 Loss: 0.00721415867891445
Epoch: 6 Idx: 0 Loss: 0.013413817490925224
Epoch: 6 Idx: 5000 Loss: 0.010859351630541378
Epoch: 7 Idx: 0 Loss: 0.010449819174204782
Epoch: 7 Idx: 5000 Loss: 0.008059454433081776
Epoch: 8 Idx: 0 Loss: 0.009170095619123356
Epoch: 8 Idx: 5000 Loss: 0.030270643207965273
Epoch: 9 Idx: 0 Loss: 0.007178235366681731
Epoch: 9 Idx: 5000 Loss: 0.007307057488259203
Epoch: 10 Idx: 0 Loss: 0.00531240320036524
Epoch: 10 Idx: 5000 Loss: 0.010792350101639845
Epoch: 11 Idx: 0 Loss: 0.01996309881962413
Epoch: 11 Idx: 5000 Loss: 0.010501336650084224
Epoch: 12 Idx: 0 Loss: 0.02020672227691876
Epoch: 12 Idx: 5000 Loss: 0.01674549558526981
Epoch: 13 Idx: 0 Loss: 0.01372655760660388
Epoch: 13 Idx: 5000 Loss: 0.007846152822835956
Epoch: 14 Idx: 0 Loss: 0.019093719372371337
Epoch: 14 Idx: 5000 Loss: 0.007433508664858376
Epoch: 15 Idx: 0 Loss: 0.007997710662832593
Epoch: 15 Idx: 5000 Loss: 0.026407488648359144
Epoch: 16 Idx: 0 Loss: 0.012715450072878115
Epoch: 16 Idx: 5000 Loss: 0.017381086701282925
Epoch: 17 Idx: 0 Loss: 0.03146762887358579
Epoch: 17 Idx: 5000 Loss: 0.015100240034185888
Epoch: 18 Idx: 0 Loss: 0.01905918395043936
Epoch: 18 Idx: 5000 Loss: 0.013005177004119722
Epoch: 19 Idx: 0 Loss: 0.0196380799345784
Epoch: 19 Idx: 5000 Loss: 0.014514404296474335
Epoch: 20 Idx: 0 Loss: 0.013514104973245112
Epoch: 20 Idx: 5000 Loss: 0.014402866849775226
Epoch: 21 Idx: 0 Loss: 0.023900868918211776
Epoch: 21 Idx: 5000 Loss: 0.007453132589201649
Epoch: 22 Idx: 0 Loss: 0.02887439935008458
Epoch: 22 Idx: 5000 Loss: 0.019313260108680945
Epoch: 23 Idx: 0 Loss: 0.019658165771156172
Epoch: 23 Idx: 5000 Loss: 0.009605170365519201
Epoch: 24 Idx: 0 Loss: 0.03404265761607021
Epoch: 24 Idx: 5000 Loss: 0.021810630515779313
Epoch: 25 Idx: 0 Loss: 0.03045135324904285
Epoch: 25 Idx: 5000 Loss: 0.0201004998036459
Epoch: 26 Idx: 0 Loss: 0.02686619714979241
Epoch: 26 Idx: 5000 Loss: 0.017981761089651112
Epoch: 27 Idx: 0 Loss: 0.0329044372358014
Epoch: 27 Idx: 5000 Loss: 0.009540702044959498
Epoch: 28 Idx: 0 Loss: 0.010279326965140514
Epoch: 28 Idx: 5000 Loss: 0.007003852480562049
Epoch: 29 Idx: 0 Loss: 0.02288274687178178
Epoch: 29 Idx: 5000 Loss: 0.0289756234893608
Epoch: 30 Idx: 0 Loss: 0.02109837727126117
Epoch: 30 Idx: 5000 Loss: 0.01115367059275729
Epoch: 31 Idx: 0 Loss: 0.012894915750548668
Epoch: 31 Idx: 5000 Loss: 0.030449712820856012
Epoch: 32 Idx: 0 Loss: 0.021886560456522854
Epoch: 32 Idx: 5000 Loss: 0.01449230154120261
Epoch: 33 Idx: 0 Loss: 0.013355515539454797
Epoch: 33 Idx: 5000 Loss: 0.007821596836628569
Epoch: 34 Idx: 0 Loss: 0.015061397222728909
Epoch: 34 Idx: 5000 Loss: 0.015998919300674753
Epoch: 35 Idx: 0 Loss: 0.02010546080410087
Epoch: 35 Idx: 5000 Loss: 0.006821963307137155
Epoch: 36 Idx: 0 Loss: 0.009818117112108084
Epoch: 36 Idx: 5000 Loss: 0.01526209841100075
Epoch: 37 Idx: 0 Loss: 0.012464525003431457
Epoch: 37 Idx: 5000 Loss: 0.006759876943859719
Epoch: 38 Idx: 0 Loss: 0.014897813745312505
Epoch: 38 Idx: 5000 Loss: 0.010963576794241283
Epoch: 39 Idx: 0 Loss: 0.01208168111804963
Epoch: 39 Idx: 5000 Loss: 0.018305774219490548
Epoch: 40 Idx: 0 Loss: 0.005882942141402883
Epoch: 40 Idx: 5000 Loss: 0.03746322658137087
Epoch: 41 Idx: 0 Loss: 0.011115521882431822
Epoch: 41 Idx: 5000 Loss: 0.019784353326398177
Epoch: 42 Idx: 0 Loss: 0.012804892511268155
Epoch: 42 Idx: 5000 Loss: 0.016058860325790812
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc243>
Subject: Job 4066869: <python main.py 5 26 False False> in cluster <dcc> Exited

Job <python main.py 5 26 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
Job was executed on host(s) <dccxc243>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:35 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:35 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 26 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46144.55 sec.
    Max Memory :                                 3022 MB
    Average Memory :                             2770.76 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40395.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46170 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

