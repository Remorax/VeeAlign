2020-09-16 07:37:37.216802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:47.530566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 07:37:47.644630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 07:37:47.644695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 07:37:47.646711: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 07:37:47.671093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 07:37:47.719133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 07:37:47.764617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 07:37:47.790488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 07:37:47.790843: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 07:37:47.790866: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 07:37:47.791331: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 07:37:47.814959: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600055000 Hz
2020-09-16 07:37:47.815176: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dca2fbab70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 07:37:47.815196: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 07:37:47.817271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 07:37:47.817292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18908089227568636
Epoch: 0 Idx: 5000 Loss: 0.01133122003738625
Epoch: 1 Idx: 0 Loss: 0.015471468348785112
Epoch: 1 Idx: 5000 Loss: 0.010466331031949739
Epoch: 2 Idx: 0 Loss: 0.02494643998041811
Epoch: 2 Idx: 5000 Loss: 0.010124367432466298
Epoch: 3 Idx: 0 Loss: 0.01436526507325361
Epoch: 3 Idx: 5000 Loss: 0.030923435121945324
Epoch: 4 Idx: 0 Loss: 0.026975966247055127
Epoch: 4 Idx: 5000 Loss: 0.01206810350553111
Epoch: 5 Idx: 0 Loss: 0.020501036517121582
Epoch: 5 Idx: 5000 Loss: 0.009613057679008687
Epoch: 6 Idx: 0 Loss: 0.021254216101557824
Epoch: 6 Idx: 5000 Loss: 0.012329798597143182
Epoch: 7 Idx: 0 Loss: 0.01695505758026357
Epoch: 7 Idx: 5000 Loss: 0.011053923555067274
Epoch: 8 Idx: 0 Loss: 0.012808261679872344
Epoch: 8 Idx: 5000 Loss: 0.012278221036517128
Epoch: 9 Idx: 0 Loss: 0.028338135498600193
Epoch: 9 Idx: 5000 Loss: 0.008896239499764362
Epoch: 10 Idx: 0 Loss: 0.00945749140420122
Epoch: 10 Idx: 5000 Loss: 0.011406862093222865
Epoch: 11 Idx: 0 Loss: 0.02116825460264921
Epoch: 11 Idx: 5000 Loss: 0.015721657028537093
Epoch: 12 Idx: 0 Loss: 0.007451580957879679
Epoch: 12 Idx: 5000 Loss: 0.008630504272380272
Epoch: 13 Idx: 0 Loss: 0.011070195691482133
Epoch: 13 Idx: 5000 Loss: 0.011860738633288084
Epoch: 14 Idx: 0 Loss: 0.021327092508288965
Epoch: 14 Idx: 5000 Loss: 0.0122567500453169
Epoch: 15 Idx: 0 Loss: 0.010779906078264997
Epoch: 15 Idx: 5000 Loss: 0.027283242107070192
Epoch: 16 Idx: 0 Loss: 0.0090501118022552
Epoch: 16 Idx: 5000 Loss: 0.009916597980331392
Epoch: 17 Idx: 0 Loss: 0.009768378989736605
Epoch: 17 Idx: 5000 Loss: 0.014140969892408789
Epoch: 18 Idx: 0 Loss: 0.020471410777727628
Epoch: 18 Idx: 5000 Loss: 0.019861178078983587
Epoch: 19 Idx: 0 Loss: 0.021816029223677764
Epoch: 19 Idx: 5000 Loss: 0.012666272325920346
Epoch: 20 Idx: 0 Loss: 0.013142659540502796
Epoch: 20 Idx: 5000 Loss: 0.010516077932723206
Epoch: 21 Idx: 0 Loss: 0.013633000918313074
Epoch: 21 Idx: 5000 Loss: 0.025244130197412132
Epoch: 22 Idx: 0 Loss: 0.00975547395058334
Epoch: 22 Idx: 5000 Loss: 0.029095692612873616
Epoch: 23 Idx: 0 Loss: 0.02641798328929499
Epoch: 23 Idx: 5000 Loss: 0.011682492178882141
Epoch: 24 Idx: 0 Loss: 0.0183214312533472
Epoch: 24 Idx: 5000 Loss: 0.0162795001074608
Epoch: 25 Idx: 0 Loss: 0.018676621337880322
Epoch: 25 Idx: 5000 Loss: 0.009482070968780305
Epoch: 26 Idx: 0 Loss: 0.008906595477464084
Epoch: 26 Idx: 5000 Loss: 0.006274097736403465
Epoch: 27 Idx: 0 Loss: 0.011083353083930976
Epoch: 27 Idx: 5000 Loss: 0.0215767145105958
Epoch: 28 Idx: 0 Loss: 0.028426182971222735
Epoch: 28 Idx: 5000 Loss: 0.023274750747825236
Epoch: 29 Idx: 0 Loss: 0.019073977950685585
Epoch: 29 Idx: 5000 Loss: 0.023412440893098286
Epoch: 30 Idx: 0 Loss: 0.020544421720970783
Epoch: 30 Idx: 5000 Loss: 0.0219953658174916
Epoch: 31 Idx: 0 Loss: 0.02161683021986014
Epoch: 31 Idx: 5000 Loss: 0.014480072821703905
Epoch: 32 Idx: 0 Loss: 0.015146031191704238
Epoch: 32 Idx: 5000 Loss: 0.014902822681131188
Epoch: 33 Idx: 0 Loss: 0.012213987025092007
Epoch: 33 Idx: 5000 Loss: 0.010795298894633123
Epoch: 34 Idx: 0 Loss: 0.01368688762060568
Epoch: 34 Idx: 5000 Loss: 0.012407377591909234
Epoch: 35 Idx: 0 Loss: 0.011471724961920796
Epoch: 35 Idx: 5000 Loss: 0.012571147275982086
Epoch: 36 Idx: 0 Loss: 0.009824673681358573
Epoch: 36 Idx: 5000 Loss: 0.04260988468739649
Epoch: 37 Idx: 0 Loss: 0.017773685397448467
Epoch: 37 Idx: 5000 Loss: 0.014217650434622128
Epoch: 38 Idx: 0 Loss: 0.00949905045529812
Epoch: 38 Idx: 5000 Loss: 0.01478730606548024
Epoch: 39 Idx: 0 Loss: 0.026229216913199092
Epoch: 39 Idx: 5000 Loss: 0.013621676695842876
Epoch: 40 Idx: 0 Loss: 0.01524066378172856
Epoch: 40 Idx: 5000 Loss: 0.012657113192685207
Epoch: 41 Idx: 0 Loss: 0.012057221819098317
Epoch: 41 Idx: 5000 Loss: 0.016516260755995008
Epoch: 42 Idx: 0 Loss: 0.017279656312393386
Epoch: 42 Idx: 5000 Loss: 0.01500592501009326
Epoch: 43 Idx: 0 Loss: 0.0175797764968895
Epoch: 43 Idx: 5000 Loss: 0.011170011386979003
Epoch: 44 Idx: 0 Loss: 0.01080084490928618
Epoch: 44 Idx: 5000 Loss: 0.011618119208493264
Epoch: 45 Idx: 0 Loss: 0.006988323215035064
Epoch: 45 Idx: 5000 Loss: 0.01332727019223513
Epoch: 46 Idx: 0 Loss: 0.015921884543068088
Epoch: 46 Idx: 5000 Loss: 0.02073249922818915
Epoch: 47 Idx: 0 Loss: 0.02124930272404896
Epoch: 47 Idx: 5000 Loss: 0.009358742162193562
Epoch: 48 Idx: 0 Loss: 0.009078025420975137
Epoch: 48 Idx: 5000 Loss: 0.005273716267531057
Epoch: 49 Idx: 0 Loss: 0.007433435537583933
Epoch: 49 Idx: 5000 Loss: 0.015917843283149175
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.2343775052486367
Epoch: 0 Idx: 5000 Loss: 0.029262513701651307
Epoch: 1 Idx: 0 Loss: 0.019993824702167037
Epoch: 1 Idx: 5000 Loss: 0.016166908796941735
Epoch: 2 Idx: 0 Loss: 0.02604334859258918
Epoch: 2 Idx: 5000 Loss: 0.01883009088038965
Epoch: 3 Idx: 0 Loss: 0.010991452239238857
Epoch: 3 Idx: 5000 Loss: 0.01130521679453829
Epoch: 4 Idx: 0 Loss: 0.004787183898635115
Epoch: 4 Idx: 5000 Loss: 0.00815333084259219
Epoch: 5 Idx: 0 Loss: 0.012836502476601574
Epoch: 5 Idx: 5000 Loss: 0.010036686642736273
Epoch: 6 Idx: 0 Loss: 0.015444933861967608
Epoch: 6 Idx: 5000 Loss: 0.010415274017320994
Epoch: 7 Idx: 0 Loss: 0.008066893043764371
Epoch: 7 Idx: 5000 Loss: 0.014683536075573747
Epoch: 8 Idx: 0 Loss: 0.009095139460625786
Epoch: 8 Idx: 5000 Loss: 0.019692105692975678
Epoch: 9 Idx: 0 Loss: 0.02566087193905496
Epoch: 9 Idx: 5000 Loss: 0.009581874857057061
Epoch: 10 Idx: 0 Loss: 0.01066188736938586
Epoch: 10 Idx: 5000 Loss: 0.00993065636882648
Epoch: 11 Idx: 0 Loss: 0.02359662296403955
Epoch: 11 Idx: 5000 Loss: 0.006925962532321663
Epoch: 12 Idx: 0 Loss: 0.012944694814222587
Epoch: 12 Idx: 5000 Loss: 0.028306039376622683
Epoch: 13 Idx: 0 Loss: 0.03713936952402115
Epoch: 13 Idx: 5000 Loss: 0.011092233462360917
Epoch: 14 Idx: 0 Loss: 0.01181069827440592
Epoch: 14 Idx: 5000 Loss: 0.012056575218324754
Epoch: 15 Idx: 0 Loss: 0.016137207128259203
Epoch: 15 Idx: 5000 Loss: 0.017092066395841807
Epoch: 16 Idx: 0 Loss: 0.012998047896936819
Epoch: 16 Idx: 5000 Loss: 0.012706957227990607
Epoch: 17 Idx: 0 Loss: 0.03717274499775579
Epoch: 17 Idx: 5000 Loss: 0.054436149082746126
Epoch: 18 Idx: 0 Loss: 0.009250356771868803
Epoch: 18 Idx: 5000 Loss: 0.022459175827116918
Epoch: 19 Idx: 0 Loss: 0.0051865674783256495
Epoch: 19 Idx: 5000 Loss: 0.011372006861399258
Epoch: 20 Idx: 0 Loss: 0.010226536694855723
Epoch: 20 Idx: 5000 Loss: 0.012676908147619941
Epoch: 21 Idx: 0 Loss: 0.017640188391156462
Epoch: 21 Idx: 5000 Loss: 0.014632369655882656
Epoch: 22 Idx: 0 Loss: 0.007647319956515916
Epoch: 22 Idx: 5000 Loss: 0.025636622961240772
Epoch: 23 Idx: 0 Loss: 0.011964000376715168
Epoch: 23 Idx: 5000 Loss: 0.01334977972876569
Epoch: 24 Idx: 0 Loss: 0.0117899793434907
Epoch: 24 Idx: 5000 Loss: 0.02985642305923225
Epoch: 25 Idx: 0 Loss: 0.029973888949213615
Epoch: 25 Idx: 5000 Loss: 0.008982527995858821
Epoch: 26 Idx: 0 Loss: 0.008827508382122129
Epoch: 26 Idx: 5000 Loss: 0.013361905856074868
Epoch: 27 Idx: 0 Loss: 0.018181221019131166
Epoch: 27 Idx: 5000 Loss: 0.0030059876519682722
Epoch: 28 Idx: 0 Loss: 0.009889819179165708
Epoch: 28 Idx: 5000 Loss: 0.007165571923930638
Epoch: 29 Idx: 0 Loss: 0.01796633382866727
Epoch: 29 Idx: 5000 Loss: 0.03269666408730343
Epoch: 30 Idx: 0 Loss: 0.013861949688602625
Epoch: 30 Idx: 5000 Loss: 0.011460718127566593
Epoch: 31 Idx: 0 Loss: 0.013930707077213823
Epoch: 31 Idx: 5000 Loss: 0.009913797628081642
Epoch: 32 Idx: 0 Loss: 0.017353208225632903
Epoch: 32 Idx: 5000 Loss: 0.010064832183477163
Epoch: 33 Idx: 0 Loss: 0.01663623301535129
Epoch: 33 Idx: 5000 Loss: 0.013663639864542665
Epoch: 34 Idx: 0 Loss: 0.018355323139286485
Epoch: 34 Idx: 5000 Loss: 0.01168762107108546
Epoch: 35 Idx: 0 Loss: 0.015425842145044206
Epoch: 35 Idx: 5000 Loss: 0.01829189374850533
Epoch: 36 Idx: 0 Loss: 0.01912725759258179
Epoch: 36 Idx: 5000 Loss: 0.009617994999574227
Epoch: 37 Idx: 0 Loss: 0.019706393669691975
Epoch: 37 Idx: 5000 Loss: 0.006671093231387454
Epoch: 38 Idx: 0 Loss: 0.010011026129325369
Epoch: 38 Idx: 5000 Loss: 0.04445908503640106
Epoch: 39 Idx: 0 Loss: 0.01755566416061699
Epoch: 39 Idx: 5000 Loss: 0.01828509847718549
Epoch: 40 Idx: 0 Loss: 0.02352995997905459
Epoch: 40 Idx: 5000 Loss: 0.005458476951802192
Epoch: 41 Idx: 0 Loss: 0.01778878564698036
Epoch: 41 Idx: 5000 Loss: 0.028378381643893304
Epoch: 42 Idx: 0 Loss: 0.008595929872030113
Epoch: 42 Idx: 5000 Loss: 0.011227491126001325
Epoch: 43 Idx: 0 Loss: 0.01609095963814474
Epoch: 43 Idx: 5000 Loss: 0.013919301335393108
Epoch: 44 Idx: 0 Loss: 0.03046241179400254
Epoch: 44 Idx: 5000 Loss: 0.029366475749011103
Epoch: 45 Idx: 0 Loss: 0.05766543965356395
Epoch: 45 Idx: 5000 Loss: 0.012559860583405089
Epoch: 46 Idx: 0 Loss: 0.018784753554385136
Epoch: 46 Idx: 5000 Loss: 0.011944436590727057
Epoch: 47 Idx: 0 Loss: 0.006873227075699222
Epoch: 47 Idx: 5000 Loss: 0.0317969401689983
Epoch: 48 Idx: 0 Loss: 0.018137786012119062
Epoch: 48 Idx: 5000 Loss: 0.01793243478837994
Epoch: 49 Idx: 0 Loss: 0.008426996842792672
Epoch: 49 Idx: 5000 Loss: 0.015448279463726974
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.16731685572287958
Epoch: 0 Idx: 5000 Loss: 0.012895423372183735
Epoch: 1 Idx: 0 Loss: 0.026641726888124606
Epoch: 1 Idx: 5000 Loss: 0.01626193505829623
Epoch: 2 Idx: 0 Loss: 0.006882801047665726
Epoch: 2 Idx: 5000 Loss: 0.01750893494390466
Epoch: 3 Idx: 0 Loss: 0.01225221559581496
Epoch: 3 Idx: 5000 Loss: 0.013534514790162162
Epoch: 4 Idx: 0 Loss: 0.015484290679959522
Epoch: 4 Idx: 5000 Loss: 0.030054932105827385
Epoch: 5 Idx: 0 Loss: 0.012522685030547454
Epoch: 5 Idx: 5000 Loss: 0.025269409478001277
Epoch: 6 Idx: 0 Loss: 0.011280964314389717
Epoch: 6 Idx: 5000 Loss: 0.009729712515488499
Epoch: 7 Idx: 0 Loss: 0.014386593771566907
Epoch: 7 Idx: 5000 Loss: 0.022555587518911742
Epoch: 8 Idx: 0 Loss: 0.020633313268950383
Epoch: 8 Idx: 5000 Loss: 0.022193945522848455
Epoch: 9 Idx: 0 Loss: 0.00898075970747426
Epoch: 9 Idx: 5000 Loss: 0.014814650174421672
Epoch: 10 Idx: 0 Loss: 0.02572948362064262
Epoch: 10 Idx: 5000 Loss: 0.010213503391483962
Epoch: 11 Idx: 0 Loss: 0.006874016128548091
Epoch: 11 Idx: 5000 Loss: 0.00876612488284154
Epoch: 12 Idx: 0 Loss: 0.019533640871926498
Epoch: 12 Idx: 5000 Loss: 0.012864830402534423
Epoch: 13 Idx: 0 Loss: 0.010716294347951821
Epoch: 13 Idx: 5000 Loss: 0.007851303396055961
Epoch: 14 Idx: 0 Loss: 0.01216136669941425
Epoch: 14 Idx: 5000 Loss: 0.029430586938579965
Epoch: 15 Idx: 0 Loss: 0.01370907257418545
Epoch: 15 Idx: 5000 Loss: 0.021684016269590378
Epoch: 16 Idx: 0 Loss: 0.0164673831359623
Epoch: 16 Idx: 5000 Loss: 0.015124938001497478
Epoch: 17 Idx: 0 Loss: 0.017565102019713667
Epoch: 17 Idx: 5000 Loss: 0.01995371528818535
Epoch: 18 Idx: 0 Loss: 0.01837161005029773
Epoch: 18 Idx: 5000 Loss: 0.009417208031401269
Epoch: 19 Idx: 0 Loss: 0.012565546806730072
Epoch: 19 Idx: 5000 Loss: 0.011708479011704971
Epoch: 20 Idx: 0 Loss: 0.009094804100633576
Epoch: 20 Idx: 5000 Loss: 0.017689120687359918
Epoch: 21 Idx: 0 Loss: 0.015583453510116963
Epoch: 21 Idx: 5000 Loss: 0.018156115417596375
Epoch: 22 Idx: 0 Loss: 0.00776833621379279
Epoch: 22 Idx: 5000 Loss: 0.015270742474273848
Epoch: 23 Idx: 0 Loss: 0.006949336235672885
Epoch: 23 Idx: 5000 Loss: 0.014332076303790662
Epoch: 24 Idx: 0 Loss: 0.00851364161810677
Epoch: 24 Idx: 5000 Loss: 0.008614548517132614
Epoch: 25 Idx: 0 Loss: 0.007975403630179633
Epoch: 25 Idx: 5000 Loss: 0.027481303191957414
Epoch: 26 Idx: 0 Loss: 0.014164435563347549
Epoch: 26 Idx: 5000 Loss: 0.004659700571673444
Epoch: 27 Idx: 0 Loss: 0.021779603331556822
Epoch: 27 Idx: 5000 Loss: 0.010089986249331467
Epoch: 28 Idx: 0 Loss: 0.04084302929856462
Epoch: 28 Idx: 5000 Loss: 0.009382681210622319
Epoch: 29 Idx: 0 Loss: 0.007246003621586205
Epoch: 29 Idx: 5000 Loss: 0.018531281076192865
Epoch: 30 Idx: 0 Loss: 0.012710027358465749
Epoch: 30 Idx: 5000 Loss: 0.020336508936928285
Epoch: 31 Idx: 0 Loss: 0.005460840575396787
Epoch: 31 Idx: 5000 Loss: 0.013939448200745027
Epoch: 32 Idx: 0 Loss: 0.03299515686075653
Epoch: 32 Idx: 5000 Loss: 0.006100818910515989
Epoch: 33 Idx: 0 Loss: 0.00541719760381176
Epoch: 33 Idx: 5000 Loss: 0.013769168371075984
Epoch: 34 Idx: 0 Loss: 0.016306763508339043
Epoch: 34 Idx: 5000 Loss: 0.03530958041196687
Epoch: 35 Idx: 0 Loss: 0.00646294650676023
Epoch: 35 Idx: 5000 Loss: 0.011203277988989149
Epoch: 36 Idx: 0 Loss: 0.013753193806902202
Epoch: 36 Idx: 5000 Loss: 0.009030170281695438
Epoch: 37 Idx: 0 Loss: 0.009689308892596844
Epoch: 37 Idx: 5000 Loss: 0.009874275159590912
Epoch: 38 Idx: 0 Loss: 0.020401715898939306
Epoch: 38 Idx: 5000 Loss: 0.011540150778513239
Epoch: 39 Idx: 0 Loss: 0.01217780699628829
Epoch: 39 Idx: 5000 Loss: 0.01714280230792442
Epoch: 40 Idx: 0 Loss: 0.011395111737611777
Epoch: 40 Idx: 5000 Loss: 0.026425727308649782
Epoch: 41 Idx: 0 Loss: 0.015567449236294825
Epoch: 41 Idx: 5000 Loss: 0.027168338842437002
Epoch: 42 Idx: 0 Loss: 0.03210612431695645
Epoch: 42 Idx: 5000 Loss: 0.022443090062871568
Epoch: 43 Idx: 0 Loss: 0.00677123692163127
Epoch: 43 Idx: 5000 Loss: 0.017617564944184518
Epoch: 44 Idx: 0 Loss: 0.012348133651253996
Epoch: 44 Idx: 5000 Loss: 0.02359994446462648
Epoch: 45 Idx: 0 Loss: 0.01752166214469213
Epoch: 45 Idx: 5000 Loss: 0.013421218385472063
Epoch: 46 Idx: 0 Loss: 0.013797204965823973
Epoch: 46 Idx: 5000 Loss: 0.01715010458894766
Epoch: 47 Idx: 0 Loss: 0.009793728316861997
Epoch: 47 Idx: 5000 Loss: 0.015884172245759096
Epoch: 48 Idx: 0 Loss: 0.01910297925286563
Epoch: 48 Idx: 5000 Loss: 0.01849009650279377
Epoch: 49 Idx: 0 Loss: 0.01747259174510485
Epoch: 49 Idx: 5000 Loss: 0.007152091843197964
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.1846080488897579
Epoch: 0 Idx: 5000 Loss: 0.012299049725922854
Epoch: 1 Idx: 0 Loss: 0.024619820918258737
Epoch: 1 Idx: 5000 Loss: 0.011318393092888604
Epoch: 2 Idx: 0 Loss: 0.016373311018863718
Epoch: 2 Idx: 5000 Loss: 0.023509402464192607
Epoch: 3 Idx: 0 Loss: 0.027663024912598318
Epoch: 3 Idx: 5000 Loss: 0.019910048575637683
Epoch: 4 Idx: 0 Loss: 0.014000345759491469
Epoch: 4 Idx: 5000 Loss: 0.017326464839170226
Epoch: 5 Idx: 0 Loss: 0.011732804768377656
Epoch: 5 Idx: 5000 Loss: 0.012633518588336428
Epoch: 6 Idx: 0 Loss: 0.00834301043740717
Epoch: 6 Idx: 5000 Loss: 0.025234176248210005
Epoch: 7 Idx: 0 Loss: 0.011903452902291839
Epoch: 7 Idx: 5000 Loss: 0.007282566682046784
Epoch: 8 Idx: 0 Loss: 0.01825593536319301
Epoch: 8 Idx: 5000 Loss: 0.008949833696566848
Epoch: 9 Idx: 0 Loss: 0.031659503140252204
Epoch: 9 Idx: 5000 Loss: 0.01658455101443593
Epoch: 10 Idx: 0 Loss: 0.011409780972624812
Epoch: 10 Idx: 5000 Loss: 0.007656692876467208
Epoch: 11 Idx: 0 Loss: 0.015708172803556762
Epoch: 11 Idx: 5000 Loss: 0.008879470203376271
Epoch: 12 Idx: 0 Loss: 0.01652560259170128
Epoch: 12 Idx: 5000 Loss: 0.01948551621776113
Epoch: 13 Idx: 0 Loss: 0.023286861370201566
Epoch: 13 Idx: 5000 Loss: 0.020860595941695953
Epoch: 14 Idx: 0 Loss: 0.008251432509420738
Epoch: 14 Idx: 5000 Loss: 0.015127414294468684
Epoch: 15 Idx: 0 Loss: 0.005321221772445242
Epoch: 15 Idx: 5000 Loss: 0.011120726979056472
Epoch: 16 Idx: 0 Loss: 0.013418175759617228
Epoch: 16 Idx: 5000 Loss: 0.037850586263925276
Epoch: 17 Idx: 0 Loss: 0.00943860160601037
Epoch: 17 Idx: 5000 Loss: 0.011832721074936079
Epoch: 18 Idx: 0 Loss: 0.013635499118417611
Epoch: 18 Idx: 5000 Loss: 0.02405334844791292
Epoch: 19 Idx: 0 Loss: 0.01891450433809516
Epoch: 19 Idx: 5000 Loss: 0.01631736378752916
Epoch: 20 Idx: 0 Loss: 0.029155887215535407
Epoch: 20 Idx: 5000 Loss: 0.029523197678479142
Epoch: 21 Idx: 0 Loss: 0.008307668172847922
Epoch: 21 Idx: 5000 Loss: 0.01445895553357553
Epoch: 22 Idx: 0 Loss: 0.022299955158013623
Epoch: 22 Idx: 5000 Loss: 0.01273146221870644
Epoch: 23 Idx: 0 Loss: 0.011774983484558214
Epoch: 23 Idx: 5000 Loss: 0.01737292147607667
Epoch: 24 Idx: 0 Loss: 0.022041995240874822
Epoch: 24 Idx: 5000 Loss: 0.009709395382096678
Epoch: 25 Idx: 0 Loss: 0.012376886287465493
Epoch: 25 Idx: 5000 Loss: 0.01743227534098485
Epoch: 26 Idx: 0 Loss: 0.029330168861222285
Epoch: 26 Idx: 5000 Loss: 0.013777483391990482
Epoch: 27 Idx: 0 Loss: 0.024879283783566693
Epoch: 27 Idx: 5000 Loss: 0.012146616977104596
Epoch: 28 Idx: 0 Loss: 0.012730664651619301
Epoch: 28 Idx: 5000 Loss: 0.012098940499493418
Epoch: 29 Idx: 0 Loss: 0.007492552591629658
Epoch: 29 Idx: 5000 Loss: 0.01312459813903934
Epoch: 30 Idx: 0 Loss: 0.01826404260547709
Epoch: 30 Idx: 5000 Loss: 0.012147678293684322
Epoch: 31 Idx: 0 Loss: 0.012616673844844939
Epoch: 31 Idx: 5000 Loss: 0.019431954731764352
Epoch: 32 Idx: 0 Loss: 0.021003585379242313
Epoch: 32 Idx: 5000 Loss: 0.03379137556309156
Epoch: 33 Idx: 0 Loss: 0.014190377162689033
Epoch: 33 Idx: 5000 Loss: 0.009197648940369795
Epoch: 34 Idx: 0 Loss: 0.012062300988191412
Epoch: 34 Idx: 5000 Loss: 0.006643374522800531
Epoch: 35 Idx: 0 Loss: 0.008336103012657903
Epoch: 35 Idx: 5000 Loss: 0.013339644871590232
Epoch: 36 Idx: 0 Loss: 0.009735727924489637
Epoch: 36 Idx: 5000 Loss: 0.008947684713082486
Epoch: 37 Idx: 0 Loss: 0.017871279938011596
Epoch: 37 Idx: 5000 Loss: 0.013727010760314821
Epoch: 38 Idx: 0 Loss: 0.009007960201666242
Epoch: 38 Idx: 5000 Loss: 0.006109615941518917
Epoch: 39 Idx: 0 Loss: 0.027059056739177214
Epoch: 39 Idx: 5000 Loss: 0.030797146954614343
Epoch: 40 Idx: 0 Loss: 0.00954754231552161
Epoch: 40 Idx: 5000 Loss: 0.012634540938521401
Epoch: 41 Idx: 0 Loss: 0.015225482793808722
Epoch: 41 Idx: 5000 Loss: 0.011828117018018194
Epoch: 42 Idx: 0 Loss: 0.02532904068845134
Epoch: 42 Idx: 5000 Loss: 0.022632594818361745
Epoch: 43 Idx: 0 Loss: 0.024594560448329524
Epoch: 43 Idx: 5000 Loss: 0.024061180463779516
Epoch: 44 Idx: 0 Loss: 0.01885289230153605
Epoch: 44 Idx: 5000 Loss: 0.021681989853773728
Epoch: 45 Idx: 0 Loss: 0.03017266438226347
Epoch: 45 Idx: 5000 Loss: 0.01257468446476963
Epoch: 46 Idx: 0 Loss: 0.01358180734147464
Epoch: 46 Idx: 5000 Loss: 0.009896042586385968
Epoch: 47 Idx: 0 Loss: 0.03458102099947215
Epoch: 47 Idx: 5000 Loss: 0.017510992228906126
Epoch: 48 Idx: 0 Loss: 0.01573322323002979
Epoch: 48 Idx: 5000 Loss: 0.01230753732774684
Epoch: 49 Idx: 0 Loss: 0.014770745973708033
Epoch: 49 Idx: 5000 Loss: 0.014530178036748886
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.23834559123079418
Epoch: 1 Idx: 0 Loss: 0.0050301641014720115
Epoch: 2 Idx: 0 Loss: 0.007331264453813038
Epoch: 3 Idx: 0 Loss: 0.02651588881263755
Epoch: 4 Idx: 0 Loss: 0.014898954452568142
Epoch: 5 Idx: 0 Loss: 0.008598583254640033
Epoch: 6 Idx: 0 Loss: 0.013893896756818649
Epoch: 7 Idx: 0 Loss: 0.008961552894112403
Epoch: 8 Idx: 0 Loss: 0.013520467091011885
Epoch: 9 Idx: 0 Loss: 0.00701604148090283
Epoch: 10 Idx: 0 Loss: 0.005319585693340482
Epoch: 11 Idx: 0 Loss: 0.010867397039937632
Epoch: 12 Idx: 0 Loss: 0.04369274727379187
Epoch: 13 Idx: 0 Loss: 0.019625360850269457
Epoch: 14 Idx: 0 Loss: 0.011930065058960588
Epoch: 15 Idx: 0 Loss: 0.024991869868761268
Epoch: 16 Idx: 0 Loss: 0.005536532628071659
Epoch: 17 Idx: 0 Loss: 0.01136533895775205
Epoch: 18 Idx: 0 Loss: 0.010709791772398506
Epoch: 19 Idx: 0 Loss: 0.006678009439381342
Epoch: 20 Idx: 0 Loss: 0.015624046477623105
Epoch: 21 Idx: 0 Loss: 0.02418944574787539
Epoch: 22 Idx: 0 Loss: 0.03466782989857888
Epoch: 23 Idx: 0 Loss: 0.009753050556207829
Epoch: 24 Idx: 0 Loss: 0.016130060661909574
Epoch: 25 Idx: 0 Loss: 0.014236443939660112
Epoch: 26 Idx: 0 Loss: 0.01197365490700444
Epoch: 27 Idx: 0 Loss: 0.010679903110708867
Epoch: 28 Idx: 0 Loss: 0.01092955163990301
Epoch: 29 Idx: 0 Loss: 0.02358164667563285
Epoch: 30 Idx: 0 Loss: 0.010071236277672783
Epoch: 31 Idx: 0 Loss: 0.013615784698839405
Epoch: 32 Idx: 0 Loss: 0.010309151076047799
Epoch: 33 Idx: 0 Loss: 0.010199190985079907
Epoch: 34 Idx: 0 Loss: 0.011133539893563325
Epoch: 35 Idx: 0 Loss: 0.017271964453274846
Epoch: 36 Idx: 0 Loss: 0.025714526204790807
Epoch: 37 Idx: 0 Loss: 0.017632750961113323
Epoch: 38 Idx: 0 Loss: 0.011502709148746931
Epoch: 39 Idx: 0 Loss: 0.04026107940739989
Epoch: 40 Idx: 0 Loss: 0.006885535281269301
Epoch: 41 Idx: 0 Loss: 0.022362706818749876
Epoch: 42 Idx: 0 Loss: 0.012170359975732303
Epoch: 43 Idx: 0 Loss: 0.015143150407790785
Epoch: 44 Idx: 0 Loss: 0.009598042107086147
Epoch: 45 Idx: 0 Loss: 0.023405601231844562
Epoch: 46 Idx: 0 Loss: 0.01898468452283058
Epoch: 47 Idx: 0 Loss: 0.015834017379048923
Epoch: 48 Idx: 0 Loss: 0.015445601001358274
Epoch: 49 Idx: 0 Loss: 0.028819790714789118
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.14132050041498057
Epoch: 0 Idx: 5000 Loss: 0.01223798652571723
Epoch: 1 Idx: 0 Loss: 0.016573581187220212
Epoch: 1 Idx: 5000 Loss: 0.01806818597203183
Epoch: 2 Idx: 0 Loss: 0.012833648882459917
Epoch: 2 Idx: 5000 Loss: 0.026772419833209604
Epoch: 3 Idx: 0 Loss: 0.008713427102668864
Epoch: 3 Idx: 5000 Loss: 0.018177454772971967
Epoch: 4 Idx: 0 Loss: 0.00975944736700024
Epoch: 4 Idx: 5000 Loss: 0.016464096328673364
Epoch: 5 Idx: 0 Loss: 0.007838676746801523
Epoch: 5 Idx: 5000 Loss: 0.019960899353212953
Epoch: 6 Idx: 0 Loss: 0.05953289354268228
Epoch: 6 Idx: 5000 Loss: 0.025124325752901182
Epoch: 7 Idx: 0 Loss: 0.025602827001607816
Epoch: 7 Idx: 5000 Loss: 0.013222002206627068
Epoch: 8 Idx: 0 Loss: 0.010446462272141637
Epoch: 8 Idx: 5000 Loss: 0.015026611691499346
Epoch: 9 Idx: 0 Loss: 0.009266684593680359
Epoch: 9 Idx: 5000 Loss: 0.021634316229410155
Epoch: 10 Idx: 0 Loss: 0.041477117666301515
Epoch: 10 Idx: 5000 Loss: 0.010367852111125429
Epoch: 11 Idx: 0 Loss: 0.016329273006654776
Epoch: 11 Idx: 5000 Loss: 0.00833772266800131
Epoch: 12 Idx: 0 Loss: 0.010875587456368904
Epoch: 12 Idx: 5000 Loss: 0.011616282307551358
Epoch: 13 Idx: 0 Loss: 0.012536899035989786
Epoch: 13 Idx: 5000 Loss: 0.01711109405954426
Epoch: 14 Idx: 0 Loss: 0.00990297897770158
Epoch: 14 Idx: 5000 Loss: 0.01825086866814231
Epoch: 15 Idx: 0 Loss: 0.012700867978179969
Epoch: 15 Idx: 5000 Loss: 0.01289666309813916
Epoch: 16 Idx: 0 Loss: 0.0037761790792052233
Epoch: 16 Idx: 5000 Loss: 0.010551871104720627
Epoch: 17 Idx: 0 Loss: 0.012871768363566629
Epoch: 17 Idx: 5000 Loss: 0.020522707031763752
Epoch: 18 Idx: 0 Loss: 0.017172088280386695
Epoch: 18 Idx: 5000 Loss: 0.009650570767169134
Epoch: 19 Idx: 0 Loss: 0.02946453584418381
Epoch: 19 Idx: 5000 Loss: 0.007908213891634394
Epoch: 20 Idx: 0 Loss: 0.011215607386961021
Epoch: 20 Idx: 5000 Loss: 0.010763937168044642
Epoch: 21 Idx: 0 Loss: 0.01965016245282863
Epoch: 21 Idx: 5000 Loss: 0.018358259664114376
Epoch: 22 Idx: 0 Loss: 0.00914939807549159
Epoch: 22 Idx: 5000 Loss: 0.01367792475560534
Epoch: 23 Idx: 0 Loss: 0.018699913338284063
Epoch: 23 Idx: 5000 Loss: 0.025181869655782445
Epoch: 24 Idx: 0 Loss: 0.014674914828084265
Epoch: 24 Idx: 5000 Loss: 0.012569365899126553
Epoch: 25 Idx: 0 Loss: 0.025236282835164964
Epoch: 25 Idx: 5000 Loss: 0.012883940011316812
Epoch: 26 Idx: 0 Loss: 0.014430822768439253
Epoch: 26 Idx: 5000 Loss: 0.00423114093905172
Epoch: 27 Idx: 0 Loss: 0.00937626999857699
Epoch: 27 Idx: 5000 Loss: 0.013780253731732315
Epoch: 28 Idx: 0 Loss: 0.025138100511966948
Epoch: 28 Idx: 5000 Loss: 0.0206854930256562
Epoch: 29 Idx: 0 Loss: 0.012742216515019713
Epoch: 29 Idx: 5000 Loss: 0.008559282569091988
Epoch: 30 Idx: 0 Loss: 0.01655154426487902
Epoch: 30 Idx: 5000 Loss: 0.005211958967480305
Epoch: 31 Idx: 0 Loss: 0.019045744621742938
Epoch: 31 Idx: 5000 Loss: 0.030827446209560603
Epoch: 32 Idx: 0 Loss: 0.009322396965303691
Epoch: 32 Idx: 5000 Loss: 0.02821048007635825
Epoch: 33 Idx: 0 Loss: 0.025028511912419883
Epoch: 33 Idx: 5000 Loss: 0.015252193885270743
Epoch: 34 Idx: 0 Loss: 0.022350537216631758
Epoch: 34 Idx: 5000 Loss: 0.029148127997225756
Epoch: 35 Idx: 0 Loss: 0.00806926045225513
Epoch: 35 Idx: 5000 Loss: 0.016616435780539573
Epoch: 36 Idx: 0 Loss: 0.014658542791052059
Epoch: 36 Idx: 5000 Loss: 0.010001788682283186
Epoch: 37 Idx: 0 Loss: 0.009151371874609113
Epoch: 37 Idx: 5000 Loss: 0.029459687567045433
Epoch: 38 Idx: 0 Loss: 0.008260107338868405
Epoch: 38 Idx: 5000 Loss: 0.018724748466368252
Epoch: 39 Idx: 0 Loss: 0.006967634447812918
Epoch: 39 Idx: 5000 Loss: 0.01197394165954249
Epoch: 40 Idx: 0 Loss: 0.011258684771643414
Epoch: 40 Idx: 5000 Loss: 0.016864417538202274
Epoch: 41 Idx: 0 Loss: 0.012628205726530402
Epoch: 41 Idx: 5000 Loss: 0.009809683248419115
Epoch: 42 Idx: 0 Loss: 0.013019913467329456
Epoch: 42 Idx: 5000 Loss: 0.02452518790186406
Epoch: 43 Idx: 0 Loss: 0.03161656431869846
Epoch: 43 Idx: 5000 Loss: 0.012324972707051685
Epoch: 44 Idx: 0 Loss: 0.0076198953585031575
Epoch: 44 Idx: 5000 Loss: 0.050233094300604984
Epoch: 45 Idx: 0 Loss: 0.021298723592420972
Epoch: 45 Idx: 5000 Loss: 0.025253073837410416
Epoch: 46 Idx: 0 Loss: 0.009278672474929122
Epoch: 46 Idx: 5000 Loss: 0.007210814114997315
Epoch: 47 Idx: 0 Loss: 0.011699483388840044
Epoch: 47 Idx: 5000 Loss: 0.02566657184981668
Epoch: 48 Idx: 0 Loss: 0.009435972942582669
Epoch: 48 Idx: 5000 Loss: 0.015736688350095018
Epoch: 49 Idx: 0 Loss: 0.009786652477796986
Epoch: 49 Idx: 5000 Loss: 0.027390922223898127
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.21586757937264367
Epoch: 1 Idx: 0 Loss: 0.009066427564077993
Epoch: 2 Idx: 0 Loss: 0.030374520710152626
Epoch: 3 Idx: 0 Loss: 0.015195670574269465
Epoch: 4 Idx: 0 Loss: 0.01650368597360444
Epoch: 5 Idx: 0 Loss: 0.018293622162701393
Epoch: 6 Idx: 0 Loss: 0.013007456505000263
Epoch: 7 Idx: 0 Loss: 0.009013868506389102
Epoch: 8 Idx: 0 Loss: 0.01850368126986227
Epoch: 9 Idx: 0 Loss: 0.007215126122032723
Epoch: 10 Idx: 0 Loss: 0.010444955734915856
Epoch: 11 Idx: 0 Loss: 0.018738743418142155
Epoch: 12 Idx: 0 Loss: 0.018800384782138184
Epoch: 13 Idx: 0 Loss: 0.022613461858410365
Epoch: 14 Idx: 0 Loss: 0.006417913696929322
Epoch: 15 Idx: 0 Loss: 0.01363273089181084
Epoch: 16 Idx: 0 Loss: 0.010959519015701483
Epoch: 17 Idx: 0 Loss: 0.023514414201989062
Epoch: 18 Idx: 0 Loss: 0.021022333399327287
Epoch: 19 Idx: 0 Loss: 0.01643969930421149
Epoch: 20 Idx: 0 Loss: 0.010373022123343982
Epoch: 21 Idx: 0 Loss: 0.0068111486343248335
Epoch: 22 Idx: 0 Loss: 0.004459495883571325
Epoch: 23 Idx: 0 Loss: 0.01233986302253042
Epoch: 24 Idx: 0 Loss: 0.018632487946000743
Epoch: 25 Idx: 0 Loss: 0.016469146588138025
Epoch: 26 Idx: 0 Loss: 0.018129647834985885
Epoch: 27 Idx: 0 Loss: 0.010464057062728096
Epoch: 28 Idx: 0 Loss: 0.009002720671701207
Epoch: 29 Idx: 0 Loss: 0.011451744472843098
Epoch: 30 Idx: 0 Loss: 0.013142407099018816
Epoch: 31 Idx: 0 Loss: 0.018089356729917898
Epoch: 32 Idx: 0 Loss: 0.006665119217009067
Epoch: 33 Idx: 0 Loss: 0.00796882841730661
Epoch: 34 Idx: 0 Loss: 0.03414963696259622
Epoch: 35 Idx: 0 Loss: 0.022133082268182985
Epoch: 36 Idx: 0 Loss: 0.012269885732315982
Epoch: 37 Idx: 0 Loss: 0.0178071922837231
Epoch: 38 Idx: 0 Loss: 0.009400458306140204
Epoch: 39 Idx: 0 Loss: 0.008580720968908228
Epoch: 40 Idx: 0 Loss: 0.025113571718256237
Epoch: 41 Idx: 0 Loss: 0.00933313613442108
Epoch: 42 Idx: 0 Loss: 0.017140792940080248
Epoch: 43 Idx: 0 Loss: 0.014544029366977025
Epoch: 44 Idx: 0 Loss: 0.011559469737607136
Epoch: 45 Idx: 0 Loss: 0.010840726881342612
Epoch: 46 Idx: 0 Loss: 0.027611711530291107
Epoch: 47 Idx: 0 Loss: 0.012135450169754128
Epoch: 48 Idx: 0 Loss: 0.02308223713507704
Epoch: 49 Idx: 0 Loss: 0.01801240018421682
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7857142857142857, 0.7333333333333333, 0.7586206896551724, 0.7432432432432431, 0.7746478873239436)
Performance for  [('ekaw', 'sigkdd')] is : (0.7692307692307693, 0.9090909090909091, 0.8333333333333333, 0.8771929824561403, 0.7936507936507936)
Performance for  [('conference', 'edas')] is : (0.875, 0.8235294117647058, 0.8484848484848485, 0.8333333333333333, 0.8641975308641975)
Performance for  [('cmt', 'ekaw')] is : (0.5, 0.5454545454545454, 0.5217391304347826, 0.5357142857142857, 0.5084745762711864)
Performance for  [('confOf', 'edas')] is : (0.6, 0.631578947368421, 0.6153846153846154, 0.625, 0.6060606060606061)
Performance for  [('iasted', 'sigkdd')] is : (0.6470588235294118, 0.7333333333333333, 0.6875, 0.7142857142857143, 0.6626506024096386)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.6666666666666666, 0.8, 0.7142857142857142, 0.9090909090909091)
Final Results: [0.73957198 0.72042674 0.72358037 0.72043647 0.73125327]
Threshold:  0.906
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2ba40ac5daf0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc238>
Subject: Job 4142693: <python main.py 3 18 False False> in cluster <dcc> Done

Job <python main.py 3 18 False False> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:23 2020
Job was executed on host(s) <dccxc238>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 07:37:31 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 07:37:31 2020
Terminated at Wed Sep 16 15:43:40 2020
Results reported at Wed Sep 16 15:43:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 3 18 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   29094.30 sec.
    Max Memory :                                 4211 MB
    Average Memory :                             4062.56 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39206.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   29174 sec.
    Turnaround time :                            31517 sec.

The output (if any) is above this job summary.

