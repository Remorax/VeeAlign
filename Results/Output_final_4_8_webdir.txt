2020-09-16 10:12:31.988576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:12:40.844818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 10:12:40.960949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:14:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 10:12:40.961051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:12:40.963080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 10:12:40.964682: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 10:12:40.965173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 10:12:40.967227: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 10:12:40.968796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 10:12:40.969030: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib
2020-09-16 10:12:40.969052: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 10:12:40.969491: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 10:12:41.011782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600110000 Hz
2020-09-16 10:12:41.012087: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ad525f8f00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 10:12:41.012110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 10:12:41.015424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 10:12:41.015490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/naveen9/arvind/VeeAlign/
Ontologies being aligned are:  [('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1887927062235773
Epoch: 0 Idx: 5000 Loss: 0.008719200721593602
Epoch: 1 Idx: 0 Loss: 0.012941023178006435
Epoch: 1 Idx: 5000 Loss: 0.010622291679107929
Epoch: 2 Idx: 0 Loss: 0.01892697527357585
Epoch: 2 Idx: 5000 Loss: 0.025974383197067172
Epoch: 3 Idx: 0 Loss: 0.016042605148180226
Epoch: 3 Idx: 5000 Loss: 0.014498519525021408
Epoch: 4 Idx: 0 Loss: 0.01545820625223824
Epoch: 4 Idx: 5000 Loss: 0.018379792245208193
Epoch: 5 Idx: 0 Loss: 0.011789779937334766
Epoch: 5 Idx: 5000 Loss: 0.025923042669848483
Epoch: 6 Idx: 0 Loss: 0.00912515821721926
Epoch: 6 Idx: 5000 Loss: 0.0148624799679095
Epoch: 7 Idx: 0 Loss: 0.009666446006510412
Epoch: 7 Idx: 5000 Loss: 0.031052751280907516
Epoch: 8 Idx: 0 Loss: 0.014965356633409758
Epoch: 8 Idx: 5000 Loss: 0.013016191455715972
Epoch: 9 Idx: 0 Loss: 0.009491036283647846
Epoch: 9 Idx: 5000 Loss: 0.012733689957455538
Epoch: 10 Idx: 0 Loss: 0.007403996030156075
Epoch: 10 Idx: 5000 Loss: 0.020147920607589073
Epoch: 11 Idx: 0 Loss: 0.010600597061606232
Epoch: 11 Idx: 5000 Loss: 0.01622161659244576
Epoch: 12 Idx: 0 Loss: 0.01550897674198067
Epoch: 12 Idx: 5000 Loss: 0.00943014998142518
Epoch: 13 Idx: 0 Loss: 0.03730183355522916
Epoch: 13 Idx: 5000 Loss: 0.006929692708026871
Epoch: 14 Idx: 0 Loss: 0.0242784634936902
Epoch: 14 Idx: 5000 Loss: 0.02647202314835078
Epoch: 15 Idx: 0 Loss: 0.02457940707111595
Epoch: 15 Idx: 5000 Loss: 0.0051507865206674155
Epoch: 16 Idx: 0 Loss: 0.013324371857362939
Epoch: 16 Idx: 5000 Loss: 0.028823717811165012
Epoch: 17 Idx: 0 Loss: 0.014605612756753216
Epoch: 17 Idx: 5000 Loss: 0.028458973196782443
Epoch: 18 Idx: 0 Loss: 0.015227309465912076
Epoch: 18 Idx: 5000 Loss: 0.039762049555730206
Epoch: 19 Idx: 0 Loss: 0.020731877791233963
Epoch: 19 Idx: 5000 Loss: 0.010478269965710456
Epoch: 20 Idx: 0 Loss: 0.008755648179198194
Epoch: 20 Idx: 5000 Loss: 0.03040813997287074
Epoch: 21 Idx: 0 Loss: 0.010881776482533039
Epoch: 21 Idx: 5000 Loss: 0.012215417754702515
Epoch: 22 Idx: 0 Loss: 0.007706029236321488
Epoch: 22 Idx: 5000 Loss: 0.030602035193774788
Epoch: 23 Idx: 0 Loss: 0.014683022263402382
Epoch: 23 Idx: 5000 Loss: 0.016872260390241027
Epoch: 24 Idx: 0 Loss: 0.011683833141379135
Epoch: 24 Idx: 5000 Loss: 0.00921127458448119
Epoch: 25 Idx: 0 Loss: 0.008307457667278466
Epoch: 25 Idx: 5000 Loss: 0.041022810920655094
Epoch: 26 Idx: 0 Loss: 0.014163093435140543
Epoch: 26 Idx: 5000 Loss: 0.030764084097495394
Epoch: 27 Idx: 0 Loss: 0.004956729662590678
Epoch: 27 Idx: 5000 Loss: 0.01829614339653108
Epoch: 28 Idx: 0 Loss: 0.019726707743345114
Epoch: 28 Idx: 5000 Loss: 0.01805842796231403
Epoch: 29 Idx: 0 Loss: 0.018447073010591817
Epoch: 29 Idx: 5000 Loss: 0.011360446653500727
Epoch: 30 Idx: 0 Loss: 0.05630521104760772
Epoch: 30 Idx: 5000 Loss: 0.00687342891541551
Epoch: 31 Idx: 0 Loss: 0.010401046226613262
Epoch: 31 Idx: 5000 Loss: 0.012771807903372834
Epoch: 32 Idx: 0 Loss: 0.026145178888761184
Epoch: 32 Idx: 5000 Loss: 0.013182146415795412
Epoch: 33 Idx: 0 Loss: 0.014107456275972563
Epoch: 33 Idx: 5000 Loss: 0.009270551882785187
Epoch: 34 Idx: 0 Loss: 0.003869645150398807
Epoch: 34 Idx: 5000 Loss: 0.018508806981500203
Epoch: 35 Idx: 0 Loss: 0.012778705465226359
Epoch: 35 Idx: 5000 Loss: 0.012610862093580522
Epoch: 36 Idx: 0 Loss: 0.03767765070715501
Epoch: 36 Idx: 5000 Loss: 0.012371625376124802
Epoch: 37 Idx: 0 Loss: 0.029702416790590894
Epoch: 37 Idx: 5000 Loss: 0.02138263936681101
Epoch: 38 Idx: 0 Loss: 0.009531088103462053
Epoch: 38 Idx: 5000 Loss: 0.02157415695352359
Epoch: 39 Idx: 0 Loss: 0.01538358544373706
Epoch: 39 Idx: 5000 Loss: 0.03567384981804761
Epoch: 40 Idx: 0 Loss: 0.007694026367836815
Epoch: 40 Idx: 5000 Loss: 0.032550103832439024
Epoch: 41 Idx: 0 Loss: 0.011156585075915753
Epoch: 41 Idx: 5000 Loss: 0.011038724656023399
Epoch: 42 Idx: 0 Loss: 0.012778146623569811
Epoch: 42 Idx: 5000 Loss: 0.008589089922436803
Epoch: 43 Idx: 0 Loss: 0.012343050827358086
Epoch: 43 Idx: 5000 Loss: 0.021587683714749607
Epoch: 44 Idx: 0 Loss: 0.02409113919800663
Epoch: 44 Idx: 5000 Loss: 0.008809586982600422
Epoch: 45 Idx: 0 Loss: 0.011797198575504162
Epoch: 45 Idx: 5000 Loss: 0.015592302279118193
Epoch: 46 Idx: 0 Loss: 0.02384344799209757
Epoch: 46 Idx: 5000 Loss: 0.012728494144407243
Epoch: 47 Idx: 0 Loss: 0.007741446127448576
Epoch: 47 Idx: 5000 Loss: 0.02312163186679964
Epoch: 48 Idx: 0 Loss: 0.005089507941576152
Epoch: 48 Idx: 5000 Loss: 0.010195792131801133
Epoch: 49 Idx: 0 Loss: 0.03116387106400452
Epoch: 49 Idx: 5000 Loss: 0.021060766958726107
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.20917109845591186
Epoch: 0 Idx: 5000 Loss: 0.046744864773657226
Epoch: 1 Idx: 0 Loss: 0.04169672927841586
Epoch: 1 Idx: 5000 Loss: 0.05451635449795016
Epoch: 2 Idx: 0 Loss: 0.02082986810809311
Epoch: 2 Idx: 5000 Loss: 0.009468843364693714
Epoch: 3 Idx: 0 Loss: 0.009971330546225449
Epoch: 3 Idx: 5000 Loss: 0.02316274662073174
Epoch: 4 Idx: 0 Loss: 0.007702295453570892
Epoch: 4 Idx: 5000 Loss: 0.00561055143224554
Epoch: 5 Idx: 0 Loss: 0.015331646629485697
Epoch: 5 Idx: 5000 Loss: 0.0287445355549398
Epoch: 6 Idx: 0 Loss: 0.006410449725464971
Epoch: 6 Idx: 5000 Loss: 0.015476942289465799
Epoch: 7 Idx: 0 Loss: 0.01260872986581106
Epoch: 7 Idx: 5000 Loss: 0.007553858693571441
Epoch: 8 Idx: 0 Loss: 0.025337316452743286
Epoch: 8 Idx: 5000 Loss: 0.029532018743545614
Epoch: 9 Idx: 0 Loss: 0.01142430364798274
Epoch: 9 Idx: 5000 Loss: 0.03551659416360296
Epoch: 10 Idx: 0 Loss: 0.015992866271907977
Epoch: 10 Idx: 5000 Loss: 0.021152096685366797
Epoch: 11 Idx: 0 Loss: 0.012757759443615537
Epoch: 11 Idx: 5000 Loss: 0.01334237424205964
Epoch: 12 Idx: 0 Loss: 0.029850870459100617
Epoch: 12 Idx: 5000 Loss: 0.009667983892724125
Epoch: 13 Idx: 0 Loss: 0.012600770730339165
Epoch: 13 Idx: 5000 Loss: 0.010762883785405384
Epoch: 14 Idx: 0 Loss: 0.017605148370038223
Epoch: 14 Idx: 5000 Loss: 0.023796892984128282
Epoch: 15 Idx: 0 Loss: 0.024990911219198976
Epoch: 15 Idx: 5000 Loss: 0.012584945164376225
Epoch: 16 Idx: 0 Loss: 0.009497149365170971
Epoch: 16 Idx: 5000 Loss: 0.019451319688901063
Epoch: 17 Idx: 0 Loss: 0.008549305748762961
Epoch: 17 Idx: 5000 Loss: 0.025159607271956735
Epoch: 18 Idx: 0 Loss: 0.01800145721170165
Epoch: 18 Idx: 5000 Loss: 0.010138184725684634
Epoch: 19 Idx: 0 Loss: 0.006997814534464427
Epoch: 19 Idx: 5000 Loss: 0.010645214280104606
Epoch: 20 Idx: 0 Loss: 0.04019277092448485
Epoch: 20 Idx: 5000 Loss: 0.016503991570927502
Epoch: 21 Idx: 0 Loss: 0.009161387675374028
Epoch: 21 Idx: 5000 Loss: 0.01606060276634535
Epoch: 22 Idx: 0 Loss: 0.009497708073066456
Epoch: 22 Idx: 5000 Loss: 0.022509417329453368
Epoch: 23 Idx: 0 Loss: 0.01721126673641858
Epoch: 23 Idx: 5000 Loss: 0.013555785172657271
Epoch: 24 Idx: 0 Loss: 0.028208456519786804
Epoch: 24 Idx: 5000 Loss: 0.019885419606151155
Epoch: 25 Idx: 0 Loss: 0.05857503214138462
Epoch: 25 Idx: 5000 Loss: 0.027010350352657135
Epoch: 26 Idx: 0 Loss: 0.01339906706137316
Epoch: 26 Idx: 5000 Loss: 0.005398885774459395
Epoch: 27 Idx: 0 Loss: 0.02304338927602834
Epoch: 27 Idx: 5000 Loss: 0.011438403217064484
Epoch: 28 Idx: 0 Loss: 0.016272476023410525
Epoch: 28 Idx: 5000 Loss: 0.013986914056804491
Epoch: 29 Idx: 0 Loss: 0.03573187066964073
Epoch: 29 Idx: 5000 Loss: 0.019057436309672576
Epoch: 30 Idx: 0 Loss: 0.016118654131484066
Epoch: 30 Idx: 5000 Loss: 0.015082551565128225
Epoch: 31 Idx: 0 Loss: 0.023497900378772967
Epoch: 31 Idx: 5000 Loss: 0.04754251340416226
Epoch: 32 Idx: 0 Loss: 0.013567911261425003
Epoch: 32 Idx: 5000 Loss: 0.006455756650894445
Epoch: 33 Idx: 0 Loss: 0.01475611165727199
Epoch: 33 Idx: 5000 Loss: 0.006854470424045661
Epoch: 34 Idx: 0 Loss: 0.007937906611498192
Epoch: 34 Idx: 5000 Loss: 0.014798649784107238
Epoch: 35 Idx: 0 Loss: 0.009281062777292662
Epoch: 35 Idx: 5000 Loss: 0.02711026388489603
Epoch: 36 Idx: 0 Loss: 0.018492674765872068
Epoch: 36 Idx: 5000 Loss: 0.013519995229911963
Epoch: 37 Idx: 0 Loss: 0.01766306822690091
Epoch: 37 Idx: 5000 Loss: 0.012688157335876225
Epoch: 38 Idx: 0 Loss: 0.010484925595773898
Epoch: 38 Idx: 5000 Loss: 0.016152375373756786
Epoch: 39 Idx: 0 Loss: 0.007126552713270916
Epoch: 39 Idx: 5000 Loss: 0.014158700090995378
Epoch: 40 Idx: 0 Loss: 0.018381251792383698
Epoch: 40 Idx: 5000 Loss: 0.01254447505261213
Epoch: 41 Idx: 0 Loss: 0.00846636879474561
Epoch: 41 Idx: 5000 Loss: 0.0176695345321022
Epoch: 42 Idx: 0 Loss: 0.030384555403143533
Epoch: 42 Idx: 5000 Loss: 0.014804697932828986
Epoch: 43 Idx: 0 Loss: 0.010822057285351318
Epoch: 43 Idx: 5000 Loss: 0.02265086646575721
Epoch: 44 Idx: 0 Loss: 0.011106706476361326
Epoch: 44 Idx: 5000 Loss: 0.014855822924115905
Epoch: 45 Idx: 0 Loss: 0.010913583152243594
Epoch: 45 Idx: 5000 Loss: 0.013038615509956638
Epoch: 46 Idx: 0 Loss: 0.004241004877338106
Epoch: 46 Idx: 5000 Loss: 0.02302923386008244
Epoch: 47 Idx: 0 Loss: 0.025069650035451918
Epoch: 47 Idx: 5000 Loss: 0.014332193009380996
Epoch: 48 Idx: 0 Loss: 0.03560124686258284
Epoch: 48 Idx: 5000 Loss: 0.015684362712491132
Epoch: 49 Idx: 0 Loss: 0.009514721834938834
Epoch: 49 Idx: 5000 Loss: 0.016612703924338487
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.1919987410429175
Epoch: 0 Idx: 5000 Loss: 0.030719166682652538
Epoch: 1 Idx: 0 Loss: 0.0214147791738692
Epoch: 1 Idx: 5000 Loss: 0.021896987505450098
Epoch: 2 Idx: 0 Loss: 0.012674308558719646
Epoch: 2 Idx: 5000 Loss: 0.01353405168516857
Epoch: 3 Idx: 0 Loss: 0.011835801363517083
Epoch: 3 Idx: 5000 Loss: 0.012052685952537456
Epoch: 4 Idx: 0 Loss: 0.009029495762604653
Epoch: 4 Idx: 5000 Loss: 0.01316547421046251
Epoch: 5 Idx: 0 Loss: 0.013016394425309082
Epoch: 5 Idx: 5000 Loss: 0.01039371750797145
Epoch: 6 Idx: 0 Loss: 0.0115511520329313
Epoch: 6 Idx: 5000 Loss: 0.014713991496838354
Epoch: 7 Idx: 0 Loss: 0.01197951175388302
Epoch: 7 Idx: 5000 Loss: 0.007278652218428006
Epoch: 8 Idx: 0 Loss: 0.007801494179336379
Epoch: 8 Idx: 5000 Loss: 0.04191788450873436
Epoch: 9 Idx: 0 Loss: 0.005789324857211001
Epoch: 9 Idx: 5000 Loss: 0.011993125449062874
Epoch: 10 Idx: 0 Loss: 0.023562472020509026
Epoch: 10 Idx: 5000 Loss: 0.010239884969011813
Epoch: 11 Idx: 0 Loss: 0.005465015667346404
Epoch: 11 Idx: 5000 Loss: 0.007145523363874521
Epoch: 12 Idx: 0 Loss: 0.01838859261892981
Epoch: 12 Idx: 5000 Loss: 0.013181160095117044
Epoch: 13 Idx: 0 Loss: 0.008793935068853436
Epoch: 13 Idx: 5000 Loss: 0.025813952550022237
Epoch: 14 Idx: 0 Loss: 0.01176571887982927
Epoch: 14 Idx: 5000 Loss: 0.012757104032360831
Epoch: 15 Idx: 0 Loss: 0.012453319823530854
Epoch: 15 Idx: 5000 Loss: 0.01961590608181471
Epoch: 16 Idx: 0 Loss: 0.009354366035058142
Epoch: 16 Idx: 5000 Loss: 0.007742669212804041
Epoch: 17 Idx: 0 Loss: 0.013609545058658391
Epoch: 17 Idx: 5000 Loss: 0.018558703392336378
Epoch: 18 Idx: 0 Loss: 0.0090154115798001
Epoch: 18 Idx: 5000 Loss: 0.013545299540601305
Epoch: 19 Idx: 0 Loss: 0.014394446162158132
Epoch: 19 Idx: 5000 Loss: 0.017716607446016837
Epoch: 20 Idx: 0 Loss: 0.00809292506081902
Epoch: 20 Idx: 5000 Loss: 0.012333785899345667
Epoch: 21 Idx: 0 Loss: 0.012287319722068205
Epoch: 21 Idx: 5000 Loss: 0.004096498867539377
Epoch: 22 Idx: 0 Loss: 0.021563001007891665
Epoch: 22 Idx: 5000 Loss: 0.006127760459371017
Epoch: 23 Idx: 0 Loss: 0.013591743518947479
Epoch: 23 Idx: 5000 Loss: 0.013121282028265442
Epoch: 24 Idx: 0 Loss: 0.011370421478424143
Epoch: 24 Idx: 5000 Loss: 0.012134502339096324
Epoch: 25 Idx: 0 Loss: 0.01196222019100185
Epoch: 25 Idx: 5000 Loss: 0.011749119370820422
Epoch: 26 Idx: 0 Loss: 0.023660761062811685
Epoch: 26 Idx: 5000 Loss: 0.011651850148287245
Epoch: 27 Idx: 0 Loss: 0.02886909244200489
Epoch: 27 Idx: 5000 Loss: 0.02427601265840579
Epoch: 28 Idx: 0 Loss: 0.021115484455497702
Epoch: 28 Idx: 5000 Loss: 0.011569420014551041
Epoch: 29 Idx: 0 Loss: 0.013611769476324958
Epoch: 29 Idx: 5000 Loss: 0.020634782204682078
Epoch: 30 Idx: 0 Loss: 0.011237974661792095
Epoch: 30 Idx: 5000 Loss: 0.012181296234056832
Epoch: 31 Idx: 0 Loss: 0.01176062077245081
Epoch: 31 Idx: 5000 Loss: 0.030593874103072363
Epoch: 32 Idx: 0 Loss: 0.014414411988867046
Epoch: 32 Idx: 5000 Loss: 0.008626153238044745
Epoch: 33 Idx: 0 Loss: 0.016168384628135073
Epoch: 33 Idx: 5000 Loss: 0.016144885952770346
Epoch: 34 Idx: 0 Loss: 0.007342781443456205
Epoch: 34 Idx: 5000 Loss: 0.018107960175348263
Epoch: 35 Idx: 0 Loss: 0.010994400298619785
Epoch: 35 Idx: 5000 Loss: 0.011700528753042894
Epoch: 36 Idx: 0 Loss: 0.012114917162040842
Epoch: 36 Idx: 5000 Loss: 0.013269310817479701
Epoch: 37 Idx: 0 Loss: 0.008955827639374758
Epoch: 37 Idx: 5000 Loss: 0.013241977211050075
Epoch: 38 Idx: 0 Loss: 0.010816097946548125
Epoch: 38 Idx: 5000 Loss: 0.01528699449125114
Epoch: 39 Idx: 0 Loss: 0.011861553364825465
Epoch: 39 Idx: 5000 Loss: 0.018733257298929818
Epoch: 40 Idx: 0 Loss: 0.008584473580358366
Epoch: 40 Idx: 5000 Loss: 0.047755311572227926
Epoch: 41 Idx: 0 Loss: 0.043112463642989
Epoch: 41 Idx: 5000 Loss: 0.014579414378743457
Epoch: 42 Idx: 0 Loss: 0.013623586862575785
Epoch: 42 Idx: 5000 Loss: 0.010639972012759211
Epoch: 43 Idx: 0 Loss: 0.013216317754271706
Epoch: 43 Idx: 5000 Loss: 0.012614770369188141
Epoch: 44 Idx: 0 Loss: 0.011023701031859156
Epoch: 44 Idx: 5000 Loss: 0.011631689847822752
Epoch: 45 Idx: 0 Loss: 0.022725604153875617
Epoch: 45 Idx: 5000 Loss: 0.006969566696062061
Epoch: 46 Idx: 0 Loss: 0.01961523867249461
Epoch: 46 Idx: 5000 Loss: 0.020048371204632834
Epoch: 47 Idx: 0 Loss: 0.005416427003404524
Epoch: 47 Idx: 5000 Loss: 0.01515205063791529
Epoch: 48 Idx: 0 Loss: 0.028562387860754365
Epoch: 48 Idx: 5000 Loss: 0.009520431619857174
Epoch: 49 Idx: 0 Loss: 0.01715905283512347
Epoch: 49 Idx: 5000 Loss: 0.01611622490096643
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.18792289440159388
Epoch: 0 Idx: 5000 Loss: 0.024221337221667808
Epoch: 1 Idx: 0 Loss: 0.028859929628194024
Epoch: 1 Idx: 5000 Loss: 0.01625491930411606
Epoch: 2 Idx: 0 Loss: 0.009186526766218187
Epoch: 2 Idx: 5000 Loss: 0.014620711309709716
Epoch: 3 Idx: 0 Loss: 0.006966864262216332
Epoch: 3 Idx: 5000 Loss: 0.010813359127086314
Epoch: 4 Idx: 0 Loss: 0.02360564142622654
Epoch: 4 Idx: 5000 Loss: 0.012580990458703811
Epoch: 5 Idx: 0 Loss: 0.021666201156310787
Epoch: 5 Idx: 5000 Loss: 0.005908559918905635
Epoch: 6 Idx: 0 Loss: 0.01400750380074878
Epoch: 6 Idx: 5000 Loss: 0.01563997860522225
Epoch: 7 Idx: 0 Loss: 0.016773717802803838
Epoch: 7 Idx: 5000 Loss: 0.006734166452070524
Epoch: 8 Idx: 0 Loss: 0.008755232315769102
Epoch: 8 Idx: 5000 Loss: 0.014758147122041803
Epoch: 9 Idx: 0 Loss: 0.011535369814382811
Epoch: 9 Idx: 5000 Loss: 0.006345248177663711
Epoch: 10 Idx: 0 Loss: 0.028904576099966675
Epoch: 10 Idx: 5000 Loss: 0.008498618541918553
Epoch: 11 Idx: 0 Loss: 0.005112012405122141
Epoch: 11 Idx: 5000 Loss: 0.025751953594827442
Epoch: 12 Idx: 0 Loss: 0.015867775568062834
Epoch: 12 Idx: 5000 Loss: 0.013136027321708554
Epoch: 13 Idx: 0 Loss: 0.008671729051206547
Epoch: 13 Idx: 5000 Loss: 0.006740524943680577
Epoch: 14 Idx: 0 Loss: 0.007058361800284734
Epoch: 14 Idx: 5000 Loss: 0.014342785530905228
Epoch: 15 Idx: 0 Loss: 0.006687847798702914
Epoch: 15 Idx: 5000 Loss: 0.011702550375315165
Epoch: 16 Idx: 0 Loss: 0.010986741402824496
Epoch: 16 Idx: 5000 Loss: 0.013494509068225635
Epoch: 17 Idx: 0 Loss: 0.00939648234170345
Epoch: 17 Idx: 5000 Loss: 0.007383844104874864
Epoch: 18 Idx: 0 Loss: 0.010569958355968332
Epoch: 18 Idx: 5000 Loss: 0.03135251398348915
Epoch: 19 Idx: 0 Loss: 0.013920071307131623
Epoch: 19 Idx: 5000 Loss: 0.01524056931695189
Epoch: 20 Idx: 0 Loss: 0.013576062900026246
Epoch: 20 Idx: 5000 Loss: 0.027641947452694295
Epoch: 21 Idx: 0 Loss: 0.029764726951809484
Epoch: 21 Idx: 5000 Loss: 0.011677049206664531
Epoch: 22 Idx: 0 Loss: 0.031089532886117564
Epoch: 22 Idx: 5000 Loss: 0.028324053346417005
Epoch: 23 Idx: 0 Loss: 0.010642901695234753
Epoch: 23 Idx: 5000 Loss: 0.03084412687356268
Epoch: 24 Idx: 0 Loss: 0.01970565966585512
Epoch: 24 Idx: 5000 Loss: 0.03365933032863725
Epoch: 25 Idx: 0 Loss: 0.010585962255542055
Epoch: 25 Idx: 5000 Loss: 0.009125634288503756
Epoch: 26 Idx: 0 Loss: 0.03084071979515258
Epoch: 26 Idx: 5000 Loss: 0.027774388064930725
Epoch: 27 Idx: 0 Loss: 0.017771234201964088
Epoch: 27 Idx: 5000 Loss: 0.024120285256630538
Epoch: 28 Idx: 0 Loss: 0.03845623179994016
Epoch: 28 Idx: 5000 Loss: 0.01550448526692055
Epoch: 29 Idx: 0 Loss: 0.008439571605480388
Epoch: 29 Idx: 5000 Loss: 0.015237737448673834
Epoch: 30 Idx: 0 Loss: 0.008509600738396482
Epoch: 30 Idx: 5000 Loss: 0.009264834775912114
Epoch: 31 Idx: 0 Loss: 0.023732259112092542
Epoch: 31 Idx: 5000 Loss: 0.018978620910841036
Epoch: 32 Idx: 0 Loss: 0.00571175289641337
Epoch: 32 Idx: 5000 Loss: 0.007639040886965643
Epoch: 33 Idx: 0 Loss: 0.013770300455447903
Epoch: 33 Idx: 5000 Loss: 0.01954412034061531
Epoch: 34 Idx: 0 Loss: 0.015795984580168804
Epoch: 34 Idx: 5000 Loss: 0.009368566320153631
Epoch: 35 Idx: 0 Loss: 0.011507962453766967
Epoch: 35 Idx: 5000 Loss: 0.023167703859101735
Epoch: 36 Idx: 0 Loss: 0.017967548849782626
Epoch: 36 Idx: 5000 Loss: 0.0158157641684068
Epoch: 37 Idx: 0 Loss: 0.022005851827791252
Epoch: 37 Idx: 5000 Loss: 0.026417798496070646
Epoch: 38 Idx: 0 Loss: 0.053100587949268606
Epoch: 38 Idx: 5000 Loss: 0.0301146339740239
Epoch: 39 Idx: 0 Loss: 0.016358424291237628
Epoch: 39 Idx: 5000 Loss: 0.008111826250055632
Epoch: 40 Idx: 0 Loss: 0.015914387311903644
Epoch: 40 Idx: 5000 Loss: 0.012941230110610142
Epoch: 41 Idx: 0 Loss: 0.02442471122204492
Epoch: 41 Idx: 5000 Loss: 0.008580321548578787
Epoch: 42 Idx: 0 Loss: 0.027904539843779094
Epoch: 42 Idx: 5000 Loss: 0.013541298125880384
Epoch: 43 Idx: 0 Loss: 0.013385771452207217
Epoch: 43 Idx: 5000 Loss: 0.014362451211968313
Epoch: 44 Idx: 0 Loss: 0.0067994097663680465
Epoch: 44 Idx: 5000 Loss: 0.04440841192658786
Epoch: 45 Idx: 0 Loss: 0.02522290415677668
Epoch: 45 Idx: 5000 Loss: 0.013960609053113995
Epoch: 46 Idx: 0 Loss: 0.01964243515514688
Epoch: 46 Idx: 5000 Loss: 0.0071715316779110555
Epoch: 47 Idx: 0 Loss: 0.0071407566590448715
Epoch: 47 Idx: 5000 Loss: 0.011656024691678545
Epoch: 48 Idx: 0 Loss: 0.01564843803027122
Epoch: 48 Idx: 5000 Loss: 0.01877571631402539
Epoch: 49 Idx: 0 Loss: 0.013545784162051093
Epoch: 49 Idx: 5000 Loss: 0.01709076525566497
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.21151120461947662
Epoch: 1 Idx: 0 Loss: 0.010286159133900368
Epoch: 2 Idx: 0 Loss: 0.019318915697704338
Epoch: 3 Idx: 0 Loss: 0.03090824218034782
Epoch: 4 Idx: 0 Loss: 0.007289443181785605
Epoch: 5 Idx: 0 Loss: 0.014426785742585406
Epoch: 6 Idx: 0 Loss: 0.017241636096650283
Epoch: 7 Idx: 0 Loss: 0.009026414412369031
Epoch: 8 Idx: 0 Loss: 0.010154468316601294
Epoch: 9 Idx: 0 Loss: 0.013566357572035902
Epoch: 10 Idx: 0 Loss: 0.055967720368891805
Epoch: 11 Idx: 0 Loss: 0.013390350362369557
Epoch: 12 Idx: 0 Loss: 0.025104913539728792
Epoch: 13 Idx: 0 Loss: 0.027457174394626097
Epoch: 14 Idx: 0 Loss: 0.009968265974059642
Epoch: 15 Idx: 0 Loss: 0.004742140245913242
Epoch: 16 Idx: 0 Loss: 0.04066797675402512
Epoch: 17 Idx: 0 Loss: 0.020328574184549746
Epoch: 18 Idx: 0 Loss: 0.009974694502379824
Epoch: 19 Idx: 0 Loss: 0.006570312309700286
Epoch: 20 Idx: 0 Loss: 0.011434762667104189
Epoch: 21 Idx: 0 Loss: 0.008344824378760735
Epoch: 22 Idx: 0 Loss: 0.011964453631973616
Epoch: 23 Idx: 0 Loss: 0.007407564770614334
Epoch: 24 Idx: 0 Loss: 0.018167222952033466
Epoch: 25 Idx: 0 Loss: 0.01977480796451115
Epoch: 26 Idx: 0 Loss: 0.011820524437395733
Epoch: 27 Idx: 0 Loss: 0.007869955454013127
Epoch: 28 Idx: 0 Loss: 0.0061573940170121235
Epoch: 29 Idx: 0 Loss: 0.0072533169538782135
Epoch: 30 Idx: 0 Loss: 0.0170360733430713
Epoch: 31 Idx: 0 Loss: 0.00843338424175389
Epoch: 32 Idx: 0 Loss: 0.04740624365636463
Epoch: 33 Idx: 0 Loss: 0.02311941665355511
Epoch: 34 Idx: 0 Loss: 0.04667821502788522
Epoch: 35 Idx: 0 Loss: 0.024215665590863612
Epoch: 36 Idx: 0 Loss: 0.017244267212464873
Epoch: 37 Idx: 0 Loss: 0.010598373844495364
Epoch: 38 Idx: 0 Loss: 0.01434219983145414
Epoch: 39 Idx: 0 Loss: 0.010344247171298277
Epoch: 40 Idx: 0 Loss: 0.009718657318499559
Epoch: 41 Idx: 0 Loss: 0.019143169148806143
Epoch: 42 Idx: 0 Loss: 0.01779716151940505
Epoch: 43 Idx: 0 Loss: 0.012378968562648442
Epoch: 44 Idx: 0 Loss: 0.006275694907524851
Epoch: 45 Idx: 0 Loss: 0.019027148414961066
Epoch: 46 Idx: 0 Loss: 0.047719956987782274
Epoch: 47 Idx: 0 Loss: 0.01522812225119467
Epoch: 48 Idx: 0 Loss: 0.014285524823823012
Epoch: 49 Idx: 0 Loss: 0.017688863990834493
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.16160841924610794
Epoch: 0 Idx: 5000 Loss: 0.00734067180316533
Epoch: 1 Idx: 0 Loss: 0.027629014478666267
Epoch: 1 Idx: 5000 Loss: 0.02119782941022319
Epoch: 2 Idx: 0 Loss: 0.00779659309841875
Epoch: 2 Idx: 5000 Loss: 0.020873726613998826
Epoch: 3 Idx: 0 Loss: 0.013404829404458245
Epoch: 3 Idx: 5000 Loss: 0.010576640100011876
Epoch: 4 Idx: 0 Loss: 0.0075769620302207925
Epoch: 4 Idx: 5000 Loss: 0.007886761233746624
Epoch: 5 Idx: 0 Loss: 0.01076654648345159
Epoch: 5 Idx: 5000 Loss: 0.0162127366536322
Epoch: 6 Idx: 0 Loss: 0.012399202486950285
Epoch: 6 Idx: 5000 Loss: 0.010630053414372474
Epoch: 7 Idx: 0 Loss: 0.025416519080790883
Epoch: 7 Idx: 5000 Loss: 0.027653350229022218
Epoch: 8 Idx: 0 Loss: 0.006507397692352245
Epoch: 8 Idx: 5000 Loss: 0.016077517744100243
Epoch: 9 Idx: 0 Loss: 0.012315050140877058
Epoch: 9 Idx: 5000 Loss: 0.012021749412130647
Epoch: 10 Idx: 0 Loss: 0.01451771991451041
Epoch: 10 Idx: 5000 Loss: 0.008317901885431292
Epoch: 11 Idx: 0 Loss: 0.023716090023192405
Epoch: 11 Idx: 5000 Loss: 0.012938666190359247
Epoch: 12 Idx: 0 Loss: 0.00764817494228913
Epoch: 12 Idx: 5000 Loss: 0.010467821021720555
Epoch: 13 Idx: 0 Loss: 0.01787818103851729
Epoch: 13 Idx: 5000 Loss: 0.03491156076362574
Epoch: 14 Idx: 0 Loss: 0.022252705405074968
Epoch: 14 Idx: 5000 Loss: 0.013853871887989855
Epoch: 15 Idx: 0 Loss: 0.04199161344985882
Epoch: 15 Idx: 5000 Loss: 0.010607301246015654
Epoch: 16 Idx: 0 Loss: 0.012987994989851233
Epoch: 16 Idx: 5000 Loss: 0.015185226308274472
Epoch: 17 Idx: 0 Loss: 0.008521271999727631
Epoch: 17 Idx: 5000 Loss: 0.01625775506868519
Epoch: 18 Idx: 0 Loss: 0.011625932772457628
Epoch: 18 Idx: 5000 Loss: 0.014429345142913757
Epoch: 19 Idx: 0 Loss: 0.01831681479287429
Epoch: 19 Idx: 5000 Loss: 0.018095156970977997
Epoch: 20 Idx: 0 Loss: 0.00979863696622931
Epoch: 20 Idx: 5000 Loss: 0.01808356608023231
Epoch: 21 Idx: 0 Loss: 0.009860807030279655
Epoch: 21 Idx: 5000 Loss: 0.009209269435226722
Epoch: 22 Idx: 0 Loss: 0.017479185153350278
Epoch: 22 Idx: 5000 Loss: 0.012573587925445348
Epoch: 23 Idx: 0 Loss: 0.010138803580758977
Epoch: 23 Idx: 5000 Loss: 0.005856283930240075
Epoch: 24 Idx: 0 Loss: 0.01528510806586773
Epoch: 24 Idx: 5000 Loss: 0.01309662528959144
Epoch: 25 Idx: 0 Loss: 0.03775755728608288
Epoch: 25 Idx: 5000 Loss: 0.010621931452149218
Epoch: 26 Idx: 0 Loss: 0.02567169952900626
Epoch: 26 Idx: 5000 Loss: 0.00914514626443253
Epoch: 27 Idx: 0 Loss: 0.007886182765061147
Epoch: 27 Idx: 5000 Loss: 0.015210180508964824
Epoch: 28 Idx: 0 Loss: 0.010517628012689845
Epoch: 28 Idx: 5000 Loss: 0.03773142804287705
Epoch: 29 Idx: 0 Loss: 0.02518884514841972
Epoch: 29 Idx: 5000 Loss: 0.0190289577365866
Epoch: 30 Idx: 0 Loss: 0.02605012338152536
Epoch: 30 Idx: 5000 Loss: 0.007659776563667165
Epoch: 31 Idx: 0 Loss: 0.006439629077890037
Epoch: 31 Idx: 5000 Loss: 0.012179361176165941
Epoch: 32 Idx: 0 Loss: 0.010472121673881495
Epoch: 32 Idx: 5000 Loss: 0.01095594742223513
Epoch: 33 Idx: 0 Loss: 0.010235160065883892
Epoch: 33 Idx: 5000 Loss: 0.012159535925375192
Epoch: 34 Idx: 0 Loss: 0.01200367791807327
Epoch: 34 Idx: 5000 Loss: 0.021148346547523157
Epoch: 35 Idx: 0 Loss: 0.00699572596888173
Epoch: 35 Idx: 5000 Loss: 0.02053457445373373
Epoch: 36 Idx: 0 Loss: 0.007358014775008955
Epoch: 36 Idx: 5000 Loss: 0.012787772370544782
Epoch: 37 Idx: 0 Loss: 0.007016554590552712
Epoch: 37 Idx: 5000 Loss: 0.02422853891102196
Epoch: 38 Idx: 0 Loss: 0.016996529960475053
Epoch: 38 Idx: 5000 Loss: 0.021863852299091106
Epoch: 39 Idx: 0 Loss: 0.019684594136381135
Epoch: 39 Idx: 5000 Loss: 0.014256153839431693
Epoch: 40 Idx: 0 Loss: 0.014778479946336442
Epoch: 40 Idx: 5000 Loss: 0.008322424584952585
Epoch: 41 Idx: 0 Loss: 0.015996894061188906
Epoch: 41 Idx: 5000 Loss: 0.00829319405522912
Epoch: 42 Idx: 0 Loss: 0.07326947847971868
Epoch: 42 Idx: 5000 Loss: 0.005066730893305907
Epoch: 43 Idx: 0 Loss: 0.019374082979503444
Epoch: 43 Idx: 5000 Loss: 0.011867426740184102
Epoch: 44 Idx: 0 Loss: 0.012438829916592942
Epoch: 44 Idx: 5000 Loss: 0.01389219828798796
Epoch: 45 Idx: 0 Loss: 0.00982663041295588
Epoch: 45 Idx: 5000 Loss: 0.01622449633686463
Epoch: 46 Idx: 0 Loss: 0.026626756865012955
Epoch: 46 Idx: 5000 Loss: 0.008609911674287471
Epoch: 47 Idx: 0 Loss: 0.007096764809626508
Epoch: 47 Idx: 5000 Loss: 0.03091270605857853
Epoch: 48 Idx: 0 Loss: 0.01724083155110305
Epoch: 48 Idx: 5000 Loss: 0.007127603812781401
Epoch: 49 Idx: 0 Loss: 0.014509610925695856
Epoch: 49 Idx: 5000 Loss: 0.015365459643306186
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.2043515769255279
Epoch: 1 Idx: 0 Loss: 0.013126040294545982
Epoch: 2 Idx: 0 Loss: 0.016958813789696485
Epoch: 3 Idx: 0 Loss: 0.010016702528876669
Epoch: 4 Idx: 0 Loss: 0.017072545059181984
Epoch: 5 Idx: 0 Loss: 0.01353190010014342
Epoch: 6 Idx: 0 Loss: 0.012401749678247247
Epoch: 7 Idx: 0 Loss: 0.011238312376491717
Epoch: 8 Idx: 0 Loss: 0.017704905069753835
Epoch: 9 Idx: 0 Loss: 0.01742277354470385
Epoch: 10 Idx: 0 Loss: 0.027749128362508726
Epoch: 11 Idx: 0 Loss: 0.014285640962074775
Epoch: 12 Idx: 0 Loss: 0.016825305477606484
Epoch: 13 Idx: 0 Loss: 0.008123124723229484
Epoch: 14 Idx: 0 Loss: 0.006632004574673585
Epoch: 15 Idx: 0 Loss: 0.00820424568780253
Epoch: 16 Idx: 0 Loss: 0.017023175894852582
Epoch: 17 Idx: 0 Loss: 0.017440826477687073
Epoch: 18 Idx: 0 Loss: 0.009448310562634595
Epoch: 19 Idx: 0 Loss: 0.02539833044059018
Epoch: 20 Idx: 0 Loss: 0.015279540262046523
Epoch: 21 Idx: 0 Loss: 0.017134133214817306
Epoch: 22 Idx: 0 Loss: 0.029887339917504984
Epoch: 23 Idx: 0 Loss: 0.020647832777764018
Epoch: 24 Idx: 0 Loss: 0.014953907728140054
Epoch: 25 Idx: 0 Loss: 0.020936593110927153
Epoch: 26 Idx: 0 Loss: 0.017304057138004064
Epoch: 27 Idx: 0 Loss: 0.010734241750308935
Epoch: 28 Idx: 0 Loss: 0.03003340114348113
Epoch: 29 Idx: 0 Loss: 0.008831970925863132
Epoch: 30 Idx: 0 Loss: 0.02233743325942992
Epoch: 31 Idx: 0 Loss: 0.02296428586771445
Epoch: 32 Idx: 0 Loss: 0.017053486991546345
Epoch: 33 Idx: 0 Loss: 0.005503490961523052
Epoch: 34 Idx: 0 Loss: 0.039373884899678954
Epoch: 35 Idx: 0 Loss: 0.006580656447109589
Epoch: 36 Idx: 0 Loss: 0.015270716293710379
Epoch: 37 Idx: 0 Loss: 0.004143045261221413
Epoch: 38 Idx: 0 Loss: 0.022239980289246293
Epoch: 39 Idx: 0 Loss: 0.008429914964684681
Epoch: 40 Idx: 0 Loss: 0.008538840590940825
Epoch: 41 Idx: 0 Loss: 0.009798034097413328
Epoch: 42 Idx: 0 Loss: 0.015317065244279537
Epoch: 43 Idx: 0 Loss: 0.023230799957424737
Epoch: 44 Idx: 0 Loss: 0.04346093220955603
Epoch: 45 Idx: 0 Loss: 0.005737734884081237
Epoch: 46 Idx: 0 Loss: 0.025631508053550266
Epoch: 47 Idx: 0 Loss: 0.024759574031994996
Epoch: 48 Idx: 0 Loss: 0.016436333722654888
Epoch: 49 Idx: 0 Loss: 0.011469471189801381
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.6875, 0.7333333333333333, 0.7096774193548386, 0.7236842105263157, 0.6962025316455696)
Performance for  [('ekaw', 'sigkdd')] is : (0.8461538461538461, 1.0, 0.9166666666666666, 0.9649122807017543, 0.8730158730158731)
Performance for  [('conference', 'edas')] is : (0.7333333333333333, 0.6470588235294118, 0.6875, 0.6626506024096386, 0.7142857142857143)
Performance for  [('cmt', 'ekaw')] is : (0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454)
Performance for  [('confOf', 'edas')] is : (0.6, 0.631578947368421, 0.6153846153846154, 0.625, 0.6060606060606061)
Performance for  [('iasted', 'sigkdd')] is : (0.6111111111111112, 0.7333333333333333, 0.6666666666666666, 0.7051282051282052, 0.6321839080459771)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.5555555555555556, 0.7142857142857143, 0.6097560975609756, 0.8620689655172413)
Final Results: [0.71765041 0.69233065 0.69366223 0.69094085 0.70418173]
Threshold:  0.897

------------------------------------------------------------
Sender: LSF System <rer@dccxc237>
Subject: Job 4142636: <python main.py 8 4 False False> in cluster <dcc> Done

Job <python main.py 8 4 False False> was submitted from host <dccxl001> by user <naveen9> in cluster <dcc> at Wed Sep 16 06:55:14 2020
Job was executed on host(s) <dccxc237>, in queue <x86_24h>, as user <naveen9> in cluster <dcc> at Wed Sep 16 10:12:26 2020
</u/naveen9> was used as the home directory.
</u/naveen9/arvind/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 10:12:26 2020
Terminated at Thu Sep 17 04:52:35 2020
Results reported at Thu Sep 17 04:52:35 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 8 4 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   67193.66 sec.
    Max Memory :                                 2930 MB
    Average Memory :                             2757.89 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40487.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   67223 sec.
    Turnaround time :                            79041 sec.

The output (if any) is above this job summary.

