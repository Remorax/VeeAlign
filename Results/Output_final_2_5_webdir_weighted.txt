2020-09-16 09:40:28.490177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 09:40:38.386397: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 09:40:38.497450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 09:40:38.497538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 09:40:38.499621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 09:40:38.501399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 09:40:38.501870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 09:40:38.504018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 09:40:38.505648: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 09:40:38.505867: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib
2020-09-16 09:40:38.505890: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 09:40:38.506309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 09:40:38.547865: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600150000 Hz
2020-09-16 09:40:38.548162: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e352e069a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 09:40:38.548184: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 09:40:38.551503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 09:40:38.551568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/naveen9/arvind/VeeAlign/
Ontologies being aligned are:  [('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/naveen9/arvind/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18909603169122446
Epoch: 0 Idx: 5000 Loss: 0.006431242129177288
Epoch: 1 Idx: 0 Loss: 0.009245366451222667
Epoch: 1 Idx: 5000 Loss: 0.03532481552830552
Epoch: 2 Idx: 0 Loss: 0.012643427568099
Epoch: 2 Idx: 5000 Loss: 0.018502817639610626
Epoch: 3 Idx: 0 Loss: 0.007720255724648883
Epoch: 3 Idx: 5000 Loss: 0.027560124180194302
Epoch: 4 Idx: 0 Loss: 0.028835695084273825
Epoch: 4 Idx: 5000 Loss: 0.010999045712449895
Epoch: 5 Idx: 0 Loss: 0.025564104501986575
Epoch: 5 Idx: 5000 Loss: 0.008429897393806302
Epoch: 6 Idx: 0 Loss: 0.008184145098294366
Epoch: 6 Idx: 5000 Loss: 0.006326697554914816
Epoch: 7 Idx: 0 Loss: 0.018801968488094595
Epoch: 7 Idx: 5000 Loss: 0.008971439822247565
Epoch: 8 Idx: 0 Loss: 0.010227091124473894
Epoch: 8 Idx: 5000 Loss: 0.012614130563588571
Epoch: 9 Idx: 0 Loss: 0.004049698028660093
Epoch: 9 Idx: 5000 Loss: 0.026036365104176163
Epoch: 10 Idx: 0 Loss: 0.01420156497720855
Epoch: 10 Idx: 5000 Loss: 0.02267122146687721
Epoch: 11 Idx: 0 Loss: 0.03908058456646256
Epoch: 11 Idx: 5000 Loss: 0.02820964811241055
Epoch: 12 Idx: 0 Loss: 0.021374815789444206
Epoch: 12 Idx: 5000 Loss: 0.012593873767776452
Epoch: 13 Idx: 0 Loss: 0.01709697279055488
Epoch: 13 Idx: 5000 Loss: 0.006849944568659746
Epoch: 14 Idx: 0 Loss: 0.023777971080789828
Epoch: 14 Idx: 5000 Loss: 0.024825368677300855
Epoch: 15 Idx: 0 Loss: 0.01688931847971966
Epoch: 15 Idx: 5000 Loss: 0.03964880058366842
Epoch: 16 Idx: 0 Loss: 0.01042269832834797
Epoch: 16 Idx: 5000 Loss: 0.023979522213138198
Epoch: 17 Idx: 0 Loss: 0.026287871371812602
Epoch: 17 Idx: 5000 Loss: 0.012338476277998707
Epoch: 18 Idx: 0 Loss: 0.007991382136709729
Epoch: 18 Idx: 5000 Loss: 0.0165068010319965
Epoch: 19 Idx: 0 Loss: 0.016411834505842014
Epoch: 19 Idx: 5000 Loss: 0.015005924691528399
Epoch: 20 Idx: 0 Loss: 0.00927348208034916
Epoch: 20 Idx: 5000 Loss: 0.016328341972547865
Epoch: 21 Idx: 0 Loss: 0.010954488232524246
Epoch: 21 Idx: 5000 Loss: 0.016230691516937682
Epoch: 22 Idx: 0 Loss: 0.014896467672918206
Epoch: 22 Idx: 5000 Loss: 0.017189292537163673
Epoch: 23 Idx: 0 Loss: 0.01082268636998493
Epoch: 23 Idx: 5000 Loss: 0.019838108852991636
Epoch: 24 Idx: 0 Loss: 0.008361599030966246
Epoch: 24 Idx: 5000 Loss: 0.00907488925391852
Epoch: 25 Idx: 0 Loss: 0.0091773578549296
Epoch: 25 Idx: 5000 Loss: 0.016905253456232363
Epoch: 26 Idx: 0 Loss: 0.005378999723868056
Epoch: 26 Idx: 5000 Loss: 0.026677195640437995
Epoch: 27 Idx: 0 Loss: 0.011443477044575458
Epoch: 27 Idx: 5000 Loss: 0.026479633115415263
Epoch: 28 Idx: 0 Loss: 0.011414965676118513
Epoch: 28 Idx: 5000 Loss: 0.011751394596048936
Epoch: 29 Idx: 0 Loss: 0.011482649163427157
Epoch: 29 Idx: 5000 Loss: 0.007623683096949515
Epoch: 30 Idx: 0 Loss: 0.008276349607850658
Epoch: 30 Idx: 5000 Loss: 0.010322285694569852
Epoch: 31 Idx: 0 Loss: 0.024942416586122805
Epoch: 31 Idx: 5000 Loss: 0.017438679927353276
Epoch: 32 Idx: 0 Loss: 0.02950658370206015
Epoch: 32 Idx: 5000 Loss: 0.011926803154430959
Epoch: 33 Idx: 0 Loss: 0.007689393843214246
Epoch: 33 Idx: 5000 Loss: 0.018895598956767852
Epoch: 34 Idx: 0 Loss: 0.009881073333206121
Epoch: 34 Idx: 5000 Loss: 0.013928881069077333
Epoch: 35 Idx: 0 Loss: 0.01901953152566392
Epoch: 35 Idx: 5000 Loss: 0.017878097633742634
Epoch: 36 Idx: 0 Loss: 0.007594392135812196
Epoch: 36 Idx: 5000 Loss: 0.04423012377326836
Epoch: 37 Idx: 0 Loss: 0.02272641802389186
Epoch: 37 Idx: 5000 Loss: 0.01891851455266192
Epoch: 38 Idx: 0 Loss: 0.028190755239563863
Epoch: 38 Idx: 5000 Loss: 0.037339469623397875
Epoch: 39 Idx: 0 Loss: 0.016984515596447827
Epoch: 39 Idx: 5000 Loss: 0.009617044043211875
Epoch: 40 Idx: 0 Loss: 0.017382599020578468
Epoch: 40 Idx: 5000 Loss: 0.010602762931991316
Epoch: 41 Idx: 0 Loss: 0.026067372402671214
Epoch: 41 Idx: 5000 Loss: 0.03714209837822023
Epoch: 42 Idx: 0 Loss: 0.008372151358481036
Epoch: 42 Idx: 5000 Loss: 0.005580560327660855
Epoch: 43 Idx: 0 Loss: 0.011905673274223509
Epoch: 43 Idx: 5000 Loss: 0.015224020243767677
Epoch: 44 Idx: 0 Loss: 0.01612659499863311
Epoch: 44 Idx: 5000 Loss: 0.010159494190808145
Epoch: 45 Idx: 0 Loss: 0.00932599539929431
Epoch: 45 Idx: 5000 Loss: 0.013069181824152891
Epoch: 46 Idx: 0 Loss: 0.020944737577487604
Epoch: 46 Idx: 5000 Loss: 0.035129450841345215
Epoch: 47 Idx: 0 Loss: 0.013852015599788218
Epoch: 47 Idx: 5000 Loss: 0.02697387402272651
Epoch: 48 Idx: 0 Loss: 0.010065576987480045
Epoch: 48 Idx: 5000 Loss: 0.022307078175332617
Epoch: 49 Idx: 0 Loss: 0.03234934625618198
Epoch: 49 Idx: 5000 Loss: 0.010968394514504374
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.22086093133741222
Epoch: 0 Idx: 5000 Loss: 0.01658910544757762
Epoch: 1 Idx: 0 Loss: 0.018260989802296262
Epoch: 1 Idx: 5000 Loss: 0.014410254277322032
Epoch: 2 Idx: 0 Loss: 0.015704713238878672
Epoch: 2 Idx: 5000 Loss: 0.009536494983223787
Epoch: 3 Idx: 0 Loss: 0.03660341309708501
Epoch: 3 Idx: 5000 Loss: 0.01024818283867484
Epoch: 4 Idx: 0 Loss: 0.009914610853639753
Epoch: 4 Idx: 5000 Loss: 0.01159744779097565
Epoch: 5 Idx: 0 Loss: 0.012781262313445011
Epoch: 5 Idx: 5000 Loss: 0.013031405835590072
Epoch: 6 Idx: 0 Loss: 0.008166630382365425
Epoch: 6 Idx: 5000 Loss: 0.010986307503146098
Epoch: 7 Idx: 0 Loss: 0.027260674577635667
Epoch: 7 Idx: 5000 Loss: 0.01054188290488984
Epoch: 8 Idx: 0 Loss: 0.005853248750120626
Epoch: 8 Idx: 5000 Loss: 0.0170421171876151
Epoch: 9 Idx: 0 Loss: 0.016583751759384893
Epoch: 9 Idx: 5000 Loss: 0.005367196204757393
Epoch: 10 Idx: 0 Loss: 0.011684694541257822
Epoch: 10 Idx: 5000 Loss: 0.006757071448300218
Epoch: 11 Idx: 0 Loss: 0.012477681260780613
Epoch: 11 Idx: 5000 Loss: 0.033176879807494675
Epoch: 12 Idx: 0 Loss: 0.01572489011071674
Epoch: 12 Idx: 5000 Loss: 0.02529314336933012
Epoch: 13 Idx: 0 Loss: 0.004360878535973899
Epoch: 13 Idx: 5000 Loss: 0.009672334563869628
Epoch: 14 Idx: 0 Loss: 0.00962468450916694
Epoch: 14 Idx: 5000 Loss: 0.023093033819644917
Epoch: 15 Idx: 0 Loss: 0.01049959451678976
Epoch: 15 Idx: 5000 Loss: 0.010599826541489953
Epoch: 16 Idx: 0 Loss: 0.008280334619516485
Epoch: 16 Idx: 5000 Loss: 0.04535052088620921
Epoch: 17 Idx: 0 Loss: 0.017439127150399705
Epoch: 17 Idx: 5000 Loss: 0.03269380695800978
Epoch: 18 Idx: 0 Loss: 0.0226684731104769
Epoch: 18 Idx: 5000 Loss: 0.009574757668980747
Epoch: 19 Idx: 0 Loss: 0.0067545291532894155
Epoch: 19 Idx: 5000 Loss: 0.013089366283760012
Epoch: 20 Idx: 0 Loss: 0.022678396259069894
Epoch: 20 Idx: 5000 Loss: 0.029316513569374255
Epoch: 21 Idx: 0 Loss: 0.007618299818771854
Epoch: 21 Idx: 5000 Loss: 0.009654616903420652
Epoch: 22 Idx: 0 Loss: 0.017715667126628684
Epoch: 22 Idx: 5000 Loss: 0.015252231432651035
Epoch: 23 Idx: 0 Loss: 0.03196991788223015
Epoch: 23 Idx: 5000 Loss: 0.012187393089540033
Epoch: 24 Idx: 0 Loss: 0.015596483546808263
Epoch: 24 Idx: 5000 Loss: 0.01250103050735591
Epoch: 25 Idx: 0 Loss: 0.021116490092724167
Epoch: 25 Idx: 5000 Loss: 0.008545382679082367
Epoch: 26 Idx: 0 Loss: 0.007970836272209639
Epoch: 26 Idx: 5000 Loss: 0.033980962821351504
Epoch: 27 Idx: 0 Loss: 0.008956525736710831
Epoch: 27 Idx: 5000 Loss: 0.009797196050202977
Epoch: 28 Idx: 0 Loss: 0.011496184331626635
Epoch: 28 Idx: 5000 Loss: 0.013716484273940864
Epoch: 29 Idx: 0 Loss: 0.017038799389390492
Epoch: 29 Idx: 5000 Loss: 0.01156313928177569
Epoch: 30 Idx: 0 Loss: 0.01989589073860179
Epoch: 30 Idx: 5000 Loss: 0.007802637899413824
Epoch: 31 Idx: 0 Loss: 0.016302279474493225
Epoch: 31 Idx: 5000 Loss: 0.025254192967800494
Epoch: 32 Idx: 0 Loss: 0.031944017435986016
Epoch: 32 Idx: 5000 Loss: 0.007991996982166218
Epoch: 33 Idx: 0 Loss: 0.02903915202547205
Epoch: 33 Idx: 5000 Loss: 0.013273668578025938
Epoch: 34 Idx: 0 Loss: 0.00631969376077922
Epoch: 34 Idx: 5000 Loss: 0.009787048625030163
Epoch: 35 Idx: 0 Loss: 0.02302983316559344
Epoch: 35 Idx: 5000 Loss: 0.01717548245859555
Epoch: 36 Idx: 0 Loss: 0.013831027008927622
Epoch: 36 Idx: 5000 Loss: 0.021279138374146606
Epoch: 37 Idx: 0 Loss: 0.010534087395598989
Epoch: 37 Idx: 5000 Loss: 0.011484188252494962
Epoch: 38 Idx: 0 Loss: 0.015704353827179652
Epoch: 38 Idx: 5000 Loss: 0.0225583198828248
Epoch: 39 Idx: 0 Loss: 0.01766263752317156
Epoch: 39 Idx: 5000 Loss: 0.008978923687316629
Epoch: 40 Idx: 0 Loss: 0.012872366334254244
Epoch: 40 Idx: 5000 Loss: 0.006300129413944599
Epoch: 41 Idx: 0 Loss: 0.028213528490648933
Epoch: 41 Idx: 5000 Loss: 0.023662793625706238
Epoch: 42 Idx: 0 Loss: 0.017664370796473684
Epoch: 42 Idx: 5000 Loss: 0.012935599169924414
Epoch: 43 Idx: 0 Loss: 0.009976818962853266
Epoch: 43 Idx: 5000 Loss: 0.020753017398136044
Epoch: 44 Idx: 0 Loss: 0.012541598652257964
Epoch: 44 Idx: 5000 Loss: 0.008639382820013499
Epoch: 45 Idx: 0 Loss: 0.017922130375901336
Epoch: 45 Idx: 5000 Loss: 0.02856932210977748
Epoch: 46 Idx: 0 Loss: 0.017144362575887393
Epoch: 46 Idx: 5000 Loss: 0.013492440059559309
Epoch: 47 Idx: 0 Loss: 0.009073167925836564
Epoch: 47 Idx: 5000 Loss: 0.011271452254474445
Epoch: 48 Idx: 0 Loss: 0.020672442320675527
Epoch: 48 Idx: 5000 Loss: 0.016265081767263136
Epoch: 49 Idx: 0 Loss: 0.00837594271301393
Epoch: 49 Idx: 5000 Loss: 0.011469559709465145
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.16693091532396143
Epoch: 0 Idx: 5000 Loss: 0.010907368747729494
Epoch: 1 Idx: 0 Loss: 0.03992295013398565
Epoch: 1 Idx: 5000 Loss: 0.01055751664343044
Epoch: 2 Idx: 0 Loss: 0.020455972847036128
Epoch: 2 Idx: 5000 Loss: 0.008269766747837247
Epoch: 3 Idx: 0 Loss: 0.007776853269915603
Epoch: 3 Idx: 5000 Loss: 0.006263681549962284
Epoch: 4 Idx: 0 Loss: 0.011001804341451597
Epoch: 4 Idx: 5000 Loss: 0.01443369798208984
Epoch: 5 Idx: 0 Loss: 0.023266382045969165
Epoch: 5 Idx: 5000 Loss: 0.012993879253180098
Epoch: 6 Idx: 0 Loss: 0.02544912927702426
Epoch: 6 Idx: 5000 Loss: 0.018062965191720286
Epoch: 7 Idx: 0 Loss: 0.013586926999420164
Epoch: 7 Idx: 5000 Loss: 0.014766191384071538
Epoch: 8 Idx: 0 Loss: 0.017807891408889453
Epoch: 8 Idx: 5000 Loss: 0.012108890952138388
Epoch: 9 Idx: 0 Loss: 0.004548889011098725
Epoch: 9 Idx: 5000 Loss: 0.020522201633222548
Epoch: 10 Idx: 0 Loss: 0.006501173843098933
Epoch: 10 Idx: 5000 Loss: 0.010950768453502513
Epoch: 11 Idx: 0 Loss: 0.011227902754587456
Epoch: 11 Idx: 5000 Loss: 0.028919470524886165
Epoch: 12 Idx: 0 Loss: 0.020730175349255607
Epoch: 12 Idx: 5000 Loss: 0.011164980530865296
Epoch: 13 Idx: 0 Loss: 0.015000238176023441
Epoch: 13 Idx: 5000 Loss: 0.012424978290731756
Epoch: 14 Idx: 0 Loss: 0.014500132618188492
Epoch: 14 Idx: 5000 Loss: 0.007523791759581185
Epoch: 15 Idx: 0 Loss: 0.01028574897275562
Epoch: 15 Idx: 5000 Loss: 0.02265748422498899
Epoch: 16 Idx: 0 Loss: 0.02422950084235983
Epoch: 16 Idx: 5000 Loss: 0.01432169318135107
Epoch: 17 Idx: 0 Loss: 0.009053572246295244
Epoch: 17 Idx: 5000 Loss: 0.01359184546043578
Epoch: 18 Idx: 0 Loss: 0.023214497156190297
Epoch: 18 Idx: 5000 Loss: 0.011252586995356872
Epoch: 19 Idx: 0 Loss: 0.02714487317192528
Epoch: 19 Idx: 5000 Loss: 0.021853728605723217
Epoch: 20 Idx: 0 Loss: 0.020189039357718208
Epoch: 20 Idx: 5000 Loss: 0.038615251834427995
Epoch: 21 Idx: 0 Loss: 0.008167794142234728
Epoch: 21 Idx: 5000 Loss: 0.02199957632441168
Epoch: 22 Idx: 0 Loss: 0.008502769320732897
Epoch: 22 Idx: 5000 Loss: 0.012825172590180484
Epoch: 23 Idx: 0 Loss: 0.012767895802023806
Epoch: 23 Idx: 5000 Loss: 0.009850523749563956
Epoch: 24 Idx: 0 Loss: 0.005292822982068698
Epoch: 24 Idx: 5000 Loss: 0.0071369556364644145
Epoch: 25 Idx: 0 Loss: 0.01397854007873579
Epoch: 25 Idx: 5000 Loss: 0.01510507284214591
Epoch: 26 Idx: 0 Loss: 0.02326858694418063
Epoch: 26 Idx: 5000 Loss: 0.01729227805915313
Epoch: 27 Idx: 0 Loss: 0.026100110539390514
Epoch: 27 Idx: 5000 Loss: 0.008732720244283926
Epoch: 28 Idx: 0 Loss: 0.028641760100173577
Epoch: 28 Idx: 5000 Loss: 0.013185874746033742
Epoch: 29 Idx: 0 Loss: 0.012236057815857918
Epoch: 29 Idx: 5000 Loss: 0.03002493709005888
Epoch: 30 Idx: 0 Loss: 0.011156000031041847
Epoch: 30 Idx: 5000 Loss: 0.05023597933920717
Epoch: 31 Idx: 0 Loss: 0.007432010306170224
Epoch: 31 Idx: 5000 Loss: 0.013094488447677022
Epoch: 32 Idx: 0 Loss: 0.011755282656155589
Epoch: 32 Idx: 5000 Loss: 0.0128143621104024
Epoch: 33 Idx: 0 Loss: 0.05250669828576185
Epoch: 33 Idx: 5000 Loss: 0.026734067642065897
Epoch: 34 Idx: 0 Loss: 0.012913800371903152
Epoch: 34 Idx: 5000 Loss: 0.023960951625315315
Epoch: 35 Idx: 0 Loss: 0.013009903494780477
Epoch: 35 Idx: 5000 Loss: 0.013411788702684717
Epoch: 36 Idx: 0 Loss: 0.016517791805473026
Epoch: 36 Idx: 5000 Loss: 0.014975383754694196
Epoch: 37 Idx: 0 Loss: 0.018517780315291974
Epoch: 37 Idx: 5000 Loss: 0.03483148371500964
Epoch: 38 Idx: 0 Loss: 0.013628200138987964
Epoch: 38 Idx: 5000 Loss: 0.01702746376046269
Epoch: 39 Idx: 0 Loss: 0.034764379520108656
Epoch: 39 Idx: 5000 Loss: 0.01618578925277557
Epoch: 40 Idx: 0 Loss: 0.006695526218275027
Epoch: 40 Idx: 5000 Loss: 0.010136105584464702
Epoch: 41 Idx: 0 Loss: 0.01669899122220154
Epoch: 41 Idx: 5000 Loss: 0.014966041379571051
Epoch: 42 Idx: 0 Loss: 0.023619146145913275
Epoch: 42 Idx: 5000 Loss: 0.01886610695009908
Epoch: 43 Idx: 0 Loss: 0.024224766649305833
Epoch: 43 Idx: 5000 Loss: 0.017857068681494122
Epoch: 44 Idx: 0 Loss: 0.005806179123425092
Epoch: 44 Idx: 5000 Loss: 0.01022784596175196
Epoch: 45 Idx: 0 Loss: 0.011786336528840407
Epoch: 45 Idx: 5000 Loss: 0.02789291747134906
Epoch: 46 Idx: 0 Loss: 0.028195301231930734
Epoch: 46 Idx: 5000 Loss: 0.009373945865843895
Epoch: 47 Idx: 0 Loss: 0.004566140440747903
Epoch: 47 Idx: 5000 Loss: 0.014272163047588972
Epoch: 48 Idx: 0 Loss: 0.035557578083999605
Epoch: 48 Idx: 5000 Loss: 0.015328846219282467
Epoch: 49 Idx: 0 Loss: 0.013945299333064884
Epoch: 49 Idx: 5000 Loss: 0.0059030268375451014
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.21123637466719025
Epoch: 0 Idx: 5000 Loss: 0.02146577232790814
Epoch: 1 Idx: 0 Loss: 0.01591073465957103
Epoch: 1 Idx: 5000 Loss: 0.025657114856607113
Epoch: 2 Idx: 0 Loss: 0.047115024963060845
Epoch: 2 Idx: 5000 Loss: 0.014763459871583489
Epoch: 3 Idx: 0 Loss: 0.012150550201051071
Epoch: 3 Idx: 5000 Loss: 0.012977500749698553
Epoch: 4 Idx: 0 Loss: 0.025350097065200337
Epoch: 4 Idx: 5000 Loss: 0.020206470349994912
Epoch: 5 Idx: 0 Loss: 0.033060553352724446
Epoch: 5 Idx: 5000 Loss: 0.008251256070314988
Epoch: 6 Idx: 0 Loss: 0.01340592058989085
Epoch: 6 Idx: 5000 Loss: 0.028143139542388455
Epoch: 7 Idx: 0 Loss: 0.016618010022281762
Epoch: 7 Idx: 5000 Loss: 0.008757565251156934
Epoch: 8 Idx: 0 Loss: 0.01686706973226805
Epoch: 8 Idx: 5000 Loss: 0.011789303969300351
Epoch: 9 Idx: 0 Loss: 0.014795015904618222
Epoch: 9 Idx: 5000 Loss: 0.009806254825822576
Epoch: 10 Idx: 0 Loss: 0.030698433783397608
Epoch: 10 Idx: 5000 Loss: 0.011035335896988442
Epoch: 11 Idx: 0 Loss: 0.009708785042434193
Epoch: 11 Idx: 5000 Loss: 0.014043195901237086
Epoch: 12 Idx: 0 Loss: 0.01411650498352018
Epoch: 12 Idx: 5000 Loss: 0.016788476619916955
Epoch: 13 Idx: 0 Loss: 0.006273284310009809
Epoch: 13 Idx: 5000 Loss: 0.03137234370685999
Epoch: 14 Idx: 0 Loss: 0.01935157558917061
Epoch: 14 Idx: 5000 Loss: 0.034955847654738775
Epoch: 15 Idx: 0 Loss: 0.03616336993913807
Epoch: 15 Idx: 5000 Loss: 0.021507480864049626
Epoch: 16 Idx: 0 Loss: 0.011938395913685233
Epoch: 16 Idx: 5000 Loss: 0.010423192272784227
Epoch: 17 Idx: 0 Loss: 0.005761699686577857
Epoch: 17 Idx: 5000 Loss: 0.018708104586380985
Epoch: 18 Idx: 0 Loss: 0.01207082743944549
Epoch: 18 Idx: 5000 Loss: 0.02874535379782212
Epoch: 19 Idx: 0 Loss: 0.02630657426535367
Epoch: 19 Idx: 5000 Loss: 0.013394646584033594
Epoch: 20 Idx: 0 Loss: 0.012048725669720994
Epoch: 20 Idx: 5000 Loss: 0.007255324695539171
Epoch: 21 Idx: 0 Loss: 0.020035559415667016
Epoch: 21 Idx: 5000 Loss: 0.020898272861653903
Epoch: 22 Idx: 0 Loss: 0.016370101492493024
Epoch: 22 Idx: 5000 Loss: 0.029957214476521363
Epoch: 23 Idx: 0 Loss: 0.013074580499784272
Epoch: 23 Idx: 5000 Loss: 0.02284430916926205
Epoch: 24 Idx: 0 Loss: 0.01577133602308423
Epoch: 24 Idx: 5000 Loss: 0.024219922986270688
Epoch: 25 Idx: 0 Loss: 0.008027599798799414
Epoch: 25 Idx: 5000 Loss: 0.030394608427436697
Epoch: 26 Idx: 0 Loss: 0.011755383195061996
Epoch: 26 Idx: 5000 Loss: 0.01651883454292246
Epoch: 27 Idx: 0 Loss: 0.011686741735373754
Epoch: 27 Idx: 5000 Loss: 0.011858088713451542
Epoch: 28 Idx: 0 Loss: 0.02100747495687602
Epoch: 28 Idx: 5000 Loss: 0.01693638509862311
Epoch: 29 Idx: 0 Loss: 0.007184767399727364
Epoch: 29 Idx: 5000 Loss: 0.03178065652016855
Epoch: 30 Idx: 0 Loss: 0.020989389986515023
Epoch: 30 Idx: 5000 Loss: 0.015795511509289026
Epoch: 31 Idx: 0 Loss: 0.036542894462258446
Epoch: 31 Idx: 5000 Loss: 0.02389035577941879
Epoch: 32 Idx: 0 Loss: 0.030446281460202382
Epoch: 32 Idx: 5000 Loss: 0.013189524947922974
Epoch: 33 Idx: 0 Loss: 0.027758386798435918
Epoch: 33 Idx: 5000 Loss: 0.015801339580880015
Epoch: 34 Idx: 0 Loss: 0.012086729343747186
Epoch: 34 Idx: 5000 Loss: 0.007594702334824984
Epoch: 35 Idx: 0 Loss: 0.01638519688099171
Epoch: 35 Idx: 5000 Loss: 0.02357529735937236
Epoch: 36 Idx: 0 Loss: 0.010283731883988739
Epoch: 36 Idx: 5000 Loss: 0.024274209629210976
Epoch: 37 Idx: 0 Loss: 0.02248414060390301
Epoch: 37 Idx: 5000 Loss: 0.018586640114823832
Epoch: 38 Idx: 0 Loss: 0.010597926662455622
Epoch: 38 Idx: 5000 Loss: 0.007317254113334742
Epoch: 39 Idx: 0 Loss: 0.015526608565233926
Epoch: 39 Idx: 5000 Loss: 0.017385558690888574
Epoch: 40 Idx: 0 Loss: 0.014953633962628225
Epoch: 40 Idx: 5000 Loss: 0.020990481975934935
Epoch: 41 Idx: 0 Loss: 0.018566727492834063
Epoch: 41 Idx: 5000 Loss: 0.009731543814062188
Epoch: 42 Idx: 0 Loss: 0.008514112659427916
Epoch: 42 Idx: 5000 Loss: 0.01906927596620147
Epoch: 43 Idx: 0 Loss: 0.01341314450341409
Epoch: 43 Idx: 5000 Loss: 0.011941886035831569
Epoch: 44 Idx: 0 Loss: 0.010970025266425222
Epoch: 44 Idx: 5000 Loss: 0.008381843671233666
Epoch: 45 Idx: 0 Loss: 0.01970129825232269
Epoch: 45 Idx: 5000 Loss: 0.01469681795669768
Epoch: 46 Idx: 0 Loss: 0.01420225725180588
Epoch: 46 Idx: 5000 Loss: 0.02273341269177707
Epoch: 47 Idx: 0 Loss: 0.015257348197890213
Epoch: 47 Idx: 5000 Loss: 0.015064822148789393
Epoch: 48 Idx: 0 Loss: 0.024983186977148603
Epoch: 48 Idx: 5000 Loss: 0.010263939781859077
Epoch: 49 Idx: 0 Loss: 0.009902418379915675
Epoch: 49 Idx: 5000 Loss: 0.024776557535469805
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.2325792402789741
Epoch: 1 Idx: 0 Loss: 0.018905560121790392
Epoch: 2 Idx: 0 Loss: 0.018859193180832692
Epoch: 3 Idx: 0 Loss: 0.016046447284001415
Epoch: 4 Idx: 0 Loss: 0.01159809696466745
Epoch: 5 Idx: 0 Loss: 0.01248234949854363
Epoch: 6 Idx: 0 Loss: 0.044077678638576104
Epoch: 7 Idx: 0 Loss: 0.008170962736206688
Epoch: 8 Idx: 0 Loss: 0.02769477379754299
Epoch: 9 Idx: 0 Loss: 0.015098470415516513
Epoch: 10 Idx: 0 Loss: 0.004108428496572567
Epoch: 11 Idx: 0 Loss: 0.01349492062177841
Epoch: 12 Idx: 0 Loss: 0.020378625574165473
Epoch: 13 Idx: 0 Loss: 0.012206779943140065
Epoch: 14 Idx: 0 Loss: 0.02097228448405412
Epoch: 15 Idx: 0 Loss: 0.005370988427288634
Epoch: 16 Idx: 0 Loss: 0.007655087940196375
Epoch: 17 Idx: 0 Loss: 0.008180314383541032
Epoch: 18 Idx: 0 Loss: 0.01196922975591436
Epoch: 19 Idx: 0 Loss: 0.012801293796288932
Epoch: 20 Idx: 0 Loss: 0.007230569882939275
Epoch: 21 Idx: 0 Loss: 0.011779977713462297
Epoch: 22 Idx: 0 Loss: 0.012149085994214617
Epoch: 23 Idx: 0 Loss: 0.008630253231976892
Epoch: 24 Idx: 0 Loss: 0.013250661606602763
Epoch: 25 Idx: 0 Loss: 0.008303312790000029
Epoch: 26 Idx: 0 Loss: 0.02608674631937899
Epoch: 27 Idx: 0 Loss: 0.013836014838010021
Epoch: 28 Idx: 0 Loss: 0.022706181352836717
Epoch: 29 Idx: 0 Loss: 0.01376663086196241
Epoch: 30 Idx: 0 Loss: 0.02810969146638343
Epoch: 31 Idx: 0 Loss: 0.004518981650385865
Epoch: 32 Idx: 0 Loss: 0.013224138787647239
Epoch: 33 Idx: 0 Loss: 0.012150617936488629
Epoch: 34 Idx: 0 Loss: 0.007570038536052934
Epoch: 35 Idx: 0 Loss: 0.012532190713749397
Epoch: 36 Idx: 0 Loss: 0.02952909773616565
Epoch: 37 Idx: 0 Loss: 0.010032222603556835
Epoch: 38 Idx: 0 Loss: 0.010860153869728807
Epoch: 39 Idx: 0 Loss: 0.02290509601396377
Epoch: 40 Idx: 0 Loss: 0.011987535973915185
Epoch: 41 Idx: 0 Loss: 0.017087642499905915
Epoch: 42 Idx: 0 Loss: 0.007127155406867638
Epoch: 43 Idx: 0 Loss: 0.009820550315820888
Epoch: 44 Idx: 0 Loss: 0.009806126185467372
Epoch: 45 Idx: 0 Loss: 0.02489894712618017
Epoch: 46 Idx: 0 Loss: 0.010941875217933572
Epoch: 47 Idx: 0 Loss: 0.034934246930131606
Epoch: 48 Idx: 0 Loss: 0.007380762281227015
Epoch: 49 Idx: 0 Loss: 0.011034575906631816
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.1599045690036556
Epoch: 0 Idx: 5000 Loss: 0.007083623745273181
Epoch: 1 Idx: 0 Loss: 0.007504957682659372
Epoch: 1 Idx: 5000 Loss: 0.017037608607977768
Epoch: 2 Idx: 0 Loss: 0.013670059862604438
Epoch: 2 Idx: 5000 Loss: 0.015026377999227009
Epoch: 3 Idx: 0 Loss: 0.019352819464374473
Epoch: 3 Idx: 5000 Loss: 0.014154942329913912
Epoch: 4 Idx: 0 Loss: 0.011159232148215145
Epoch: 4 Idx: 5000 Loss: 0.013656755939040206
Epoch: 5 Idx: 0 Loss: 0.011806723305606117
Epoch: 5 Idx: 5000 Loss: 0.0106399615118145
Epoch: 6 Idx: 0 Loss: 0.013487890435429719
Epoch: 6 Idx: 5000 Loss: 0.020012407091969768
Epoch: 7 Idx: 0 Loss: 0.007599869203886907
Epoch: 7 Idx: 5000 Loss: 0.016947625436430993
Epoch: 8 Idx: 0 Loss: 0.008067383732874644
Epoch: 8 Idx: 5000 Loss: 0.01933173329781226
Epoch: 9 Idx: 0 Loss: 0.02855351211107033
Epoch: 9 Idx: 5000 Loss: 0.03681434352025056
Epoch: 10 Idx: 0 Loss: 0.00840383635951761
Epoch: 10 Idx: 5000 Loss: 0.013560358121540567
Epoch: 11 Idx: 0 Loss: 0.021239215480506064
Epoch: 11 Idx: 5000 Loss: 0.011253566687941363
Epoch: 12 Idx: 0 Loss: 0.018997306002254646
Epoch: 12 Idx: 5000 Loss: 0.009240328502370897
Epoch: 13 Idx: 0 Loss: 0.008754447168620567
Epoch: 13 Idx: 5000 Loss: 0.010063635179067575
Epoch: 14 Idx: 0 Loss: 0.010222917299748568
Epoch: 14 Idx: 5000 Loss: 0.024756040966061505
Epoch: 15 Idx: 0 Loss: 0.007202758557775735
Epoch: 15 Idx: 5000 Loss: 0.041780056042938434
Epoch: 16 Idx: 0 Loss: 0.010198164251589545
Epoch: 16 Idx: 5000 Loss: 0.00984541586975985
Epoch: 17 Idx: 0 Loss: 0.00521395035248394
Epoch: 17 Idx: 5000 Loss: 0.01357863831241468
Epoch: 18 Idx: 0 Loss: 0.010427929466915026
Epoch: 18 Idx: 5000 Loss: 0.013644831924216914
Epoch: 19 Idx: 0 Loss: 0.021442845673046045
Epoch: 19 Idx: 5000 Loss: 0.0071238994764812845
Epoch: 20 Idx: 0 Loss: 0.014539669461733545
Epoch: 20 Idx: 5000 Loss: 0.031701370154751767
Epoch: 21 Idx: 0 Loss: 0.013924010612958605
Epoch: 21 Idx: 5000 Loss: 0.006654247942594074
Epoch: 22 Idx: 0 Loss: 0.009516346243046234
Epoch: 22 Idx: 5000 Loss: 0.028173820276619067
Epoch: 23 Idx: 0 Loss: 0.014155502287396765
Epoch: 23 Idx: 5000 Loss: 0.009873593549264773
Epoch: 24 Idx: 0 Loss: 0.030208804392551036
Epoch: 24 Idx: 5000 Loss: 0.009651156936851011
Epoch: 25 Idx: 0 Loss: 0.010545693114567201
Epoch: 25 Idx: 5000 Loss: 0.02247015949664629
Epoch: 26 Idx: 0 Loss: 0.020888544120120856
Epoch: 26 Idx: 5000 Loss: 0.005471260991945719
Epoch: 27 Idx: 0 Loss: 0.0053354436492866735
Epoch: 27 Idx: 5000 Loss: 0.01104314235569958
Epoch: 28 Idx: 0 Loss: 0.011483363999063021
Epoch: 28 Idx: 5000 Loss: 0.03302163892273626
Epoch: 29 Idx: 0 Loss: 0.02385056911315787
Epoch: 29 Idx: 5000 Loss: 0.017617287159903513
Epoch: 30 Idx: 0 Loss: 0.01841200996985126
Epoch: 30 Idx: 5000 Loss: 0.010772572237633053
Epoch: 31 Idx: 0 Loss: 0.014458447450123245
Epoch: 31 Idx: 5000 Loss: 0.012949432676063036
Epoch: 32 Idx: 0 Loss: 0.013353898261276637
Epoch: 32 Idx: 5000 Loss: 0.024319506601977684
Epoch: 33 Idx: 0 Loss: 0.007490479594171465
Epoch: 33 Idx: 5000 Loss: 0.02419906370428137
Epoch: 34 Idx: 0 Loss: 0.014424896797007727
Epoch: 34 Idx: 5000 Loss: 0.005258688755604741
Epoch: 35 Idx: 0 Loss: 0.036033278155247025
Epoch: 35 Idx: 5000 Loss: 0.00838790902352287
Epoch: 36 Idx: 0 Loss: 0.02952182496626894
Epoch: 36 Idx: 5000 Loss: 0.021848243052091616
Epoch: 37 Idx: 0 Loss: 0.014682941046210806
Epoch: 37 Idx: 5000 Loss: 0.01091264908894285
Epoch: 38 Idx: 0 Loss: 0.004228037169514159
Epoch: 38 Idx: 5000 Loss: 0.011502769806826506
Epoch: 39 Idx: 0 Loss: 0.023137086119889
Epoch: 39 Idx: 5000 Loss: 0.02957138038753692
Epoch: 40 Idx: 0 Loss: 0.0241242877139927
Epoch: 40 Idx: 5000 Loss: 0.008315953578666728
Epoch: 41 Idx: 0 Loss: 0.016757736745945925
Epoch: 41 Idx: 5000 Loss: 0.023345052487565066
Epoch: 42 Idx: 0 Loss: 0.01685826838288391
Epoch: 42 Idx: 5000 Loss: 0.00815606062657889
Epoch: 43 Idx: 0 Loss: 0.01531467494876544
Epoch: 43 Idx: 5000 Loss: 0.016626826171055355
Epoch: 44 Idx: 0 Loss: 0.00754107891458569
Epoch: 44 Idx: 5000 Loss: 0.015963483169682737
Epoch: 45 Idx: 0 Loss: 0.012777320630452168
Epoch: 45 Idx: 5000 Loss: 0.010000251683528315
Epoch: 46 Idx: 0 Loss: 0.02551324564575464
Epoch: 46 Idx: 5000 Loss: 0.0057329600755825685
Epoch: 47 Idx: 0 Loss: 0.010989416437105697
Epoch: 47 Idx: 5000 Loss: 0.009401220520273453
Epoch: 48 Idx: 0 Loss: 0.023058136241202284
Epoch: 48 Idx: 5000 Loss: 0.00821962468275007
Epoch: 49 Idx: 0 Loss: 0.015187219848485459
Epoch: 49 Idx: 5000 Loss: 0.028819781963371996
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.2054097491037054
Epoch: 1 Idx: 0 Loss: 0.014935703793798234
Epoch: 2 Idx: 0 Loss: 0.013364756861953863
Epoch: 3 Idx: 0 Loss: 0.007393503148068
Epoch: 4 Idx: 0 Loss: 0.031132869366016835
Epoch: 5 Idx: 0 Loss: 0.01586133341746391
Epoch: 6 Idx: 0 Loss: 0.014662142631047124
Epoch: 7 Idx: 0 Loss: 0.011573080957503031
Epoch: 8 Idx: 0 Loss: 0.03177180342168041
Epoch: 9 Idx: 0 Loss: 0.009096401566353699
Epoch: 10 Idx: 0 Loss: 0.030552209143177182
Epoch: 11 Idx: 0 Loss: 0.02372852045411531
Epoch: 12 Idx: 0 Loss: 0.013907923928245223
Epoch: 13 Idx: 0 Loss: 0.02816868647587891
Epoch: 14 Idx: 0 Loss: 0.004683379382804044
Epoch: 15 Idx: 0 Loss: 0.010546937693638738
Epoch: 16 Idx: 0 Loss: 0.01160514291256122
Epoch: 17 Idx: 0 Loss: 0.03658200499089028
Epoch: 18 Idx: 0 Loss: 0.03838436740246348
Epoch: 19 Idx: 0 Loss: 0.02741660088840897
Epoch: 20 Idx: 0 Loss: 0.04032922341977504
Epoch: 21 Idx: 0 Loss: 0.0033325296027844516
Epoch: 22 Idx: 0 Loss: 0.012457509598201369
Epoch: 23 Idx: 0 Loss: 0.009596812040357634
Epoch: 24 Idx: 0 Loss: 0.017402040563557944
Epoch: 25 Idx: 0 Loss: 0.011330499141878937
Epoch: 26 Idx: 0 Loss: 0.022311323531368547
Epoch: 27 Idx: 0 Loss: 0.010049864525075782
Epoch: 28 Idx: 0 Loss: 0.01568935408820643
Epoch: 29 Idx: 0 Loss: 0.019742103943736936
Epoch: 30 Idx: 0 Loss: 0.01645503382511649
Epoch: 31 Idx: 0 Loss: 0.008703716652769984
Epoch: 32 Idx: 0 Loss: 0.00588038131103802
Epoch: 33 Idx: 0 Loss: 0.006139568620901565
Epoch: 34 Idx: 0 Loss: 0.019061563409996925
Epoch: 35 Idx: 0 Loss: 0.032497385674680454
Epoch: 36 Idx: 0 Loss: 0.016597819667004462
Epoch: 37 Idx: 0 Loss: 0.009302991385202923
Epoch: 38 Idx: 0 Loss: 0.005168571554897462
Epoch: 39 Idx: 0 Loss: 0.007822477771895434
Epoch: 40 Idx: 0 Loss: 0.019692068204115336
Epoch: 41 Idx: 0 Loss: 0.00976631517040142
Epoch: 42 Idx: 0 Loss: 0.0091404905015251
Epoch: 43 Idx: 0 Loss: 0.04193776471160867
Epoch: 44 Idx: 0 Loss: 0.010245153761266121
Epoch: 45 Idx: 0 Loss: 0.03342915956193022
Epoch: 46 Idx: 0 Loss: 0.005193400939965443
Epoch: 47 Idx: 0 Loss: 0.016545266812415083
Epoch: 48 Idx: 0 Loss: 0.012850556918814513
Epoch: 49 Idx: 0 Loss: 0.019861771162505176
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7857142857142857, 0.7333333333333333, 0.7586206896551724, 0.7432432432432431, 0.7746478873239436)
Performance for  [('ekaw', 'sigkdd')] is : (0.8461538461538461, 1.0, 0.9166666666666666, 0.9649122807017543, 0.8730158730158731)
Performance for  [('conference', 'edas')] is : (0.8461538461538461, 0.6470588235294118, 0.7333333333333334, 0.6790123456790124, 0.7971014492753623)
Performance for  [('cmt', 'ekaw')] is : (0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454)
Performance for  [('confOf', 'edas')] is : (0.6190476190476191, 0.6842105263157895, 0.6500000000000001, 0.6701030927835052, 0.6310679611650486)
Performance for  [('iasted', 'sigkdd')] is : (0.6470588235294118, 0.7333333333333333, 0.6875, 0.7142857142857143, 0.6626506024096386)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.6666666666666666, 0.8, 0.7142857142857142, 0.9090909090909091)
Final Results: [0.75565471 0.71572246 0.72736789 0.71875671 0.74186132]
Threshold:  0.915

------------------------------------------------------------
Sender: LSF System <rer@dccxc263>
Subject: Job 4142597: <python main.py 5 2 False True> in cluster <dcc> Done

Job <python main.py 5 2 False True> was submitted from host <dccxl001> by user <naveen9> in cluster <dcc> at Wed Sep 16 06:55:12 2020
Job was executed on host(s) <dccxc263>, in queue <x86_24h>, as user <naveen9> in cluster <dcc> at Wed Sep 16 09:40:23 2020
</u/naveen9> was used as the home directory.
</u/naveen9/arvind/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 09:40:23 2020
Terminated at Wed Sep 16 22:56:03 2020
Results reported at Wed Sep 16 22:56:03 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 2 False True
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   47726.05 sec.
    Max Memory :                                 2893 MB
    Average Memory :                             2723.19 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40524.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   47750 sec.
    Turnaround time :                            57651 sec.

The output (if any) is above this job summary.

