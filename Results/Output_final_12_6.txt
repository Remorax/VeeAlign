2020-09-16 10:05:34.250460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:05:37.743519: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-16 10:05:37.864238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-16 10:05:37.864328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-16 10:05:37.866199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-16 10:05:37.867679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-16 10:05:37.868046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-16 10:05:37.869974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-16 10:05:37.871491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-16 10:05:37.871713: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:/usr/local/cuda/lib64
2020-09-16 10:05:37.871736: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-16 10:05:37.872064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-16 10:05:37.879527: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599830000 Hz
2020-09-16 10:05:37.879717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f51d934c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-16 10:05:37.879739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-16 10:05:37.881802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-16 10:05:37.881845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /u/shagutt1/VeeAlign/
Ontologies being aligned are:  [('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/conference.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/cmt.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/edas.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/u/shagutt1/VeeAlign/datasets/conference/ontologies/confOf.owl', '/u/shagutt1/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 122893
Starting sliding window evaluation...
Step 0.0/7
Val onto:  [('conference', 'confOf'), ('confOf', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.22547006644094303
Epoch: 0 Idx: 5000 Loss: 0.012517725033927913
Epoch: 1 Idx: 0 Loss: 0.018513842586730327
Epoch: 1 Idx: 5000 Loss: 0.009197099250700076
Epoch: 2 Idx: 0 Loss: 0.016434881503440846
Epoch: 2 Idx: 5000 Loss: 0.011543365404428598
Epoch: 3 Idx: 0 Loss: 0.017130212005980805
Epoch: 3 Idx: 5000 Loss: 0.008941187639240336
Epoch: 4 Idx: 0 Loss: 0.010889505889938624
Epoch: 4 Idx: 5000 Loss: 0.009615431767162324
Epoch: 5 Idx: 0 Loss: 0.012496860369610192
Epoch: 5 Idx: 5000 Loss: 0.0076032229402349825
Epoch: 6 Idx: 0 Loss: 0.009806926103308865
Epoch: 6 Idx: 5000 Loss: 0.008597424795262267
Epoch: 7 Idx: 0 Loss: 0.02118586875042612
Epoch: 7 Idx: 5000 Loss: 0.019912165463782223
Epoch: 8 Idx: 0 Loss: 0.025289031054332542
Epoch: 8 Idx: 5000 Loss: 0.00901079400387971
Epoch: 9 Idx: 0 Loss: 0.005307013885126761
Epoch: 9 Idx: 5000 Loss: 0.0176178332117724
Epoch: 10 Idx: 0 Loss: 0.023154598383650755
Epoch: 10 Idx: 5000 Loss: 0.014066819418369039
Epoch: 11 Idx: 0 Loss: 0.012548271396916645
Epoch: 11 Idx: 5000 Loss: 0.03769158166983032
Epoch: 12 Idx: 0 Loss: 0.021525918881066114
Epoch: 12 Idx: 5000 Loss: 0.010368042431182292
Epoch: 13 Idx: 0 Loss: 0.013767525379074792
Epoch: 13 Idx: 5000 Loss: 0.01776686708580459
Epoch: 14 Idx: 0 Loss: 0.0179412141697892
Epoch: 14 Idx: 5000 Loss: 0.019634706729465354
Epoch: 15 Idx: 0 Loss: 0.03191951461532912
Epoch: 15 Idx: 5000 Loss: 0.02420746555796128
Epoch: 16 Idx: 0 Loss: 0.009828575692205967
Epoch: 16 Idx: 5000 Loss: 0.011990114026722653
Epoch: 17 Idx: 0 Loss: 0.013094402818864419
Epoch: 17 Idx: 5000 Loss: 0.015530129327807656
Epoch: 18 Idx: 0 Loss: 0.017343026064616674
Epoch: 18 Idx: 5000 Loss: 0.014441707348409463
Epoch: 19 Idx: 0 Loss: 0.03416808488075396
Epoch: 19 Idx: 5000 Loss: 0.012793455612446816
Epoch: 20 Idx: 0 Loss: 0.007873106207194105
Epoch: 20 Idx: 5000 Loss: 0.012822135427777267
Epoch: 21 Idx: 0 Loss: 0.021326417442904935
Epoch: 21 Idx: 5000 Loss: 0.04648315226248713
Epoch: 22 Idx: 0 Loss: 0.010117092919314865
Epoch: 22 Idx: 5000 Loss: 0.01886356431053974
Epoch: 23 Idx: 0 Loss: 0.03361736908564128
Epoch: 23 Idx: 5000 Loss: 0.022511026961630574
Epoch: 24 Idx: 0 Loss: 0.011381573057578472
Epoch: 24 Idx: 5000 Loss: 0.012112690958161289
Epoch: 25 Idx: 0 Loss: 0.013158300849001851
Epoch: 25 Idx: 5000 Loss: 0.013526303560386439
Epoch: 26 Idx: 0 Loss: 0.017539805577091665
Epoch: 26 Idx: 5000 Loss: 0.033809210460008926
Epoch: 27 Idx: 0 Loss: 0.0060998536858750205
Epoch: 27 Idx: 5000 Loss: 0.01176109754315521
Epoch: 28 Idx: 0 Loss: 0.03267485327344653
Epoch: 28 Idx: 5000 Loss: 0.008737266294470813
Epoch: 29 Idx: 0 Loss: 0.016021030118850022
Epoch: 29 Idx: 5000 Loss: 0.010277765147725756
Epoch: 30 Idx: 0 Loss: 0.012343017433349687
Epoch: 30 Idx: 5000 Loss: 0.009707627856738819
Epoch: 31 Idx: 0 Loss: 0.03840865378516734
Epoch: 31 Idx: 5000 Loss: 0.010091856625235068
Epoch: 32 Idx: 0 Loss: 0.018827967350996185
Epoch: 32 Idx: 5000 Loss: 0.02817047219680141
Epoch: 33 Idx: 0 Loss: 0.010332967444375776
Epoch: 33 Idx: 5000 Loss: 0.035643446853704915
Epoch: 34 Idx: 0 Loss: 0.015071340545684543
Epoch: 34 Idx: 5000 Loss: 0.023623787348295483
Epoch: 35 Idx: 0 Loss: 0.023038368595726777
Epoch: 35 Idx: 5000 Loss: 0.009146740961802662
Epoch: 36 Idx: 0 Loss: 0.014568873582448849
Epoch: 36 Idx: 5000 Loss: 0.018233753763204723
Epoch: 37 Idx: 0 Loss: 0.027690108465101733
Epoch: 37 Idx: 5000 Loss: 0.008125152402557475
Epoch: 38 Idx: 0 Loss: 0.02761018630815576
Epoch: 38 Idx: 5000 Loss: 0.007670320457468733
Epoch: 39 Idx: 0 Loss: 0.010471416920518055
Epoch: 39 Idx: 5000 Loss: 0.012876793070798932
Epoch: 40 Idx: 0 Loss: 0.0140027721188993
Epoch: 40 Idx: 5000 Loss: 0.015934214951532286
Epoch: 41 Idx: 0 Loss: 0.01624352946182035
Epoch: 41 Idx: 5000 Loss: 0.005694428174952232
Epoch: 42 Idx: 0 Loss: 0.008327789326796668
Epoch: 42 Idx: 5000 Loss: 0.014476486741635906
Epoch: 43 Idx: 0 Loss: 0.03398495521066773
Epoch: 43 Idx: 5000 Loss: 0.030438307377083314
Epoch: 44 Idx: 0 Loss: 0.012385295417929425
Epoch: 44 Idx: 5000 Loss: 0.01643192060773186
Epoch: 45 Idx: 0 Loss: 0.01584974744233554
Epoch: 45 Idx: 5000 Loss: 0.024512316916843115
Epoch: 46 Idx: 0 Loss: 0.04082733143511379
Epoch: 46 Idx: 5000 Loss: 0.03437381005673243
Epoch: 47 Idx: 0 Loss: 0.012077518607465032
Epoch: 47 Idx: 5000 Loss: 0.02114198564769971
Epoch: 48 Idx: 0 Loss: 0.012527685436003813
Epoch: 48 Idx: 5000 Loss: 0.021970552805789384
Epoch: 49 Idx: 0 Loss: 0.029257283501531325
Epoch: 49 Idx: 5000 Loss: 0.015597181686340788
Len (direct inputs):  1555
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 1.0/7
Val onto:  [('conference', 'ekaw'), ('cmt', 'sigkdd')] test_onto:  [('ekaw', 'sigkdd')]
Training size: 110566 Testing size: 4138
Epoch: 0 Idx: 0 Loss: 0.2399705463620332
Epoch: 0 Idx: 5000 Loss: 0.04051162074328361
Epoch: 1 Idx: 0 Loss: 0.01280823649444473
Epoch: 1 Idx: 5000 Loss: 0.010420121144996325
Epoch: 2 Idx: 0 Loss: 0.019565383841413726
Epoch: 2 Idx: 5000 Loss: 0.014041011935001015
Epoch: 3 Idx: 0 Loss: 0.024316737899690077
Epoch: 3 Idx: 5000 Loss: 0.016223774765595445
Epoch: 4 Idx: 0 Loss: 0.010264253947874821
Epoch: 4 Idx: 5000 Loss: 0.012095343943967541
Epoch: 5 Idx: 0 Loss: 0.01429499394042093
Epoch: 5 Idx: 5000 Loss: 0.011064116038967342
Epoch: 6 Idx: 0 Loss: 0.014669357445263055
Epoch: 6 Idx: 5000 Loss: 0.01471433412357314
Epoch: 7 Idx: 0 Loss: 0.022167973104901442
Epoch: 7 Idx: 5000 Loss: 0.012494270605779791
Epoch: 8 Idx: 0 Loss: 0.015031722758247549
Epoch: 8 Idx: 5000 Loss: 0.012587689180458541
Epoch: 9 Idx: 0 Loss: 0.018415361877902436
Epoch: 9 Idx: 5000 Loss: 0.014382441220940213
Epoch: 10 Idx: 0 Loss: 0.04588612577439185
Epoch: 10 Idx: 5000 Loss: 0.025437456234327388
Epoch: 11 Idx: 0 Loss: 0.014112139821009322
Epoch: 11 Idx: 5000 Loss: 0.015478712540483802
Epoch: 12 Idx: 0 Loss: 0.012541146281817812
Epoch: 12 Idx: 5000 Loss: 0.038100608754488494
Epoch: 13 Idx: 0 Loss: 0.012636416489517377
Epoch: 13 Idx: 5000 Loss: 0.012630591613612584
Epoch: 14 Idx: 0 Loss: 0.01304490056507931
Epoch: 14 Idx: 5000 Loss: 0.012578811278947949
Epoch: 15 Idx: 0 Loss: 0.010157502545571264
Epoch: 15 Idx: 5000 Loss: 0.03144611273733177
Epoch: 16 Idx: 0 Loss: 0.01033186392811885
Epoch: 16 Idx: 5000 Loss: 0.04512499948195929
Epoch: 17 Idx: 0 Loss: 0.016200255951457618
Epoch: 17 Idx: 5000 Loss: 0.04340677558077086
Epoch: 18 Idx: 0 Loss: 0.008609462063118956
Epoch: 18 Idx: 5000 Loss: 0.011039556508192744
Epoch: 19 Idx: 0 Loss: 0.01305978358878939
Epoch: 19 Idx: 5000 Loss: 0.029655282274202673
Epoch: 20 Idx: 0 Loss: 0.019681263944142345
Epoch: 20 Idx: 5000 Loss: 0.014083217927166821
Epoch: 21 Idx: 0 Loss: 0.01292143715306844
Epoch: 21 Idx: 5000 Loss: 0.023911091694524402
Epoch: 22 Idx: 0 Loss: 0.016210308896818886
Epoch: 22 Idx: 5000 Loss: 0.01707280569956721
Epoch: 23 Idx: 0 Loss: 0.01039272061610549
Epoch: 23 Idx: 5000 Loss: 0.016460369586560705
Epoch: 24 Idx: 0 Loss: 0.01564164716479442
Epoch: 24 Idx: 5000 Loss: 0.018180611307278202
Epoch: 25 Idx: 0 Loss: 0.012014130218874233
Epoch: 25 Idx: 5000 Loss: 0.015504123929198688
Epoch: 26 Idx: 0 Loss: 0.010150053515163609
Epoch: 26 Idx: 5000 Loss: 0.008521804203377795
Epoch: 27 Idx: 0 Loss: 0.0066765608216910344
Epoch: 27 Idx: 5000 Loss: 0.028303974885689705
Epoch: 28 Idx: 0 Loss: 0.00692089971293066
Epoch: 28 Idx: 5000 Loss: 0.03500659605146736
Epoch: 29 Idx: 0 Loss: 0.011423399019141155
Epoch: 29 Idx: 5000 Loss: 0.008561378974442873
Epoch: 30 Idx: 0 Loss: 0.014828822479347666
Epoch: 30 Idx: 5000 Loss: 0.031012904980418872
Epoch: 31 Idx: 0 Loss: 0.01620243545678743
Epoch: 31 Idx: 5000 Loss: 0.0183690445344277
Epoch: 32 Idx: 0 Loss: 0.0054081989819733415
Epoch: 32 Idx: 5000 Loss: 0.026322733232342216
Epoch: 33 Idx: 0 Loss: 0.022027426386497167
Epoch: 33 Idx: 5000 Loss: 0.015616639098166895
Epoch: 34 Idx: 0 Loss: 0.01573218047466641
Epoch: 34 Idx: 5000 Loss: 0.008179936391457407
Epoch: 35 Idx: 0 Loss: 0.007202720218544609
Epoch: 35 Idx: 5000 Loss: 0.017591707336284908
Epoch: 36 Idx: 0 Loss: 0.023325300669406912
Epoch: 36 Idx: 5000 Loss: 0.013101640545620625
Epoch: 37 Idx: 0 Loss: 0.030137768827232903
Epoch: 37 Idx: 5000 Loss: 0.007008653008880362
Epoch: 38 Idx: 0 Loss: 0.010126772249617836
Epoch: 38 Idx: 5000 Loss: 0.049005283868147016
Epoch: 39 Idx: 0 Loss: 0.007467479395582934
Epoch: 39 Idx: 5000 Loss: 0.01084392965685617
Epoch: 40 Idx: 0 Loss: 0.02109398078688492
Epoch: 40 Idx: 5000 Loss: 0.019313440526736513
Epoch: 41 Idx: 0 Loss: 0.00868585985682026
Epoch: 41 Idx: 5000 Loss: 0.004986316453346056
Epoch: 42 Idx: 0 Loss: 0.024072503976543577
Epoch: 42 Idx: 5000 Loss: 0.019899292308929895
Epoch: 43 Idx: 0 Loss: 0.010013671161786593
Epoch: 43 Idx: 5000 Loss: 0.01247489965759195
Epoch: 44 Idx: 0 Loss: 0.011747798993911707
Epoch: 44 Idx: 5000 Loss: 0.016348762985732578
Epoch: 45 Idx: 0 Loss: 0.00943075134146462
Epoch: 45 Idx: 5000 Loss: 0.012860691644186736
Epoch: 46 Idx: 0 Loss: 0.01837967462815619
Epoch: 46 Idx: 5000 Loss: 0.022978360521245612
Epoch: 47 Idx: 0 Loss: 0.02800461424993235
Epoch: 47 Idx: 5000 Loss: 0.010012758715818314
Epoch: 48 Idx: 0 Loss: 0.009371877388257194
Epoch: 48 Idx: 5000 Loss: 0.016359023864625004
Epoch: 49 Idx: 0 Loss: 0.01748937800533889
Epoch: 49 Idx: 5000 Loss: 0.025490934567454524
Len (direct inputs):  2729
Inputs len 3577 11 4127
Len (direct inputs):  561
Starting sliding window evaluation...
Step 2.0/7
Val onto:  [('cmt', 'conference'), ('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 105154 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.17142295914955302
Epoch: 0 Idx: 5000 Loss: 0.0309993035092581
Epoch: 1 Idx: 0 Loss: 0.016618946432074365
Epoch: 1 Idx: 5000 Loss: 0.012277357440543594
Epoch: 2 Idx: 0 Loss: 0.011559976303701161
Epoch: 2 Idx: 5000 Loss: 0.011190109694929994
Epoch: 3 Idx: 0 Loss: 0.019121721145716707
Epoch: 3 Idx: 5000 Loss: 0.01069274009799059
Epoch: 4 Idx: 0 Loss: 0.02122007526703863
Epoch: 4 Idx: 5000 Loss: 0.01101658106803087
Epoch: 5 Idx: 0 Loss: 0.009193739903400056
Epoch: 5 Idx: 5000 Loss: 0.010010382136145853
Epoch: 6 Idx: 0 Loss: 0.012371425461311088
Epoch: 6 Idx: 5000 Loss: 0.01619655000263625
Epoch: 7 Idx: 0 Loss: 0.018391642773793744
Epoch: 7 Idx: 5000 Loss: 0.04198400321002817
Epoch: 8 Idx: 0 Loss: 0.03839700066159891
Epoch: 8 Idx: 5000 Loss: 0.01169195883716234
Epoch: 9 Idx: 0 Loss: 0.006553287401827416
Epoch: 9 Idx: 5000 Loss: 0.014004481762983743
Epoch: 10 Idx: 0 Loss: 0.006730603351031103
Epoch: 10 Idx: 5000 Loss: 0.01542692120678817
Epoch: 11 Idx: 0 Loss: 0.018426710264665296
Epoch: 11 Idx: 5000 Loss: 0.018690543241556758
Epoch: 12 Idx: 0 Loss: 0.014755028169132737
Epoch: 12 Idx: 5000 Loss: 0.009922237919037787
Epoch: 13 Idx: 0 Loss: 0.008823966809586511
Epoch: 13 Idx: 5000 Loss: 0.009363769714571146
Epoch: 14 Idx: 0 Loss: 0.007957234077373936
Epoch: 14 Idx: 5000 Loss: 0.015042841821079156
Epoch: 15 Idx: 0 Loss: 0.010607085234396843
Epoch: 15 Idx: 5000 Loss: 0.007857535042045035
Epoch: 16 Idx: 0 Loss: 0.044433569266761605
Epoch: 16 Idx: 5000 Loss: 0.014449586467237317
Epoch: 17 Idx: 0 Loss: 0.019473946294471547
Epoch: 17 Idx: 5000 Loss: 0.009670659647073582
Epoch: 18 Idx: 0 Loss: 0.016683035895304593
Epoch: 18 Idx: 5000 Loss: 0.01095346304636654
Epoch: 19 Idx: 0 Loss: 0.011409435236532161
Epoch: 19 Idx: 5000 Loss: 0.019124252391235032
Epoch: 20 Idx: 0 Loss: 0.006431770150493808
Epoch: 20 Idx: 5000 Loss: 0.014383349645698141
Epoch: 21 Idx: 0 Loss: 0.015832650352471382
Epoch: 21 Idx: 5000 Loss: 0.015050968738180273
Epoch: 22 Idx: 0 Loss: 0.009549595115265512
Epoch: 22 Idx: 5000 Loss: 0.009830072785850701
Epoch: 23 Idx: 0 Loss: 0.008766030251352957
Epoch: 23 Idx: 5000 Loss: 0.03455181236617624
Epoch: 24 Idx: 0 Loss: 0.02285787939246536
Epoch: 24 Idx: 5000 Loss: 0.024376332732843956
Epoch: 25 Idx: 0 Loss: 0.03591779580219499
Epoch: 25 Idx: 5000 Loss: 0.026881967867943217
Epoch: 26 Idx: 0 Loss: 0.010884856398780056
Epoch: 26 Idx: 5000 Loss: 0.015170031696060678
Epoch: 27 Idx: 0 Loss: 0.028405439327318063
Epoch: 27 Idx: 5000 Loss: 0.010605529691820792
Epoch: 28 Idx: 0 Loss: 0.013148158199621958
Epoch: 28 Idx: 5000 Loss: 0.007020971256715682
Epoch: 29 Idx: 0 Loss: 0.006119435014246366
Epoch: 29 Idx: 5000 Loss: 0.01661862283471572
Epoch: 30 Idx: 0 Loss: 0.014640551435294025
Epoch: 30 Idx: 5000 Loss: 0.03334154685916067
Epoch: 31 Idx: 0 Loss: 0.007660905523775418
Epoch: 31 Idx: 5000 Loss: 0.012377412296113019
Epoch: 32 Idx: 0 Loss: 0.0161937148284021
Epoch: 32 Idx: 5000 Loss: 0.009834186920198839
Epoch: 33 Idx: 0 Loss: 0.010633037444678858
Epoch: 33 Idx: 5000 Loss: 0.026571007747605038
Epoch: 34 Idx: 0 Loss: 0.01126117313784521
Epoch: 34 Idx: 5000 Loss: 0.01138212488062421
Epoch: 35 Idx: 0 Loss: 0.005421271909380854
Epoch: 35 Idx: 5000 Loss: 0.015100196351971632
Epoch: 36 Idx: 0 Loss: 0.013273469704352493
Epoch: 36 Idx: 5000 Loss: 0.01639994289610872
Epoch: 37 Idx: 0 Loss: 0.022133889906991798
Epoch: 37 Idx: 5000 Loss: 0.013321391783553635
Epoch: 38 Idx: 0 Loss: 0.022742667431491365
Epoch: 38 Idx: 5000 Loss: 0.017656797581331634
Epoch: 39 Idx: 0 Loss: 0.024864812166830452
Epoch: 39 Idx: 5000 Loss: 0.0095932762860609
Epoch: 40 Idx: 0 Loss: 0.020479215851126158
Epoch: 40 Idx: 5000 Loss: 0.021516961183292445
Epoch: 41 Idx: 0 Loss: 0.017480655202718645
Epoch: 41 Idx: 5000 Loss: 0.022576703294773633
Epoch: 42 Idx: 0 Loss: 0.02102911983375444
Epoch: 42 Idx: 5000 Loss: 0.023759362694338718
Epoch: 43 Idx: 0 Loss: 0.0300988805682381
Epoch: 43 Idx: 5000 Loss: 0.010856663929882725
Epoch: 44 Idx: 0 Loss: 0.008386849788284943
Epoch: 44 Idx: 5000 Loss: 0.02349924956212472
Epoch: 45 Idx: 0 Loss: 0.009756768297708183
Epoch: 45 Idx: 5000 Loss: 0.009837881820733531
Epoch: 46 Idx: 0 Loss: 0.01827459272274977
Epoch: 46 Idx: 5000 Loss: 0.02101330253289879
Epoch: 47 Idx: 0 Loss: 0.0067421736390328646
Epoch: 47 Idx: 5000 Loss: 0.017384525530484297
Epoch: 48 Idx: 0 Loss: 0.025882503271741485
Epoch: 48 Idx: 5000 Loss: 0.012273142954809467
Epoch: 49 Idx: 0 Loss: 0.022958041581922127
Epoch: 49 Idx: 5000 Loss: 0.008539911589414083
Len (direct inputs):  3454
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 3.0/7
Val onto:  [('cmt', 'iasted'), ('confOf', 'sigkdd')] test_onto:  [('cmt', 'ekaw')]
Training size: 110871 Testing size: 3734
Epoch: 0 Idx: 0 Loss: 0.18620720359061363
Epoch: 0 Idx: 5000 Loss: 0.03400460229384707
Epoch: 1 Idx: 0 Loss: 0.025733944411022343
Epoch: 1 Idx: 5000 Loss: 0.01894804656258857
Epoch: 2 Idx: 0 Loss: 0.007347795151141517
Epoch: 2 Idx: 5000 Loss: 0.0167875119958314
Epoch: 3 Idx: 0 Loss: 0.00519164227425375
Epoch: 3 Idx: 5000 Loss: 0.007219896451828878
Epoch: 4 Idx: 0 Loss: 0.014252039993737657
Epoch: 4 Idx: 5000 Loss: 0.007790064524833126
Epoch: 5 Idx: 0 Loss: 0.007344167490873579
Epoch: 5 Idx: 5000 Loss: 0.009149338155484101
Epoch: 6 Idx: 0 Loss: 0.009504514352424538
Epoch: 6 Idx: 5000 Loss: 0.016751869920283283
Epoch: 7 Idx: 0 Loss: 0.013252178273455779
Epoch: 7 Idx: 5000 Loss: 0.007503958150878521
Epoch: 8 Idx: 0 Loss: 0.018359651335391327
Epoch: 8 Idx: 5000 Loss: 0.005332667885395602
Epoch: 9 Idx: 0 Loss: 0.022654463529889368
Epoch: 9 Idx: 5000 Loss: 0.007556574544182109
Epoch: 10 Idx: 0 Loss: 0.013870030978536795
Epoch: 10 Idx: 5000 Loss: 0.019434078714733315
Epoch: 11 Idx: 0 Loss: 0.008649933306284404
Epoch: 11 Idx: 5000 Loss: 0.01121515051723238
Epoch: 12 Idx: 0 Loss: 0.013139065542415899
Epoch: 12 Idx: 5000 Loss: 0.016123774426507663
Epoch: 13 Idx: 0 Loss: 0.007266351124032158
Epoch: 13 Idx: 5000 Loss: 0.022206759940984606
Epoch: 14 Idx: 0 Loss: 0.008026228464834853
Epoch: 14 Idx: 5000 Loss: 0.014505529805730331
Epoch: 15 Idx: 0 Loss: 0.019792045662701017
Epoch: 15 Idx: 5000 Loss: 0.013016068924292464
Epoch: 16 Idx: 0 Loss: 0.009116256088719975
Epoch: 16 Idx: 5000 Loss: 0.01069406084071093
Epoch: 17 Idx: 0 Loss: 0.011211558515210274
Epoch: 17 Idx: 5000 Loss: 0.011609327503702773
Epoch: 18 Idx: 0 Loss: 0.014223033400347068
Epoch: 18 Idx: 5000 Loss: 0.008836433394471765
Epoch: 19 Idx: 0 Loss: 0.019982263818240396
Epoch: 19 Idx: 5000 Loss: 0.012662490092374462
Epoch: 20 Idx: 0 Loss: 0.013488474562168744
Epoch: 20 Idx: 5000 Loss: 0.007386181799543702
Epoch: 21 Idx: 0 Loss: 0.017836855787962982
Epoch: 21 Idx: 5000 Loss: 0.01352697792439134
Epoch: 22 Idx: 0 Loss: 0.01381363477799874
Epoch: 22 Idx: 5000 Loss: 0.012729418753983606
Epoch: 23 Idx: 0 Loss: 0.0159904487851153
Epoch: 23 Idx: 5000 Loss: 0.019228267965368723
Epoch: 24 Idx: 0 Loss: 0.03207333277563573
Epoch: 24 Idx: 5000 Loss: 0.011771094450693319
Epoch: 25 Idx: 0 Loss: 0.010098823211100377
Epoch: 25 Idx: 5000 Loss: 0.008629266656014063
Epoch: 26 Idx: 0 Loss: 0.03374218795325855
Epoch: 26 Idx: 5000 Loss: 0.012666667093050043
Epoch: 27 Idx: 0 Loss: 0.04650354866523827
Epoch: 27 Idx: 5000 Loss: 0.008166962710576629
Epoch: 28 Idx: 0 Loss: 0.007321093082799204
Epoch: 28 Idx: 5000 Loss: 0.009335518038741417
Epoch: 29 Idx: 0 Loss: 0.007147396384679511
Epoch: 29 Idx: 5000 Loss: 0.01809347909489876
Epoch: 30 Idx: 0 Loss: 0.009116133199140494
Epoch: 30 Idx: 5000 Loss: 0.013095248867718592
Epoch: 31 Idx: 0 Loss: 0.026781912620183673
Epoch: 31 Idx: 5000 Loss: 0.012948966614288885
Epoch: 32 Idx: 0 Loss: 0.033684369791452895
Epoch: 32 Idx: 5000 Loss: 0.01440960253755331
Epoch: 33 Idx: 0 Loss: 0.01214550945167846
Epoch: 33 Idx: 5000 Loss: 0.016941286309807006
Epoch: 34 Idx: 0 Loss: 0.011372693806511392
Epoch: 34 Idx: 5000 Loss: 0.01498286389242014
Epoch: 35 Idx: 0 Loss: 0.01830200159559392
Epoch: 35 Idx: 5000 Loss: 0.0205031071335101
Epoch: 36 Idx: 0 Loss: 0.01982889647130135
Epoch: 36 Idx: 5000 Loss: 0.015083831217471508
Epoch: 37 Idx: 0 Loss: 0.012697141648735342
Epoch: 37 Idx: 5000 Loss: 0.015948020409253957
Epoch: 38 Idx: 0 Loss: 0.013328144053129723
Epoch: 38 Idx: 5000 Loss: 0.012026035795151895
Epoch: 39 Idx: 0 Loss: 0.013799199948095456
Epoch: 39 Idx: 5000 Loss: 0.026172959161690455
Epoch: 40 Idx: 0 Loss: 0.019097438044222616
Epoch: 40 Idx: 5000 Loss: 0.009071311310200874
Epoch: 41 Idx: 0 Loss: 0.013035693952410133
Epoch: 41 Idx: 5000 Loss: 0.012064185891745492
Epoch: 42 Idx: 0 Loss: 0.012413001969813302
Epoch: 42 Idx: 5000 Loss: 0.02066055697463408
Epoch: 43 Idx: 0 Loss: 0.009501414352003346
Epoch: 43 Idx: 5000 Loss: 0.011941585421527592
Epoch: 44 Idx: 0 Loss: 0.013950311397854735
Epoch: 44 Idx: 5000 Loss: 0.01225732442811084
Epoch: 45 Idx: 0 Loss: 0.014028118543757087
Epoch: 45 Idx: 5000 Loss: 0.010732632464812665
Epoch: 46 Idx: 0 Loss: 0.023048313503616778
Epoch: 46 Idx: 5000 Loss: 0.013568982220012524
Epoch: 47 Idx: 0 Loss: 0.02584859695347451
Epoch: 47 Idx: 5000 Loss: 0.014721777508932301
Epoch: 48 Idx: 0 Loss: 0.01052537701973657
Epoch: 48 Idx: 5000 Loss: 0.015709677008566694
Epoch: 49 Idx: 0 Loss: 0.012598632002601383
Epoch: 49 Idx: 5000 Loss: 0.016895341124632677
Len (direct inputs):  2562
Inputs len 2044 11 3723
Len (direct inputs):  1690
Starting sliding window evaluation...
Step 4.0/7
Val onto:  [('ekaw', 'iasted'), ('conference', 'iasted')] test_onto:  [('confOf', 'edas')]
Training size: 96593 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.22140979217322532
Epoch: 1 Idx: 0 Loss: 0.02454894973139856
Epoch: 2 Idx: 0 Loss: 0.013259665634121752
Epoch: 3 Idx: 0 Loss: 0.015222489953107168
Epoch: 4 Idx: 0 Loss: 0.00690326761893624
Epoch: 5 Idx: 0 Loss: 0.010621861158473815
Epoch: 6 Idx: 0 Loss: 0.011113784157168325
Epoch: 7 Idx: 0 Loss: 0.02067801185365049
Epoch: 8 Idx: 0 Loss: 0.017931928417466277
Epoch: 9 Idx: 0 Loss: 0.003973883355759735
Epoch: 10 Idx: 0 Loss: 0.019745050443088684
Epoch: 11 Idx: 0 Loss: 0.018241801966971952
Epoch: 12 Idx: 0 Loss: 0.04305577500466669
Epoch: 13 Idx: 0 Loss: 0.011203641680944891
Epoch: 14 Idx: 0 Loss: 0.010555050161842055
Epoch: 15 Idx: 0 Loss: 0.01915650308666222
Epoch: 16 Idx: 0 Loss: 0.010267694509293965
Epoch: 17 Idx: 0 Loss: 0.005621042916517514
Epoch: 18 Idx: 0 Loss: 0.015503119007574355
Epoch: 19 Idx: 0 Loss: 0.006860762981660471
Epoch: 20 Idx: 0 Loss: 0.01624228486610063
Epoch: 21 Idx: 0 Loss: 0.007961064958170604
Epoch: 22 Idx: 0 Loss: 0.010259507372454318
Epoch: 23 Idx: 0 Loss: 0.021819136452653716
Epoch: 24 Idx: 0 Loss: 0.008620034909624924
Epoch: 25 Idx: 0 Loss: 0.010057034433636841
Epoch: 26 Idx: 0 Loss: 0.013402587172994813
Epoch: 27 Idx: 0 Loss: 0.005885303521876174
Epoch: 28 Idx: 0 Loss: 0.009162836622848933
Epoch: 29 Idx: 0 Loss: 0.01309951339245639
Epoch: 30 Idx: 0 Loss: 0.010517990878338754
Epoch: 31 Idx: 0 Loss: 0.015675412279814126
Epoch: 32 Idx: 0 Loss: 0.010934847406416153
Epoch: 33 Idx: 0 Loss: 0.023616715823403255
Epoch: 34 Idx: 0 Loss: 0.018284382562407185
Epoch: 35 Idx: 0 Loss: 0.007108443345244351
Epoch: 36 Idx: 0 Loss: 0.011844421077732236
Epoch: 37 Idx: 0 Loss: 0.009099973292738713
Epoch: 38 Idx: 0 Loss: 0.020529562525478252
Epoch: 39 Idx: 0 Loss: 0.021803130152326065
Epoch: 40 Idx: 0 Loss: 0.01363798367305613
Epoch: 41 Idx: 0 Loss: 0.022910641659522023
Epoch: 42 Idx: 0 Loss: 0.009390277715626717
Epoch: 43 Idx: 0 Loss: 0.015746769118550972
Epoch: 44 Idx: 0 Loss: 0.014973930521317107
Epoch: 45 Idx: 0 Loss: 0.018724327621071353
Epoch: 46 Idx: 0 Loss: 0.005469129287243826
Epoch: 47 Idx: 0 Loss: 0.01190932484430612
Epoch: 48 Idx: 0 Loss: 0.02649402513571985
Epoch: 49 Idx: 0 Loss: 0.013857414012928712
Len (direct inputs):  3734
Inputs len 3800 19 4745
Len (direct inputs):  964
Starting sliding window evaluation...
Step 5.0/7
Val onto:  [('cmt', 'edas'), ('cmt', 'confOf')] test_onto:  [('iasted', 'sigkdd')]
Training size: 108728 Testing size: 7539
Epoch: 0 Idx: 0 Loss: 0.14051200592543345
Epoch: 0 Idx: 5000 Loss: 0.011590408135565188
Epoch: 1 Idx: 0 Loss: 0.01746940726297081
Epoch: 1 Idx: 5000 Loss: 0.016013899509233015
Epoch: 2 Idx: 0 Loss: 0.012280658477893926
Epoch: 2 Idx: 5000 Loss: 0.014671004799613703
Epoch: 3 Idx: 0 Loss: 0.020264426257596304
Epoch: 3 Idx: 5000 Loss: 0.007412972157634934
Epoch: 4 Idx: 0 Loss: 0.005021708327562194
Epoch: 4 Idx: 5000 Loss: 0.014488970823697728
Epoch: 5 Idx: 0 Loss: 0.013743883601763953
Epoch: 5 Idx: 5000 Loss: 0.008520181060890815
Epoch: 6 Idx: 0 Loss: 0.024254455348637058
Epoch: 6 Idx: 5000 Loss: 0.008342287436341392
Epoch: 7 Idx: 0 Loss: 0.01566707874388016
Epoch: 7 Idx: 5000 Loss: 0.014506686224238204
Epoch: 8 Idx: 0 Loss: 0.01726244285899766
Epoch: 8 Idx: 5000 Loss: 0.01891242409936613
Epoch: 9 Idx: 0 Loss: 0.03908827244807235
Epoch: 9 Idx: 5000 Loss: 0.022395934487441697
Epoch: 10 Idx: 0 Loss: 0.009253168530988919
Epoch: 10 Idx: 5000 Loss: 0.011057245951197498
Epoch: 11 Idx: 0 Loss: 0.00970420993259397
Epoch: 11 Idx: 5000 Loss: 0.016912668147700496
Epoch: 12 Idx: 0 Loss: 0.029692813426230924
Epoch: 12 Idx: 5000 Loss: 0.030219828703723237
Epoch: 13 Idx: 0 Loss: 0.005746200942168502
Epoch: 13 Idx: 5000 Loss: 0.014959407607030226
Epoch: 14 Idx: 0 Loss: 0.01516129128085884
Epoch: 14 Idx: 5000 Loss: 0.01550695150875031
Epoch: 15 Idx: 0 Loss: 0.00804609614680322
Epoch: 15 Idx: 5000 Loss: 0.010559882978652336
Epoch: 16 Idx: 0 Loss: 0.016934948493499767
Epoch: 16 Idx: 5000 Loss: 0.011980416426138426
Epoch: 17 Idx: 0 Loss: 0.02092485000027777
Epoch: 17 Idx: 5000 Loss: 0.023883644170408107
Epoch: 18 Idx: 0 Loss: 0.020086433288335225
Epoch: 18 Idx: 5000 Loss: 0.013842964428809732
Epoch: 19 Idx: 0 Loss: 0.029418132375293685
Epoch: 19 Idx: 5000 Loss: 0.012382648397936173
Epoch: 20 Idx: 0 Loss: 0.015545958553306647
Epoch: 20 Idx: 5000 Loss: 0.018175983156651223
Epoch: 21 Idx: 0 Loss: 0.024098209502197536
Epoch: 21 Idx: 5000 Loss: 0.010497857907546135
Epoch: 22 Idx: 0 Loss: 0.008552135583686359
Epoch: 22 Idx: 5000 Loss: 0.01791571859872814
Epoch: 23 Idx: 0 Loss: 0.011529595586765886
Epoch: 23 Idx: 5000 Loss: 0.01929611163883027
Epoch: 24 Idx: 0 Loss: 0.0071929587524815
Epoch: 24 Idx: 5000 Loss: 0.037821959004856597
Epoch: 25 Idx: 0 Loss: 0.012878071406806389
Epoch: 25 Idx: 5000 Loss: 0.009597871014368538
Epoch: 26 Idx: 0 Loss: 0.013106879922104311
Epoch: 26 Idx: 5000 Loss: 0.006752285258281246
Epoch: 27 Idx: 0 Loss: 0.0070348326644326525
Epoch: 27 Idx: 5000 Loss: 0.01472464279811637
Epoch: 28 Idx: 0 Loss: 0.010910266577112308
Epoch: 28 Idx: 5000 Loss: 0.014878733312559043
Epoch: 29 Idx: 0 Loss: 0.017273820319835917
Epoch: 29 Idx: 5000 Loss: 0.008331072860761023
Epoch: 30 Idx: 0 Loss: 0.02058928216111877
Epoch: 30 Idx: 5000 Loss: 0.020051665252229435
Epoch: 31 Idx: 0 Loss: 0.022559844148898126
Epoch: 31 Idx: 5000 Loss: 0.012773585964860886
Epoch: 32 Idx: 0 Loss: 0.008747114681901057
Epoch: 32 Idx: 5000 Loss: 0.019969912726680063
Epoch: 33 Idx: 0 Loss: 0.011028173131480195
Epoch: 33 Idx: 5000 Loss: 0.01820255218055912
Epoch: 34 Idx: 0 Loss: 0.026279737318692376
Epoch: 34 Idx: 5000 Loss: 0.010440973565159955
Epoch: 35 Idx: 0 Loss: 0.012419048221074229
Epoch: 35 Idx: 5000 Loss: 0.02080686973905754
Epoch: 36 Idx: 0 Loss: 0.010472110216490133
Epoch: 36 Idx: 5000 Loss: 0.04486130985807163
Epoch: 37 Idx: 0 Loss: 0.006643853407200839
Epoch: 37 Idx: 5000 Loss: 0.04322554201654413
Epoch: 38 Idx: 0 Loss: 0.013134343431389738
Epoch: 38 Idx: 5000 Loss: 0.012255287494585472
Epoch: 39 Idx: 0 Loss: 0.013967094607679217
Epoch: 39 Idx: 5000 Loss: 0.010669387598094989
Epoch: 40 Idx: 0 Loss: 0.016352222873779604
Epoch: 40 Idx: 5000 Loss: 0.011619552646563645
Epoch: 41 Idx: 0 Loss: 0.04049868346314634
Epoch: 41 Idx: 5000 Loss: 0.015649962326151352
Epoch: 42 Idx: 0 Loss: 0.018591628084280273
Epoch: 42 Idx: 5000 Loss: 0.00923917093587892
Epoch: 43 Idx: 0 Loss: 0.02799682827716197
Epoch: 43 Idx: 5000 Loss: 0.02255774162620942
Epoch: 44 Idx: 0 Loss: 0.017366589583959202
Epoch: 44 Idx: 5000 Loss: 0.009458256685973087
Epoch: 45 Idx: 0 Loss: 0.0077406159084341414
Epoch: 45 Idx: 5000 Loss: 0.012408884350559594
Epoch: 46 Idx: 0 Loss: 0.01853836013195304
Epoch: 46 Idx: 5000 Loss: 0.008559264236944726
Epoch: 47 Idx: 0 Loss: 0.0065708111265959926
Epoch: 47 Idx: 5000 Loss: 0.02799291947238778
Epoch: 48 Idx: 0 Loss: 0.010816713859524194
Epoch: 48 Idx: 5000 Loss: 0.018824540247339108
Epoch: 49 Idx: 0 Loss: 0.01368322334150866
Epoch: 49 Idx: 5000 Loss: 0.02570083772181977
Len (direct inputs):  2762
Inputs len 6762 15 7524
Len (direct inputs):  777
Starting sliding window evaluation...
Step 6.0/7
Val onto:  [('edas', 'iasted'), ('edas', 'ekaw')] test_onto:  [('confOf', 'iasted')]
Training size: 92881 Testing size: 5883
Epoch: 0 Idx: 0 Loss: 0.1953786030151553
Epoch: 1 Idx: 0 Loss: 0.014827356053525654
Epoch: 2 Idx: 0 Loss: 0.014999026092370431
Epoch: 3 Idx: 0 Loss: 0.012873052062356435
Epoch: 4 Idx: 0 Loss: 0.012169974318000211
Epoch: 5 Idx: 0 Loss: 0.015344072230410406
Epoch: 6 Idx: 0 Loss: 0.005011407322495526
Epoch: 7 Idx: 0 Loss: 0.017732924091714487
Epoch: 8 Idx: 0 Loss: 0.00570598800326174
Epoch: 9 Idx: 0 Loss: 0.009461424265644008
Epoch: 10 Idx: 0 Loss: 0.008412543069234231
Epoch: 11 Idx: 0 Loss: 0.006597322047491619
Epoch: 12 Idx: 0 Loss: 0.008093688732532883
Epoch: 13 Idx: 0 Loss: 0.04318109028407659
Epoch: 14 Idx: 0 Loss: 0.01566550829073572
Epoch: 15 Idx: 0 Loss: 0.004371508434744676
Epoch: 16 Idx: 0 Loss: 0.00815696453911516
Epoch: 17 Idx: 0 Loss: 0.025749925171819982
Epoch: 18 Idx: 0 Loss: 0.013637169612800717
Epoch: 19 Idx: 0 Loss: 0.018984191894232495
Epoch: 20 Idx: 0 Loss: 0.01141045347396966
Epoch: 21 Idx: 0 Loss: 0.01726461640278592
Epoch: 22 Idx: 0 Loss: 0.005711632048881482
Epoch: 23 Idx: 0 Loss: 0.008310460493899604
Epoch: 24 Idx: 0 Loss: 0.029769695473586114
Epoch: 25 Idx: 0 Loss: 0.03213076942938953
Epoch: 26 Idx: 0 Loss: 0.01676389740841027
Epoch: 27 Idx: 0 Loss: 0.013329358711776172
Epoch: 28 Idx: 0 Loss: 0.019663344657516374
Epoch: 29 Idx: 0 Loss: 0.0066852803602616365
Epoch: 30 Idx: 0 Loss: 0.010919231163260297
Epoch: 31 Idx: 0 Loss: 0.009301018669751072
Epoch: 32 Idx: 0 Loss: 0.006115353189133368
Epoch: 33 Idx: 0 Loss: 0.0051233675324397045
Epoch: 34 Idx: 0 Loss: 0.026142945564779425
Epoch: 35 Idx: 0 Loss: 0.020470223251744905
Epoch: 36 Idx: 0 Loss: 0.009409896880711255
Epoch: 37 Idx: 0 Loss: 0.0070920943999971
Epoch: 38 Idx: 0 Loss: 0.008147717009436811
Epoch: 39 Idx: 0 Loss: 0.0054620868281677806
Epoch: 40 Idx: 0 Loss: 0.0456762901472507
Epoch: 41 Idx: 0 Loss: 0.027616424383349193
Epoch: 42 Idx: 0 Loss: 0.01594727459121555
Epoch: 43 Idx: 0 Loss: 0.02667906574014367
Epoch: 44 Idx: 0 Loss: 0.013581998264387241
Epoch: 45 Idx: 0 Loss: 0.03369295140048869
Epoch: 46 Idx: 0 Loss: 0.009582466012087284
Epoch: 47 Idx: 0 Loss: 0.0074761320385011275
Epoch: 48 Idx: 0 Loss: 0.005480497433562983
Epoch: 49 Idx: 0 Loss: 0.013192597538121712
Len (direct inputs):  3029
Inputs len 5244 9 5874
Len (direct inputs):  639
Performance for  [('conference', 'sigkdd')] is : (0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333)
Performance for  [('ekaw', 'sigkdd')] is : (0.7692307692307693, 0.9090909090909091, 0.8333333333333333, 0.8771929824561403, 0.7936507936507936)
Performance for  [('conference', 'edas')] is : (0.8461538461538461, 0.6470588235294118, 0.7333333333333334, 0.6790123456790124, 0.7971014492753623)
Performance for  [('cmt', 'ekaw')] is : (0.6, 0.5454545454545454, 0.5714285714285713, 0.5555555555555556, 0.5882352941176471)
Performance for  [('confOf', 'edas')] is : (0.6, 0.631578947368421, 0.6153846153846154, 0.625, 0.6060606060606061)
Performance for  [('iasted', 'sigkdd')] is : (0.6470588235294118, 0.7333333333333333, 0.6875, 0.7142857142857143, 0.6626506024096386)
Performance for  [('confOf', 'iasted')] is : (1.0, 0.6666666666666666, 0.8, 0.7142857142857142, 0.9090909090909091)
Final Results: [0.74225382 0.69521665 0.71061617 0.69980938 0.72716043]
Threshold:  0.915
Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x2b2c4d808af0>
Traceback (most recent call last):
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py", line 201, in __del__
  File "/u/shagutt1/miniconda3/envs/allennlp_robustfill/lib/python3.8/site-packages/tensorflow/python/eager/context.py", line 2008, in eager_mode
TypeError: 'NoneType' object is not callable

------------------------------------------------------------
Sender: LSF System <rer@dccxc243>
Subject: Job 4142769: <python main.py 6 12 False False> in cluster <dcc> Done

Job <python main.py 6 12 False False> was submitted from host <dccxl010> by user <shagutt1> in cluster <dcc> at Wed Sep 16 06:58:27 2020
Job was executed on host(s) <dccxc243>, in queue <x86_24h>, as user <shagutt1> in cluster <dcc> at Wed Sep 16 10:05:32 2020
</u/shagutt1> was used as the home directory.
</u/shagutt1/VeeAlign/src> was used as the working directory.
Started at Wed Sep 16 10:05:32 2020
Terminated at Wed Sep 16 17:34:16 2020
Results reported at Wed Sep 16 17:34:16 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 12 False False
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   26924.95 sec.
    Max Memory :                                 4212 MB
    Average Memory :                             4053.28 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               39205.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                15
    Run time :                                   26951 sec.
    Turnaround time :                            38149 sec.

The output (if any) is above this job summary.

