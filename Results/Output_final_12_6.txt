2020-09-15 15:49:39.573815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:43.184235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:43.305744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:1e:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:43.305852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:43.307803: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:43.309279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:43.309679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:43.311534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:43.312912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:43.313148: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:43.313170: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:43.313493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:43.320360: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599940000 Hz
2020-09-15 15:49:43.320553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ad7e8f06f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:43.320573: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:43.322409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:43.322446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1965838195800149
Epoch: 0 Idx: 5000 Loss: 0.016459016199588592
Epoch: 1 Idx: 0 Loss: 0.010819067925803392
Epoch: 1 Idx: 5000 Loss: 0.011143567066176228
Epoch: 2 Idx: 0 Loss: 0.007890730979902635
Epoch: 2 Idx: 5000 Loss: 0.019285988684391197
Epoch: 3 Idx: 0 Loss: 0.027993190905286174
Epoch: 3 Idx: 5000 Loss: 0.01729448458374417
Epoch: 4 Idx: 0 Loss: 0.018541713029720405
Epoch: 4 Idx: 5000 Loss: 0.011294120893728238
Epoch: 5 Idx: 0 Loss: 0.015313656729570963
Epoch: 5 Idx: 5000 Loss: 0.009745262344754483
Epoch: 6 Idx: 0 Loss: 0.012423262593524081
Epoch: 6 Idx: 5000 Loss: 0.022807319453561535
Epoch: 7 Idx: 0 Loss: 0.024830349935900775
Epoch: 7 Idx: 5000 Loss: 0.009721924448154912
Epoch: 8 Idx: 0 Loss: 0.01335575759642017
Epoch: 8 Idx: 5000 Loss: 0.005280328455141826
Epoch: 9 Idx: 0 Loss: 0.02729191827157567
Epoch: 9 Idx: 5000 Loss: 0.006695360303127262
Epoch: 10 Idx: 0 Loss: 0.01892339706977126
Epoch: 10 Idx: 5000 Loss: 0.017114295088537238
Epoch: 11 Idx: 0 Loss: 0.01028494359137148
Epoch: 11 Idx: 5000 Loss: 0.017743761584660272
Epoch: 12 Idx: 0 Loss: 0.01382125231035966
Epoch: 12 Idx: 5000 Loss: 0.014048028219783446
Epoch: 13 Idx: 0 Loss: 0.011522664313139835
Epoch: 13 Idx: 5000 Loss: 0.00640283468000988
Epoch: 14 Idx: 0 Loss: 0.014031925671210175
Epoch: 14 Idx: 5000 Loss: 0.008577279189717915
Epoch: 15 Idx: 0 Loss: 0.025073681790248825
Epoch: 15 Idx: 5000 Loss: 0.016365800689516916
Epoch: 16 Idx: 0 Loss: 0.020961694034550213
Epoch: 16 Idx: 5000 Loss: 0.021118017606792112
Epoch: 17 Idx: 0 Loss: 0.01387279823604955
Epoch: 17 Idx: 5000 Loss: 0.010858283848546077
Epoch: 18 Idx: 0 Loss: 0.024631688677482964
Epoch: 18 Idx: 5000 Loss: 0.015011107360981824
Epoch: 19 Idx: 0 Loss: 0.027512619465036962
Epoch: 19 Idx: 5000 Loss: 0.005553662713831148
Epoch: 20 Idx: 0 Loss: 0.0065044456634877085
Epoch: 20 Idx: 5000 Loss: 0.013199408044121697
Epoch: 21 Idx: 0 Loss: 0.008811110118728708
Epoch: 21 Idx: 5000 Loss: 0.02251724142880692
Epoch: 22 Idx: 0 Loss: 0.013451975300616112
Epoch: 22 Idx: 5000 Loss: 0.021067942040525943
Epoch: 23 Idx: 0 Loss: 0.010294059269179447
Epoch: 23 Idx: 5000 Loss: 0.010170467855884793
Epoch: 24 Idx: 0 Loss: 0.01503019994703362
Epoch: 24 Idx: 5000 Loss: 0.007946894217022908
Epoch: 25 Idx: 0 Loss: 0.01283334360860912
Epoch: 25 Idx: 5000 Loss: 0.011446894336300811
Epoch: 26 Idx: 0 Loss: 0.008897360081330671
Epoch: 26 Idx: 5000 Loss: 0.016064355527160804
Epoch: 27 Idx: 0 Loss: 0.02895169236983749
Epoch: 27 Idx: 5000 Loss: 0.015564634517706533
Epoch: 28 Idx: 0 Loss: 0.0074081884783162525
Epoch: 28 Idx: 5000 Loss: 0.027161502590165056
Epoch: 29 Idx: 0 Loss: 0.020475156524284967
Epoch: 29 Idx: 5000 Loss: 0.014472514421921974
Epoch: 30 Idx: 0 Loss: 0.018430213135983118
Epoch: 30 Idx: 5000 Loss: 0.009265475284075248
Epoch: 31 Idx: 0 Loss: 0.008367915231700709
Epoch: 31 Idx: 5000 Loss: 0.0065841549672621055
Epoch: 32 Idx: 0 Loss: 0.009316688382291483
Epoch: 32 Idx: 5000 Loss: 0.013507689527005973
Epoch: 33 Idx: 0 Loss: 0.017961527806407272
Epoch: 33 Idx: 5000 Loss: 0.014303765096509088
Epoch: 34 Idx: 0 Loss: 0.020422294427912338
Epoch: 34 Idx: 5000 Loss: 0.013748694302252371
Epoch: 35 Idx: 0 Loss: 0.007127326542047282
Epoch: 35 Idx: 5000 Loss: 0.02946043438289359
Epoch: 36 Idx: 0 Loss: 0.030804924891206037
Epoch: 36 Idx: 5000 Loss: 0.017936728214577487
Epoch: 37 Idx: 0 Loss: 0.00981812398388043
Epoch: 37 Idx: 5000 Loss: 0.007220434004753037
Epoch: 38 Idx: 0 Loss: 0.01635131360225607
Epoch: 38 Idx: 5000 Loss: 0.012640720078913568
Epoch: 39 Idx: 0 Loss: 0.012538573919591785
Epoch: 39 Idx: 5000 Loss: 0.008913542997550487
Epoch: 40 Idx: 0 Loss: 0.00884143107007793
Epoch: 40 Idx: 5000 Loss: 0.019142660433946815
Epoch: 41 Idx: 0 Loss: 0.00829703664626035
Epoch: 41 Idx: 5000 Loss: 0.01743617213528288
Epoch: 42 Idx: 0 Loss: 0.05369115970732181
Epoch: 42 Idx: 5000 Loss: 0.008082158501756207
Epoch: 43 Idx: 0 Loss: 0.03167507997306912
Epoch: 43 Idx: 5000 Loss: 0.02300603983516765
Epoch: 44 Idx: 0 Loss: 0.013292505878522744
Epoch: 44 Idx: 5000 Loss: 0.009538598032832876
Epoch: 45 Idx: 0 Loss: 0.00981561851761556
Epoch: 45 Idx: 5000 Loss: 0.00760263457423487
Epoch: 46 Idx: 0 Loss: 0.011527507024210518
Epoch: 46 Idx: 5000 Loss: 0.009617551293501274
Epoch: 47 Idx: 0 Loss: 0.014092969624827716
Epoch: 47 Idx: 5000 Loss: 0.017181875799311807
Epoch: 48 Idx: 0 Loss: 0.013002244927085016
Epoch: 48 Idx: 5000 Loss: 0.0170837420749452
Epoch: 49 Idx: 0 Loss: 0.006538474361682101
Epoch: 49 Idx: 5000 Loss: 0.019645662709077895
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15702141302964237
Epoch: 0 Idx: 5000 Loss: 0.014149332245838937
Epoch: 1 Idx: 0 Loss: 0.01912218432419071
Epoch: 1 Idx: 5000 Loss: 0.028347968316357136
Epoch: 2 Idx: 0 Loss: 0.017672030793339125
Epoch: 2 Idx: 5000 Loss: 0.011236469154338645
Epoch: 3 Idx: 0 Loss: 0.011150176314671289
Epoch: 3 Idx: 5000 Loss: 0.007919255353155153
Epoch: 4 Idx: 0 Loss: 0.01871536035973442
Epoch: 4 Idx: 5000 Loss: 0.008916484125676367
Epoch: 5 Idx: 0 Loss: 0.01873641149615989
Epoch: 5 Idx: 5000 Loss: 0.020114055583802318
Epoch: 6 Idx: 0 Loss: 0.010798659656178643
Epoch: 6 Idx: 5000 Loss: 0.01647278842131846
Epoch: 7 Idx: 0 Loss: 0.010634266402632046
Epoch: 7 Idx: 5000 Loss: 0.01542143566358502
Epoch: 8 Idx: 0 Loss: 0.008085842640788952
Epoch: 8 Idx: 5000 Loss: 0.012781282753313132
Epoch: 9 Idx: 0 Loss: 0.020744066296565625
Epoch: 9 Idx: 5000 Loss: 0.00311895874571712
Epoch: 10 Idx: 0 Loss: 0.021216314401411075
Epoch: 10 Idx: 5000 Loss: 0.018052867565901763
Epoch: 11 Idx: 0 Loss: 0.01417143955922538
Epoch: 11 Idx: 5000 Loss: 0.007584050551208008
Epoch: 12 Idx: 0 Loss: 0.008044441245936404
Epoch: 12 Idx: 5000 Loss: 0.01691150067657922
Epoch: 13 Idx: 0 Loss: 0.006524090638315141
Epoch: 13 Idx: 5000 Loss: 0.006890055825835135
Epoch: 14 Idx: 0 Loss: 0.012520602606046354
Epoch: 14 Idx: 5000 Loss: 0.011966754501876807
Epoch: 15 Idx: 0 Loss: 0.015930902783461844
Epoch: 15 Idx: 5000 Loss: 0.01773433801102305
Epoch: 16 Idx: 0 Loss: 0.023603853713906227
Epoch: 16 Idx: 5000 Loss: 0.012340579620389435
Epoch: 17 Idx: 0 Loss: 0.007961820068075885
Epoch: 17 Idx: 5000 Loss: 0.019725712750850746
Epoch: 18 Idx: 0 Loss: 0.022586096037429344
Epoch: 18 Idx: 5000 Loss: 0.03686299225594791
Epoch: 19 Idx: 0 Loss: 0.027773995579997664
Epoch: 19 Idx: 5000 Loss: 0.01177148230937151
Epoch: 20 Idx: 0 Loss: 0.020839624645684902
Epoch: 20 Idx: 5000 Loss: 0.009371714077630652
Epoch: 21 Idx: 0 Loss: 0.010261889222454326
Epoch: 21 Idx: 5000 Loss: 0.019470899921515683
Epoch: 22 Idx: 0 Loss: 0.004339515552025805
Epoch: 22 Idx: 5000 Loss: 0.030429465946628067
Epoch: 23 Idx: 0 Loss: 0.020665588560809744
Epoch: 23 Idx: 5000 Loss: 0.03135405386354996
Epoch: 24 Idx: 0 Loss: 0.013805353803127918
Epoch: 24 Idx: 5000 Loss: 0.014022817029475812
Epoch: 25 Idx: 0 Loss: 0.021055809943958677
Epoch: 25 Idx: 5000 Loss: 0.015283864743127124
Epoch: 26 Idx: 0 Loss: 0.011122415613629543
Epoch: 26 Idx: 5000 Loss: 0.015886183956197956
Epoch: 27 Idx: 0 Loss: 0.020224667490591496
Epoch: 27 Idx: 5000 Loss: 0.012992669584547633
Epoch: 28 Idx: 0 Loss: 0.011416414854887685
Epoch: 28 Idx: 5000 Loss: 0.005209185061974669
Epoch: 29 Idx: 0 Loss: 0.03121371295119194
Epoch: 29 Idx: 5000 Loss: 0.013905834680367267
Epoch: 30 Idx: 0 Loss: 0.021529623241615888
Epoch: 30 Idx: 5000 Loss: 0.022629736013904327
Epoch: 31 Idx: 0 Loss: 0.013851436915617766
Epoch: 31 Idx: 5000 Loss: 0.01644226747023319
Epoch: 32 Idx: 0 Loss: 0.03234499848455657
Epoch: 32 Idx: 5000 Loss: 0.010902720790476087
Epoch: 33 Idx: 0 Loss: 0.009095949805280057
Epoch: 33 Idx: 5000 Loss: 0.026171511814836297
Epoch: 34 Idx: 0 Loss: 0.0337915508794468
Epoch: 34 Idx: 5000 Loss: 0.004610286782689624
Epoch: 35 Idx: 0 Loss: 0.007343834738683994
Epoch: 35 Idx: 5000 Loss: 0.02023591142225488
Epoch: 36 Idx: 0 Loss: 0.019409526418211503
Epoch: 36 Idx: 5000 Loss: 0.023135950995674923
Epoch: 37 Idx: 0 Loss: 0.012078480541381269
Epoch: 37 Idx: 5000 Loss: 0.006461039507246736
Epoch: 38 Idx: 0 Loss: 0.019750524190124547
Epoch: 38 Idx: 5000 Loss: 0.02163818882985792
Epoch: 39 Idx: 0 Loss: 0.026174674890291683
Epoch: 39 Idx: 5000 Loss: 0.008005105903577874
Epoch: 40 Idx: 0 Loss: 0.01609535293853187
Epoch: 40 Idx: 5000 Loss: 0.014469812200178872
Epoch: 41 Idx: 0 Loss: 0.011338827240077707
Epoch: 41 Idx: 5000 Loss: 0.014015499655099893
Epoch: 42 Idx: 0 Loss: 0.019693386075832688
Epoch: 42 Idx: 5000 Loss: 0.017905241697712015
Epoch: 43 Idx: 0 Loss: 0.014715060122650963
Epoch: 43 Idx: 5000 Loss: 0.009201503981820036
Epoch: 44 Idx: 0 Loss: 0.05266104400995147
Epoch: 44 Idx: 5000 Loss: 0.007922680533204447
Epoch: 45 Idx: 0 Loss: 0.012287293371396982
Epoch: 45 Idx: 5000 Loss: 0.015755644254247348
Epoch: 46 Idx: 0 Loss: 0.020300161815856966
Epoch: 46 Idx: 5000 Loss: 0.015668273619075825
Epoch: 47 Idx: 0 Loss: 0.006464556813055846
Epoch: 47 Idx: 5000 Loss: 0.02155152773184514
Epoch: 48 Idx: 0 Loss: 0.01881897434712989
Epoch: 48 Idx: 5000 Loss: 0.017077042877090214
Epoch: 49 Idx: 0 Loss: 0.04019005897507198
Epoch: 49 Idx: 5000 Loss: 0.017183481979377965
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14498378008391752
Epoch: 0 Idx: 5000 Loss: 0.01287638235606026
Epoch: 1 Idx: 0 Loss: 0.014835289115765458
Epoch: 1 Idx: 5000 Loss: 0.02799732036115394
Epoch: 2 Idx: 0 Loss: 0.016486250138715408
Epoch: 2 Idx: 5000 Loss: 0.028799020676948835
Epoch: 3 Idx: 0 Loss: 0.007389120745583774
Epoch: 3 Idx: 5000 Loss: 0.013447135582268238
Epoch: 4 Idx: 0 Loss: 0.010682826562115262
Epoch: 4 Idx: 5000 Loss: 0.017585206802043146
Epoch: 5 Idx: 0 Loss: 0.02323468085502779
Epoch: 5 Idx: 5000 Loss: 0.026127807220509995
Epoch: 6 Idx: 0 Loss: 0.007452730814532156
Epoch: 6 Idx: 5000 Loss: 0.018966804426522203
Epoch: 7 Idx: 0 Loss: 0.01913348709326568
Epoch: 7 Idx: 5000 Loss: 0.015717515566267885
Epoch: 8 Idx: 0 Loss: 0.010613558232543839
Epoch: 8 Idx: 5000 Loss: 0.019524544328082327
Epoch: 9 Idx: 0 Loss: 0.02301460171612899
Epoch: 9 Idx: 5000 Loss: 0.010238073824062848
Epoch: 10 Idx: 0 Loss: 0.012480821207262682
Epoch: 10 Idx: 5000 Loss: 0.009653106527247633
Epoch: 11 Idx: 0 Loss: 0.01239001764450519
Epoch: 11 Idx: 5000 Loss: 0.011828790660084656
Epoch: 12 Idx: 0 Loss: 0.0035892416380749665
Epoch: 12 Idx: 5000 Loss: 0.008172566383852897
Epoch: 13 Idx: 0 Loss: 0.01025578808177172
Epoch: 13 Idx: 5000 Loss: 0.010322590749376354
Epoch: 14 Idx: 0 Loss: 0.032099626262211495
Epoch: 14 Idx: 5000 Loss: 0.01849639597360868
Epoch: 15 Idx: 0 Loss: 0.014662673816015444
Epoch: 15 Idx: 5000 Loss: 0.010966807732532922
Epoch: 16 Idx: 0 Loss: 0.01879076677308722
Epoch: 16 Idx: 5000 Loss: 0.01244656789587663
Epoch: 17 Idx: 0 Loss: 0.011514828430878237
Epoch: 17 Idx: 5000 Loss: 0.018791372361347997
Epoch: 18 Idx: 0 Loss: 0.017302975544812613
Epoch: 18 Idx: 5000 Loss: 0.03239875172514006
Epoch: 19 Idx: 0 Loss: 0.009952304554800338
Epoch: 19 Idx: 5000 Loss: 0.030497631202396593
Epoch: 20 Idx: 0 Loss: 0.02070726046303706
Epoch: 20 Idx: 5000 Loss: 0.06752289626607134
Epoch: 21 Idx: 0 Loss: 0.0074882004293953894
Epoch: 21 Idx: 5000 Loss: 0.030324222978180677
Epoch: 22 Idx: 0 Loss: 0.021161575817992537
Epoch: 22 Idx: 5000 Loss: 0.008509586397185645
Epoch: 23 Idx: 0 Loss: 0.015073181868427994
Epoch: 23 Idx: 5000 Loss: 0.017467447461254844
Epoch: 24 Idx: 0 Loss: 0.008836901361404133
Epoch: 24 Idx: 5000 Loss: 0.010362415276457267
Epoch: 25 Idx: 0 Loss: 0.010082621898690372
Epoch: 25 Idx: 5000 Loss: 0.010071372748094734
Epoch: 26 Idx: 0 Loss: 0.024697135605555587
Epoch: 26 Idx: 5000 Loss: 0.01984422748228104
Epoch: 27 Idx: 0 Loss: 0.010499303372571971
Epoch: 27 Idx: 5000 Loss: 0.028966531779619227
Epoch: 28 Idx: 0 Loss: 0.03485707482369725
Epoch: 28 Idx: 5000 Loss: 0.012917943953933845
Epoch: 29 Idx: 0 Loss: 0.01242827655509121
Epoch: 29 Idx: 5000 Loss: 0.013886955572938326
Epoch: 30 Idx: 0 Loss: 0.007637424150119693
Epoch: 30 Idx: 5000 Loss: 0.02929598284684574
Epoch: 31 Idx: 0 Loss: 0.013243500212207875
Epoch: 31 Idx: 5000 Loss: 0.018708942298676152
Epoch: 32 Idx: 0 Loss: 0.010897653300795281
Epoch: 32 Idx: 5000 Loss: 0.009074936896000647
Epoch: 33 Idx: 0 Loss: 0.0030471621895797755
Epoch: 33 Idx: 5000 Loss: 0.009516268642911774
Epoch: 34 Idx: 0 Loss: 0.019843107348227466
Epoch: 34 Idx: 5000 Loss: 0.01823527591250238
Epoch: 35 Idx: 0 Loss: 0.03456279917860933
Epoch: 35 Idx: 5000 Loss: 0.009630001175854993
Epoch: 36 Idx: 0 Loss: 0.012082251385853783
Epoch: 36 Idx: 5000 Loss: 0.024724402268737906
Epoch: 37 Idx: 0 Loss: 0.01778344141031513
Traceback (most recent call last):
  File "main.py", line 505, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "main.py", line 383, in to_feature
    for elem in inputs]
  File "main.py", line 383, in <listcomp>
    for elem in inputs]
  File "main.py", line 379, in <listcomp>
    inputs_lenpadded = [[[[path[:max_pathlen] + [0 for i in range(max_pathlen -len(path[:max_pathlen]))]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc278>
Subject: Job 4066885: <python main.py 6 12 False False> in cluster <dcc> Exited

Job <python main.py 6 12 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:40 2020
Job was executed on host(s) <dccxc278>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:37 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 6 12 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46123.97 sec.
    Max Memory :                                 2949 MB
    Average Memory :                             2743.24 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40468.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46169 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

