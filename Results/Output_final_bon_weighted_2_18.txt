2020-09-15 15:49:42.003986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.476802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:49:45.593301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:49:45.593407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:49:45.595576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:49:45.597206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:49:45.598109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:49:45.600184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:49:45.601780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:49:45.602077: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:49:45.602100: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:49:45.602450: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:49:45.611256: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599850000 Hz
2020-09-15 15:49:45.611453: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7da7f01a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:49:45.611475: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:49:45.613595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:49:45.613630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.1911407280221233
Epoch: 0 Idx: 5000 Loss: 0.00976223360928704
Epoch: 1 Idx: 0 Loss: 0.00762789980528233
Epoch: 1 Idx: 5000 Loss: 0.02461118385940389
Epoch: 2 Idx: 0 Loss: 0.01701348710285434
Epoch: 2 Idx: 5000 Loss: 0.012111001259736633
Epoch: 3 Idx: 0 Loss: 0.014538534230426852
Epoch: 3 Idx: 5000 Loss: 0.010561276089798196
Epoch: 4 Idx: 0 Loss: 0.01852569160850215
Epoch: 4 Idx: 5000 Loss: 0.008157651957072881
Epoch: 5 Idx: 0 Loss: 0.02085564132436257
Epoch: 5 Idx: 5000 Loss: 0.012508994612306583
Epoch: 6 Idx: 0 Loss: 0.008355861241550612
Epoch: 6 Idx: 5000 Loss: 0.05121283065822678
Epoch: 7 Idx: 0 Loss: 0.0221027181771802
Epoch: 7 Idx: 5000 Loss: 0.014021897031989358
Epoch: 8 Idx: 0 Loss: 0.009590836618824945
Epoch: 8 Idx: 5000 Loss: 0.011057141113054773
Epoch: 9 Idx: 0 Loss: 0.009622988855762125
Epoch: 9 Idx: 5000 Loss: 0.008454329650754855
Epoch: 10 Idx: 0 Loss: 0.01766935927329039
Epoch: 10 Idx: 5000 Loss: 0.011209005145480767
Epoch: 11 Idx: 0 Loss: 0.014604128084255508
Epoch: 11 Idx: 5000 Loss: 0.011417910760057806
Epoch: 12 Idx: 0 Loss: 0.007532146490089232
Epoch: 12 Idx: 5000 Loss: 0.02138538071426829
Epoch: 13 Idx: 0 Loss: 0.014356933823877337
Epoch: 13 Idx: 5000 Loss: 0.007239259788949034
Epoch: 14 Idx: 0 Loss: 0.05640822804921095
Epoch: 14 Idx: 5000 Loss: 0.01040593018702102
Epoch: 15 Idx: 0 Loss: 0.0117630902999794
Epoch: 15 Idx: 5000 Loss: 0.02214047799850147
Epoch: 16 Idx: 0 Loss: 0.01957137857312681
Epoch: 16 Idx: 5000 Loss: 0.008479677856650502
Epoch: 17 Idx: 0 Loss: 0.015485970154542388
Epoch: 17 Idx: 5000 Loss: 0.004344112399206191
Epoch: 18 Idx: 0 Loss: 0.005220191874517958
Epoch: 18 Idx: 5000 Loss: 0.01026784526525552
Epoch: 19 Idx: 0 Loss: 0.014825026231043117
Epoch: 19 Idx: 5000 Loss: 0.006976179137628463
Epoch: 20 Idx: 0 Loss: 0.016206321324773787
Epoch: 20 Idx: 5000 Loss: 0.012267907950049364
Epoch: 21 Idx: 0 Loss: 0.017542917204636292
Epoch: 21 Idx: 5000 Loss: 0.022962347621572923
Epoch: 22 Idx: 0 Loss: 0.00988022654352648
Epoch: 22 Idx: 5000 Loss: 0.03153812520026259
Epoch: 23 Idx: 0 Loss: 0.015325934548403922
Epoch: 23 Idx: 5000 Loss: 0.015304552637602846
Epoch: 24 Idx: 0 Loss: 0.013325880389898518
Epoch: 24 Idx: 5000 Loss: 0.016720049891431565
Epoch: 25 Idx: 0 Loss: 0.032887573417442285
Epoch: 25 Idx: 5000 Loss: 0.01178591299149699
Epoch: 26 Idx: 0 Loss: 0.00683013583550501
Epoch: 26 Idx: 5000 Loss: 0.013465396934747319
Epoch: 27 Idx: 0 Loss: 0.012699759260013333
Epoch: 27 Idx: 5000 Loss: 0.035557469981596854
Epoch: 28 Idx: 0 Loss: 0.008278019906245597
Epoch: 28 Idx: 5000 Loss: 0.013771393387106864
Epoch: 29 Idx: 0 Loss: 0.027644861084116606
Epoch: 29 Idx: 5000 Loss: 0.009069705120136355
Epoch: 30 Idx: 0 Loss: 0.02032006424668728
Epoch: 30 Idx: 5000 Loss: 0.007809098156782976
Epoch: 31 Idx: 0 Loss: 0.016100872083513545
Epoch: 31 Idx: 5000 Loss: 0.009186895176823598
Epoch: 32 Idx: 0 Loss: 0.011298747802314667
Epoch: 32 Idx: 5000 Loss: 0.01704422010377296
Epoch: 33 Idx: 0 Loss: 0.016710144687035352
Epoch: 33 Idx: 5000 Loss: 0.013321772964454314
Epoch: 34 Idx: 0 Loss: 0.020025647630473632
Epoch: 34 Idx: 5000 Loss: 0.02443755779197595
Epoch: 35 Idx: 0 Loss: 0.012647130592591531
Epoch: 35 Idx: 5000 Loss: 0.04516602127148535
Epoch: 36 Idx: 0 Loss: 0.014822120470731736
Epoch: 36 Idx: 5000 Loss: 0.03254402019984578
Epoch: 37 Idx: 0 Loss: 0.031216855231264766
Epoch: 37 Idx: 5000 Loss: 0.012758576256062469
Epoch: 38 Idx: 0 Loss: 0.005875225641978905
Epoch: 38 Idx: 5000 Loss: 0.02729452628529095
Epoch: 39 Idx: 0 Loss: 0.02734305775071892
Epoch: 39 Idx: 5000 Loss: 0.012282791703752387
Epoch: 40 Idx: 0 Loss: 0.00800188281709396
Epoch: 40 Idx: 5000 Loss: 0.019426958735907888
Epoch: 41 Idx: 0 Loss: 0.00865797083922962
Epoch: 41 Idx: 5000 Loss: 0.010494589530115658
Epoch: 42 Idx: 0 Loss: 0.0134404306415877
Epoch: 42 Idx: 5000 Loss: 0.01164099297198076
Epoch: 43 Idx: 0 Loss: 0.015567558526386291
Epoch: 43 Idx: 5000 Loss: 0.024417998790763885
Epoch: 44 Idx: 0 Loss: 0.01828878269987896
Epoch: 44 Idx: 5000 Loss: 0.012934038589200347
Epoch: 45 Idx: 0 Loss: 0.0190467192787917
Epoch: 45 Idx: 5000 Loss: 0.01227304370897485
Epoch: 46 Idx: 0 Loss: 0.012619785074204352
Epoch: 46 Idx: 5000 Loss: 0.015205858570565148
Epoch: 47 Idx: 0 Loss: 0.018400870794556656
Epoch: 47 Idx: 5000 Loss: 0.008724251029657494
Epoch: 48 Idx: 0 Loss: 0.005964658818634857
Epoch: 48 Idx: 5000 Loss: 0.025919333987104293
Epoch: 49 Idx: 0 Loss: 0.023879504422096083
Epoch: 49 Idx: 5000 Loss: 0.009922908243100834
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14078657274135792
Epoch: 0 Idx: 5000 Loss: 0.020685746375259384
Epoch: 1 Idx: 0 Loss: 0.013983093233270544
Epoch: 1 Idx: 5000 Loss: 0.017526332291857356
Epoch: 2 Idx: 0 Loss: 0.00989328547435316
Epoch: 2 Idx: 5000 Loss: 0.008008105779446141
Epoch: 3 Idx: 0 Loss: 0.02018686041923338
Epoch: 3 Idx: 5000 Loss: 0.0181228056698063
Epoch: 4 Idx: 0 Loss: 0.01617594847358928
Epoch: 4 Idx: 5000 Loss: 0.03326017035298111
Epoch: 5 Idx: 0 Loss: 0.012595438925710281
Epoch: 5 Idx: 5000 Loss: 0.007631658577772948
Epoch: 6 Idx: 0 Loss: 0.019566294564544333
Epoch: 6 Idx: 5000 Loss: 0.014869194366278912
Epoch: 7 Idx: 0 Loss: 0.014704419085760326
Epoch: 7 Idx: 5000 Loss: 0.009889062571402527
Epoch: 8 Idx: 0 Loss: 0.006094075020564013
Epoch: 8 Idx: 5000 Loss: 0.01394107154027217
Epoch: 9 Idx: 0 Loss: 0.022439417561407025
Epoch: 9 Idx: 5000 Loss: 0.007163461210492756
Epoch: 10 Idx: 0 Loss: 0.031789433641330786
Epoch: 10 Idx: 5000 Loss: 0.00564965133507935
Epoch: 11 Idx: 0 Loss: 0.0287312384769484
Epoch: 11 Idx: 5000 Loss: 0.022370082731960984
Epoch: 12 Idx: 0 Loss: 0.011149415735591561
Epoch: 12 Idx: 5000 Loss: 0.008479288763666187
Epoch: 13 Idx: 0 Loss: 0.011488959698017793
Epoch: 13 Idx: 5000 Loss: 0.02825349352512276
Epoch: 14 Idx: 0 Loss: 0.008854065738111427
Epoch: 14 Idx: 5000 Loss: 0.008340244130935464
Epoch: 15 Idx: 0 Loss: 0.02081464781664213
Epoch: 15 Idx: 5000 Loss: 0.007136920103898457
Epoch: 16 Idx: 0 Loss: 0.024550848545665117
Epoch: 16 Idx: 5000 Loss: 0.01012946812663343
Epoch: 17 Idx: 0 Loss: 0.010705586304621933
Epoch: 17 Idx: 5000 Loss: 0.017253520346016075
Epoch: 18 Idx: 0 Loss: 0.007732798391082161
Epoch: 18 Idx: 5000 Loss: 0.007059971060803718
Epoch: 19 Idx: 0 Loss: 0.028029977541972843
Epoch: 19 Idx: 5000 Loss: 0.017890743534921247
Epoch: 20 Idx: 0 Loss: 0.00754926609256423
Epoch: 20 Idx: 5000 Loss: 0.012594548810063846
Epoch: 21 Idx: 0 Loss: 0.007185985502466904
Epoch: 21 Idx: 5000 Loss: 0.01267159796810987
Epoch: 22 Idx: 0 Loss: 0.011426101344388519
Epoch: 22 Idx: 5000 Loss: 0.006482618075919587
Epoch: 23 Idx: 0 Loss: 0.01399915199921323
Epoch: 23 Idx: 5000 Loss: 0.014042007918464255
Epoch: 24 Idx: 0 Loss: 0.041569261167255483
Epoch: 24 Idx: 5000 Loss: 0.008967618558435975
Epoch: 25 Idx: 0 Loss: 0.021034312904063615
Epoch: 25 Idx: 5000 Loss: 0.011058512975165854
Epoch: 26 Idx: 0 Loss: 0.014784860655834276
Epoch: 26 Idx: 5000 Loss: 0.0172850235009568
Epoch: 27 Idx: 0 Loss: 0.017519555395367738
Epoch: 27 Idx: 5000 Loss: 0.02249904985743353
Epoch: 28 Idx: 0 Loss: 0.02067660215742425
Epoch: 28 Idx: 5000 Loss: 0.00742084645212347
Epoch: 29 Idx: 0 Loss: 0.0074141273253823785
Epoch: 29 Idx: 5000 Loss: 0.02000140898921706
Epoch: 30 Idx: 0 Loss: 0.017310148348988627
Epoch: 30 Idx: 5000 Loss: 0.00908060076858023
Epoch: 31 Idx: 0 Loss: 0.010475590418218139
Epoch: 31 Idx: 5000 Loss: 0.03757711556458608
Epoch: 32 Idx: 0 Loss: 0.021846783675720592
Epoch: 32 Idx: 5000 Loss: 0.029397035022321872
Epoch: 33 Idx: 0 Loss: 0.008073054448332298
Epoch: 33 Idx: 5000 Loss: 0.019706523651697134
Epoch: 34 Idx: 0 Loss: 0.021851895043139787
Epoch: 34 Idx: 5000 Loss: 0.017742223246131308
Epoch: 35 Idx: 0 Loss: 0.013186092651653016
Epoch: 35 Idx: 5000 Loss: 0.008198496350845508
Epoch: 36 Idx: 0 Loss: 0.026140644283424795
Epoch: 36 Idx: 5000 Loss: 0.019940139013871795
Epoch: 37 Idx: 0 Loss: 0.03787556501579264
Epoch: 37 Idx: 5000 Loss: 0.015090615600988337
Epoch: 38 Idx: 0 Loss: 0.013967350784024843
Epoch: 38 Idx: 5000 Loss: 0.01639275612539204
Epoch: 39 Idx: 0 Loss: 0.010942420732267321
Epoch: 39 Idx: 5000 Loss: 0.01141379563047792
Epoch: 40 Idx: 0 Loss: 0.010837175403730196
Epoch: 40 Idx: 5000 Loss: 0.022628715326388056
Epoch: 41 Idx: 0 Loss: 0.01453917632889655
Epoch: 41 Idx: 5000 Loss: 0.02671636784537372
Epoch: 42 Idx: 0 Loss: 0.013590948898944437
Epoch: 42 Idx: 5000 Loss: 0.011161007731708701
Epoch: 43 Idx: 0 Loss: 0.01021651354168227
Epoch: 43 Idx: 5000 Loss: 0.006096546511892759
Epoch: 44 Idx: 0 Loss: 0.011093103645461646
Epoch: 44 Idx: 5000 Loss: 0.03847346042330665
Epoch: 45 Idx: 0 Loss: 0.010877692028232428
Epoch: 45 Idx: 5000 Loss: 0.01874926872790257
Epoch: 46 Idx: 0 Loss: 0.024197923300276494
Epoch: 46 Idx: 5000 Loss: 0.015720782472601398
Epoch: 47 Idx: 0 Loss: 0.009144788357895988
Epoch: 47 Idx: 5000 Loss: 0.02155290855040355
Epoch: 48 Idx: 0 Loss: 0.006663911651361691
Epoch: 48 Idx: 5000 Loss: 0.03409283118432999
Epoch: 49 Idx: 0 Loss: 0.01708309236574651
Epoch: 49 Idx: 5000 Loss: 0.03238185172211491
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14504118755980683
Epoch: 0 Idx: 5000 Loss: 0.041531511428865714
Epoch: 1 Idx: 0 Loss: 0.017105106833522035
Epoch: 1 Idx: 5000 Loss: 0.008845712282847843
Epoch: 2 Idx: 0 Loss: 0.012499725885779217
Epoch: 2 Idx: 5000 Loss: 0.007158701991363154
Epoch: 3 Idx: 0 Loss: 0.017205177479774646
Epoch: 3 Idx: 5000 Loss: 0.013775794734898764
Epoch: 4 Idx: 0 Loss: 0.00718150886010673
Epoch: 4 Idx: 5000 Loss: 0.0479373050419135
Epoch: 5 Idx: 0 Loss: 0.007785932131953508
Epoch: 5 Idx: 5000 Loss: 0.014262339625127771
Epoch: 6 Idx: 0 Loss: 0.008886801929268894
Epoch: 6 Idx: 5000 Loss: 0.010236392747457832
Epoch: 7 Idx: 0 Loss: 0.01287718193118252
Epoch: 7 Idx: 5000 Loss: 0.037495743014488936
Epoch: 8 Idx: 0 Loss: 0.006694766984569235
Epoch: 8 Idx: 5000 Loss: 0.008672845245405895
Epoch: 9 Idx: 0 Loss: 0.01664874863499635
Epoch: 9 Idx: 5000 Loss: 0.028974712933723664
Epoch: 10 Idx: 0 Loss: 0.009174642028222713
Epoch: 10 Idx: 5000 Loss: 0.018930665030894703
Epoch: 11 Idx: 0 Loss: 0.017225320807422697
Epoch: 11 Idx: 5000 Loss: 0.0066636299161294925
Epoch: 12 Idx: 0 Loss: 0.010624021348790497
Epoch: 12 Idx: 5000 Loss: 0.024376633881719276
Epoch: 13 Idx: 0 Loss: 0.0032658599519015856
Epoch: 13 Idx: 5000 Loss: 0.027793027635473918
Epoch: 14 Idx: 0 Loss: 0.009763677515741549
Epoch: 14 Idx: 5000 Loss: 0.01271097490985123
Epoch: 15 Idx: 0 Loss: 0.007028206025413954
Epoch: 15 Idx: 5000 Loss: 0.018711527649113397
Epoch: 16 Idx: 0 Loss: 0.01518325727152307
Epoch: 16 Idx: 5000 Loss: 0.022403198181201837
Epoch: 17 Idx: 0 Loss: 0.01036799560739219
Epoch: 17 Idx: 5000 Loss: 0.021035135431523185
Epoch: 18 Idx: 0 Loss: 0.010604816320953506
Epoch: 18 Idx: 5000 Loss: 0.012780284540802954
Epoch: 19 Idx: 0 Loss: 0.011149420352722485
Epoch: 19 Idx: 5000 Loss: 0.02440593282750767
Epoch: 20 Idx: 0 Loss: 0.020258799677875812
Epoch: 20 Idx: 5000 Loss: 0.011915254482949895
Epoch: 21 Idx: 0 Loss: 0.008774391470466594
Epoch: 21 Idx: 5000 Loss: 0.01709334252720191
Epoch: 22 Idx: 0 Loss: 0.03248666217675002
Epoch: 22 Idx: 5000 Loss: 0.01696522528575383
Epoch: 23 Idx: 0 Loss: 0.014494619817666107
Epoch: 23 Idx: 5000 Loss: 0.017000352388432147
Epoch: 24 Idx: 0 Loss: 0.008736793790811178
Epoch: 24 Idx: 5000 Loss: 0.018971104288322355
Epoch: 25 Idx: 0 Loss: 0.026387164238444276
Epoch: 25 Idx: 5000 Loss: 0.011124842269994956
Epoch: 26 Idx: 0 Loss: 0.024820985714711037
Epoch: 26 Idx: 5000 Loss: 0.016938340329637393
Epoch: 27 Idx: 0 Loss: 0.024169678894251274
Epoch: 27 Idx: 5000 Loss: 0.017321995895364053
Epoch: 28 Idx: 0 Loss: 0.008401546469183925
Epoch: 28 Idx: 5000 Loss: 0.014392747954735387
Epoch: 29 Idx: 0 Loss: 0.022344941727449108
Epoch: 29 Idx: 5000 Loss: 0.03434171430788039
Epoch: 30 Idx: 0 Loss: 0.007277053985319399
Epoch: 30 Idx: 5000 Loss: 0.019524858523973284
Epoch: 31 Idx: 0 Loss: 0.041019082926512684
Epoch: 31 Idx: 5000 Loss: 0.007588905960405727
Epoch: 32 Idx: 0 Loss: 0.008117932700515385
Epoch: 32 Idx: 5000 Loss: 0.01719288841123676
Epoch: 33 Idx: 0 Loss: 0.0070047672456867525
Epoch: 33 Idx: 5000 Loss: 0.013225657858293579
Epoch: 34 Idx: 0 Loss: 0.025637780576542812
Epoch: 34 Idx: 5000 Loss: 0.009079340284176953
Epoch: 35 Idx: 0 Loss: 0.01814585536699265
Epoch: 35 Idx: 5000 Loss: 0.029985709921388874
Epoch: 36 Idx: 0 Loss: 0.012207545596126797
Traceback (most recent call last):
  File "main.py", line 517, in <module>
    loss.backward()
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc215>
Subject: Job 4066902: <python main.py 18 2 True True> in cluster <dcc> Exited

Job <python main.py 18 2 True True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:41 2020
Job was executed on host(s) <dccxc215>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:49:40 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:49:40 2020
Terminated at Wed Sep 16 04:38:41 2020
Results reported at Wed Sep 16 04:38:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 18 2 True True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46133.03 sec.
    Max Memory :                                 2872 MB
    Average Memory :                             2677.36 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40545.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46169 sec.
    Turnaround time :                            46200 sec.

The output (if any) is above this job summary.

