2020-09-15 15:48:44.707887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:51.789517: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:51.918006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:10:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:51.918072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:51.920457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:51.922199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:51.922659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:51.924856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:51.926401: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:51.926668: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:51.926689: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:51.927146: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:51.963717: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2600150000 Hz
2020-09-15 15:48:51.963967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5589a9015920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:51.963987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:51.966995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:51.967030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.18673062363250725
Epoch: 0 Idx: 5000 Loss: 0.007829192129911799
Epoch: 1 Idx: 0 Loss: 0.009411060936822974
Epoch: 1 Idx: 5000 Loss: 0.01526521024652077
Epoch: 2 Idx: 0 Loss: 0.007136091545696067
Epoch: 2 Idx: 5000 Loss: 0.03190390914507239
Epoch: 3 Idx: 0 Loss: 0.04414008443484592
Epoch: 3 Idx: 5000 Loss: 0.010926556105428873
Epoch: 4 Idx: 0 Loss: 0.006372581283166073
Epoch: 4 Idx: 5000 Loss: 0.0037222000356875572
Epoch: 5 Idx: 0 Loss: 0.012654145670624412
Epoch: 5 Idx: 5000 Loss: 0.0177611183746514
Epoch: 6 Idx: 0 Loss: 0.018493069228382168
Epoch: 6 Idx: 5000 Loss: 0.013064018069320279
Epoch: 7 Idx: 0 Loss: 0.012284651818954273
Epoch: 7 Idx: 5000 Loss: 0.01644975943697896
Epoch: 8 Idx: 0 Loss: 0.01653714274566162
Epoch: 8 Idx: 5000 Loss: 0.007141873079741825
Epoch: 9 Idx: 0 Loss: 0.011445635815784377
Epoch: 9 Idx: 5000 Loss: 0.01156879234346489
Epoch: 10 Idx: 0 Loss: 0.03558363714873992
Epoch: 10 Idx: 5000 Loss: 0.013030246882888397
Epoch: 11 Idx: 0 Loss: 0.029415528486303157
Epoch: 11 Idx: 5000 Loss: 0.013230059416098543
Epoch: 12 Idx: 0 Loss: 0.006237620367772681
Epoch: 12 Idx: 5000 Loss: 0.0317324007418715
Epoch: 13 Idx: 0 Loss: 0.012060999637351235
Epoch: 13 Idx: 5000 Loss: 0.02403890218874083
Epoch: 14 Idx: 0 Loss: 0.021220287747621948
Epoch: 14 Idx: 5000 Loss: 0.017366435248872207
Epoch: 15 Idx: 0 Loss: 0.01970170158912054
Epoch: 15 Idx: 5000 Loss: 0.03516804652914813
Epoch: 16 Idx: 0 Loss: 0.013966480804270003
Epoch: 16 Idx: 5000 Loss: 0.017501172142153864
Epoch: 17 Idx: 0 Loss: 0.02192671087982094
Epoch: 17 Idx: 5000 Loss: 0.02547566202088234
Epoch: 18 Idx: 0 Loss: 0.017301983464834646
Epoch: 18 Idx: 5000 Loss: 0.0345527994861603
Epoch: 19 Idx: 0 Loss: 0.015011941399671262
Epoch: 19 Idx: 5000 Loss: 0.01817792211175443
Epoch: 20 Idx: 0 Loss: 0.006439263303598901
Epoch: 20 Idx: 5000 Loss: 0.03466334158596425
Epoch: 21 Idx: 0 Loss: 0.0349906609161563
Epoch: 21 Idx: 5000 Loss: 0.02173716078191471
Epoch: 22 Idx: 0 Loss: 0.02244939844292089
Epoch: 22 Idx: 5000 Loss: 0.007429372990317067
Epoch: 23 Idx: 0 Loss: 0.03459757591666568
Epoch: 23 Idx: 5000 Loss: 0.012363284848184048
Epoch: 24 Idx: 0 Loss: 0.021149699133524217
Epoch: 24 Idx: 5000 Loss: 0.007857461700884714
Epoch: 25 Idx: 0 Loss: 0.016849038294953683
Epoch: 25 Idx: 5000 Loss: 0.015949745336678978
Epoch: 26 Idx: 0 Loss: 0.007305009686015078
Epoch: 26 Idx: 5000 Loss: 0.023588789979313414
Epoch: 27 Idx: 0 Loss: 0.012349983139334577
Epoch: 27 Idx: 5000 Loss: 0.01894511417562524
Epoch: 28 Idx: 0 Loss: 0.008440384662359045
Epoch: 28 Idx: 5000 Loss: 0.013592140297455065
Epoch: 29 Idx: 0 Loss: 0.009178998637810503
Epoch: 29 Idx: 5000 Loss: 0.03185454490744069
Epoch: 30 Idx: 0 Loss: 0.012172331006549231
Epoch: 30 Idx: 5000 Loss: 0.010033502767865164
Epoch: 31 Idx: 0 Loss: 0.015040641736178095
Epoch: 31 Idx: 5000 Loss: 0.014503826828630656
Epoch: 32 Idx: 0 Loss: 0.023823261064205604
Epoch: 32 Idx: 5000 Loss: 0.014026713778234747
Epoch: 33 Idx: 0 Loss: 0.009493528135910105
Epoch: 33 Idx: 5000 Loss: 0.013685833396681123
Epoch: 34 Idx: 0 Loss: 0.012053774943823157
Epoch: 34 Idx: 5000 Loss: 0.02333776712374583
Epoch: 35 Idx: 0 Loss: 0.04880434363044364
Epoch: 35 Idx: 5000 Loss: 0.015140290114016313
Epoch: 36 Idx: 0 Loss: 0.020382484623019642
Epoch: 36 Idx: 5000 Loss: 0.042432675066624174
Epoch: 37 Idx: 0 Loss: 0.0244191987890496
Epoch: 37 Idx: 5000 Loss: 0.035576301330859664
Epoch: 38 Idx: 0 Loss: 0.011971314751173651
Epoch: 38 Idx: 5000 Loss: 0.02545601661344162
Epoch: 39 Idx: 0 Loss: 0.01007756138384819
Epoch: 39 Idx: 5000 Loss: 0.013423714051740596
Epoch: 40 Idx: 0 Loss: 0.006391127722538076
Epoch: 40 Idx: 5000 Loss: 0.018452733452313498
Epoch: 41 Idx: 0 Loss: 0.007883080643336215
Epoch: 41 Idx: 5000 Loss: 0.013629438105782744
Epoch: 42 Idx: 0 Loss: 0.004952555411647583
Epoch: 42 Idx: 5000 Loss: 0.034686626338863547
Epoch: 43 Idx: 0 Loss: 0.009044770592864588
Epoch: 43 Idx: 5000 Loss: 0.024554999424053585
Epoch: 44 Idx: 0 Loss: 0.012904963879486458
Epoch: 44 Idx: 5000 Loss: 0.016066429477375205
Epoch: 45 Idx: 0 Loss: 0.01982768132410004
Epoch: 45 Idx: 5000 Loss: 0.020333193791356525
Epoch: 46 Idx: 0 Loss: 0.04536947722704422
Epoch: 46 Idx: 5000 Loss: 0.019684641768570814
Epoch: 47 Idx: 0 Loss: 0.00546594689492906
Epoch: 47 Idx: 5000 Loss: 0.007492503612297557
Epoch: 48 Idx: 0 Loss: 0.012572862570849462
Epoch: 48 Idx: 5000 Loss: 0.053634472566426575
Epoch: 49 Idx: 0 Loss: 0.015588509251666426
Epoch: 49 Idx: 5000 Loss: 0.02021146760473711
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.14769387740664727
Epoch: 0 Idx: 5000 Loss: 0.00803484522699265
Epoch: 1 Idx: 0 Loss: 0.00765857106746161
Epoch: 1 Idx: 5000 Loss: 0.014933043820958659
Epoch: 2 Idx: 0 Loss: 0.027098995421282756
Epoch: 2 Idx: 5000 Loss: 0.01786754237678778
Epoch: 3 Idx: 0 Loss: 0.020709304059915723
Epoch: 3 Idx: 5000 Loss: 0.013849500145023078
Epoch: 4 Idx: 0 Loss: 0.012031097786517944
Epoch: 4 Idx: 5000 Loss: 0.013306061891837171
Epoch: 5 Idx: 0 Loss: 0.01758885123981901
Epoch: 5 Idx: 5000 Loss: 0.012503212478047445
Epoch: 6 Idx: 0 Loss: 0.018409357947980612
Epoch: 6 Idx: 5000 Loss: 0.007053554327000491
Epoch: 7 Idx: 0 Loss: 0.01740134836303816
Epoch: 7 Idx: 5000 Loss: 0.02528891291687179
Epoch: 8 Idx: 0 Loss: 0.014257281968284673
Epoch: 8 Idx: 5000 Loss: 0.013616587730918873
Epoch: 9 Idx: 0 Loss: 0.012786825866773047
Epoch: 9 Idx: 5000 Loss: 0.006142427191980894
Epoch: 10 Idx: 0 Loss: 0.009205182486516732
Epoch: 10 Idx: 5000 Loss: 0.015336807383639734
Epoch: 11 Idx: 0 Loss: 0.010383863854923858
Epoch: 11 Idx: 5000 Loss: 0.0074292878513729805
Epoch: 12 Idx: 0 Loss: 0.01598823517301929
Epoch: 12 Idx: 5000 Loss: 0.013442352271305944
Epoch: 13 Idx: 0 Loss: 0.012335999336213238
Epoch: 13 Idx: 5000 Loss: 0.008151680305998455
Epoch: 14 Idx: 0 Loss: 0.011285808114570407
Epoch: 14 Idx: 5000 Loss: 0.006995052010349849
Epoch: 15 Idx: 0 Loss: 0.026293873648952075
Epoch: 15 Idx: 5000 Loss: 0.00763972063056566
Epoch: 16 Idx: 0 Loss: 0.01680574464496823
Epoch: 16 Idx: 5000 Loss: 0.018122704998938314
Epoch: 17 Idx: 0 Loss: 0.01424487444233892
Epoch: 17 Idx: 5000 Loss: 0.014966412751972788
Epoch: 18 Idx: 0 Loss: 0.020760026698727792
Epoch: 18 Idx: 5000 Loss: 0.011311328557074663
Epoch: 19 Idx: 0 Loss: 0.02405292489064767
Epoch: 19 Idx: 5000 Loss: 0.01912566442409886
Epoch: 20 Idx: 0 Loss: 0.028727099445406575
Epoch: 20 Idx: 5000 Loss: 0.012757171390135106
Epoch: 21 Idx: 0 Loss: 0.01223393289460738
Epoch: 21 Idx: 5000 Loss: 0.01658636040576193
Epoch: 22 Idx: 0 Loss: 0.012700292754208331
Epoch: 22 Idx: 5000 Loss: 0.00577894927599764
Epoch: 23 Idx: 0 Loss: 0.02480334414589728
Epoch: 23 Idx: 5000 Loss: 0.01595020755763437
Epoch: 24 Idx: 0 Loss: 0.037150326406461265
Epoch: 24 Idx: 5000 Loss: 0.013931871082140062
Epoch: 25 Idx: 0 Loss: 0.00750593163633815
Epoch: 25 Idx: 5000 Loss: 0.015325989335751897
Epoch: 26 Idx: 0 Loss: 0.011547388271368107
Epoch: 26 Idx: 5000 Loss: 0.026835125068950784
Epoch: 27 Idx: 0 Loss: 0.012011757470002153
Epoch: 27 Idx: 5000 Loss: 0.02215784139984773
Epoch: 28 Idx: 0 Loss: 0.013013533834506541
Epoch: 28 Idx: 5000 Loss: 0.010770811301856021
Epoch: 29 Idx: 0 Loss: 0.01908598468533083
Epoch: 29 Idx: 5000 Loss: 0.030218391830038563
Epoch: 30 Idx: 0 Loss: 0.02417501073685365
Epoch: 30 Idx: 5000 Loss: 0.008703096912652907
Epoch: 31 Idx: 0 Loss: 0.04920008208684853
Epoch: 31 Idx: 5000 Loss: 0.015105133791909387
Epoch: 32 Idx: 0 Loss: 0.013802199092608936
Epoch: 32 Idx: 5000 Loss: 0.01637879506804338
Epoch: 33 Idx: 0 Loss: 0.014921774717331401
Epoch: 33 Idx: 5000 Loss: 0.026153581957296168
Epoch: 34 Idx: 0 Loss: 0.007940292189315312
Epoch: 34 Idx: 5000 Loss: 0.012115037754310914
Epoch: 35 Idx: 0 Loss: 0.015250195941573626
Epoch: 35 Idx: 5000 Loss: 0.023058603147108166
Epoch: 36 Idx: 0 Loss: 0.012744792391420269
Epoch: 36 Idx: 5000 Loss: 0.03740404150634649
Epoch: 37 Idx: 0 Loss: 0.008645228631582322
Epoch: 37 Idx: 5000 Loss: 0.006267143687611883
Epoch: 38 Idx: 0 Loss: 0.008089228367032367
Epoch: 38 Idx: 5000 Loss: 0.009330634251822706
Epoch: 39 Idx: 0 Loss: 0.014644201721312752
Epoch: 39 Idx: 5000 Loss: 0.01206933175589069
Epoch: 40 Idx: 0 Loss: 0.00620519393201084
Epoch: 40 Idx: 5000 Loss: 0.022953485284224494
Epoch: 41 Idx: 0 Loss: 0.013303042261839352
Epoch: 41 Idx: 5000 Loss: 0.027698919171879683
Epoch: 42 Idx: 0 Loss: 0.009275578236517597
Epoch: 42 Idx: 5000 Loss: 0.027183918251781375
Epoch: 43 Idx: 0 Loss: 0.0077236324959793455
Epoch: 43 Idx: 5000 Loss: 0.012968789526362337
Epoch: 44 Idx: 0 Loss: 0.013490171400003926
Epoch: 44 Idx: 5000 Loss: 0.009464235891272006
Epoch: 45 Idx: 0 Loss: 0.046178967334266734
Epoch: 45 Idx: 5000 Loss: 0.013480079744065532
Epoch: 46 Idx: 0 Loss: 0.009622644841190298
Epoch: 46 Idx: 5000 Loss: 0.009853313809001998
Epoch: 47 Idx: 0 Loss: 0.019515293909058658
Epoch: 47 Idx: 5000 Loss: 0.042058154028247446
Epoch: 48 Idx: 0 Loss: 0.005836103659575563
Epoch: 48 Idx: 5000 Loss: 0.025544937401675124
Epoch: 49 Idx: 0 Loss: 0.017713279552340568
Epoch: 49 Idx: 5000 Loss: 0.009472166254192307
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14929552799620974
Epoch: 0 Idx: 5000 Loss: 0.020425824026585
Epoch: 1 Idx: 0 Loss: 0.014123273243343983
Epoch: 1 Idx: 5000 Loss: 0.007026865069319144
Epoch: 2 Idx: 0 Loss: 0.011989974719575771
Epoch: 2 Idx: 5000 Loss: 0.01632915548806661
Epoch: 3 Idx: 0 Loss: 0.016426556467958906
Epoch: 3 Idx: 5000 Loss: 0.022611085890580977
Epoch: 4 Idx: 0 Loss: 0.012971608166334393
Epoch: 4 Idx: 5000 Loss: 0.014767794607679439
Epoch: 5 Idx: 0 Loss: 0.041396122271806855
Epoch: 5 Idx: 5000 Loss: 0.009760688966867208
Epoch: 6 Idx: 0 Loss: 0.008940770497717422
Epoch: 6 Idx: 5000 Loss: 0.0197595641013367
Epoch: 7 Idx: 0 Loss: 0.011298336339068262
Epoch: 7 Idx: 5000 Loss: 0.01177002753126439
Epoch: 8 Idx: 0 Loss: 0.011527760286106277
Epoch: 8 Idx: 5000 Loss: 0.038294681153396265
Epoch: 9 Idx: 0 Loss: 0.010531536699355071
Epoch: 9 Idx: 5000 Loss: 0.0249472074996284
Epoch: 10 Idx: 0 Loss: 0.014504404858130756
Epoch: 10 Idx: 5000 Loss: 0.012436138295401787
Epoch: 11 Idx: 0 Loss: 0.02380568198982802
Epoch: 11 Idx: 5000 Loss: 0.014200855942880853
Epoch: 12 Idx: 0 Loss: 0.01230793191675172
Epoch: 12 Idx: 5000 Loss: 0.009312606769982794
Epoch: 13 Idx: 0 Loss: 0.00633353244953965
Epoch: 13 Idx: 5000 Loss: 0.007542819007559687
Epoch: 14 Idx: 0 Loss: 0.0660653035477634
Epoch: 14 Idx: 5000 Loss: 0.010823165290290381
Epoch: 15 Idx: 0 Loss: 0.006682169984581472
Epoch: 15 Idx: 5000 Loss: 0.018073683259803207
Epoch: 16 Idx: 0 Loss: 0.02040048915865197
Epoch: 16 Idx: 5000 Loss: 0.011770390621196544
Epoch: 17 Idx: 0 Loss: 0.029984349155538957
Epoch: 17 Idx: 5000 Loss: 0.016842695190420243
Epoch: 18 Idx: 0 Loss: 0.009936612404819047
Epoch: 18 Idx: 5000 Loss: 0.010465906873997403
Epoch: 19 Idx: 0 Loss: 0.013726928622567879
Epoch: 19 Idx: 5000 Loss: 0.013399813870536022
Epoch: 20 Idx: 0 Loss: 0.01145817769113031
Epoch: 20 Idx: 5000 Loss: 0.009121723507945328
Epoch: 21 Idx: 0 Loss: 0.00645209289730866
Epoch: 21 Idx: 5000 Loss: 0.01756589995860097
Epoch: 22 Idx: 0 Loss: 0.010333148807205431
Epoch: 22 Idx: 5000 Loss: 0.01680427648294313
Epoch: 23 Idx: 0 Loss: 0.01284110170046079
Epoch: 23 Idx: 5000 Loss: 0.013205276898500875
Epoch: 24 Idx: 0 Loss: 0.00815700339146104
Epoch: 24 Idx: 5000 Loss: 0.013834778070598693
Epoch: 25 Idx: 0 Loss: 0.03574137832813713
Epoch: 25 Idx: 5000 Loss: 0.023942481542167764
Epoch: 26 Idx: 0 Loss: 0.009791633699175538
Epoch: 26 Idx: 5000 Loss: 0.01061998413159944
Epoch: 27 Idx: 0 Loss: 0.018044638969310536
Epoch: 27 Idx: 5000 Loss: 0.017951471652745042
Epoch: 28 Idx: 0 Loss: 0.014066756121835812
Epoch: 28 Idx: 5000 Loss: 0.014173570780154528
Epoch: 29 Idx: 0 Loss: 0.011455248925783415
Epoch: 29 Idx: 5000 Loss: 0.01351975045359209
Epoch: 30 Idx: 0 Loss: 0.006544976761894677
Epoch: 30 Idx: 5000 Loss: 0.02523343688697856
Epoch: 31 Idx: 0 Loss: 0.012526082986851832
Epoch: 31 Idx: 5000 Loss: 0.010909063794310987
Epoch: 32 Idx: 0 Loss: 0.025658660314022235
Epoch: 32 Idx: 5000 Loss: 0.005870650229130625
Epoch: 33 Idx: 0 Loss: 0.014436481413285693
Epoch: 33 Idx: 5000 Loss: 0.018325739013946928
Epoch: 34 Idx: 0 Loss: 0.012226663527480294
Epoch: 34 Idx: 5000 Loss: 0.004182385180179831
Epoch: 35 Idx: 0 Loss: 0.008202082306256563
Epoch: 35 Idx: 5000 Loss: 0.01482683835906716
Epoch: 36 Idx: 0 Loss: 0.025171446291397392
Epoch: 36 Idx: 5000 Loss: 0.0038893713543830285
Epoch: 37 Idx: 0 Loss: 0.012488295146330283
Epoch: 37 Idx: 5000 Loss: 0.0132689040291567
Epoch: 38 Idx: 0 Loss: 0.014647151359256965
Epoch: 38 Idx: 5000 Loss: 0.018938011695177902
Epoch: 39 Idx: 0 Loss: 0.01668349150681533
Epoch: 39 Idx: 5000 Loss: 0.01867757418198368
Epoch: 40 Idx: 0 Loss: 0.013232890334356158
Epoch: 40 Idx: 5000 Loss: 0.020583028954176803
Epoch: 41 Idx: 0 Loss: 0.007558735871957822
Epoch: 41 Idx: 5000 Loss: 0.0125496845735366
Epoch: 42 Idx: 0 Loss: 0.01535746207816785
Epoch: 42 Idx: 5000 Loss: 0.011268135548253433
Epoch: 43 Idx: 0 Loss: 0.006242170423933114
Epoch: 43 Idx: 5000 Loss: 0.012937204138714228
Epoch: 44 Idx: 0 Loss: 0.01252169654133655
Epoch: 44 Idx: 5000 Loss: 0.0132796315405293
Epoch: 45 Idx: 0 Loss: 0.010572580409516185
Epoch: 45 Idx: 5000 Loss: 0.02232509261910156
Epoch: 46 Idx: 0 Loss: 0.016189799932689493
Epoch: 46 Idx: 5000 Loss: 0.010343803646375264
Epoch: 47 Idx: 0 Loss: 0.02746107967409418
Epoch: 47 Idx: 5000 Loss: 0.02344452829263104
Epoch: 48 Idx: 0 Loss: 0.024754803070819384
Epoch: 48 Idx: 5000 Loss: 0.012835245761118656
Epoch: 49 Idx: 0 Loss: 0.020424730978099888
Epoch: 49 Idx: 5000 Loss: 0.008525118415046724
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.23146037185064433
Epoch: 0 Idx: 5000 Loss: 0.030628178140943974
Epoch: 1 Idx: 0 Loss: 0.005388972343887048
Epoch: 1 Idx: 5000 Loss: 0.022226821154584495
Epoch: 2 Idx: 0 Loss: 0.012791033267317491
Epoch: 2 Idx: 5000 Loss: 0.02304074284742037
Epoch: 3 Idx: 0 Loss: 0.028135204787880886
Epoch: 3 Idx: 5000 Loss: 0.011814190712003032
Epoch: 4 Idx: 0 Loss: 0.026243979589088813
Epoch: 4 Idx: 5000 Loss: 0.013402950542034043
Epoch: 5 Idx: 0 Loss: 0.011911013051313772
Epoch: 5 Idx: 5000 Loss: 0.009273392385340189
Epoch: 6 Idx: 0 Loss: 0.012218374773871943
Epoch: 6 Idx: 5000 Loss: 0.008303389774181201
Epoch: 7 Idx: 0 Loss: 0.019366285138598956
Epoch: 7 Idx: 5000 Loss: 0.02345300523540719
Epoch: 8 Idx: 0 Loss: 0.04178201775341532
Epoch: 8 Idx: 5000 Loss: 0.018258431756328346
Epoch: 9 Idx: 0 Loss: 0.015545445365090253
Epoch: 9 Idx: 5000 Loss: 0.025180256093355342
Epoch: 10 Idx: 0 Loss: 0.011343212949235487
Epoch: 10 Idx: 5000 Loss: 0.037135271828767094
Epoch: 11 Idx: 0 Loss: 0.010584764630755531
Epoch: 11 Idx: 5000 Loss: 0.010056883379152889
Epoch: 12 Idx: 0 Loss: 0.012989482088623931
Epoch: 12 Idx: 5000 Loss: 0.010752129325390002
Epoch: 13 Idx: 0 Loss: 0.008450242339594358
Epoch: 13 Idx: 5000 Loss: 0.016719869711113576
Epoch: 14 Idx: 0 Loss: 0.017386488756480134
Epoch: 14 Idx: 5000 Loss: 0.016573145864256945
Epoch: 15 Idx: 0 Loss: 0.013892196076294381
Epoch: 15 Idx: 5000 Loss: 0.009205962391036068
Epoch: 16 Idx: 0 Loss: 0.04310811238854969
Epoch: 16 Idx: 5000 Loss: 0.01233053530192776
Epoch: 17 Idx: 0 Loss: 0.012875071872211041
Epoch: 17 Idx: 5000 Loss: 0.009299424578603256
Epoch: 18 Idx: 0 Loss: 0.006277377483778742
Epoch: 18 Idx: 5000 Loss: 0.017065666307542773
Epoch: 19 Idx: 0 Loss: 0.010463532193645165
Epoch: 19 Idx: 5000 Loss: 0.008765056521135385
Epoch: 20 Idx: 0 Loss: 0.03222531102954272
Epoch: 20 Idx: 5000 Loss: 0.015344434789601857
Epoch: 21 Idx: 0 Loss: 0.005248514605346907
Epoch: 21 Idx: 5000 Loss: 0.024479097565719532
Epoch: 22 Idx: 0 Loss: 0.006869382982280289
Epoch: 22 Idx: 5000 Loss: 0.023177132994775664
Epoch: 23 Idx: 0 Loss: 0.016082865793372182
Epoch: 23 Idx: 5000 Loss: 0.021011926868506985
Epoch: 24 Idx: 0 Loss: 0.010556843420394825
Epoch: 24 Idx: 5000 Loss: 0.005782930719380376
Epoch: 25 Idx: 0 Loss: 0.015125175674969456
Epoch: 25 Idx: 5000 Loss: 0.017078592897752386
Epoch: 26 Idx: 0 Loss: 0.02391385294843408
Epoch: 26 Idx: 5000 Loss: 0.02182978688624853
Epoch: 27 Idx: 0 Loss: 0.00992780536498976
Epoch: 27 Idx: 5000 Loss: 0.00831122001313183
Epoch: 28 Idx: 0 Loss: 0.010614195296035953
Epoch: 28 Idx: 5000 Loss: 0.010226015303884933
Epoch: 29 Idx: 0 Loss: 0.003960596339297781
Epoch: 29 Idx: 5000 Loss: 0.023019439065824182
Epoch: 30 Idx: 0 Loss: 0.016754230899555397
Epoch: 30 Idx: 5000 Loss: 0.025236144730932154
Epoch: 31 Idx: 0 Loss: 0.025210905322430834
Epoch: 31 Idx: 5000 Loss: 0.010010302086579622
Epoch: 32 Idx: 0 Loss: 0.011772340304094965
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 335, in forward
    node_weights = self.masked_softmax(node_weights.squeeze(1).reshape(-1, self.n_neighbours, self.max_pathlen)) # dim: (batch_size, 4, max_pathlen)
  File "main.py", line 297, in masked_softmax
    mask = ((inp != 0).double() - 1) * 9999  # for -inf
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc263>
Subject: Job 4066858: <python main.py 5 10 False True> in cluster <dcc> Exited

Job <python main.py 5 10 False True> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc263>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:40 2020
Results reported at Wed Sep 16 04:38:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 10 False True
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46179.62 sec.
    Max Memory :                                 2947 MB
    Average Memory :                             2734.05 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40470.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46201 sec.
    Turnaround time :                            46202 sec.

The output (if any) is above this job summary.

