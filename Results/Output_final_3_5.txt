2020-09-15 15:48:44.597175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:51.591889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-15 15:48:51.699527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:13:00.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-09-15 15:48:51.699592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-15 15:48:51.701793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-15 15:48:51.721227: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-15 15:48:51.756544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-15 15:48:51.803722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-15 15:48:51.825765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-15 15:48:51.826256: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/share/lsf-9.1.3/10.1/linux3.10-glibc2.17-x86_64/lib:=/opt/share/gcc-4.9.2_rhel6/x86_64/lib/:/opt/share/gcc-4.9.2_rhel6/x86_64/lib64:/opt/share/Python-3.6.2/x86_64/lib:=/opt/share/gcc-5.4.0/x86_64/lib/:/opt/share/gcc-5.4.0/x86_64/lib64:/opt/share/isl-0.17/x86_64/lib/:/opt/share/protobuf-3.1.0/x86_64/lib/:/opt/share/leveldb-1.19/x86_64/lib/:/opt/share/boost-1.62.0/x86_64/lib/:/opt/share/torch-7/x86_64/install/lib:/opt/share/Python-2.7.12/x86_64/lib:/opt/share/Python-3.5.2/x86_64/lib:/opt/share/cuDNN-v5.1-8.0/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/share/cuda-8.0/
2020-09-15 15:48:51.826279: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-15 15:48:51.826689: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 15:48:51.860166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599875000 Hz
2020-09-15 15:48:51.860446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563e8fc05300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-15 15:48:51.860469: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-15 15:48:51.863287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 15:48:51.863326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Prefix path:  /dccstor/cogfin/arvind/da/VeeAlign/
Ontologies being aligned are:  [('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/conference.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/cmt.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/sigkdd.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/edas.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/ekaw.owl'), ('/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/confOf.owl', '/dccstor/cogfin/arvind/da/VeeAlign/datasets/conference/ontologies/iasted.owl')]
Total number of extracted unique classes and properties from entire RA set:  829
Constructing abbrevation resolution dict....
Results after abbreviation resolution:  {'PC': 'Program Committee', 'OC': 'Organizing Committee'}
Resolving abbreviations...
Number of entities: 119639
Starting sliding window evaluation...
Step 0/7
Val onto:  [('confof', 'ekaw')] test_onto:  [('conference', 'sigkdd')]
Training size: 112565 Testing size: 3871
Epoch: 0 Idx: 0 Loss: 0.180089952577613
Epoch: 0 Idx: 5000 Loss: 0.03737795992098297
Epoch: 1 Idx: 0 Loss: 0.009428918772712774
Epoch: 1 Idx: 5000 Loss: 0.012639822807899463
Epoch: 2 Idx: 0 Loss: 0.005171772616875482
Epoch: 2 Idx: 5000 Loss: 0.01693037477132093
Epoch: 3 Idx: 0 Loss: 0.014647911331180291
Epoch: 3 Idx: 5000 Loss: 0.024440861492753437
Epoch: 4 Idx: 0 Loss: 0.010877119263254964
Epoch: 4 Idx: 5000 Loss: 0.02409451042189778
Epoch: 5 Idx: 0 Loss: 0.014023804108004169
Epoch: 5 Idx: 5000 Loss: 0.013286017927846871
Epoch: 6 Idx: 0 Loss: 0.012200724141774987
Epoch: 6 Idx: 5000 Loss: 0.019543245764928063
Epoch: 7 Idx: 0 Loss: 0.01660301392556903
Epoch: 7 Idx: 5000 Loss: 0.011393477408349924
Epoch: 8 Idx: 0 Loss: 0.015965801702192535
Epoch: 8 Idx: 5000 Loss: 0.009538051765526374
Epoch: 9 Idx: 0 Loss: 0.02996407248791759
Epoch: 9 Idx: 5000 Loss: 0.016751037273339035
Epoch: 10 Idx: 0 Loss: 0.02907184065890385
Epoch: 10 Idx: 5000 Loss: 0.05731145938146988
Epoch: 11 Idx: 0 Loss: 0.014139179584934497
Epoch: 11 Idx: 5000 Loss: 0.017314611777237896
Epoch: 12 Idx: 0 Loss: 0.003917501716286632
Epoch: 12 Idx: 5000 Loss: 0.016383897516809985
Epoch: 13 Idx: 0 Loss: 0.014326168418366743
Epoch: 13 Idx: 5000 Loss: 0.02478827977854329
Epoch: 14 Idx: 0 Loss: 0.014556983152357997
Epoch: 14 Idx: 5000 Loss: 0.009490650562493798
Epoch: 15 Idx: 0 Loss: 0.009046533277805819
Epoch: 15 Idx: 5000 Loss: 0.013119796029939264
Epoch: 16 Idx: 0 Loss: 0.007830070731626516
Epoch: 16 Idx: 5000 Loss: 0.008417134276830033
Epoch: 17 Idx: 0 Loss: 0.020449765247721553
Epoch: 17 Idx: 5000 Loss: 0.008799588910694562
Epoch: 18 Idx: 0 Loss: 0.027200847961777477
Epoch: 18 Idx: 5000 Loss: 0.01983787482679329
Epoch: 19 Idx: 0 Loss: 0.015663228032104126
Epoch: 19 Idx: 5000 Loss: 0.009157365944020647
Epoch: 20 Idx: 0 Loss: 0.005329256453186988
Epoch: 20 Idx: 5000 Loss: 0.0076627067715625725
Epoch: 21 Idx: 0 Loss: 0.015339138617790142
Epoch: 21 Idx: 5000 Loss: 0.026086665029502267
Epoch: 22 Idx: 0 Loss: 0.02860042264991029
Epoch: 22 Idx: 5000 Loss: 0.04043700604433274
Epoch: 23 Idx: 0 Loss: 0.011651045034071914
Epoch: 23 Idx: 5000 Loss: 0.039314042827955954
Epoch: 24 Idx: 0 Loss: 0.019073405017559417
Epoch: 24 Idx: 5000 Loss: 0.02125204127699804
Epoch: 25 Idx: 0 Loss: 0.01976973502545567
Epoch: 25 Idx: 5000 Loss: 0.012628943529723309
Epoch: 26 Idx: 0 Loss: 0.008242650350497985
Epoch: 26 Idx: 5000 Loss: 0.013341109743102188
Epoch: 27 Idx: 0 Loss: 0.00686226940715847
Epoch: 27 Idx: 5000 Loss: 0.007777005452706282
Epoch: 28 Idx: 0 Loss: 0.016663282932612968
Epoch: 28 Idx: 5000 Loss: 0.01552712362799535
Epoch: 29 Idx: 0 Loss: 0.01002578858253222
Epoch: 29 Idx: 5000 Loss: 0.010809834009404416
Epoch: 30 Idx: 0 Loss: 0.014311118750161892
Epoch: 30 Idx: 5000 Loss: 0.010493522133078999
Epoch: 31 Idx: 0 Loss: 0.02653050577686431
Epoch: 31 Idx: 5000 Loss: 0.008480211278158569
Epoch: 32 Idx: 0 Loss: 0.01746512559866254
Epoch: 32 Idx: 5000 Loss: 0.010877549808967255
Epoch: 33 Idx: 0 Loss: 0.008086066756470996
Epoch: 33 Idx: 5000 Loss: 0.023296610271886255
Epoch: 34 Idx: 0 Loss: 0.013118652953960528
Epoch: 34 Idx: 5000 Loss: 0.007585015289970205
Epoch: 35 Idx: 0 Loss: 0.007383941705161623
Epoch: 35 Idx: 5000 Loss: 0.012772399432437475
Epoch: 36 Idx: 0 Loss: 0.013688239496547499
Epoch: 36 Idx: 5000 Loss: 0.009159447896315802
Epoch: 37 Idx: 0 Loss: 0.04548811373255489
Epoch: 37 Idx: 5000 Loss: 0.010454270868969148
Epoch: 38 Idx: 0 Loss: 0.018605840821611992
Epoch: 38 Idx: 5000 Loss: 0.0288695632616756
Epoch: 39 Idx: 0 Loss: 0.011968439442191059
Epoch: 39 Idx: 5000 Loss: 0.013574582095563696
Epoch: 40 Idx: 0 Loss: 0.01715386063739925
Epoch: 40 Idx: 5000 Loss: 0.013792964864176221
Epoch: 41 Idx: 0 Loss: 0.02727009400889407
Epoch: 41 Idx: 5000 Loss: 0.019692652251721135
Epoch: 42 Idx: 0 Loss: 0.012109134512571222
Epoch: 42 Idx: 5000 Loss: 0.05082079157967066
Epoch: 43 Idx: 0 Loss: 0.009747281010798995
Epoch: 43 Idx: 5000 Loss: 0.02756919803224254
Epoch: 44 Idx: 0 Loss: 0.039122492576725
Epoch: 44 Idx: 5000 Loss: 0.030551659334493195
Epoch: 45 Idx: 0 Loss: 0.007781321285292669
Epoch: 45 Idx: 5000 Loss: 0.014944928761773845
Epoch: 46 Idx: 0 Loss: 0.01284053565074455
Epoch: 46 Idx: 5000 Loss: 0.012407934509077486
Epoch: 47 Idx: 0 Loss: 0.011976366899256609
Epoch: 47 Idx: 5000 Loss: 0.014832701420547439
Epoch: 48 Idx: 0 Loss: 0.00553940759717687
Epoch: 48 Idx: 5000 Loss: 0.015394011659625385
Epoch: 49 Idx: 0 Loss: 0.020625419970150806
Epoch: 49 Idx: 5000 Loss: 0.012103557941182713
Len (direct inputs):  429
Inputs len 2744 15 3856
Len (direct inputs):  1127
Starting sliding window evaluation...
Step 2/7
Val onto:  [('conference', 'ekaw')] test_onto:  [('cmt', 'sigkdd')]
Training size: 111450 Testing size: 2364
Epoch: 0 Idx: 0 Loss: 0.15774796769437538
Epoch: 0 Idx: 5000 Loss: 0.010690270816298052
Epoch: 1 Idx: 0 Loss: 0.014185139554935257
Epoch: 1 Idx: 5000 Loss: 0.016369734522438867
Epoch: 2 Idx: 0 Loss: 0.028455369178077637
Epoch: 2 Idx: 5000 Loss: 0.011758292935975644
Epoch: 3 Idx: 0 Loss: 0.019718497764640193
Epoch: 3 Idx: 5000 Loss: 0.012030176898594442
Epoch: 4 Idx: 0 Loss: 0.018897681907878522
Epoch: 4 Idx: 5000 Loss: 0.017349301260210524
Epoch: 5 Idx: 0 Loss: 0.008084212543579189
Epoch: 5 Idx: 5000 Loss: 0.02244188001032342
Epoch: 6 Idx: 0 Loss: 0.02566837215998956
Epoch: 6 Idx: 5000 Loss: 0.015598914592759486
Epoch: 7 Idx: 0 Loss: 0.01703475496410691
Epoch: 7 Idx: 5000 Loss: 0.005797919145752735
Epoch: 8 Idx: 0 Loss: 0.016605471092094298
Epoch: 8 Idx: 5000 Loss: 0.007977176090749995
Epoch: 9 Idx: 0 Loss: 0.03187915898539922
Epoch: 9 Idx: 5000 Loss: 0.008761543316173355
Epoch: 10 Idx: 0 Loss: 0.00953366087902987
Epoch: 10 Idx: 5000 Loss: 0.008424832866624266
Epoch: 11 Idx: 0 Loss: 0.01339042809446095
Epoch: 11 Idx: 5000 Loss: 0.008755751297870847
Epoch: 12 Idx: 0 Loss: 0.011521991712078678
Epoch: 12 Idx: 5000 Loss: 0.016186674568115733
Epoch: 13 Idx: 0 Loss: 0.010987734481278651
Epoch: 13 Idx: 5000 Loss: 0.019220167536060657
Epoch: 14 Idx: 0 Loss: 0.013448199816886322
Epoch: 14 Idx: 5000 Loss: 0.011933482461973902
Epoch: 15 Idx: 0 Loss: 0.013278157997519451
Epoch: 15 Idx: 5000 Loss: 0.01590436751853733
Epoch: 16 Idx: 0 Loss: 0.028366801195719278
Epoch: 16 Idx: 5000 Loss: 0.019888036664304675
Epoch: 17 Idx: 0 Loss: 0.016353275104844137
Epoch: 17 Idx: 5000 Loss: 0.011987732125160366
Epoch: 18 Idx: 0 Loss: 0.010541190094313773
Epoch: 18 Idx: 5000 Loss: 0.006273669951581967
Epoch: 19 Idx: 0 Loss: 0.023697783694726915
Epoch: 19 Idx: 5000 Loss: 0.005729782964209593
Epoch: 20 Idx: 0 Loss: 0.014278947342780344
Epoch: 20 Idx: 5000 Loss: 0.0178622187535743
Epoch: 21 Idx: 0 Loss: 0.02054254698080328
Epoch: 21 Idx: 5000 Loss: 0.01852450672241776
Epoch: 22 Idx: 0 Loss: 0.04200691410174206
Epoch: 22 Idx: 5000 Loss: 0.016113446702162984
Epoch: 23 Idx: 0 Loss: 0.020610610234868855
Epoch: 23 Idx: 5000 Loss: 0.031646604636222826
Epoch: 24 Idx: 0 Loss: 0.013613646241003419
Epoch: 24 Idx: 5000 Loss: 0.021359553791868068
Epoch: 25 Idx: 0 Loss: 0.015215552949242499
Epoch: 25 Idx: 5000 Loss: 0.009141842895364764
Epoch: 26 Idx: 0 Loss: 0.010051466988075321
Epoch: 26 Idx: 5000 Loss: 0.006640540639815931
Epoch: 27 Idx: 0 Loss: 0.01613761313513508
Epoch: 27 Idx: 5000 Loss: 0.010514089131103032
Epoch: 28 Idx: 0 Loss: 0.00680564775814892
Epoch: 28 Idx: 5000 Loss: 0.02240002384741856
Epoch: 29 Idx: 0 Loss: 0.010233671746987204
Epoch: 29 Idx: 5000 Loss: 0.007002314944309285
Epoch: 30 Idx: 0 Loss: 0.01932808253166865
Epoch: 30 Idx: 5000 Loss: 0.026998898680243907
Epoch: 31 Idx: 0 Loss: 0.04248108006913434
Epoch: 31 Idx: 5000 Loss: 0.014792037309638512
Epoch: 32 Idx: 0 Loss: 0.018133487442171747
Epoch: 32 Idx: 5000 Loss: 0.01213624778736107
Epoch: 33 Idx: 0 Loss: 0.014600164158537546
Epoch: 33 Idx: 5000 Loss: 0.008207657144037494
Epoch: 34 Idx: 0 Loss: 0.011135506325645847
Epoch: 34 Idx: 5000 Loss: 0.017827065440851265
Epoch: 35 Idx: 0 Loss: 0.006740401924538019
Epoch: 35 Idx: 5000 Loss: 0.020838806027181835
Epoch: 36 Idx: 0 Loss: 0.01546460547313041
Epoch: 36 Idx: 5000 Loss: 0.0343645055674344
Epoch: 37 Idx: 0 Loss: 0.009615092789646753
Epoch: 37 Idx: 5000 Loss: 0.019835531929962714
Epoch: 38 Idx: 0 Loss: 0.012823815597362854
Epoch: 38 Idx: 5000 Loss: 0.01638038295761201
Epoch: 39 Idx: 0 Loss: 0.010573211273620374
Epoch: 39 Idx: 5000 Loss: 0.00820466795742112
Epoch: 40 Idx: 0 Loss: 0.012269890390342302
Epoch: 40 Idx: 5000 Loss: 0.01876330958097739
Epoch: 41 Idx: 0 Loss: 0.022836745011153285
Epoch: 41 Idx: 5000 Loss: 0.006937199539233189
Epoch: 42 Idx: 0 Loss: 0.004484943338479416
Epoch: 42 Idx: 5000 Loss: 0.06052766658889884
Epoch: 43 Idx: 0 Loss: 0.014247457232346595
Epoch: 43 Idx: 5000 Loss: 0.009242490843087293
Epoch: 44 Idx: 0 Loss: 0.020821093885635397
Epoch: 44 Idx: 5000 Loss: 0.017811056110622718
Epoch: 45 Idx: 0 Loss: 0.02473687546776185
Epoch: 45 Idx: 5000 Loss: 0.010692953906291594
Epoch: 46 Idx: 0 Loss: 0.02121783033401021
Epoch: 46 Idx: 5000 Loss: 0.01878476220980605
Epoch: 47 Idx: 0 Loss: 0.004346003245973074
Epoch: 47 Idx: 5000 Loss: 0.037748191249779336
Epoch: 48 Idx: 0 Loss: 0.009827075666252436
Epoch: 48 Idx: 5000 Loss: 0.010240271199736084
Epoch: 49 Idx: 0 Loss: 0.009399526999707327
Epoch: 49 Idx: 5000 Loss: 0.008761665279247311
Len (direct inputs):  1737
Inputs len 1372 12 2352
Len (direct inputs):  992
Starting sliding window evaluation...
Step 4/7
Val onto:  [('ekaw', 'sigkdd')] test_onto:  [('cmt', 'conference')]
Training size: 111356 Testing size: 4145
Epoch: 0 Idx: 0 Loss: 0.14195938421246532
Epoch: 0 Idx: 5000 Loss: 0.023283219813085294
Epoch: 1 Idx: 0 Loss: 0.015463434499382245
Epoch: 1 Idx: 5000 Loss: 0.008306279574115175
Epoch: 2 Idx: 0 Loss: 0.009000978486609263
Epoch: 2 Idx: 5000 Loss: 0.007846084266787184
Epoch: 3 Idx: 0 Loss: 0.013638109450518469
Epoch: 3 Idx: 5000 Loss: 0.013577363346876068
Epoch: 4 Idx: 0 Loss: 0.007334219580041094
Epoch: 4 Idx: 5000 Loss: 0.016056216670614982
Epoch: 5 Idx: 0 Loss: 0.013885813379109055
Epoch: 5 Idx: 5000 Loss: 0.023067028723394892
Epoch: 6 Idx: 0 Loss: 0.021543257514925584
Epoch: 6 Idx: 5000 Loss: 0.024002460905899418
Epoch: 7 Idx: 0 Loss: 0.009546408235428662
Epoch: 7 Idx: 5000 Loss: 0.012768575092464441
Epoch: 8 Idx: 0 Loss: 0.012630507204284195
Epoch: 8 Idx: 5000 Loss: 0.007628590617381751
Epoch: 9 Idx: 0 Loss: 0.017996939667431475
Epoch: 9 Idx: 5000 Loss: 0.027059421387923117
Epoch: 10 Idx: 0 Loss: 0.010528267706082561
Epoch: 10 Idx: 5000 Loss: 0.025228157142552894
Epoch: 11 Idx: 0 Loss: 0.01873265170562847
Epoch: 11 Idx: 5000 Loss: 0.008440539179651955
Epoch: 12 Idx: 0 Loss: 0.016624152893646847
Epoch: 12 Idx: 5000 Loss: 0.014247372905376102
Epoch: 13 Idx: 0 Loss: 0.0071895995072690285
Epoch: 13 Idx: 5000 Loss: 0.014347613488492054
Epoch: 14 Idx: 0 Loss: 0.022921179855070813
Epoch: 14 Idx: 5000 Loss: 0.008120060664806089
Epoch: 15 Idx: 0 Loss: 0.029534222565784512
Epoch: 15 Idx: 5000 Loss: 0.01934911322410024
Epoch: 16 Idx: 0 Loss: 0.008813582616014523
Epoch: 16 Idx: 5000 Loss: 0.012959292775878501
Epoch: 17 Idx: 0 Loss: 0.009823093982504442
Epoch: 17 Idx: 5000 Loss: 0.010604619936738523
Epoch: 18 Idx: 0 Loss: 0.004499429055097799
Epoch: 18 Idx: 5000 Loss: 0.013064965724376678
Epoch: 19 Idx: 0 Loss: 0.014675332734247006
Epoch: 19 Idx: 5000 Loss: 0.03588658585443333
Epoch: 20 Idx: 0 Loss: 0.010343887051103333
Epoch: 20 Idx: 5000 Loss: 0.017969486844063007
Epoch: 21 Idx: 0 Loss: 0.004782143209696032
Epoch: 21 Idx: 5000 Loss: 0.012973086428411409
Epoch: 22 Idx: 0 Loss: 0.015747680980755862
Epoch: 22 Idx: 5000 Loss: 0.02004175285680261
Epoch: 23 Idx: 0 Loss: 0.02554125836635349
Epoch: 23 Idx: 5000 Loss: 0.029945723463227925
Epoch: 24 Idx: 0 Loss: 0.010672846796278057
Epoch: 24 Idx: 5000 Loss: 0.010381512613429279
Epoch: 25 Idx: 0 Loss: 0.022341591163151604
Epoch: 25 Idx: 5000 Loss: 0.006350184094236648
Epoch: 26 Idx: 0 Loss: 0.024138455517733335
Epoch: 26 Idx: 5000 Loss: 0.01427942146430128
Epoch: 27 Idx: 0 Loss: 0.015113133610970508
Epoch: 27 Idx: 5000 Loss: 0.012427205694641247
Epoch: 28 Idx: 0 Loss: 0.017984392408723626
Epoch: 28 Idx: 5000 Loss: 0.006724832503367442
Epoch: 29 Idx: 0 Loss: 0.007112651586851211
Epoch: 29 Idx: 5000 Loss: 0.026705938413945716
Epoch: 30 Idx: 0 Loss: 0.02369300384994706
Epoch: 30 Idx: 5000 Loss: 0.00810885359450761
Epoch: 31 Idx: 0 Loss: 0.01349258234049703
Epoch: 31 Idx: 5000 Loss: 0.03427647321383764
Epoch: 32 Idx: 0 Loss: 0.009541135741777314
Epoch: 32 Idx: 5000 Loss: 0.02995111444110275
Epoch: 33 Idx: 0 Loss: 0.007855469664454776
Epoch: 33 Idx: 5000 Loss: 0.010481891318430844
Epoch: 34 Idx: 0 Loss: 0.009926792830878196
Epoch: 34 Idx: 5000 Loss: 0.01881477358181954
Epoch: 35 Idx: 0 Loss: 0.017369751648299597
Epoch: 35 Idx: 5000 Loss: 0.012047361014577592
Epoch: 36 Idx: 0 Loss: 0.012230199892719317
Epoch: 36 Idx: 5000 Loss: 0.011216264742606782
Epoch: 37 Idx: 0 Loss: 0.024918870148891572
Epoch: 37 Idx: 5000 Loss: 0.03254145393172537
Epoch: 38 Idx: 0 Loss: 0.019924202827873685
Epoch: 38 Idx: 5000 Loss: 0.019681956730993235
Epoch: 39 Idx: 0 Loss: 0.007903495690961843
Epoch: 39 Idx: 5000 Loss: 0.026839118509014555
Epoch: 40 Idx: 0 Loss: 0.011832553078006106
Epoch: 40 Idx: 5000 Loss: 0.01445075996818445
Epoch: 41 Idx: 0 Loss: 0.011510319127607199
Epoch: 41 Idx: 5000 Loss: 0.00851243588956178
Epoch: 42 Idx: 0 Loss: 0.009385688264327507
Epoch: 42 Idx: 5000 Loss: 0.014189769319163952
Epoch: 43 Idx: 0 Loss: 0.010799408454112182
Epoch: 43 Idx: 5000 Loss: 0.010320130506762275
Epoch: 44 Idx: 0 Loss: 0.02810878055028501
Epoch: 44 Idx: 5000 Loss: 0.01197992236167283
Epoch: 45 Idx: 0 Loss: 0.02349343509173494
Epoch: 45 Idx: 5000 Loss: 0.016472358910347182
Epoch: 46 Idx: 0 Loss: 0.020603342336485874
Epoch: 46 Idx: 5000 Loss: 0.004630839815042295
Epoch: 47 Idx: 0 Loss: 0.01184469476851685
Epoch: 47 Idx: 5000 Loss: 0.011881855986583537
Epoch: 48 Idx: 0 Loss: 0.01740878661231892
Epoch: 48 Idx: 5000 Loss: 0.014006003393959436
Epoch: 49 Idx: 0 Loss: 0.012334054022518637
Epoch: 49 Idx: 5000 Loss: 0.010761960034398546
Len (direct inputs):  561
Inputs len 1568 15 4130
Len (direct inputs):  2577
Starting sliding window evaluation...
Step 6/7
Val onto:  [('edas', 'sigkdd')] test_onto:  [('conference', 'edas')]
Training size: 106045 Testing size: 7817
Epoch: 0 Idx: 0 Loss: 0.22064869817890698
Epoch: 0 Idx: 5000 Loss: 0.015543411230394133
Epoch: 1 Idx: 0 Loss: 0.01646943053628073
Epoch: 1 Idx: 5000 Loss: 0.011044185038301414
Epoch: 2 Idx: 0 Loss: 0.01175951887192061
Epoch: 2 Idx: 5000 Loss: 0.029492370809246642
Epoch: 3 Idx: 0 Loss: 0.015622772047260428
Epoch: 3 Idx: 5000 Loss: 0.013462639474923793
Epoch: 4 Idx: 0 Loss: 0.015243014801308002
Epoch: 4 Idx: 5000 Loss: 0.013249783573592605
Epoch: 5 Idx: 0 Loss: 0.008777669303086152
Epoch: 5 Idx: 5000 Loss: 0.014314164209078835
Epoch: 6 Idx: 0 Loss: 0.016181381624481704
Epoch: 6 Idx: 5000 Loss: 0.012718359939242493
Epoch: 7 Idx: 0 Loss: 0.017646511248470075
Epoch: 7 Idx: 5000 Loss: 0.014391819438812032
Epoch: 8 Idx: 0 Loss: 0.031044640276221367
Epoch: 8 Idx: 5000 Loss: 0.01456698954315757
Epoch: 9 Idx: 0 Loss: 0.012920208385940775
Epoch: 9 Idx: 5000 Loss: 0.020111708179173234
Epoch: 10 Idx: 0 Loss: 0.011466773952539262
Epoch: 10 Idx: 5000 Loss: 0.0077239787830235
Epoch: 11 Idx: 0 Loss: 0.0444265668262755
Epoch: 11 Idx: 5000 Loss: 0.014822979510615942
Epoch: 12 Idx: 0 Loss: 0.011217003792390032
Epoch: 12 Idx: 5000 Loss: 0.011676336678887275
Epoch: 13 Idx: 0 Loss: 0.008350183132071632
Epoch: 13 Idx: 5000 Loss: 0.02329390148857144
Epoch: 14 Idx: 0 Loss: 0.01812346829456182
Epoch: 14 Idx: 5000 Loss: 0.006583260568120553
Epoch: 15 Idx: 0 Loss: 0.016694456243560904
Epoch: 15 Idx: 5000 Loss: 0.015281146174704965
Epoch: 16 Idx: 0 Loss: 0.009416920362498325
Epoch: 16 Idx: 5000 Loss: 0.022554563096378124
Epoch: 17 Idx: 0 Loss: 0.009273035058252903
Epoch: 17 Idx: 5000 Loss: 0.01608763689713876
Epoch: 18 Idx: 0 Loss: 0.050144550189659264
Epoch: 18 Idx: 5000 Loss: 0.009472263427123154
Epoch: 19 Idx: 0 Loss: 0.02171043774806685
Epoch: 19 Idx: 5000 Loss: 0.007181835135506501
Epoch: 20 Idx: 0 Loss: 0.02254264452661738
Epoch: 20 Idx: 5000 Loss: 0.007517917946734695
Epoch: 21 Idx: 0 Loss: 0.01932302455097611
Epoch: 21 Idx: 5000 Loss: 0.013985222083924729
Epoch: 22 Idx: 0 Loss: 0.015257485778368086
Epoch: 22 Idx: 5000 Loss: 0.0265322449624156
Epoch: 23 Idx: 0 Loss: 0.017890718750973356
Epoch: 23 Idx: 5000 Loss: 0.029557090124385663
Epoch: 24 Idx: 0 Loss: 0.013923495612848774
Epoch: 24 Idx: 5000 Loss: 0.008706230382326501
Epoch: 25 Idx: 0 Loss: 0.010333660976936868
Epoch: 25 Idx: 5000 Loss: 0.013894098404648284
Epoch: 26 Idx: 0 Loss: 0.013500373199610899
Epoch: 26 Idx: 5000 Loss: 0.025554633615521755
Epoch: 27 Idx: 0 Loss: 0.009995517473419506
Epoch: 27 Idx: 5000 Loss: 0.011736531956085542
Epoch: 28 Idx: 0 Loss: 0.015794391292213838
Epoch: 28 Idx: 5000 Loss: 0.021503850148281777
Epoch: 29 Idx: 0 Loss: 0.034974657342596034
Epoch: 29 Idx: 5000 Loss: 0.021469949792742023
Epoch: 30 Idx: 0 Loss: 0.03933652458807136
Epoch: 30 Idx: 5000 Loss: 0.015637198741582325
Epoch: 31 Idx: 0 Loss: 0.006761842509549945
Epoch: 31 Idx: 5000 Loss: 0.011792372484191035
Epoch: 32 Idx: 0 Loss: 0.008451408650548217
Epoch: 32 Idx: 5000 Loss: 0.017852526515536073
Epoch: 33 Idx: 0 Loss: 0.011052475984279561
Epoch: 33 Idx: 5000 Loss: 0.008754086020536754
Epoch: 34 Idx: 0 Loss: 0.013548031701896189
Epoch: 34 Idx: 5000 Loss: 0.024143565066604433
Epoch: 35 Idx: 0 Loss: 0.01455288813914138
Epoch: 35 Idx: 5000 Loss: 0.012875837441395272
Epoch: 36 Idx: 0 Loss: 0.018376084556443295
Epoch: 36 Idx: 5000 Loss: 0.009393410463419825
Epoch: 37 Idx: 0 Loss: 0.012188829493479134
Epoch: 37 Idx: 5000 Loss: 0.02276278354251718
Epoch: 38 Idx: 0 Loss: 0.05795649360145329
Epoch: 38 Idx: 5000 Loss: 0.028777250166732316
Epoch: 39 Idx: 0 Loss: 0.01500188723729133
Epoch: 39 Idx: 5000 Loss: 0.031164323373108503
Epoch: 40 Idx: 0 Loss: 0.009980579838235984
Epoch: 40 Idx: 5000 Loss: 0.023778729769088913
Epoch: 41 Idx: 0 Loss: 0.023485728881626
Epoch: 41 Idx: 5000 Loss: 0.007892083272940095
Epoch: 42 Idx: 0 Loss: 0.030606026997158593
Epoch: 42 Idx: 5000 Loss: 0.0295669427369855
Epoch: 43 Idx: 0 Loss: 0.021011309125183425
Epoch: 43 Idx: 5000 Loss: 0.016356259957742196
Epoch: 44 Idx: 0 Loss: 0.009305708970610314
Epoch: 44 Idx: 5000 Loss: 0.01860406374362
Epoch: 45 Idx: 0 Loss: 0.013202760252254038
Epoch: 45 Idx: 5000 Loss: 0.015328028322472013
Epoch: 46 Idx: 0 Loss: 0.02259790904201402
Epoch: 46 Idx: 5000 Loss: 0.007680471114000744
Epoch: 47 Idx: 0 Loss: 0.02239724868889456
Epoch: 47 Idx: 5000 Loss: 0.006857047021258571
Epoch: 48 Idx: 0 Loss: 0.012003695059903573
Epoch: 48 Idx: 5000 Loss: 0.02922054020948315
Epoch: 49 Idx: 0 Loss: 0.01430791689820738
Epoch: 49 Idx: 5000 Loss: 0.01690903233281736
Len (direct inputs):  877
Inputs len 5600 17 7800
Len (direct inputs):  2217
Starting sliding window evaluation...
Step 8/7
Val onto:  [('cmt', 'iasted')] test_onto:  [('confof', 'sigkdd')]
Training size: 111351 Testing size: 2336
Epoch: 0 Idx: 0 Loss: 0.20116008957471404
Epoch: 0 Idx: 5000 Loss: 0.016930938726112874
Epoch: 1 Idx: 0 Loss: 0.020390305329360946
Epoch: 1 Idx: 5000 Loss: 0.010799829983048088
Epoch: 2 Idx: 0 Loss: 0.022036929697266512
Epoch: 2 Idx: 5000 Loss: 0.021752703832493392
Epoch: 3 Idx: 0 Loss: 0.026168669422168053
Epoch: 3 Idx: 5000 Loss: 0.008865997029358698
Epoch: 4 Idx: 0 Loss: 0.022593220526243116
Epoch: 4 Idx: 5000 Loss: 0.013564692201633834
Epoch: 5 Idx: 0 Loss: 0.013952251882642465
Epoch: 5 Idx: 5000 Loss: 0.015621686524148947
Epoch: 6 Idx: 0 Loss: 0.009168167757171405
Epoch: 6 Idx: 5000 Loss: 0.011898745420658819
Epoch: 7 Idx: 0 Loss: 0.016286910991864783
Epoch: 7 Idx: 5000 Loss: 0.010516712486678495
Epoch: 8 Idx: 0 Loss: 0.021348370971346876
Epoch: 8 Idx: 5000 Loss: 0.009905366342804828
Epoch: 9 Idx: 0 Loss: 0.0065132438254429095
Epoch: 9 Idx: 5000 Loss: 0.01300394389123466
Epoch: 10 Idx: 0 Loss: 0.01104459220294149
Epoch: 10 Idx: 5000 Loss: 0.01480804059687653
Epoch: 11 Idx: 0 Loss: 0.013131787481260544
Epoch: 11 Idx: 5000 Loss: 0.013226001401990393
Epoch: 12 Idx: 0 Loss: 0.008170705434353462
Epoch: 12 Idx: 5000 Loss: 0.019327411872517207
Epoch: 13 Idx: 0 Loss: 0.009856501624794525
Epoch: 13 Idx: 5000 Loss: 0.007842051174949164
Epoch: 14 Idx: 0 Loss: 0.008561366169594907
Epoch: 14 Idx: 5000 Loss: 0.012791431273078382
Epoch: 15 Idx: 0 Loss: 0.028178060937225146
Epoch: 15 Idx: 5000 Loss: 0.02164778632711196
Epoch: 16 Idx: 0 Loss: 0.014705503523345449
Epoch: 16 Idx: 5000 Loss: 0.010680244318046274
Epoch: 17 Idx: 0 Loss: 0.04371343179487727
Epoch: 17 Idx: 5000 Loss: 0.03683587416282409
Epoch: 18 Idx: 0 Loss: 0.018069451761595887
Epoch: 18 Idx: 5000 Loss: 0.02138079787830732
Epoch: 19 Idx: 0 Loss: 0.009273095072320162
Epoch: 19 Idx: 5000 Loss: 0.02277675188222414
Epoch: 20 Idx: 0 Loss: 0.034143809608626445
Epoch: 20 Idx: 5000 Loss: 0.018173515488442052
Epoch: 21 Idx: 0 Loss: 0.010264838243220921
Epoch: 21 Idx: 5000 Loss: 0.005903936842664871
Epoch: 22 Idx: 0 Loss: 0.007214948912377786
Epoch: 22 Idx: 5000 Loss: 0.020643497121352727
Epoch: 23 Idx: 0 Loss: 0.00995639669582142
Epoch: 23 Idx: 5000 Loss: 0.005204568014106939
Epoch: 24 Idx: 0 Loss: 0.017851969453115627
Epoch: 24 Idx: 5000 Loss: 0.015842629262602326
Epoch: 25 Idx: 0 Loss: 0.010177625300675897
Epoch: 25 Idx: 5000 Loss: 0.01767015491155935
Epoch: 26 Idx: 0 Loss: 0.009245395582128144
Epoch: 26 Idx: 5000 Loss: 0.016933109407703487
Epoch: 27 Idx: 0 Loss: 0.0076560856181675935
Epoch: 27 Idx: 5000 Loss: 0.015351526942894678
Epoch: 28 Idx: 0 Loss: 0.0066731403407485155
Epoch: 28 Idx: 5000 Loss: 0.01251775122120755
Epoch: 29 Idx: 0 Loss: 0.01496946674387498
Epoch: 29 Idx: 5000 Loss: 0.012131807971246814
Epoch: 30 Idx: 0 Loss: 0.014882498103360675
Epoch: 30 Idx: 5000 Loss: 0.008277740948180633
Epoch: 31 Idx: 0 Loss: 0.012266449211878555
Epoch: 31 Idx: 5000 Loss: 0.01364963656775653
Epoch: 32 Idx: 0 Loss: 0.024886689565506076
Epoch: 32 Idx: 5000 Loss: 0.037841892335396116
Epoch: 33 Idx: 0 Loss: 0.012823305207418645
Epoch: 33 Idx: 5000 Loss: 0.019070690829267063
Epoch: 34 Idx: 0 Loss: 0.02200248767937535
Epoch: 34 Idx: 5000 Loss: 0.029146113528257498
Epoch: 35 Idx: 0 Loss: 0.007328642685650257
Epoch: 35 Idx: 5000 Loss: 0.014979135164294367
Epoch: 36 Idx: 0 Loss: 0.012585321848235043
Epoch: 36 Idx: 5000 Loss: 0.017385096255175987
Epoch: 37 Idx: 0 Loss: 0.010464226460871971
Epoch: 37 Idx: 5000 Loss: 0.02150170109848592
Epoch: 38 Idx: 0 Loss: 0.018463771472638748
Epoch: 38 Idx: 5000 Loss: 0.00594726265363539
Epoch: 39 Idx: 0 Loss: 0.007806707189670991
Epoch: 39 Idx: 5000 Loss: 0.013530400931471329
Epoch: 40 Idx: 0 Loss: 0.03373494917303809
Epoch: 40 Idx: 5000 Loss: 0.031891812487340764
Epoch: 41 Idx: 0 Loss: 0.011684636517791877
Epoch: 41 Idx: 5000 Loss: 0.006730460980668249
Epoch: 42 Idx: 0 Loss: 0.01410965564673732
Epoch: 42 Idx: 5000 Loss: 0.006093917931932537
Epoch: 43 Idx: 0 Loss: 0.012208980850830333
Epoch: 43 Idx: 5000 Loss: 0.00790749493193418
Epoch: 44 Idx: 0 Loss: 0.007669648226343903
Epoch: 44 Idx: 5000 Loss: 0.016645258857771798
Epoch: 45 Idx: 0 Loss: 0.04107082578527814
Epoch: 45 Idx: 5000 Loss: 0.02521738349376009
Epoch: 46 Idx: 0 Loss: 0.007948011097592796
Epoch: 46 Idx: 5000 Loss: 0.0101713032424063
Epoch: 47 Idx: 0 Loss: 0.011035850773835659
Epoch: 47 Idx: 5000 Loss: 0.009832675782246086
Epoch: 48 Idx: 0 Loss: 0.016260898956244885
Epoch: 48 Idx: 5000 Loss: 0.020260807849092233
Epoch: 49 Idx: 0 Loss: 0.025674691204040593
Epoch: 49 Idx: 5000 Loss: 0.02654111829568541
Len (direct inputs):  2088
Inputs len 1862 7 2329
Len (direct inputs):  474
Starting sliding window evaluation...
Step 10/7
Val onto:  [('cmt', 'ekaw')] test_onto:  [('ekaw', 'iasted')]
Training size: 104431 Testing size: 11474
Epoch: 0 Idx: 0 Loss: 0.1888264329100052
Epoch: 0 Idx: 5000 Loss: 0.02757196296852632
Epoch: 1 Idx: 0 Loss: 0.010311525568982858
Epoch: 1 Idx: 5000 Loss: 0.0353817150556904
Epoch: 2 Idx: 0 Loss: 0.011168983268333054
Epoch: 2 Idx: 5000 Loss: 0.013729611710115235
Epoch: 3 Idx: 0 Loss: 0.017963852470612912
Epoch: 3 Idx: 5000 Loss: 0.012005498140290453
Epoch: 4 Idx: 0 Loss: 0.01621151073025508
Epoch: 4 Idx: 5000 Loss: 0.01065942978485433
Epoch: 5 Idx: 0 Loss: 0.024038210480011417
Epoch: 5 Idx: 5000 Loss: 0.024505559256980503
Epoch: 6 Idx: 0 Loss: 0.03396875356597873
Epoch: 6 Idx: 5000 Loss: 0.02537095863582515
Epoch: 7 Idx: 0 Loss: 0.025399552928036157
Epoch: 7 Idx: 5000 Loss: 0.014490769098985543
Epoch: 8 Idx: 0 Loss: 0.007140414398165812
Epoch: 8 Idx: 5000 Loss: 0.02222088260195968
Epoch: 9 Idx: 0 Loss: 0.005579259381589643
Epoch: 9 Idx: 5000 Loss: 0.043264774243254006
Epoch: 10 Idx: 0 Loss: 0.012895461906967928
Epoch: 10 Idx: 5000 Loss: 0.012747332415022357
Epoch: 11 Idx: 0 Loss: 0.0169424833282851
Epoch: 11 Idx: 5000 Loss: 0.014467660185919468
Epoch: 12 Idx: 0 Loss: 0.018140441333487148
Epoch: 12 Idx: 5000 Loss: 0.008893390056841552
Epoch: 13 Idx: 0 Loss: 0.03938564858638488
Epoch: 13 Idx: 5000 Loss: 0.006443703945509326
Epoch: 14 Idx: 0 Loss: 0.014264983971624592
Epoch: 14 Idx: 5000 Loss: 0.01776486370721423
Epoch: 15 Idx: 0 Loss: 0.019027673324774057
Epoch: 15 Idx: 5000 Loss: 0.023208002266971412
Epoch: 16 Idx: 0 Loss: 0.01417925796510592
Epoch: 16 Idx: 5000 Loss: 0.02559675486979031
Epoch: 17 Idx: 0 Loss: 0.0380404752998622
Epoch: 17 Idx: 5000 Loss: 0.028595454890464243
Epoch: 18 Idx: 0 Loss: 0.005330954542370023
Epoch: 18 Idx: 5000 Loss: 0.021414814636619033
Epoch: 19 Idx: 0 Loss: 0.011997353452578997
Epoch: 19 Idx: 5000 Loss: 0.023825407208981072
Epoch: 20 Idx: 0 Loss: 0.010083639138921754
Epoch: 20 Idx: 5000 Loss: 0.01415153533486383
Epoch: 21 Idx: 0 Loss: 0.012737473720686593
Epoch: 21 Idx: 5000 Loss: 0.013415114894471666
Epoch: 22 Idx: 0 Loss: 0.009781837220779459
Epoch: 22 Idx: 5000 Loss: 0.02017230442989783
Epoch: 23 Idx: 0 Loss: 0.02369116802250007
Epoch: 23 Idx: 5000 Loss: 0.013756595859072256
Epoch: 24 Idx: 0 Loss: 0.010903740723533346
Epoch: 24 Idx: 5000 Loss: 0.013150509838148628
Epoch: 25 Idx: 0 Loss: 0.010587346611081098
Epoch: 25 Idx: 5000 Loss: 0.012280259111144023
Epoch: 26 Idx: 0 Loss: 0.006482619368800095
Epoch: 26 Idx: 5000 Loss: 0.016494745237622198
Epoch: 27 Idx: 0 Loss: 0.012091403413337788
Epoch: 27 Idx: 5000 Loss: 0.016593332429996582
Epoch: 28 Idx: 0 Loss: 0.021534345623426834
Epoch: 28 Idx: 5000 Loss: 0.019079485559021468
Epoch: 29 Idx: 0 Loss: 0.007139605960116596
Epoch: 29 Idx: 5000 Loss: 0.03731781578623321
Epoch: 30 Idx: 0 Loss: 0.015049675688950638
Epoch: 30 Idx: 5000 Loss: 0.012625866429889426
Epoch: 31 Idx: 0 Loss: 0.009852986168933122
Epoch: 31 Idx: 5000 Loss: 0.017252199228278205
Epoch: 32 Idx: 0 Loss: 0.009390837362143377
Epoch: 32 Idx: 5000 Loss: 0.009474364973698881
Epoch: 33 Idx: 0 Loss: 0.0067564909157070505
Epoch: 33 Idx: 5000 Loss: 0.021675472580118916
Epoch: 34 Idx: 0 Loss: 0.01814669730162445
Epoch: 34 Idx: 5000 Loss: 0.010769229010024362
Epoch: 35 Idx: 0 Loss: 0.006657833744875572
Epoch: 35 Idx: 5000 Loss: 0.014891170527357368
Epoch: 36 Idx: 0 Loss: 0.036095034775848606
Epoch: 36 Idx: 5000 Loss: 0.041481296153550805
Epoch: 37 Idx: 0 Loss: 0.012737449542229554
Epoch: 37 Idx: 5000 Loss: 0.01588978090238566
Epoch: 38 Idx: 0 Loss: 0.011883681569855838
Epoch: 38 Idx: 5000 Loss: 0.020853256328058525
Epoch: 39 Idx: 0 Loss: 0.006014583075079757
Epoch: 39 Idx: 5000 Loss: 0.012092809591359752
Epoch: 40 Idx: 0 Loss: 0.01634141033910146
Epoch: 40 Idx: 5000 Loss: 0.016758899596810407
Epoch: 41 Idx: 0 Loss: 0.017494249086509414
Epoch: 41 Idx: 5000 Loss: 0.00947841168703809
Epoch: 42 Idx: 0 Loss: 0.005924616595523387
Epoch: 42 Idx: 5000 Loss: 0.016761505321966994
Epoch: 43 Idx: 0 Loss: 0.007498680568924199
Epoch: 43 Idx: 5000 Loss: 0.010496069546026936
Epoch: 44 Idx: 0 Loss: 0.02628177683664558
Epoch: 44 Idx: 5000 Loss: 0.03634449006046626
Epoch: 45 Idx: 0 Loss: 0.021755698426469072
Epoch: 45 Idx: 5000 Loss: 0.009180894710647026
Epoch: 46 Idx: 0 Loss: 0.012636123602825785
Epoch: 46 Idx: 5000 Loss: 0.01701216529705766
Epoch: 47 Idx: 0 Loss: 0.016140905525412017
Epoch: 47 Idx: 5000 Loss: 0.006448918396377584
Epoch: 48 Idx: 0 Loss: 0.010159943395686565
Epoch: 48 Idx: 5000 Loss: 0.0124677597109938
Epoch: 49 Idx: 0 Loss: 0.013588615427222756
Epoch: 49 Idx: 5000 Loss: 0.009828181947560095
Len (direct inputs):  1690
Inputs len 10074 10 11464
Len (direct inputs):  1400
Starting sliding window evaluation...
Step 12/7
Val onto:  [('conference', 'iasted')] test_onto:  [('confof', 'edas')]
Training size: 104813 Testing size: 4764
Epoch: 0 Idx: 0 Loss: 0.1778078162908876
Epoch: 0 Idx: 5000 Loss: 0.04648512346461281
Epoch: 1 Idx: 0 Loss: 0.011403470331633218
Epoch: 1 Idx: 5000 Loss: 0.011306323826756377
Epoch: 2 Idx: 0 Loss: 0.033291500169615316
Epoch: 2 Idx: 5000 Loss: 0.0191786034705893
Epoch: 3 Idx: 0 Loss: 0.017617866658725022
Epoch: 3 Idx: 5000 Loss: 0.03978857679950611
Epoch: 4 Idx: 0 Loss: 0.00858185853069716
Epoch: 4 Idx: 5000 Loss: 0.010314673818625183
Epoch: 5 Idx: 0 Loss: 0.016135459768952098
Epoch: 5 Idx: 5000 Loss: 0.00719557427419013
Epoch: 6 Idx: 0 Loss: 0.016549182315900496
Epoch: 6 Idx: 5000 Loss: 0.013574090258512523
Epoch: 7 Idx: 0 Loss: 0.03834772419458197
Epoch: 7 Idx: 5000 Loss: 0.012644938045138157
Epoch: 8 Idx: 0 Loss: 0.01318464679999783
Epoch: 8 Idx: 5000 Loss: 0.007492620101854221
Epoch: 9 Idx: 0 Loss: 0.018883988124183713
Epoch: 9 Idx: 5000 Loss: 0.020405464937165413
Epoch: 10 Idx: 0 Loss: 0.030106592899847108
Epoch: 10 Idx: 5000 Loss: 0.011862890680183542
Epoch: 11 Idx: 0 Loss: 0.010565077201747328
Epoch: 11 Idx: 5000 Loss: 0.026154688861287828
Epoch: 12 Idx: 0 Loss: 0.012841543338454865
Epoch: 12 Idx: 5000 Loss: 0.016957985363917655
Epoch: 13 Idx: 0 Loss: 0.016518695546387005
Epoch: 13 Idx: 5000 Loss: 0.02484969149303899
Epoch: 14 Idx: 0 Loss: 0.0065370261786542195
Epoch: 14 Idx: 5000 Loss: 0.010129475809389847
Epoch: 15 Idx: 0 Loss: 0.008894555635179399
Epoch: 15 Idx: 5000 Loss: 0.00872850583600358
Epoch: 16 Idx: 0 Loss: 0.02006034779167777
Epoch: 16 Idx: 5000 Loss: 0.008713572643502782
Epoch: 17 Idx: 0 Loss: 0.009976338485885045
Epoch: 17 Idx: 5000 Loss: 0.011221405632246054
Epoch: 18 Idx: 0 Loss: 0.014181382710808564
Epoch: 18 Idx: 5000 Loss: 0.014419409358627372
Epoch: 19 Idx: 0 Loss: 0.033468651497929214
Epoch: 19 Idx: 5000 Loss: 0.01633835319392017
Epoch: 20 Idx: 0 Loss: 0.03438642874126335
Epoch: 20 Idx: 5000 Loss: 0.010329660908743155
Epoch: 21 Idx: 0 Loss: 0.024964048754885095
Epoch: 21 Idx: 5000 Loss: 0.011953768387062656
Epoch: 22 Idx: 0 Loss: 0.019983947495560747
Epoch: 22 Idx: 5000 Loss: 0.01277748575343047
Epoch: 23 Idx: 0 Loss: 0.00926327361180835
Epoch: 23 Idx: 5000 Loss: 0.012433945601561079
Epoch: 24 Idx: 0 Loss: 0.029563081318331574
Epoch: 24 Idx: 5000 Loss: 0.022971000336293925
Epoch: 25 Idx: 0 Loss: 0.013881153735304899
Epoch: 25 Idx: 5000 Loss: 0.016948124311308134
Epoch: 26 Idx: 0 Loss: 0.011858992953831507
Epoch: 26 Idx: 5000 Loss: 0.014564909662786372
Epoch: 27 Idx: 0 Loss: 0.0067255248348991725
Epoch: 27 Idx: 5000 Loss: 0.008528540874973255
Epoch: 28 Idx: 0 Loss: 0.016163378789700582
Traceback (most recent call last):
  File "main.py", line 514, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "main.py", line 338, in forward
    distance_weighted_path = torch.sum((self.v[None,None,:,None] * attended_path), dim=2) # batch_size * 4 * 512
  File "/u/harshitk/miniconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py", line 758, in __getattr__
    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc224>
Subject: Job 4066847: <python main.py 5 3 False False> in cluster <dcc> Exited

Job <python main.py 5 3 False False> was submitted from host <dccxl004> by user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:38 2020
Job was executed on host(s) <dccxc224>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep 15 15:48:39 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/VeeAlign/src> was used as the working directory.
Started at Tue Sep 15 15:48:39 2020
Terminated at Wed Sep 16 04:38:39 2020
Results reported at Wed Sep 16 04:38:39 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py 5 3 False False
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   46133.30 sec.
    Max Memory :                                 2883 MB
    Average Memory :                             2735.05 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40534.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                13
    Run time :                                   46200 sec.
    Turnaround time :                            46201 sec.

The output (if any) is above this job summary.

