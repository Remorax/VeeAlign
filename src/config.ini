[General]
# Language of dataset
language = en
# Value of K in K-fold sliding window in `evaluation.py`
# Determines splitting of data into training (1-1/K) and validation (1/K) in `train.py`
K = 7
# Determines if training data should be split on ontology level (True) or on element level (False)
# Set to True if you wish to train and test on ontology pairs, or False otherwise (recommended),  as in most cases.
ontology_split = True
# Max number of false (dissimilar) examples to take while training
max_false_examples = 150000

[Paths]
# This folder should contain owl files of all ontologies in the training set
train_folder = datasets/conference/ontologies/
# This folder should contain rdf alignment files of all ontologies in `ontologies_folder`
# The alignments should be named `a-b.rdf` if it contains the alignments between `a.owl` and `b.owl`
alignment_folder = datasets/conference/alignments/
# Paths where trained model should be saved/pre-trained model should be loaded
save_model_path = models/model.pt
load_model_path = models/conference_pretrained.pt
# Path where final alignments should be saved
output_folder = output/

[Preprocessing]
# Whether or not to use spellcheck for preprocessing. 
# Generally recommended, but set it to False if training data is domain specific (eg. biomedical)
# or in a non-English language 
has_spellcheck = False

[Parameters]
# Max neighbours to consider near a node
max_paths = 3
# Min neighbours a node should have to be considered
max_pathlen = 5
# Determines if one-hop neighbours should be taken as a path of length 1 or as a bag of neighbours
bag_of_neighbours = False
# Determines if weighted average should be used to obtain unified path representation, or max pooling should be used
weighted_average = False

[Hyperparameters]
# Learning rate
lr = 0.001
# Number of training epochs
num_epochs = 50
weight_decay = 0.001
batch_size = 32
